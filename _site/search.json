[
  {
    "objectID": "Hands-on_Ex07/hand-on_ex07.html",
    "href": "Hands-on_Ex07/hand-on_ex07.html",
    "title": "Hands-on Ex07",
    "section": "",
    "text": "Geographically Weighted Regression (GWR) allows relationships between predictors (independent variables) and an outcome (dependent variable) to vary by location. In hedonic pricing, we model the resale prices of condominium units using structural factors (e.g., floor area, age) and locational accessibility (e.g., proximity to transport, parks, schools).\n\n\n\n\nGeospatial: MP14_SUBZONE_WEB_PL (subzone polygons; SVY21 projection).\nAspatial: Condo_resale_2015.csv with columns such as SELLING_PRICE, AREA_SQM, AGE, and multiple proximity variables (in kilometers) to amenities (MRT, parks, schools, etc.).\n\n\n\n\nBefore we get started, it is important for us to install the necessary R packages into R and launch these R packages into R environment.\n\n# Install and load all required packages in one call --------------------------------\n# pacman::p_load() will install any missing packages and then load them into memory\npacman::p_load(olsrr, corrplot, ggpubr,\n               sf, sfdep, GWmodel, tmap,\n               tidyverse, gtsummary,\n               performance, RColorBrewer, see)\n\nThe R packages needed for this exercise are as follows:\n\nsf: spatial vector data handling; projections.\nsfdep: spatial weights and Moran’s I with tidy‑sf interface.\nGWmodel: GWR bandwidth search and model fitting.\ntmap: static/interactive maps.\ntidyverse: wrangling (dplyr, readr, ggplot2).\nolsrr, performance: OLS diagnostics, VIF, assumption checks.\ncorrplot: correlation matrix visual.\ngtsummary: publication‑quality regression tables.\nRColorBrewer: color palettes for maps.\n\n\n\n\nGWmodel package provides a collection of localised spatial statistical methods, namely: GW summary statistics, GW principal components analysis, GW discriminant analysis and various forms of GW regression; some of which are provided in basic and robust (outlier resistant) forms. Commonly, outputs or parameters of the GWmodel are mapped to provide a useful exploratory tool, which can often precede (and direct) a more traditional or sophisticated statistical analysis.\n\n\n\n\n\n\n# Read the URA Master Plan 2014 subzone shapefile -------------------------------\n# dsn: directory; layer: shapefile base name without extension\nmpsz = st_read(dsn = \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex07/data/geospatial\",\n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex07/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\n\n# Transform the coordinate reference system to SVY21 / EPSG:3414 ----------------\n# This ensures all distance‑based operations use meters (required by GWR bandwidth)\nmpsz_svy21 &lt;- st_transform(mpsz, 3414)\n\n\n# Verify the target CRS ---------------------------------------------------------\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNext, inspect layer extent (bounding box)\n\nst_bbox(mpsz_svy21)\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334 \n\n\nThe print above reports the extent of mpsz_svy21 layer by its lower and upper limits.\n\n\n\n\n\n\n\n# Read the 2015 condo resale dataset as a tibble --------------------------------\ncondo_resale = read_csv(\n  \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex07/data/aspatial/Condo_resale_2015.csv\")\n\nRows: 1436 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (23): LATITUDE, LONGITUDE, POSTCODE, SELLING_PRICE, AREA_SQM, AGE, PROX_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n# Peek at structure: variable names, types, first few rows ----------------------\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             &lt;dbl&gt; 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            &lt;dbl&gt; 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\nhead(condo_resale$LONGITUDE)\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\n\n\nhead(condo_resale$LATITUDE)\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\nThe print above reveals that the values of LONGITITUDE and LATITUDE fields are in decimal degree. Most probably wgs84 geographic coordinate system is used.\n\n# Quick descriptive statistics for all columns ----------------------------------\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\n\n\n\n# Convert LONGITUDE/LATITUDE (WGS84) to POINT geometry and reproject to SVY21 ---\n# 1) st_as_sf(): declare coordinates (lon, lat) with crs=4326 (WGS84 degrees)\n# 2) st_transform(): project to EPSG:3414 so distances are in meters\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that st_transform() of sf package is used to convert the coordinates from wgs84 (i.e. crs:4326) to svy21 (i.e. crs=3414).\n\n\n\n# Confirm the first few records including geometry --------------------------------\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n     &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1   118635       3000000      309    30     7.94          0.166            2.52 \n2   288420       3880000      290    32     6.61          0.280            1.93 \n3   267833       3325000      248    33     6.90          0.429            0.502\n4   258380       4250000      127     7     4.04          0.395            1.99 \n5   467169       1400000      145    28    11.8           0.119            1.12 \n6   466472       1320000      139    22    10.3           0.125            0.789\n# ℹ 15 more variables: PROX_URA_GROWTH_AREA &lt;dbl&gt;, PROX_HAWKER_MARKET &lt;dbl&gt;,\n#   PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;, PROX_PARK &lt;dbl&gt;,\n#   PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\n\nNotice that the output is in point feature data frame.\n\n\n\n\n\n\nWe can plot the distribution of SELLING_PRICE by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\n\n# Plot raw SELLING_PRICE distribution -----------------\n# aes(x=SELLING_PRICE) maps the price variable to the x‑axis for a histogram\nggplot(data = condo_resale.sf,\n       aes(x = `SELLING_PRICE`)) +\n  geom_histogram(bins = 20,           # 20 equal‑width bins\n                 color = \"black\",     # black outline for readability\n                 fill = \"light blue\") # soft fill color for clarity\n\n\n\n\n\n\n\n\nThe figure above reveals a right skewed distribution. This means that more condominium units were transacted at relative lower prices.\nStatistically, the skewed dsitribution can be normalised by using log transformation. The code chunk below is used to derive a new variable called LOG_SELLING_PRICE by using a log transformation on the variable SELLING_PRICE. It is performed using mutate() of dplyr package.\n\n# Create a log‑price to reduce skewness -----------------------------------------\n# mutate() adds a new variable LOG_SELLING_PRICE = log(SELLING_PRICE)\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nNow, you can plot the LOG_SELLING_PRICE using the code chunk below.\n\n# Plot the log‑transformed price distribution -----------------------------------\nggplot(data = condo_resale.sf,\n       aes(x = `LOG_SELLING_PRICE`)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\")\n\n\n\n\n\n\n\n\nNotice that the distribution is relatively less skewed after the transformation.\n\n\n\nn this section, you will learn how to draw a small multiple histograms (also known as trellis plot) by using ggarrange() of ggpubr package.\nThe code chunk below is used to create 12 histograms. Then, ggarrange() is used to organised these histogram into a 3 columns by 4 rows small multiple plot.\n\n# Build individual histograms for key predictors ---------------------------------\nAREA_SQM &lt;- ggplot(data = condo_resale.sf, aes(x = `AREA_SQM`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nAGE &lt;- ggplot(data = condo_resale.sf, aes(x = `AGE`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_CBD &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_CBD`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_CHILDCARE &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_CHILDCARE`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_ELDERLYCARE &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_URA_GROWTH_AREA &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_HAWKER_MARKET &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_KINDERGARTEN &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_MRT &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_MRT`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_PARK &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_PARK`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_PRIMARY_SCH &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_TOP_PRIMARY_SCH &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\n# Arrange the 12 histograms into a 3x4 panel ------------------------------------\n# ggarrange() helps create small‑multiples (trellis) display\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE,\n          PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA,\n          PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)\n\n\n\n\n\n\n\n\n\n\n\n\n# Switch tmap to interactive (leaflet) mode -------------------------------------\ntmap_mode(\"view\")\n\nℹ tmap mode set to \"view\".\n\n# Draw subzones base layer + condo points colored by SELLING_PRICE --------------\ntm_shape(mpsz_svy21) +\n  tm_polygons() +\n tm_shape(condo_resale.sf) +  \n  tm_dots(fill = \"SELLING_PRICE\",      # color points by price\n          fill_alpha = 0.6,            # semi‑transparent fills\n          size = 0.5,                  # dot size\n          fill.scale = tm_scale_intervals(\n            style = \"quantile\")) +     # quantile breaks (robust to skew)\n  tm_view(set_zoom_limits = c(11,14))  # limit zoom range for usability\n\nRegistered S3 method overwritten by 'jsonify':\n  method     from    \n  print.json jsonlite\n\n\n\n\n\n\n\nset_zoom_limits argument of tm_view() sets the minimum and maximum zoom level to 11 and 14 respectively.\nBefore moving on to the next section, the code below will be used to turn R display into plot mode.\n\n# Switch back to static plotting mode before continuing -------------------------\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\n\n\n\n\n\nIn this section, we will learn how to building hedonic pricing models for condominium resale units using lm() of R base.\n\n\n\n# Fit a simple linear regression with floor area as the only predictor ------------\ncondo.slr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM,\n                data = condo_resale.sf)\n\n\n# Print model summary: coefficients, R², p‑values, residual spread ----------------\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: &lt; 2.2e-16\n\n\nThe output report reveals that the SELLING_PRICE can be explained by using the formula:\n\\[\\text{Selling_Price} = -258121.1 + 14719\\cdot\\text{Area_SQM}\\]\nThe R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince p-value is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of SELLING_PRICE.\nThe Coefficients: section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.\nTo visualise the best fit curve on a scatterplot, we can incorporate lm() as a method function in ggplot’s geometry as shown in the code chunk below.\n\n# Visualize scatter with best‑fit line from lm() ---------------------------------\n# geom_smooth(method = lm) overlays the OLS regression line with CI ribbon\nggplot(data = condo_resale.sf,  \n       aes(x = `AREA_SQM`, y = `SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nFigure above reveals that there are a few statistical outliers with relatively high selling prices.\n\n\n\n\n\nBefore building a multiple regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other. If these highly correlated independent variables are used in building a regression model by mistake, the quality of the model will be compromised. This phenomenon is known as multicollinearity in statistics.\nCorrelation matrix is commonly used to visualise the relationships between the independent variables. Beside the pairs() of R, there are many packages support the display of a correlation matrix. In this section, the corrplot package will be used.\nThe code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in condo_resale data.frame.\n\n# Visualize pairwise correlations among predictors (cols 5:23 from the CSV) ------\ncorrplot(cor(condo_resale[, 5:23]),\n         diag = FALSE,\n         order = \"AOE\",      # Angular Order of Eigenvectors (stable ordering)\n         tl.pos = \"td\",      # text labels on top diagonal\n         tl.cex = 0.5,        # smaller text\n         method = \"number\",  # print numeric correlations\n         type = \"upper\")     # upper triangle only\n\n\n\n\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, LEASE_99YEAR is excluded in the subsequent model building.\n\n\n\n\nThe code chunk below using lm() to calibrate the multiple linear regression model.\n\n# Build the full hedonic model (drop LEASEHOLD_99YR to avoid high correlation) ---\ncondo.mlr &lt;- lm(\n  formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n    PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n    PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET   +\n    PROX_KINDERGARTEN   + PROX_MRT  + PROX_PARK +\n    PROX_PRIMARY_SCH + PROX_TOP_PRIMARY_SCH +\n    PROX_SHOPPING_MALL  + PROX_SUPERMARKET + \n    PROX_BUS_STOP   + NO_Of_UNITS + \n    FAMILY_FRIENDLY + FREEHOLD, \n  data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  &lt; 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  &lt; 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  &lt; 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk above consists of two parts:\n- lm() of Base R is used to calibrate a multiple linear regression model. The model output is stored in an lm object called condo.mlr.\n- summary() is used to print the model output.\n\n\n\n\n\nWith reference to the report above, it is clear that not all the independent variables are statistically significant. We will revised the model by removing those variables which are not statistically significant.\nNow, we are ready to calibrate the revised model by using the code chunk below.\n\n# Remove variables with weak significance to improve parsimony -------------------\ncondo.mlr1 &lt;- lm(\n  formula = SELLING_PRICE ~ AREA_SQM + AGE + \n    PROX_CBD + PROX_CHILDCARE + PROX_MRT +\n    PROX_ELDERLYCARE    + PROX_URA_GROWTH_AREA +\n    PROX_PARK   + PROX_PRIMARY_SCH + \n    PROX_SHOPPING_MALL  + PROX_BUS_STOP + \n    NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n  data = condo_resale.sf)\n\n\n# Verify all retained predictors are significant at 5% (or better) ---------------\nsummary(condo.mlr1)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_MRT + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_PARK + \n    PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n    FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\nAREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\nAGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\nPROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\nPROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \nPROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\nPROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\nPROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\nPROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \nPROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\nPROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\nNO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \nFAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \nFREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 756000 on 1421 degrees of freedom\nMultiple R-squared:  0.6507,    Adjusted R-squared:  0.6472 \nF-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16\n\n\nThe output above reveals that all explanatory variables are statistically significant at 95% confident level.\n\n\n\nThe gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R.\nIn the code chunk below, tbl_regression() is used to create a well formatted regression report.\n\n# Create a clean table of coefficients, CIs, and p‑values\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI\np-value\n\n\n\n\n(Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n\n\nAREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n\n\nAGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n\n\nPROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n\n\nPROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n\n\nPROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n\n\nPROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n\n\nPROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n\n\nPROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n\n\nPROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n\n\nPROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n\n\nPROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n\n\nNO_Of_UNITS\n-245\n-418, -73\n0.005\n\n\nFAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n\n\nFREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n\n\n\nAbbreviation: CI = Confidence Interval\n\n\n\n\n\n\n\n\nWith gtsummary package, model statistics can be included in the report by either appending them to the report table by using add_glance_table() or adding as a table source note by using add_glance_source_note() as shown in the code chunk below.\n\n# Append model‑level statistics as a footnote (AIC, R², sigma, etc.) -------------\ntbl_regression(condo.mlr1,\nintercept = TRUE) %&gt;%\nadd_glance_source_note(\nlabel = list(sigma ~ \"σ\"), # Greek sigma symbol\ninclude = c(r.squared, adj.r.squared,\nAIC, statistic,\np.value, sigma))\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI\np-value\n\n\n\n\n(Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n\n\nAREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n\n\nAGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n\n\nPROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n\n\nPROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n\n\nPROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n\n\nPROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n\n\nPROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n\n\nPROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n\n\nPROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n\n\nPROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n\n\nPROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n\n\nNO_Of_UNITS\n-245\n-418, -73\n0.005\n\n\nFAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n\n\nFREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n\n\n\nAbbreviation: CI = Confidence Interval\n\n\nR² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = &lt;0.001; σ = 755,957\n\n\n\n\n\n\n\n\nFor more customization options, refer to Tutorial: tbl_regression.\n\n\n\nRegression diagnostics are a set of procedures used to check if a regression model’s assumptions are met and how well the model fits the data. These diagnostics involve checking for issues like non-linear relationships, non-normal errors, non-constant variance, and influential observations to ensure the model’s conclusions are valid and reliable. Common methods include graphical analysis, like residual plots and QQ-plots, and quantitative tests\nIn this section, we would like to introduce you a fantastic R package specially programmed for performing OLS regression diagnostics. It is called olsrr. It provides a collection of very useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\n\nresidual diagnostics\n\nmeasures of influence\n\nheteroskedasticity tests\n\ncollinearity diagnostics\n\nmodel fit assessment\n\nvariable contribution assessment\n\nvariable selection procedures\n\n\n\nMulticollinearity occurs when independent variables are not truly independent, meaning a change in one is associated with a change in another. This makes it hard for the model to isolate each variable’s influence on the outcome.\nPerforming a multicollinearity test is crucial in multiple linear regression because it ensures the reliability and interpretability of the model’s results. High multicollinearity, where independent variables are highly correlated, inflates the variance of the estimated coefficients, making them unstable, unreliable, and difficult to interpret. This instability can lead to misleading statistical conclusions, such as a variable appearing statistically insignificant when it is not.\nIn the code chunk below, the check_collinearity() of performance package is used to test if there are sign of multicollinearity.\n\n# Check Variance Inflation Factors (VIF) to confirm low multicollinearity --------\nmlr.vif &lt;- check_collinearity(condo.mlr1) # compute VIFs\nmlr.vif # print the table\n\n# Check for Multicollinearity\n\nLow Correlation\n\n                 Term  VIF   VIF 95% CI adj. VIF Tolerance Tolerance 95% CI\n             AREA_SQM 1.15 [1.09, 1.23]     1.07      0.87     [0.81, 0.92]\n                  AGE 1.41 [1.33, 1.52]     1.19      0.71     [0.66, 0.75]\n             PROX_CBD 1.57 [1.47, 1.69]     1.25      0.64     [0.59, 0.68]\n       PROX_CHILDCARE 3.26 [3.00, 3.56]     1.81      0.31     [0.28, 0.33]\n             PROX_MRT 1.91 [1.78, 2.07]     1.38      0.52     [0.48, 0.56]\n     PROX_ELDERLYCARE 1.52 [1.42, 1.63]     1.23      0.66     [0.61, 0.70]\n PROX_URA_GROWTH_AREA 1.33 [1.26, 1.43]     1.15      0.75     [0.70, 0.80]\n            PROX_PARK 1.21 [1.15, 1.29]     1.10      0.83     [0.77, 0.87]\n     PROX_PRIMARY_SCH 2.21 [2.05, 2.40]     1.49      0.45     [0.42, 0.49]\n   PROX_SHOPPING_MALL 1.48 [1.39, 1.60]     1.22      0.67     [0.63, 0.72]\n        PROX_BUS_STOP 2.85 [2.62, 3.10]     1.69      0.35     [0.32, 0.38]\n          NO_Of_UNITS 1.45 [1.36, 1.56]     1.20      0.69     [0.64, 0.73]\n      FAMILY_FRIENDLY 1.38 [1.30, 1.48]     1.17      0.72     [0.67, 0.77]\n             FREEHOLD 1.44 [1.36, 1.55]     1.20      0.69     [0.65, 0.74]\n\nplot(mlr.vif) # quick visual of VIF levels\n\n\n\n\n\n\n\n\nSince the VIF of the independent variables are less than 10. We can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n\n\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\n#check_model(condo.mlr1, check = \"linearity\")\n\n# Visual check that residuals vs fitted show no strong non‑linearity -------------\nggplot(data = data.frame(Fitted = fitted(condo.mlr1), Residuals = resid(condo.mlr1)),\naes(x = Fitted, y = Residuals)) +\ngeom_point(color = 'blue', alpha = 0.6) +\ngeom_smooth(method = 'loess', se = TRUE, color = 'green', fill = 'grey70') +\ngeom_hline(yintercept = 0, color = 'black', linetype = 'dashed') +\nlabs(title = 'Linearity', subtitle = 'Reference line should be flat and horizontal',\nx = 'Fitted values', y = 'Residuals') +\ntheme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe figure above reveals that most of the data poitns are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n\nThe normality assumption test for multiple linear regression checks if the model’s residuals (the differences between observed and predicted values) are normally distributed. This is crucial for accurate hypothesis testing and confidence intervals. To test this, you can use visual methods like histograms and Q-Q plots of the residuals, or conduct statistical tests like Shapiro-Wilk test and Kolmogorov-Smirnov test.\nIn the code chunk below, check_normality() of performance package is used to perform normality assumption test on condo.mlr1 model.\n\n# Formal test (often significant with large n); complement with Q‑Q plot ---------\ncheck_normality(condo.mlr1)\n\nWarning: Non-normality of residuals detected (p &lt; .001).\n\n\nThe print above reveals that the p-value of the normality assumption test is less than alpha value of 0.05. Hence we reject the normality assumption at 95% confident level.\n\n\n\n\n\n\nNote\n\n\n\n\ncheck_normality() calls stats::shapiro.test and checks the standardized residuals (or studentized residuals for mixed models) for normal distribution.\n\nNote that this formal test almost always yields significant results for the distribution of residuals and visual inspection (e.g. Q-Q plots) are preferable.\n\n\n\nInstead of showing the test statistic, plot() of see package can be used to plot a the output of check_normality() for visual inspection as shown below.\n\n# Q‑Q plot of standardized residuals from the check_normality() output -----------\nplot(check_normality(condo.mlr1), type = \"qq\")\n\nFor confidence bands, please install `qqplotr`.\n\n\n\n\n\n\n\n\n\nQ-Q plot above below shows that majority of the data points are felt along the zero line.\nAnother way to check for normality assumption visual is by using check_model() of performance package as shown in the code chunk below.\n\n# Alternative normality panel via performance::check_model -----------------------\ncheck_model(condo.mlr1, check = \"normality\")\n\n\n\n\n\n\n\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\n\n\n\nThe hedonic model we try to build are using geographically referenced data. Hence, it is crucial to check for spatial autocorrelation because its presence can produce unreliable and misleading results. Traditional regression models, such as ordinary least squares (OLS), assume that observations are independent of one another. However, spatial data often violates this assumption.\nSpatial autocorrelation is the correlation of a variable with itself across different spatial locations. Positive spatial autocorrelation means nearby features tend to be more similar, while negative autocorrelation means they tend to be more dissimilar. This phenomenon is based on the first law of geography: “Everything is related to everything else, but nearby things are more related than distant things”.\nIgnoring spatial autocorrelation in a regression model can lead to serious statistical issues:\n\nBiased and inefficient coefficient estimates: If autocorrelation is present, standard errors of the model coefficients can be wrong, leading to unreliable hypothesis tests (p-values). The model might appear more significant than it is.\nMisleading significance tests: Standard regression models cannot distinguish between true explanatory power and the influence of spatial patterns, resulting in inaccurate p-values.\nModel misspecification: Significant spatial autocorrelation in the regression residuals often signals that important explanatory variables are missing from the model. The spatial patterning of the residuals (over- and under-predictions) can provide clues about what these missing variables might be.\nInflated Type I error rates: Researchers might incorrectly reject a true null.\n\nTo test for spatial autocorrelation, We can run a Moran’s I test on the model’s residuals. Significant spatial autocorrelation in the residuals means the model is not capturing the full spatial story.\nIn order to perform spatial autocorrelation test, we need to export the residual of the hedonic pricing model and save it as a data frame first.\n\nmlr.output &lt;- as.data.frame(condo.mlr1$residuals)\n\nNext, we will join the newly created data frame with condo_resale.sf object.\n\n# Extract residuals into the sf layer so we can map and test them -------------\ncondo_resale.sf &lt;- cbind(condo_resale.sf,\ncondo.mlr1$residuals) %&gt;%\nrename(`MLR_RES` = `condo.mlr1.residuals`) # rename residual column\n\nNext, we will use tmap package to display the distribution of the residuals on an interactive map.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\nℹ tmap mode set to \"view\".\n\n\nThe code chunks below is used to create an interactive point symbol map.\n\ntm_shape(mpsz_svy21) +\ntm_polygons(fill_alpha = 0.4) + # semi‑transparent base\ntm_shape(condo_resale.sf) +\ntm_dots(\nfill = \"MLR_RES\", # color by residual value\nsize = 0.7, # point size\ncol = \"black\", # thin border\nfill.scale = tm_scale( # custom diverging palette\nn = 10,\nvalues = rev(brewer.pal(11, \"RdBu\")), # red‑blue diverging\nstyle = \"quantile\",\nmidpoint = NA),\nfill.legend = tm_legend(title = \"Residuals\")\n) +\ntm_title(\"LM Residuals (Quantile Classification)\") +\ntm_layout(legend.outside = TRUE) +\ntm_view(set_zoom_limits = c(11,14))\n\n\n\n\n\n\nRemember to switch back to “plot” mode before continue.\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\n\nThe figure above reveal that there is sign of spatial autocorrelation.\nTo proof that our observation is indeed true, Global Moran’s I test will be performed\nFirst, we will compute the distance-based weight matrix by using st_dist_band() function of sfdep.\n\n# Build distance‑band neighbors and row‑standardized weights ------------------\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(\n    nb = st_dist_band(st_geometry(geometry), upper = 1500), # neighbors &lt;= 1.5 km\n    wt = st_weights(nb, style = \"W\"), # row‑standardized W\n    .before = 1)\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `nb = st_dist_band(st_geometry(geometry), upper = 1500)`.\nCaused by warning in `spdep::dnearneigh()`:\n! neighbour object has 10 sub-graphs\n\n\nNext, global_moran_perm() of sfdep package will be used to perform Moran’s I test for residual spatial autocorrelation\n\n# Permutation Moran’s I test on residuals -------------------------------------\nset.seed(1234) # for reproducibility of the permutation p‑value\nglobal_moran_perm(\n  condo_resale.sf$MLR_RES,\n  nb = condo_resale.sf$nb,\n  wt = condo_resale.sf$wt,\n  alternative = \"two.sided\",\n  nsim = 499)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 500 \n\nstatistic = 0.14389, observed rank = 500, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.14389 which is greater than 0, we can infer than the residuals resemble cluster distribution.\n\n\n\n\n\nIn this section, you are going to learn how to modelling hedonic pricing using both the fixed and adaptive bandwidth schemes\n\n\n\n\nIn the code chunk below bw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model. Notice that the argument **adaptive is set to FALSE indicates that we are interested to compute the fixed bandwidth.\nThere are two possible approaches can be uused to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using approach argeement.\n\n# Search for the optimal fixed bandwidth (in meters) using CV --------------------\nbw.fixed &lt;- bw.gwr(\nformula = SELLING_PRICE ~ AREA_SQM + AGE +\nPROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\nPROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK +\nPROX_PRIMARY_SCH + PROX_SHOPPING_MALL +\nPROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY +\nFREEHOLD,\ndata = condo_resale.sf,\napproach = \"CV\", # cross‑validation criterion\nkernel = \"gaussian\", # Gaussian kernel\nadaptive = FALSE, # fixed (distance) bandwidth\nlonglat = FALSE) # coordinates are projected (meters)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.379526e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3396 CV score: 4.721292e+14 \nFixed bandwidth: 971.3402 CV score: 4.721292e+14 \nFixed bandwidth: 971.3398 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3399 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \n\n\n\n\n\n\n\n\nNoteDo you know why it is in meter?\n\n\n\nThe reason why the recommended bandwidth (971.3405) is expressed in meters because of the coordinate reference system (CRS) were projected in SVY21 (EPSG:3414), all distances and spatial computations (like buffer, bandwidth, kernel distance, etc.) are measured in meters.\n\n\n\n\n\nNow we can use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.\n\n# Calibrate the fixed‑bandwidth GWR model ---------------------------------------\ngwr.fixed &lt;- gwr.basic(\nformula = SELLING_PRICE ~ AREA_SQM + AGE +\nPROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\nPROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK +\nPROX_PRIMARY_SCH + PROX_SHOPPING_MALL +\nPROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY +\nFREEHOLD,\ndata = condo_resale.sf,\nbw = bw.fixed,\nkernel = 'gaussian',\nlonglat = FALSE)\n\n\n# Inspect the fixed GWR diagnostics (AICc, R², parameter summaries) --------------\ngwr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2025-10-16 22:22:46.24389 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.34 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3599e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7426e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5001e+06 -1.5970e+05  3.1970e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8074e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112794435\n   AREA_SQM                 21575\n   AGE                     434203\n   PROX_CBD               2704604\n   PROX_CHILDCARE         1654086\n   PROX_ELDERLYCARE      38867861\n   PROX_URA_GROWTH_AREA  78515805\n   PROX_MRT               3124325\n   PROX_PARK             18122439\n   PROX_PRIMARY_SCH       4637517\n   PROX_SHOPPING_MALL     1529953\n   PROX_BUS_STOP         11342209\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720745\n   FREEHOLD               6073642\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3807 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6193 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.534069e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430418 \n\n   ***********************************************************************\n   Program stops at: 2025-10-16 22:22:47.140025 \n\n\nThe report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the globel multiple linear regression model of 42967.1.\n\n\n\n\nIn this section, we will calibrate the gwr-based hedonic pricing model by using adaptive bandwidth approach.\n\n\nSimilar to the earlier section, we will first use bw.gwr() to determine the recommended data point to use.\nThe code chunk used look very similar to the one used to compute the fixed bandwidth except the adaptive argument has changed to TRUE.\n\n# Search for the optimal adaptive bandwidth (K neighbors) using CV ----------------\nbw.adaptive &lt;- bw.gwr(\nformula = SELLING_PRICE ~ AREA_SQM + AGE +\nPROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\nPROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK +\nPROX_PRIMARY_SCH + PROX_SHOPPING_MALL +\nPROX_BUS_STOP + NO_Of_UNITS +\nFAMILY_FRIENDLY + FREEHOLD,\ndata = condo_resale.sf,\napproach = \"CV\",\nkernel = \"gaussian\",\nadaptive = TRUE, # K‑NN style bandwidth\nlonglat = FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nThe result shows that the 30 is the recommended data points to be used.\n\n\n\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\n\n# Calibrate the adaptive‑bandwidth GWR model ------------------------------------\ngwr.adaptive &lt;- gwr.basic(\n  formula = SELLING_PRICE ~ AREA_SQM + AGE +\n    PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n    PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK +\n    PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\n    NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n  data = condo_resale.sf,\n  bw = bw.adaptive,\n  kernel = 'gaussian',\n  adaptive = TRUE, # activate adaptive bandwidth in the fit\n  longlat = FALSE)\n\nThe code below can be used to display the model output.\n\n# Inspect the adaptive GWR diagnostics (AICc, R²) --------------------------------\ngwr.adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2025-10-16 22:22:54.080365 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2025-10-16 22:22:55.086396 \n\n\nThe report shows that the AICc the adaptive distance gwr is 41982.22 which is even smaller than the AICc of the fixed distance gwr of 42263.61.\n\n\n\n\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:\n\nCondition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.\nLocal R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.\nPredicted: these are the estimated (or fitted) y values 3. computed by GWR.\nResiduals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardized residuals can be produce by using these values.\nCoefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.\n\nThey are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its “data” slot in an object called SDF of the output list.\n\n\n\nTo visualise the fields in SDF, we need to first covert it into sf data.frame by using the code chunk below.\n\n# Convert the GWR output SDF (Spatial*DataFrame) to sf for mapping ---------------\ncondo_resale.sf.adaptive &lt;-\nst_as_sf(gwr.adaptive$SDF) %&gt;%\nst_transform(crs = 3414) # ensure consistent projection for mapping\n\nNext, glimpse() is used to display the content of condo_resale.sf.adaptive sf data frame.\n\n# Inspect the fields (coefficients, SE, t‑values, Local_R2, fitted yhat, etc.) ---\nglimpse(condo_resale.sf.adaptive)\n\nRows: 1,436\nColumns: 52\n$ Intercept               &lt;dbl&gt; 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM                &lt;dbl&gt; 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE                     &lt;dbl&gt; -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD                &lt;dbl&gt; -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE          &lt;dbl&gt; 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE        &lt;dbl&gt; -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA    &lt;dbl&gt; -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT                &lt;dbl&gt; -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK               &lt;dbl&gt; -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH        &lt;dbl&gt; 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL      &lt;dbl&gt; 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP           &lt;dbl&gt; 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS             &lt;dbl&gt; 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY         &lt;dbl&gt; -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD                &lt;dbl&gt; 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    &lt;dbl&gt; 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                &lt;dbl&gt; 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           &lt;dbl&gt; 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            &lt;dbl&gt; 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             &lt;dbl&gt; 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  &lt;dbl&gt; 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             &lt;dbl&gt; 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       &lt;dbl&gt; 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     &lt;dbl&gt; 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE &lt;dbl&gt; 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             &lt;dbl&gt; 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            &lt;dbl&gt; 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     &lt;dbl&gt; 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   &lt;dbl&gt; 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        &lt;dbl&gt; 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          &lt;dbl&gt; 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      &lt;dbl&gt; 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             &lt;dbl&gt; 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            &lt;dbl&gt; 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             &lt;dbl&gt; 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  &lt;dbl&gt; -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             &lt;dbl&gt; -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       &lt;dbl&gt; 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     &lt;dbl&gt; -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV &lt;dbl&gt; -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             &lt;dbl&gt; -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            &lt;dbl&gt; -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     &lt;dbl&gt; 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   &lt;dbl&gt; 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        &lt;dbl&gt; 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          &lt;dbl&gt; 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      &lt;dbl&gt; -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             &lt;dbl&gt; 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                &lt;dbl&gt; 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ geometry                &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n\n\n\n# Quick summary of fitted values (yhat) ------------------------------------------\nsummary(gwr.adaptive$SDF$yhat)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901 \n\n\n\n\n\nThe code chunks below is used to create an interactive point symbol map.\n\n# Local R²: where the local model fits well or poorly --------------------------------\ntmap_mode(\"view\")\n\nℹ tmap mode set to \"view\".\n\ntm_shape(mpsz_svy21) +\ntm_polygons(fill_alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +\ntm_dots(col = \"Local_R2\",\nborder.col = \"gray60\",\nborder.lwd = 1) +\ntm_view(set.zoom.limits = c(11,14))\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_dots()`: use 'fill' for the fill color of polygons/symbols\n(instead of 'col'), and 'col' for the outlines (instead of 'border.col').[v3-&gt;v4] `tm_view()`: use set_zoom_limits instead of set.zoom.limits\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\n\n\n\n\nThe code chunks below is used to create an interactive point symbol map.\n\n# Coefficient uncertainty vs strength for AREA_SQM: SE vs t‑value side‑by‑side ----\ntmap_mode(\"view\")\n\nℹ tmap mode set to \"view\".\n\nAREA_SQM_SE &lt;- tm_shape(mpsz_svy21) +\ntm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +\ntm_dots(col = \"AREA_SQM_SE\",\nborder.col = \"gray60\",\nborder.lwd = 1) +\ntm_view(set.zoom.limits = c(11,14))\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_polygons()`: use `fill_alpha` instead of `alpha`.[v3-&gt;v4] `tm_view()`: use set_zoom_limits instead of set.zoom.limits\n\nAREA_SQM_TV &lt;- tm_shape(mpsz_svy21) +\ntm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +\ntm_dots(col = \"AREA_SQM_TV\",\nborder.col = \"gray60\",\nborder.lwd = 1) +\ntm_view(set.zoom.limits = c(11,14))\n\n[v3-&gt;v4] `tm_polygons()`: use `fill_alpha` instead of `alpha`.\n[v3-&gt;v4] `tm_view()`: use set_zoom_limits instead of set.zoom.limits\n\n# Arrange the two interactive maps in a synchronized layout ----------------------\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV,\nasp = 1, ncol = 2,\nsync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\n\n\n\n\n\nGollini I, Lu B, Charlton M, Brunsdon C, Harris P (2015) “GWmodel: an R Package for exploring Spatial Heterogeneity using Geographically Weighted Models”. Journal of Statistical Software, 63(17):1-50, http://www.jstatsoft.org/v63/i17/\nLu B, Harris P, Charlton M, Brunsdon C (2014) “The GWmodel R Package: further topics for exploring Spatial Heterogeneity using GeographicallyWeighted Models”. Geo-spatial Information Science 17(2): 85-101, http://www.tandfonline.com/doi/abs/10.1080/1009502.2014.917453"
  },
  {
    "objectID": "Hands-on_Ex07/hand-on_ex07.html#overview",
    "href": "Hands-on_Ex07/hand-on_ex07.html#overview",
    "title": "Hands-on Ex07",
    "section": "",
    "text": "Geographically Weighted Regression (GWR) allows relationships between predictors (independent variables) and an outcome (dependent variable) to vary by location. In hedonic pricing, we model the resale prices of condominium units using structural factors (e.g., floor area, age) and locational accessibility (e.g., proximity to transport, parks, schools)."
  },
  {
    "objectID": "Hands-on_Ex07/hand-on_ex07.html#the-data",
    "href": "Hands-on_Ex07/hand-on_ex07.html#the-data",
    "title": "Hands-on Ex07",
    "section": "",
    "text": "Geospatial: MP14_SUBZONE_WEB_PL (subzone polygons; SVY21 projection).\nAspatial: Condo_resale_2015.csv with columns such as SELLING_PRICE, AREA_SQM, AGE, and multiple proximity variables (in kilometers) to amenities (MRT, parks, schools, etc.)."
  },
  {
    "objectID": "Hands-on_Ex07/hand-on_ex07.html#getting-started",
    "href": "Hands-on_Ex07/hand-on_ex07.html#getting-started",
    "title": "Hands-on Ex07",
    "section": "",
    "text": "Before we get started, it is important for us to install the necessary R packages into R and launch these R packages into R environment.\n\n# Install and load all required packages in one call --------------------------------\n# pacman::p_load() will install any missing packages and then load them into memory\npacman::p_load(olsrr, corrplot, ggpubr,\n               sf, sfdep, GWmodel, tmap,\n               tidyverse, gtsummary,\n               performance, RColorBrewer, see)\n\nThe R packages needed for this exercise are as follows:\n\nsf: spatial vector data handling; projections.\nsfdep: spatial weights and Moran’s I with tidy‑sf interface.\nGWmodel: GWR bandwidth search and model fitting.\ntmap: static/interactive maps.\ntidyverse: wrangling (dplyr, readr, ggplot2).\nolsrr, performance: OLS diagnostics, VIF, assumption checks.\ncorrplot: correlation matrix visual.\ngtsummary: publication‑quality regression tables.\nRColorBrewer: color palettes for maps."
  },
  {
    "objectID": "Hands-on_Ex07/hand-on_ex07.html#a-short-note-about-gwmodel",
    "href": "Hands-on_Ex07/hand-on_ex07.html#a-short-note-about-gwmodel",
    "title": "Hands-on Ex07",
    "section": "",
    "text": "GWmodel package provides a collection of localised spatial statistical methods, namely: GW summary statistics, GW principal components analysis, GW discriminant analysis and various forms of GW regression; some of which are provided in basic and robust (outlier resistant) forms. Commonly, outputs or parameters of the GWmodel are mapped to provide a useful exploratory tool, which can often precede (and direct) a more traditional or sophisticated statistical analysis."
  },
  {
    "objectID": "Hands-on_Ex07/hand-on_ex07.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex07/hand-on_ex07.html#geospatial-data-wrangling",
    "title": "Hands-on Ex07",
    "section": "",
    "text": "# Read the URA Master Plan 2014 subzone shapefile -------------------------------\n# dsn: directory; layer: shapefile base name without extension\nmpsz = st_read(dsn = \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex07/data/geospatial\",\n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex07/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\n\n# Transform the coordinate reference system to SVY21 / EPSG:3414 ----------------\n# This ensures all distance‑based operations use meters (required by GWR bandwidth)\nmpsz_svy21 &lt;- st_transform(mpsz, 3414)\n\n\n# Verify the target CRS ---------------------------------------------------------\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNext, inspect layer extent (bounding box)\n\nst_bbox(mpsz_svy21)\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334 \n\n\nThe print above reports the extent of mpsz_svy21 layer by its lower and upper limits."
  },
  {
    "objectID": "Hands-on_Ex07/hand-on_ex07.html#aspatial-data-wrangling",
    "href": "Hands-on_Ex07/hand-on_ex07.html#aspatial-data-wrangling",
    "title": "Hands-on Ex07",
    "section": "",
    "text": "# Read the 2015 condo resale dataset as a tibble --------------------------------\ncondo_resale = read_csv(\n  \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex07/data/aspatial/Condo_resale_2015.csv\")\n\nRows: 1436 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (23): LATITUDE, LONGITUDE, POSTCODE, SELLING_PRICE, AREA_SQM, AGE, PROX_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n# Peek at structure: variable names, types, first few rows ----------------------\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             &lt;dbl&gt; 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            &lt;dbl&gt; 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\nhead(condo_resale$LONGITUDE)\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\n\n\nhead(condo_resale$LATITUDE)\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\nThe print above reveals that the values of LONGITITUDE and LATITUDE fields are in decimal degree. Most probably wgs84 geographic coordinate system is used.\n\n# Quick descriptive statistics for all columns ----------------------------------\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\n\n\n\n# Convert LONGITUDE/LATITUDE (WGS84) to POINT geometry and reproject to SVY21 ---\n# 1) st_as_sf(): declare coordinates (lon, lat) with crs=4326 (WGS84 degrees)\n# 2) st_transform(): project to EPSG:3414 so distances are in meters\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that st_transform() of sf package is used to convert the coordinates from wgs84 (i.e. crs:4326) to svy21 (i.e. crs=3414).\n\n\n\n# Confirm the first few records including geometry --------------------------------\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n     &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1   118635       3000000      309    30     7.94          0.166            2.52 \n2   288420       3880000      290    32     6.61          0.280            1.93 \n3   267833       3325000      248    33     6.90          0.429            0.502\n4   258380       4250000      127     7     4.04          0.395            1.99 \n5   467169       1400000      145    28    11.8           0.119            1.12 \n6   466472       1320000      139    22    10.3           0.125            0.789\n# ℹ 15 more variables: PROX_URA_GROWTH_AREA &lt;dbl&gt;, PROX_HAWKER_MARKET &lt;dbl&gt;,\n#   PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;, PROX_PARK &lt;dbl&gt;,\n#   PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\n\nNotice that the output is in point feature data frame."
  },
  {
    "objectID": "Hands-on_Ex07/hand-on_ex07.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex07/hand-on_ex07.html#exploratory-data-analysis-eda",
    "title": "Hands-on Ex07",
    "section": "",
    "text": "We can plot the distribution of SELLING_PRICE by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\n\n# Plot raw SELLING_PRICE distribution -----------------\n# aes(x=SELLING_PRICE) maps the price variable to the x‑axis for a histogram\nggplot(data = condo_resale.sf,\n       aes(x = `SELLING_PRICE`)) +\n  geom_histogram(bins = 20,           # 20 equal‑width bins\n                 color = \"black\",     # black outline for readability\n                 fill = \"light blue\") # soft fill color for clarity\n\n\n\n\n\n\n\n\nThe figure above reveals a right skewed distribution. This means that more condominium units were transacted at relative lower prices.\nStatistically, the skewed dsitribution can be normalised by using log transformation. The code chunk below is used to derive a new variable called LOG_SELLING_PRICE by using a log transformation on the variable SELLING_PRICE. It is performed using mutate() of dplyr package.\n\n# Create a log‑price to reduce skewness -----------------------------------------\n# mutate() adds a new variable LOG_SELLING_PRICE = log(SELLING_PRICE)\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nNow, you can plot the LOG_SELLING_PRICE using the code chunk below.\n\n# Plot the log‑transformed price distribution -----------------------------------\nggplot(data = condo_resale.sf,\n       aes(x = `LOG_SELLING_PRICE`)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\")\n\n\n\n\n\n\n\n\nNotice that the distribution is relatively less skewed after the transformation.\n\n\n\nn this section, you will learn how to draw a small multiple histograms (also known as trellis plot) by using ggarrange() of ggpubr package.\nThe code chunk below is used to create 12 histograms. Then, ggarrange() is used to organised these histogram into a 3 columns by 4 rows small multiple plot.\n\n# Build individual histograms for key predictors ---------------------------------\nAREA_SQM &lt;- ggplot(data = condo_resale.sf, aes(x = `AREA_SQM`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nAGE &lt;- ggplot(data = condo_resale.sf, aes(x = `AGE`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_CBD &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_CBD`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_CHILDCARE &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_CHILDCARE`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_ELDERLYCARE &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_URA_GROWTH_AREA &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_HAWKER_MARKET &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_KINDERGARTEN &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_MRT &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_MRT`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_PARK &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_PARK`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_PRIMARY_SCH &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_TOP_PRIMARY_SCH &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\n# Arrange the 12 histograms into a 3x4 panel ------------------------------------\n# ggarrange() helps create small‑multiples (trellis) display\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE,\n          PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA,\n          PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)\n\n\n\n\n\n\n\n\n\n\n\n\n# Switch tmap to interactive (leaflet) mode -------------------------------------\ntmap_mode(\"view\")\n\nℹ tmap mode set to \"view\".\n\n# Draw subzones base layer + condo points colored by SELLING_PRICE --------------\ntm_shape(mpsz_svy21) +\n  tm_polygons() +\n tm_shape(condo_resale.sf) +  \n  tm_dots(fill = \"SELLING_PRICE\",      # color points by price\n          fill_alpha = 0.6,            # semi‑transparent fills\n          size = 0.5,                  # dot size\n          fill.scale = tm_scale_intervals(\n            style = \"quantile\")) +     # quantile breaks (robust to skew)\n  tm_view(set_zoom_limits = c(11,14))  # limit zoom range for usability\n\nRegistered S3 method overwritten by 'jsonify':\n  method     from    \n  print.json jsonlite\n\n\n\n\n\n\n\nset_zoom_limits argument of tm_view() sets the minimum and maximum zoom level to 11 and 14 respectively.\nBefore moving on to the next section, the code below will be used to turn R display into plot mode.\n\n# Switch back to static plotting mode before continuing -------------------------\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\"."
  },
  {
    "objectID": "Hands-on_Ex07/hand-on_ex07.html#hedonic-pricing-modelling-in-r-ols",
    "href": "Hands-on_Ex07/hand-on_ex07.html#hedonic-pricing-modelling-in-r-ols",
    "title": "Hands-on Ex07",
    "section": "",
    "text": "In this section, we will learn how to building hedonic pricing models for condominium resale units using lm() of R base.\n\n\n\n# Fit a simple linear regression with floor area as the only predictor ------------\ncondo.slr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM,\n                data = condo_resale.sf)\n\n\n# Print model summary: coefficients, R², p‑values, residual spread ----------------\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: &lt; 2.2e-16\n\n\nThe output report reveals that the SELLING_PRICE can be explained by using the formula:\n\\[\\text{Selling_Price} = -258121.1 + 14719\\cdot\\text{Area_SQM}\\]\nThe R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince p-value is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of SELLING_PRICE.\nThe Coefficients: section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.\nTo visualise the best fit curve on a scatterplot, we can incorporate lm() as a method function in ggplot’s geometry as shown in the code chunk below.\n\n# Visualize scatter with best‑fit line from lm() ---------------------------------\n# geom_smooth(method = lm) overlays the OLS regression line with CI ribbon\nggplot(data = condo_resale.sf,  \n       aes(x = `AREA_SQM`, y = `SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nFigure above reveals that there are a few statistical outliers with relatively high selling prices.\n\n\n\n\n\nBefore building a multiple regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other. If these highly correlated independent variables are used in building a regression model by mistake, the quality of the model will be compromised. This phenomenon is known as multicollinearity in statistics.\nCorrelation matrix is commonly used to visualise the relationships between the independent variables. Beside the pairs() of R, there are many packages support the display of a correlation matrix. In this section, the corrplot package will be used.\nThe code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in condo_resale data.frame.\n\n# Visualize pairwise correlations among predictors (cols 5:23 from the CSV) ------\ncorrplot(cor(condo_resale[, 5:23]),\n         diag = FALSE,\n         order = \"AOE\",      # Angular Order of Eigenvectors (stable ordering)\n         tl.pos = \"td\",      # text labels on top diagonal\n         tl.cex = 0.5,        # smaller text\n         method = \"number\",  # print numeric correlations\n         type = \"upper\")     # upper triangle only\n\n\n\n\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, LEASE_99YEAR is excluded in the subsequent model building.\n\n\n\n\nThe code chunk below using lm() to calibrate the multiple linear regression model.\n\n# Build the full hedonic model (drop LEASEHOLD_99YR to avoid high correlation) ---\ncondo.mlr &lt;- lm(\n  formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n    PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n    PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET   +\n    PROX_KINDERGARTEN   + PROX_MRT  + PROX_PARK +\n    PROX_PRIMARY_SCH + PROX_TOP_PRIMARY_SCH +\n    PROX_SHOPPING_MALL  + PROX_SUPERMARKET + \n    PROX_BUS_STOP   + NO_Of_UNITS + \n    FAMILY_FRIENDLY + FREEHOLD, \n  data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  &lt; 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  &lt; 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  &lt; 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk above consists of two parts:\n- lm() of Base R is used to calibrate a multiple linear regression model. The model output is stored in an lm object called condo.mlr.\n- summary() is used to print the model output.\n\n\n\n\n\nWith reference to the report above, it is clear that not all the independent variables are statistically significant. We will revised the model by removing those variables which are not statistically significant.\nNow, we are ready to calibrate the revised model by using the code chunk below.\n\n# Remove variables with weak significance to improve parsimony -------------------\ncondo.mlr1 &lt;- lm(\n  formula = SELLING_PRICE ~ AREA_SQM + AGE + \n    PROX_CBD + PROX_CHILDCARE + PROX_MRT +\n    PROX_ELDERLYCARE    + PROX_URA_GROWTH_AREA +\n    PROX_PARK   + PROX_PRIMARY_SCH + \n    PROX_SHOPPING_MALL  + PROX_BUS_STOP + \n    NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n  data = condo_resale.sf)\n\n\n# Verify all retained predictors are significant at 5% (or better) ---------------\nsummary(condo.mlr1)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_MRT + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_PARK + \n    PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n    FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\nAREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\nAGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\nPROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\nPROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \nPROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\nPROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\nPROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\nPROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \nPROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\nPROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\nNO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \nFAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \nFREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 756000 on 1421 degrees of freedom\nMultiple R-squared:  0.6507,    Adjusted R-squared:  0.6472 \nF-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16\n\n\nThe output above reveals that all explanatory variables are statistically significant at 95% confident level.\n\n\n\nThe gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R.\nIn the code chunk below, tbl_regression() is used to create a well formatted regression report.\n\n# Create a clean table of coefficients, CIs, and p‑values\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI\np-value\n\n\n\n\n(Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n\n\nAREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n\n\nAGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n\n\nPROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n\n\nPROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n\n\nPROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n\n\nPROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n\n\nPROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n\n\nPROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n\n\nPROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n\n\nPROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n\n\nPROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n\n\nNO_Of_UNITS\n-245\n-418, -73\n0.005\n\n\nFAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n\n\nFREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n\n\n\nAbbreviation: CI = Confidence Interval\n\n\n\n\n\n\n\n\nWith gtsummary package, model statistics can be included in the report by either appending them to the report table by using add_glance_table() or adding as a table source note by using add_glance_source_note() as shown in the code chunk below.\n\n# Append model‑level statistics as a footnote (AIC, R², sigma, etc.) -------------\ntbl_regression(condo.mlr1,\nintercept = TRUE) %&gt;%\nadd_glance_source_note(\nlabel = list(sigma ~ \"σ\"), # Greek sigma symbol\ninclude = c(r.squared, adj.r.squared,\nAIC, statistic,\np.value, sigma))\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI\np-value\n\n\n\n\n(Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n\n\nAREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n\n\nAGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n\n\nPROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n\n\nPROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n\n\nPROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n\n\nPROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n\n\nPROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n\n\nPROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n\n\nPROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n\n\nPROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n\n\nPROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n\n\nNO_Of_UNITS\n-245\n-418, -73\n0.005\n\n\nFAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n\n\nFREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n\n\n\nAbbreviation: CI = Confidence Interval\n\n\nR² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = &lt;0.001; σ = 755,957\n\n\n\n\n\n\n\n\nFor more customization options, refer to Tutorial: tbl_regression.\n\n\n\nRegression diagnostics are a set of procedures used to check if a regression model’s assumptions are met and how well the model fits the data. These diagnostics involve checking for issues like non-linear relationships, non-normal errors, non-constant variance, and influential observations to ensure the model’s conclusions are valid and reliable. Common methods include graphical analysis, like residual plots and QQ-plots, and quantitative tests\nIn this section, we would like to introduce you a fantastic R package specially programmed for performing OLS regression diagnostics. It is called olsrr. It provides a collection of very useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\n\nresidual diagnostics\n\nmeasures of influence\n\nheteroskedasticity tests\n\ncollinearity diagnostics\n\nmodel fit assessment\n\nvariable contribution assessment\n\nvariable selection procedures\n\n\n\nMulticollinearity occurs when independent variables are not truly independent, meaning a change in one is associated with a change in another. This makes it hard for the model to isolate each variable’s influence on the outcome.\nPerforming a multicollinearity test is crucial in multiple linear regression because it ensures the reliability and interpretability of the model’s results. High multicollinearity, where independent variables are highly correlated, inflates the variance of the estimated coefficients, making them unstable, unreliable, and difficult to interpret. This instability can lead to misleading statistical conclusions, such as a variable appearing statistically insignificant when it is not.\nIn the code chunk below, the check_collinearity() of performance package is used to test if there are sign of multicollinearity.\n\n# Check Variance Inflation Factors (VIF) to confirm low multicollinearity --------\nmlr.vif &lt;- check_collinearity(condo.mlr1) # compute VIFs\nmlr.vif # print the table\n\n# Check for Multicollinearity\n\nLow Correlation\n\n                 Term  VIF   VIF 95% CI adj. VIF Tolerance Tolerance 95% CI\n             AREA_SQM 1.15 [1.09, 1.23]     1.07      0.87     [0.81, 0.92]\n                  AGE 1.41 [1.33, 1.52]     1.19      0.71     [0.66, 0.75]\n             PROX_CBD 1.57 [1.47, 1.69]     1.25      0.64     [0.59, 0.68]\n       PROX_CHILDCARE 3.26 [3.00, 3.56]     1.81      0.31     [0.28, 0.33]\n             PROX_MRT 1.91 [1.78, 2.07]     1.38      0.52     [0.48, 0.56]\n     PROX_ELDERLYCARE 1.52 [1.42, 1.63]     1.23      0.66     [0.61, 0.70]\n PROX_URA_GROWTH_AREA 1.33 [1.26, 1.43]     1.15      0.75     [0.70, 0.80]\n            PROX_PARK 1.21 [1.15, 1.29]     1.10      0.83     [0.77, 0.87]\n     PROX_PRIMARY_SCH 2.21 [2.05, 2.40]     1.49      0.45     [0.42, 0.49]\n   PROX_SHOPPING_MALL 1.48 [1.39, 1.60]     1.22      0.67     [0.63, 0.72]\n        PROX_BUS_STOP 2.85 [2.62, 3.10]     1.69      0.35     [0.32, 0.38]\n          NO_Of_UNITS 1.45 [1.36, 1.56]     1.20      0.69     [0.64, 0.73]\n      FAMILY_FRIENDLY 1.38 [1.30, 1.48]     1.17      0.72     [0.67, 0.77]\n             FREEHOLD 1.44 [1.36, 1.55]     1.20      0.69     [0.65, 0.74]\n\nplot(mlr.vif) # quick visual of VIF levels\n\n\n\n\n\n\n\n\nSince the VIF of the independent variables are less than 10. We can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n\n\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\n#check_model(condo.mlr1, check = \"linearity\")\n\n# Visual check that residuals vs fitted show no strong non‑linearity -------------\nggplot(data = data.frame(Fitted = fitted(condo.mlr1), Residuals = resid(condo.mlr1)),\naes(x = Fitted, y = Residuals)) +\ngeom_point(color = 'blue', alpha = 0.6) +\ngeom_smooth(method = 'loess', se = TRUE, color = 'green', fill = 'grey70') +\ngeom_hline(yintercept = 0, color = 'black', linetype = 'dashed') +\nlabs(title = 'Linearity', subtitle = 'Reference line should be flat and horizontal',\nx = 'Fitted values', y = 'Residuals') +\ntheme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe figure above reveals that most of the data poitns are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n\nThe normality assumption test for multiple linear regression checks if the model’s residuals (the differences between observed and predicted values) are normally distributed. This is crucial for accurate hypothesis testing and confidence intervals. To test this, you can use visual methods like histograms and Q-Q plots of the residuals, or conduct statistical tests like Shapiro-Wilk test and Kolmogorov-Smirnov test.\nIn the code chunk below, check_normality() of performance package is used to perform normality assumption test on condo.mlr1 model.\n\n# Formal test (often significant with large n); complement with Q‑Q plot ---------\ncheck_normality(condo.mlr1)\n\nWarning: Non-normality of residuals detected (p &lt; .001).\n\n\nThe print above reveals that the p-value of the normality assumption test is less than alpha value of 0.05. Hence we reject the normality assumption at 95% confident level.\n\n\n\n\n\n\nNote\n\n\n\n\ncheck_normality() calls stats::shapiro.test and checks the standardized residuals (or studentized residuals for mixed models) for normal distribution.\n\nNote that this formal test almost always yields significant results for the distribution of residuals and visual inspection (e.g. Q-Q plots) are preferable.\n\n\n\nInstead of showing the test statistic, plot() of see package can be used to plot a the output of check_normality() for visual inspection as shown below.\n\n# Q‑Q plot of standardized residuals from the check_normality() output -----------\nplot(check_normality(condo.mlr1), type = \"qq\")\n\nFor confidence bands, please install `qqplotr`.\n\n\n\n\n\n\n\n\n\nQ-Q plot above below shows that majority of the data points are felt along the zero line.\nAnother way to check for normality assumption visual is by using check_model() of performance package as shown in the code chunk below.\n\n# Alternative normality panel via performance::check_model -----------------------\ncheck_model(condo.mlr1, check = \"normality\")\n\n\n\n\n\n\n\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\n\n\n\nThe hedonic model we try to build are using geographically referenced data. Hence, it is crucial to check for spatial autocorrelation because its presence can produce unreliable and misleading results. Traditional regression models, such as ordinary least squares (OLS), assume that observations are independent of one another. However, spatial data often violates this assumption.\nSpatial autocorrelation is the correlation of a variable with itself across different spatial locations. Positive spatial autocorrelation means nearby features tend to be more similar, while negative autocorrelation means they tend to be more dissimilar. This phenomenon is based on the first law of geography: “Everything is related to everything else, but nearby things are more related than distant things”.\nIgnoring spatial autocorrelation in a regression model can lead to serious statistical issues:\n\nBiased and inefficient coefficient estimates: If autocorrelation is present, standard errors of the model coefficients can be wrong, leading to unreliable hypothesis tests (p-values). The model might appear more significant than it is.\nMisleading significance tests: Standard regression models cannot distinguish between true explanatory power and the influence of spatial patterns, resulting in inaccurate p-values.\nModel misspecification: Significant spatial autocorrelation in the regression residuals often signals that important explanatory variables are missing from the model. The spatial patterning of the residuals (over- and under-predictions) can provide clues about what these missing variables might be.\nInflated Type I error rates: Researchers might incorrectly reject a true null.\n\nTo test for spatial autocorrelation, We can run a Moran’s I test on the model’s residuals. Significant spatial autocorrelation in the residuals means the model is not capturing the full spatial story.\nIn order to perform spatial autocorrelation test, we need to export the residual of the hedonic pricing model and save it as a data frame first.\n\nmlr.output &lt;- as.data.frame(condo.mlr1$residuals)\n\nNext, we will join the newly created data frame with condo_resale.sf object.\n\n# Extract residuals into the sf layer so we can map and test them -------------\ncondo_resale.sf &lt;- cbind(condo_resale.sf,\ncondo.mlr1$residuals) %&gt;%\nrename(`MLR_RES` = `condo.mlr1.residuals`) # rename residual column\n\nNext, we will use tmap package to display the distribution of the residuals on an interactive map.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\nℹ tmap mode set to \"view\".\n\n\nThe code chunks below is used to create an interactive point symbol map.\n\ntm_shape(mpsz_svy21) +\ntm_polygons(fill_alpha = 0.4) + # semi‑transparent base\ntm_shape(condo_resale.sf) +\ntm_dots(\nfill = \"MLR_RES\", # color by residual value\nsize = 0.7, # point size\ncol = \"black\", # thin border\nfill.scale = tm_scale( # custom diverging palette\nn = 10,\nvalues = rev(brewer.pal(11, \"RdBu\")), # red‑blue diverging\nstyle = \"quantile\",\nmidpoint = NA),\nfill.legend = tm_legend(title = \"Residuals\")\n) +\ntm_title(\"LM Residuals (Quantile Classification)\") +\ntm_layout(legend.outside = TRUE) +\ntm_view(set_zoom_limits = c(11,14))\n\n\n\n\n\n\nRemember to switch back to “plot” mode before continue.\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\n\nThe figure above reveal that there is sign of spatial autocorrelation.\nTo proof that our observation is indeed true, Global Moran’s I test will be performed\nFirst, we will compute the distance-based weight matrix by using st_dist_band() function of sfdep.\n\n# Build distance‑band neighbors and row‑standardized weights ------------------\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(\n    nb = st_dist_band(st_geometry(geometry), upper = 1500), # neighbors &lt;= 1.5 km\n    wt = st_weights(nb, style = \"W\"), # row‑standardized W\n    .before = 1)\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `nb = st_dist_band(st_geometry(geometry), upper = 1500)`.\nCaused by warning in `spdep::dnearneigh()`:\n! neighbour object has 10 sub-graphs\n\n\nNext, global_moran_perm() of sfdep package will be used to perform Moran’s I test for residual spatial autocorrelation\n\n# Permutation Moran’s I test on residuals -------------------------------------\nset.seed(1234) # for reproducibility of the permutation p‑value\nglobal_moran_perm(\n  condo_resale.sf$MLR_RES,\n  nb = condo_resale.sf$nb,\n  wt = condo_resale.sf$wt,\n  alternative = \"two.sided\",\n  nsim = 499)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 500 \n\nstatistic = 0.14389, observed rank = 500, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.14389 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "Hands-on_Ex07/hand-on_ex07.html#building-hedonic-pricing-models-using-gwmodel",
    "href": "Hands-on_Ex07/hand-on_ex07.html#building-hedonic-pricing-models-using-gwmodel",
    "title": "Hands-on Ex07",
    "section": "",
    "text": "In this section, you are going to learn how to modelling hedonic pricing using both the fixed and adaptive bandwidth schemes\n\n\n\n\nIn the code chunk below bw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model. Notice that the argument **adaptive is set to FALSE indicates that we are interested to compute the fixed bandwidth.\nThere are two possible approaches can be uused to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using approach argeement.\n\n# Search for the optimal fixed bandwidth (in meters) using CV --------------------\nbw.fixed &lt;- bw.gwr(\nformula = SELLING_PRICE ~ AREA_SQM + AGE +\nPROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\nPROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK +\nPROX_PRIMARY_SCH + PROX_SHOPPING_MALL +\nPROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY +\nFREEHOLD,\ndata = condo_resale.sf,\napproach = \"CV\", # cross‑validation criterion\nkernel = \"gaussian\", # Gaussian kernel\nadaptive = FALSE, # fixed (distance) bandwidth\nlonglat = FALSE) # coordinates are projected (meters)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.379526e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3396 CV score: 4.721292e+14 \nFixed bandwidth: 971.3402 CV score: 4.721292e+14 \nFixed bandwidth: 971.3398 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3399 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \n\n\n\n\n\n\n\n\nNoteDo you know why it is in meter?\n\n\n\nThe reason why the recommended bandwidth (971.3405) is expressed in meters because of the coordinate reference system (CRS) were projected in SVY21 (EPSG:3414), all distances and spatial computations (like buffer, bandwidth, kernel distance, etc.) are measured in meters.\n\n\n\n\n\nNow we can use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.\n\n# Calibrate the fixed‑bandwidth GWR model ---------------------------------------\ngwr.fixed &lt;- gwr.basic(\nformula = SELLING_PRICE ~ AREA_SQM + AGE +\nPROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\nPROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK +\nPROX_PRIMARY_SCH + PROX_SHOPPING_MALL +\nPROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY +\nFREEHOLD,\ndata = condo_resale.sf,\nbw = bw.fixed,\nkernel = 'gaussian',\nlonglat = FALSE)\n\n\n# Inspect the fixed GWR diagnostics (AICc, R², parameter summaries) --------------\ngwr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2025-10-16 22:22:46.24389 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.34 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3599e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7426e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5001e+06 -1.5970e+05  3.1970e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8074e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112794435\n   AREA_SQM                 21575\n   AGE                     434203\n   PROX_CBD               2704604\n   PROX_CHILDCARE         1654086\n   PROX_ELDERLYCARE      38867861\n   PROX_URA_GROWTH_AREA  78515805\n   PROX_MRT               3124325\n   PROX_PARK             18122439\n   PROX_PRIMARY_SCH       4637517\n   PROX_SHOPPING_MALL     1529953\n   PROX_BUS_STOP         11342209\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720745\n   FREEHOLD               6073642\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3807 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6193 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.534069e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430418 \n\n   ***********************************************************************\n   Program stops at: 2025-10-16 22:22:47.140025 \n\n\nThe report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the globel multiple linear regression model of 42967.1.\n\n\n\n\nIn this section, we will calibrate the gwr-based hedonic pricing model by using adaptive bandwidth approach.\n\n\nSimilar to the earlier section, we will first use bw.gwr() to determine the recommended data point to use.\nThe code chunk used look very similar to the one used to compute the fixed bandwidth except the adaptive argument has changed to TRUE.\n\n# Search for the optimal adaptive bandwidth (K neighbors) using CV ----------------\nbw.adaptive &lt;- bw.gwr(\nformula = SELLING_PRICE ~ AREA_SQM + AGE +\nPROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\nPROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK +\nPROX_PRIMARY_SCH + PROX_SHOPPING_MALL +\nPROX_BUS_STOP + NO_Of_UNITS +\nFAMILY_FRIENDLY + FREEHOLD,\ndata = condo_resale.sf,\napproach = \"CV\",\nkernel = \"gaussian\",\nadaptive = TRUE, # K‑NN style bandwidth\nlonglat = FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nThe result shows that the 30 is the recommended data points to be used.\n\n\n\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\n\n# Calibrate the adaptive‑bandwidth GWR model ------------------------------------\ngwr.adaptive &lt;- gwr.basic(\n  formula = SELLING_PRICE ~ AREA_SQM + AGE +\n    PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n    PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK +\n    PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\n    NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n  data = condo_resale.sf,\n  bw = bw.adaptive,\n  kernel = 'gaussian',\n  adaptive = TRUE, # activate adaptive bandwidth in the fit\n  longlat = FALSE)\n\nThe code below can be used to display the model output.\n\n# Inspect the adaptive GWR diagnostics (AICc, R²) --------------------------------\ngwr.adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2025-10-16 22:22:54.080365 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2025-10-16 22:22:55.086396 \n\n\nThe report shows that the AICc the adaptive distance gwr is 41982.22 which is even smaller than the AICc of the fixed distance gwr of 42263.61.\n\n\n\n\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:\n\nCondition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.\nLocal R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.\nPredicted: these are the estimated (or fitted) y values 3. computed by GWR.\nResiduals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardized residuals can be produce by using these values.\nCoefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.\n\nThey are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its “data” slot in an object called SDF of the output list.\n\n\n\nTo visualise the fields in SDF, we need to first covert it into sf data.frame by using the code chunk below.\n\n# Convert the GWR output SDF (Spatial*DataFrame) to sf for mapping ---------------\ncondo_resale.sf.adaptive &lt;-\nst_as_sf(gwr.adaptive$SDF) %&gt;%\nst_transform(crs = 3414) # ensure consistent projection for mapping\n\nNext, glimpse() is used to display the content of condo_resale.sf.adaptive sf data frame.\n\n# Inspect the fields (coefficients, SE, t‑values, Local_R2, fitted yhat, etc.) ---\nglimpse(condo_resale.sf.adaptive)\n\nRows: 1,436\nColumns: 52\n$ Intercept               &lt;dbl&gt; 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM                &lt;dbl&gt; 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE                     &lt;dbl&gt; -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD                &lt;dbl&gt; -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE          &lt;dbl&gt; 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE        &lt;dbl&gt; -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA    &lt;dbl&gt; -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT                &lt;dbl&gt; -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK               &lt;dbl&gt; -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH        &lt;dbl&gt; 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL      &lt;dbl&gt; 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP           &lt;dbl&gt; 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS             &lt;dbl&gt; 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY         &lt;dbl&gt; -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD                &lt;dbl&gt; 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    &lt;dbl&gt; 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                &lt;dbl&gt; 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           &lt;dbl&gt; 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            &lt;dbl&gt; 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             &lt;dbl&gt; 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  &lt;dbl&gt; 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             &lt;dbl&gt; 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       &lt;dbl&gt; 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     &lt;dbl&gt; 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE &lt;dbl&gt; 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             &lt;dbl&gt; 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            &lt;dbl&gt; 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     &lt;dbl&gt; 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   &lt;dbl&gt; 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        &lt;dbl&gt; 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          &lt;dbl&gt; 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      &lt;dbl&gt; 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             &lt;dbl&gt; 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            &lt;dbl&gt; 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             &lt;dbl&gt; 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  &lt;dbl&gt; -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             &lt;dbl&gt; -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       &lt;dbl&gt; 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     &lt;dbl&gt; -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV &lt;dbl&gt; -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             &lt;dbl&gt; -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            &lt;dbl&gt; -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     &lt;dbl&gt; 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   &lt;dbl&gt; 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        &lt;dbl&gt; 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          &lt;dbl&gt; 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      &lt;dbl&gt; -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             &lt;dbl&gt; 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                &lt;dbl&gt; 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ geometry                &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n\n\n\n# Quick summary of fitted values (yhat) ------------------------------------------\nsummary(gwr.adaptive$SDF$yhat)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901 \n\n\n\n\n\nThe code chunks below is used to create an interactive point symbol map.\n\n# Local R²: where the local model fits well or poorly --------------------------------\ntmap_mode(\"view\")\n\nℹ tmap mode set to \"view\".\n\ntm_shape(mpsz_svy21) +\ntm_polygons(fill_alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +\ntm_dots(col = \"Local_R2\",\nborder.col = \"gray60\",\nborder.lwd = 1) +\ntm_view(set.zoom.limits = c(11,14))\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_dots()`: use 'fill' for the fill color of polygons/symbols\n(instead of 'col'), and 'col' for the outlines (instead of 'border.col').[v3-&gt;v4] `tm_view()`: use set_zoom_limits instead of set.zoom.limits\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\n\n\n\n\nThe code chunks below is used to create an interactive point symbol map.\n\n# Coefficient uncertainty vs strength for AREA_SQM: SE vs t‑value side‑by‑side ----\ntmap_mode(\"view\")\n\nℹ tmap mode set to \"view\".\n\nAREA_SQM_SE &lt;- tm_shape(mpsz_svy21) +\ntm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +\ntm_dots(col = \"AREA_SQM_SE\",\nborder.col = \"gray60\",\nborder.lwd = 1) +\ntm_view(set.zoom.limits = c(11,14))\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_polygons()`: use `fill_alpha` instead of `alpha`.[v3-&gt;v4] `tm_view()`: use set_zoom_limits instead of set.zoom.limits\n\nAREA_SQM_TV &lt;- tm_shape(mpsz_svy21) +\ntm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +\ntm_dots(col = \"AREA_SQM_TV\",\nborder.col = \"gray60\",\nborder.lwd = 1) +\ntm_view(set.zoom.limits = c(11,14))\n\n[v3-&gt;v4] `tm_polygons()`: use `fill_alpha` instead of `alpha`.\n[v3-&gt;v4] `tm_view()`: use set_zoom_limits instead of set.zoom.limits\n\n# Arrange the two interactive maps in a synchronized layout ----------------------\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV,\nasp = 1, ncol = 2,\nsync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\"."
  },
  {
    "objectID": "Hands-on_Ex07/hand-on_ex07.html#reference",
    "href": "Hands-on_Ex07/hand-on_ex07.html#reference",
    "title": "Hands-on Ex07",
    "section": "",
    "text": "Gollini I, Lu B, Charlton M, Brunsdon C, Harris P (2015) “GWmodel: an R Package for exploring Spatial Heterogeneity using Geographically Weighted Models”. Journal of Statistical Software, 63(17):1-50, http://www.jstatsoft.org/v63/i17/\nLu B, Harris P, Charlton M, Brunsdon C (2014) “The GWmodel R Package: further topics for exploring Spatial Heterogeneity using GeographicallyWeighted Models”. Geo-spatial Information Science 17(2): 85-101, http://www.tandfonline.com/doi/abs/10.1080/1009502.2014.917453"
  },
  {
    "objectID": "Hands-on_Ex06/hand-on_ex06.html",
    "href": "Hands-on_Ex06/hand-on_ex06.html",
    "title": "Hands-on Ex06",
    "section": "",
    "text": "In this hands‑on exercise, we will learn how to delineate homogeneous regions by using geographically referenced multivariate data. Two major analyses are covered:\n\nhierarchical cluster analysis; and\n\nspatially constrained cluster analysis.\n\n\n\nBy the end of this exercise, we will be able to:\n\nconvert GIS polygon data into R’s simple feature data.frame using sf;\nconvert a simple feature data.frame into SpatialPolygonsDataFrame using sf → sp conversion for SKATER;\nperform cluster analysis using hclust() (Base R) and hclustgeo() (ClustGeo);\nperform spatially constrained clustering using skater() (spdep) and hclustgeo() with spatial dissimilarities; and\nvisualise outputs using ggplot2 and tmap.\n\n\n\n\n\n\n\nSegment Shan State, Myanmar into homogeneous regions at the township level using multiple ICT indicators: Radio, Television, Land line phone, Mobile phone, Computer, and Internet at home.\n\n\n\n\nTwo datasets are used:\n\nMyanmar Township Boundary Data (mynamar_township_boundaries) — ESRI Shapefile; polygons at township level.\nShan-ICT.csv — extract of The 2014 Myanmar Population and Housing Census Myanmar at township level.\n\n\n\n\n# Install and load all packages used in one call -----------------\npacman::p_load(spdep, tmap, sf, ClustGeo, ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)  # loads if installed; installs if missing\n\n\n\n\n\n\n\nNote\n\n\n\nWith tidyverse, we get readr, ggplot2, dplyr, purrr, etc.\n\n\n\n\n\n\n\n\n\n# Read township boundaries shapefile (sf) ---------------------------------------\nshan_sf &lt;- st_read(dsn = \"data/geospatial\",      # folder containing the shapefile\n                   layer = \"myanmar_township_boundaries\") %&gt;%     # shapefile layer name (without .shp)\n  dplyr::filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%  # keep only Shan State parts\n  dplyr::select(c(2:7))                          # keep fields 2..7\n\nReading layer `myanmar_township_boundaries' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex06/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n# Inspect the resulting simple feature data.frame --------------------------------\nshan_sf                                          # prints sf summary (rows, cols, bbox)\n\nSimple feature collection with 55 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 96.15107 ymin: 19.29932 xmax: 101.1699 ymax: 24.15907\nGeodetic CRS:  WGS 84\nFirst 10 features:\n             ST ST_PCODE       DT   DT_PCODE        TS  TS_PCODE\n1  Shan (North)   MMR015  Mongmit MMR015D008   Mongmit MMR015017\n2  Shan (South)   MMR014 Taunggyi MMR014D001   Pindaya MMR014006\n3  Shan (South)   MMR014 Taunggyi MMR014D001   Ywangan MMR014007\n4  Shan (South)   MMR014 Taunggyi MMR014D001  Pinlaung MMR014009\n5  Shan (North)   MMR015  Mongmit MMR015D008    Mabein MMR015018\n6  Shan (South)   MMR014 Taunggyi MMR014D001     Kalaw MMR014005\n7  Shan (South)   MMR014 Taunggyi MMR014D001     Pekon MMR014010\n8  Shan (South)   MMR014 Taunggyi MMR014D001  Lawksawk MMR014008\n9  Shan (North)   MMR015  Kyaukme MMR015D003 Nawnghkio MMR015013\n10 Shan (North)   MMR015  Kyaukme MMR015D003   Kyaukme MMR015012\n                         geometry\n1  MULTIPOLYGON (((96.96001 23...\n2  MULTIPOLYGON (((96.7731 21....\n3  MULTIPOLYGON (((96.78483 21...\n4  MULTIPOLYGON (((96.49518 20...\n5  MULTIPOLYGON (((96.66306 24...\n6  MULTIPOLYGON (((96.49518 20...\n7  MULTIPOLYGON (((97.14738 19...\n8  MULTIPOLYGON (((96.94981 22...\n9  MULTIPOLYGON (((96.75648 22...\n10 MULTIPOLYGON (((96.95498 22...\n\nglimpse(shan_sf)  \n\nRows: 55\nColumns: 7\n$ ST       &lt;chr&gt; \"Shan (North)\", \"Shan (South)\", \"Shan (South)\", \"Shan (South)…\n$ ST_PCODE &lt;chr&gt; \"MMR015\", \"MMR014\", \"MMR014\", \"MMR014\", \"MMR015\", \"MMR014\", \"…\n$ DT       &lt;chr&gt; \"Mongmit\", \"Taunggyi\", \"Taunggyi\", \"Taunggyi\", \"Mongmit\", \"Ta…\n$ DT_PCODE &lt;chr&gt; \"MMR015D008\", \"MMR014D001\", \"MMR014D001\", \"MMR014D001\", \"MMR0…\n$ TS       &lt;chr&gt; \"Mongmit\", \"Pindaya\", \"Ywangan\", \"Pinlaung\", \"Mabein\", \"Kalaw…\n$ TS_PCODE &lt;chr&gt; \"MMR015017\", \"MMR014006\", \"MMR014007\", \"MMR014009\", \"MMR01501…\n$ geometry &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((96.96001 23..., MULTIPOLYGON (((…\n\n\n\n\n\n\n# Read the ICT attributes table (CSV) ------------------------------------------\nict &lt;- readr::read_csv(\"data/aspatial/Shan-ICT.csv\")  # loads as a tibble data.frame\n\nRows: 55 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): District Pcode, District Name, Township Pcode, Township Name\ndbl (7): Total households, Radio, Television, Land line phone, Mobile phone,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Review the summary statistics of raw counts ----------------------------------\nsummary(ict)         \n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0  \n\n\n\n\n\nWe convert raw household counts to per‑thousand‑household penetration rates to remove bias due to township size.\n\n# Derive penetration rates and tidy names --------------------------------------\nict_derived &lt;- ict %&gt;%\n  dplyr::mutate(RADIO_PR    = `Radio`/`Total households` * 1000) %&gt;%            # Radio per 1000 households\n  dplyr::mutate(TV_PR       = `Television`/`Total households` * 1000) %&gt;%       # TV per 1000 households\n  dplyr::mutate(LLPHONE_PR  = `Land line phone`/`Total households` * 1000) %&gt;%  # Landline per 1000 households\n  dplyr::mutate(MPHONE_PR   = `Mobile phone`/`Total households` * 1000) %&gt;%     # Mobile per 1000 households\n  dplyr::mutate(COMPUTER_PR = `Computer`/`Total households` * 1000) %&gt;%         # Computer per 1000 households\n  dplyr::mutate(INTERNET_PR = `Internet at home`/`Total households` * 1000) %&gt;% # Internet per 1000 households\n  dplyr::rename(`DT_PCODE`     = `District Pcode`,                              # harmonise id fields to tidy names\n                `DT`           = `District Name`,\n                `TS_PCODE`     = `Township Pcode`,\n                `TS`           = `Township Name`,\n                `TT_HOUSEHOLDS`= `Total households`,\n                `RADIO`        = `Radio`,\n                `TV`           = `Television`,\n                `LLPHONE`      = `Land line phone`,\n                `MPHONE`       = `Mobile phone`,\n                `COMPUTER`     = `Computer`,\n                `INTERNET`     = `Internet at home`)\n\n\n# Review penetration rates after derivation ------------------------------------\nsummary(ict_derived)     # confirms new *_PR fields       \n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 21.05  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:138.95  \n Median : 3559   Median : 244.0   Median : 316.0   Median :210.95  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :215.68  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:268.07  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :484.52  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :116.0   Min.   :  2.78   Min.   : 36.42   Min.   : 3.278  \n 1st Qu.:450.2   1st Qu.: 22.84   1st Qu.:190.14   1st Qu.:11.832  \n Median :517.2   Median : 37.59   Median :305.27   Median :18.970  \n Mean   :509.5   Mean   : 51.09   Mean   :314.05   Mean   :24.393  \n 3rd Qu.:606.4   3rd Qu.: 69.72   3rd Qu.:428.43   3rd Qu.:29.897  \n Max.   :842.5   Max.   :181.49   Max.   :735.43   Max.   :92.402  \n  INTERNET_PR     \n Min.   :  1.041  \n 1st Qu.:  8.617  \n Median : 22.829  \n Mean   : 30.644  \n 3rd Qu.: 41.281  \n Max.   :117.985  \n\n\n\n\n\n\n\n\nNoteObservation:\n\n\n\nNotice that six new fields have been added into the data.frame. They are RADIO_PR, TV_PR, LLPHONE_PR, MPHONE_PR, COMPUTER_PR, and INTERNET_PR.\n\n\n\n\n\n\n\n\nThe code chunks below are used to create the data visualisation. They consist of two main parts. First, we will create the individual histograms using the code chunk below.\n\n# Histogram and boxplot for RADIO (raw counts) ---------------------------------\nggplot(data = ict_derived, aes(x = `RADIO`)) +          # choose RADIO (raw) for distribution\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")  # 20 bins; black border; light blue fill\n\n\n\n\n\n\n\nggplot(data = ict_derived, aes(x = `RADIO`)) +          # same variable for outlier check\n  geom_boxplot(color = \"black\", fill = \"light blue\")    # boxplot style\n\n\n\n\n\n\n\n# Histogram and boxplot for RADIO_PR (per-thousand) ----------------------------\nggplot(data = ict_derived, aes(x = `RADIO_PR`)) +       # scaled rate variable\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")  # distribution after scaling\n\n\n\n\n\n\n\nggplot(data = ict_derived, aes(x = `RADIO_PR`)) +       # outlier check on rate\n  geom_boxplot(color = \"black\", fill = \"light blue\")    # single extreme points easily seen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteWhat can you observed from the distributions reveal in the histogram and boxplot?\n\n\n\nFor RADIO (original values)\nHistogram:\n\nThe distribution is highly right-skewed (positively skewed)\n\nMost values are concentrated at the lower end (close to 0–5000)\n\nThere are a few very large values (e.g., ~30,000), suggesting the presence of extreme outliers\n\nBoxplot:\n\nConfirms the positive skewness seen in the histogram\n\nA long whisker extends to the right, and several outliers (dots) appear at high values (&gt;10,000, &gt;30,000).\nThe median is much closer to the lower quartile, reinforcing that most data is clustered at the low end.\n\n\nInterpretation: The RADIO variable has extreme variation with a few very large outliers dominating the scale. Data transformation (e.g., log transform) may be useful to reduce skewness and bring values closer to normality.\n\nFor RADIO_PR (processed/normalized values)\nHistogram:\n\nThe distribution is more uniform and relatively symmetric compared to RADIO\n\nValues spread between 0 and 500, with no extreme concentration at the low end\n\nThe central tendency seems more balanced around 200\n\nBoxplot:\n\nShows a more symmetric spread with a wider interquartile range\n\nOnly one mild outlier (~500)\n\nMedian is near the center of the box, indicating less skewness than RADIO\n\n\nInterpretation: RADIO_PR is much more normalized and balanced compared to RADIO. The transformation/processing (likely standardization or scaling) effectively reduced skewness and limited extreme outlier effects.\n\n\n\nNext, the ggarrange() function of ggpubr package is used to group these histograms together.\n\n# Multiple histograms: create one plot per ICT rate ----------------------------\nradio    &lt;- ggplot(ict_derived, aes(x = `RADIO_PR`))    + geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\ntv       &lt;- ggplot(ict_derived, aes(x = `TV_PR`))       + geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\nllphone  &lt;- ggplot(ict_derived, aes(x = `LLPHONE_PR`))  + geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\nmphone   &lt;- ggplot(ict_derived, aes(x = `MPHONE_PR`))   + geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\ncomputer &lt;- ggplot(ict_derived, aes(x = `COMPUTER_PR`)) + geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\ninternet &lt;- ggplot(ict_derived, aes(x = `INTERNET_PR`)) + geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggpubr::ggarrange(radio, tv, llphone, mphone, computer, internet,  # arrange 6 histograms\n                   ncol = 3, nrow = 2)                             # arrange plots in grid 3x2 \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Join geospatial (shan_sf) with aspatial (ict_derived) by TS_PCODE -------------\nshan_sf &lt;- dplyr::left_join(shan_sf, ict_derived, by = c(\"TS_PCODE\" = \"TS_PCODE\"))  # enrich polygons with ICT\n\n\n# Persist and reload  -----------------------------\n\nreadr::write_rds(shan_sf, \"data/rds/shan_sf.rds\")  # save result to RDS\n\nshan_sf &lt;- readr::read_rds(\"data/rds/shan_sf.rds\") # reload to ensure reproducibility\n\n\n# Quick choropleth of RADIO_PR using tmap (qtm) --------------------------------\nqtm(shan_sf, \"RADIO_PR\")      # quick thematic map for a single variable\n\n\n\n\n\n\n\n\n\n# Compare raw totals vs rate using two side-by-side choropleths -----------------\nTT_HOUSEHOLDS.map &lt;- tm_shape(shan_sf) +                            # base shape: township polygons\n  tm_fill(col = \"TT_HOUSEHOLDS\", n = 5, style = \"jenks\", title = \"Total households\") +\n  tm_borders(alpha = 0.5)                                           # light borders as in notes\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_polygons()`: instead of `style = \"jenks\"`, use fill.scale =\n`tm_scale_intervals()`.\nℹ Migrate the argument(s) 'style', 'n' to 'tm_scale_intervals(&lt;HERE&gt;)'\n[v3-&gt;v4] `tm_polygons()`: use 'fill' for the fill color of polygons/symbols\n(instead of 'col'), and 'col' for the outlines (instead of 'border.col').\n[v3-&gt;v4] `tm_polygons()`: migrate the argument(s) related to the legend of the\nvisual variable `fill` namely 'title' to 'fill.legend = tm_legend(&lt;HERE&gt;)'\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n\nRADIO.map &lt;- tm_shape(shan_sf) +                                   # second map for raw RADIO counts\n  tm_fill(col = \"RADIO\", n = 5, style = \"jenks\", title = \"Number Radio \") +\n  tm_borders(alpha = 0.5)\n\n[v3-&gt;v4] `tm_polygons()`: migrate the argument(s) related to the legend of the\nvisual variable `fill` namely 'title' to 'fill.legend = tm_legend(&lt;HERE&gt;)'\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map, asp = NA, ncol = 2)     # view side-by-side\n\n\n\n\n\n\n\n\n\n# Faceted choropleth for TT_HOUSEHOLDS and RADIO_PR ----------------------------\ntm_shape(shan_sf) +\n  tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"), style = \"jenks\") +   # show both variables as facets\n  tm_facets(sync = TRUE, ncol = 2) +                               # same breaks/legends aligned\n  tm_legend(legend.position = c(\"right\", \"bottom\")) +              # legend position\n  tm_layout(outer.margins = 0, asp = 0)                             # fill layout; ignore aspect lock\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_polygons()`: instead of `style = \"jenks\"`, use fill.scale =\n`tm_scale_intervals()`.\nℹ Migrate the argument(s) 'style' to 'tm_scale_intervals(&lt;HERE&gt;)'\n[v3-&gt;v4] `tm_legend()`: use 'tm_legend()' inside a layer function, e.g.\n'tm_polygons(..., fill.legend = tm_legend())'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteCan you identify the differences?\n\n\n\nWe use style=\"jenks\" so that the classification adapts to the real distribution of households and penetration rates. This produces more meaningful groupings and reveals disparities that fixed intervals might hide. That’s why the bottom maps (with Jenks) highlight differences in adoption (penetration rate) more clearly than the top maps (absolute counts with equal breaks).\n\n\n\n\n\n\n\n\n# Compute correlation among penetration-rate variables -------------------------\ncluster_vars.cor &lt;- stats::cor(ict_derived[, 12:17]) # columns 12..17 are *_PR variables\n\n\n# Mixed correlation plot (numbers + ellipses) ----------------------------------\ncorrplot::corrplot.mixed(cluster_vars.cor, # matrix of correlations\nlower = \"ellipse\", # lower triangle as ellipses\nupper = \"number\", # upper triangle shows numeric values\ntl.pos = \"lt\", # variable labels at left-top\ndiag = \"l\", # show diagonal line\ntl.col = \"black\") # black label text\n\n\n\n\n\n\n\n\n\nThe plot usually shows COMPUTER_PR and INTERNET_PR as highly correlated; we will keep only one (COMPUTER_PR) for clustering to avoid redundancy.\n\n\n\n\n\n\n\n# Pull clustering variables from the joined sf and drop geometry ----------------\ncluster_vars &lt;- shan_sf %&gt;%\nsf::st_set_geometry(NULL) %&gt;% # remove geometry columns\ndplyr::select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", # keep town name + selected *_PR vars\n\"MPHONE_PR\", \"COMPUTER_PR\")\n\nhead(cluster_vars, 10) # preview first 10 rows\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\n\n\n\n\n\nNoteObservation\n\n\n\nNotice that the final clustering variables list does not include variable INTERNET_PR because it is highly correlated with variable COMPUTER_PR.\n\n\nNext, we need to change the rows by township name instead of row number by using the code chunk below\n\n# Set township names as row names for clustering display -----------------------\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\" # dendrogram labels use township names\n\nhead(cluster_vars, 10) # verify row names applied\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\n\n\n\n\n\nNoteObservation\n\n\n\nNotice that the row number has been replaced into the township name.\n\n\nNow, we will delete the TS.x field by using the code chunk below.\n\n# Remove the name column from the clustering data.frame ------------------------\n\nshan_ict &lt;- dplyr::select(cluster_vars, c(2:6)) # keep only numeric *_PR fields\n\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\n# Persist to RDS to follow notes ------------------------------------------------\nreadr::write_rds(shan_ict, \"data/rds/shan_ict.rds\") # save numeric matrix as tibble\n\n\n\n\nMultiple variables have different ranges; we standardise before computing distances.\n\n\n\n\n# Min–Max scale each column to [0,1] using heatmaply::normalize -----------------\nshan_ict.std &lt;- heatmaply::normalize(shan_ict) # returns scaled data.frame\nsummary(shan_ict.std) # confirm min=0, max=1 per variable\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\n\n\n\n\n\n\nNoteObservation:\n\n\n\nNotice that the values range of the Min-max standardised clustering variables are 0-1 now.\n\n\n\n\n\n\n# Z-score scale (mean=0, sd=1) -------------------------------------------------\nshan_ict.z &lt;- scale(shan_ict) # matrix with standardized columns\npsych::describe(shan_ict.z) # convenient table incl. sd, skew, kurtosis\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\n\n\n\n\n\n\nNoteObservation:\n\n\n\nNotice the mean and standard deviation of the Z-score standardised clustering variables are 0 and 1 respectively.\n\n\n\n\n\n\n\n\nNote\n\n\n\ndescribe() of psych package is used here instead of summary() of Base R because the earlier provides standard deviation.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nZ-score standardisation method should only be used if we would assume all variables come from some normal distribution.\n\n\n\n\n\nBeside reviewing the summary statistics of the standardised clustering variables, it is also a good practice to visualise their distribution graphical.\nThe code chunk below plot the scaled Radio_PR field.\n\n# Compare histograms for RADIO_PR across raw/minmax/z-score --------------------\nr &lt;- ggplot(ict_derived, aes(x = `RADIO_PR`)) + # raw rate distribution\ngeom_histogram(bins = 20, color = \"black\", fill = \"light blue\") +\nggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std) # cast to data.frame for ggplot\ns &lt;- ggplot(shan_ict_s_df, aes(x = `RADIO_PR`)) + # min-max scaled distribution\ngeom_histogram(bins = 20, color = \"black\", fill = \"light blue\") +\nggtitle(\"Min–Max Standardisation\")\n\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z) # z-scored matrix to data.frame\nz &lt;- ggplot(shan_ict_z_df, aes(x = `RADIO_PR`)) + # z-score distribution\ngeom_histogram(bins = 20, color = \"black\", fill = \"light blue\") +\nggtitle(\"Z-score Standardisation\")\n\n\nggpubr::ggarrange(r, s, z, ncol = 3, nrow = 1) # 3 histograms in one row\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteWhat statistical conclusion can you draw from the histograms above?\n\n\n\nImplications of Standardisation Methods\n\nRaw Values\n\nKeeping raw values may be fine if all variables are measured on the same scale (e.g., all in dollars).\n\nHowever, when variables differ in scale (e.g., RADIO_PR in hundreds vs TV_PR in thousands), models may be biased toward the larger-scale variable.\n\nNot suitable for distance-based methods (kNN, clustering) or optimization algorithms (gradient descent), because large values dominate.\n\nMin–Max Standardisation\n\nScales all values to the fixed interval [0,1].\n\nPreserves the distribution shape and relative distances.\n\nWorks well when features are bounded and we want to keep proportionality (e.g., image pixels, probabilities).\n\nSensitive to outliers: a single extreme value can stretch the range and compress the majority of the data.\n\nZ-score Standardisation\n\nCenters data at mean = 0, scales variance to 1.\n\nUseful for comparing across variables with different scales or units (e.g., comparing exam scores out of 100 vs heights in cm).\n\nLess affected by outliers compared to Min–Max (though still sensitive if outliers are extreme).\n\nParticularly suitable for statistical methods assuming normality or measuring relative deviations (e.g., regression, PCA, clustering).\n\n\nWhen to use which method?\n\nUse Raw Values only if all features are already comparable in scale.\n\nUse Min–Max when working with bounded ranges (e.g., neural networks, image processing).\n\nUse Z-score when the goal is comparability across different units, or when methods assume standardized input (e.g., PCA, k-means, regression).\n\nTakeaway:\nThe histograms confirm that standardisation changes scale but not distributional shape. The choice of method depends on the statistical technique and the role of the variable in the model.\n\n\n\n# Density comparison (same three panels) ---------------------------------------\nr &lt;- ggplot(ict_derived, aes(x = `RADIO_PR`)) + geom_density(color = \"black\", fill = \"light blue\") + ggtitle(\"Raw values without standardisation\")\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std); s &lt;- ggplot(shan_ict_s_df, aes(x = `RADIO_PR`)) + geom_density(color = \"black\", fill = \"light blue\") + ggtitle(\"Min–Max Standardisation\")\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z); z &lt;- ggplot(shan_ict_z_df, aes(x = `RADIO_PR`)) + geom_density(color = \"black\", fill = \"light blue\") + ggtitle(\"Z-score Standardisation\")\n\n\nggpubr::ggarrange(r, s, z, ncol = 3, nrow = 1) # density panels\n\n\n\n\n\n\n\n\n\n\n\nIn R, many packages provide functions to calculate distance matrix. We will compute the proximity matrix by using dist() of R.\ndist() supports six distance proximity calculations, they are: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is euclidean proximity matrix.\nThe code chunk below is used to compute the proximity matrix using euclidean method.\n\n# Euclidean distance among townships based on *_PR variables --------------------\nproxmat &lt;- stats::dist(shan_ict, method = 'euclidean') # produces a 'dist' object\n\nproxmat\n\n             Mongmit   Pindaya   Ywangan  Pinlaung    Mabein     Kalaw\nPindaya    171.86828                                                  \nYwangan    381.88259 257.31610                                        \nPinlaung    57.46286 208.63519 400.05492                              \nMabein     263.37099 313.45776 529.14689 312.66966                    \nKalaw      160.05997 302.51785 499.53297 181.96406 198.14085          \nPekon       59.61977 117.91580 336.50410  94.61225 282.26877 211.91531\nLawksawk   140.11550 204.32952 432.16535 192.57320 130.36525 140.01101\nNawnghkio   89.07103 180.64047 377.87702 139.27495 204.63154 127.74787\nKyaukme    144.02475 311.01487 505.89191 139.67966 264.88283  79.42225\nMuse       563.01629 704.11252 899.44137 571.58335 453.27410 412.46033\nLaihka     141.87227 298.61288 491.83321 101.10150 345.00222 197.34633\nMongnai    115.86190 258.49346 422.71934  64.52387 358.86053 200.34668\nMawkmai    434.92968 437.99577 397.03752 398.11227 693.24602 562.59200\nKutkai      97.61092 212.81775 360.11861  78.07733 340.55064 204.93018\nMongton    192.67961 283.35574 361.23257 163.42143 425.16902 267.87522\nMongyai    256.72744 287.41816 333.12853 220.56339 516.40426 386.74701\nMongkaing  503.61965 481.71125 364.98429 476.29056 747.17454 625.24500\nLashio     251.29457 398.98167 602.17475 262.51735 231.28227 106.69059\nMongpan    193.32063 335.72896 483.68125 192.78316 301.52942 114.69105\nMatman     401.25041 354.39039 255.22031 382.40610 637.53975 537.63884\nTachileik  529.63213 635.51774 807.44220 555.01039 365.32538 373.64459\nNarphan    406.15714 474.50209 452.95769 371.26895 630.34312 463.53759\nMongkhet   349.45980 391.74783 408.97731 305.86058 610.30557 465.52013\nHsipaw     118.18050 245.98884 388.63147  76.55260 366.42787 212.36711\nMonghsat   214.20854 314.71506 432.98028 160.44703 470.48135 317.96188\nMongmao    242.54541 402.21719 542.85957 217.58854 384.91867 195.18913\nNansang    104.91839 275.44246 472.77637  85.49572 287.92364 124.30500\nLaukkaing  568.27732 726.85355 908.82520 563.81750 520.67373 427.77791\nPangsang   272.67383 428.24958 556.82263 244.47146 418.54016 224.03998\nNamtu      179.62251 225.40822 444.66868 170.04533 366.16094 307.27427\nMonghpyak  177.76325 221.30579 367.44835 222.20020 212.69450 167.08436\nKonkyan    403.39082 500.86933 528.12533 365.44693 613.51206 444.75859\nMongping   265.12574 310.64850 337.94020 229.75261 518.16310 375.64739\nHopong     136.93111 223.06050 352.85844  98.14855 398.00917 264.16294\nNyaungshwe  99.38590 216.52463 407.11649 138.12050 210.21337  95.66782\nHsihseng   131.49728 172.00796 342.91035 111.61846 381.20187 287.11074\nMongla     384.30076 549.42389 728.16301 372.59678 406.09124 260.26411\nHseni      189.37188 337.98982 534.44679 204.47572 213.61240  38.52842\nKunlong    224.12169 355.47066 531.63089 194.76257 396.61508 273.01375\nHopang     281.05362 443.26362 596.19312 265.96924 368.55167 185.14704\nNamhkan    386.02794 543.81859 714.43173 382.78835 379.56035 246.39577\nKengtung   246.45691 385.68322 573.23173 263.48638 219.47071  88.29335\nLangkho    164.26299 323.28133 507.78892 168.44228 253.84371  67.19580\nMonghsu    109.15790 198.35391 340.42789  80.86834 367.19820 237.34578\nTaunggyi   399.84278 503.75471 697.98323 429.54386 226.24011 252.26066\nPangwaun   381.51246 512.13162 580.13146 356.37963 523.44632 338.35194\nKyethi     202.92551 175.54012 287.29358 189.47065 442.07679 360.17247\nLoilen     145.48666 293.61143 469.51621  91.56527 375.06406 217.19877\nManton     430.64070 402.42888 306.16379 405.83081 674.01120 560.16577\nMongyang   309.51302 475.93982 630.71590 286.03834 411.88352 233.56349\nKunhing    173.50424 318.23811 449.67218 141.58836 375.82140 197.63683\nMongyawng  214.21738 332.92193 570.56521 235.55497 193.49994 173.43078\nTangyan    195.92520 208.43740 324.77002 169.50567 448.59948 348.06617\nNamhsan    237.78494 228.41073 286.16305 214.33352 488.33873 385.88676\n               Pekon  Lawksawk Nawnghkio   Kyaukme      Muse    Laihka\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk   157.51129                                                  \nNawnghkio  113.15370  90.82891                                        \nKyaukme    202.12206 186.29066 157.04230                              \nMuse       614.56144 510.13288 533.68806 434.75768                    \nLaihka     182.23667 246.74469 211.88187 128.24979 526.65211          \nMongnai    151.60031 241.71260 182.21245 142.45669 571.97975 100.53457\nMawkmai    416.00669 567.52693 495.15047 512.02846 926.93007 429.96554\nKutkai     114.98048 224.64646 147.44053 170.93318 592.90743 144.67198\nMongton    208.14888 311.07742 225.81118 229.28509 634.71074 212.07320\nMongyai    242.52301 391.26989 319.57938 339.27780 763.91399 264.13364\nMongkaing  480.23965 625.18712 546.69447 586.05094 995.66496 522.96309\nLashio     303.80011 220.75270 230.55346 129.95255 313.15288 238.64533\nMongpan    243.30037 228.54223 172.84425 110.37831 447.49969 210.76951\nMatman     368.25761 515.39711 444.05061 505.52285 929.11283 443.25453\nTachileik  573.39528 441.82621 470.45533 429.15493 221.19950 549.08985\nNarphan    416.84901 523.69580 435.59661 420.30003 770.40234 392.32592\nMongkhet   342.08722 487.41102 414.10280 409.03553 816.44931 324.97428\nHsipaw     145.37542 249.35081 176.09570 163.95741 591.03355 128.42987\nMonghsat   225.64279 352.31496 289.83220 253.25370 663.76026 158.93517\nMongmao    293.70625 314.64777 257.76465 146.09228 451.82530 185.99082\nNansang    160.37607 188.78869 151.13185  60.32773 489.35308  78.78999\nLaukkaing  624.82399 548.83928 552.65554 428.74978 149.26996 507.39700\nPangsang   321.81214 345.91486 287.10769 175.35273 460.24292 214.19291\nNamtu      165.02707 260.95300 257.52713 270.87277 659.16927 185.86794\nMonghpyak  190.93173 142.31691  93.03711 217.64419 539.43485 293.22640\nKonkyan    421.48797 520.31264 439.34272 393.79911 704.86973 351.75354\nMongping   259.68288 396.47081 316.14719 330.28984 744.44948 272.82761\nHopong     138.86577 274.91604 204.88286 218.84211 648.68011 157.48857\nNyaungshwe 139.31874 104.17830  43.26545 126.50414 505.88581 201.71653\nHsihseng   105.30573 257.11202 209.88026 250.27059 677.66886 175.89761\nMongla     441.20998 393.18472 381.40808 241.58966 256.80556 315.93218\nHseni      243.98001 171.50398 164.05304  81.20593 381.30567 204.49010\nKunlong    249.36301 318.30406 285.04608 215.63037 547.24297 122.68682\nHopang     336.38582 321.16462 279.84188 154.91633 377.44407 230.78652\nNamhkan    442.77120 379.41126 367.33575 247.81990 238.67060 342.43665\nKengtung   297.67761 209.38215 208.29647 136.23356 330.08211 258.23950\nLangkho    219.21623 190.30257 156.51662  51.67279 413.64173 160.94435\nMonghsu    113.84636 242.04063 170.09168 200.77712 633.21624 163.28926\nTaunggyi   440.66133 304.96838 344.79200 312.60547 250.81471 425.36916\nPangwaun   423.81347 453.02765 381.67478 308.31407 541.97887 351.78203\nKyethi     162.43575 317.74604 267.21607 328.14177 757.16745 255.83275\nLoilen     181.94596 265.29318 219.26405 146.92675 560.43400  59.69478\nManton     403.82131 551.13000 475.77296 522.86003 941.49778 458.30232\nMongyang   363.58788 363.37684 323.32123 188.59489 389.59919 229.71502\nKunhing    213.46379 278.68953 206.15773 145.00266 533.00162 142.03682\nMongyawng  248.43910 179.07229 220.61209 181.55295 422.37358 211.99976\nTangyan    167.79937 323.14701 269.07880 306.78359 736.93741 224.29176\nNamhsan    207.16559 362.84062 299.74967 347.85944 778.52971 273.79672\n             Mongnai   Mawkmai    Kutkai   Mongton   Mongyai Mongkaing\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai    374.50873                                                  \nKutkai      91.15307 364.95519                                        \nMongton    131.67061 313.35220 107.06341                              \nMongyai    203.23607 178.70499 188.94166 159.79790                    \nMongkaing  456.00842 133.29995 428.96133 365.50032 262.84016          \nLashio     270.86983 638.60773 289.82513 347.11584 466.36472 708.65819\nMongpan    178.09554 509.99632 185.18173 200.31803 346.39710 563.56780\nMatman     376.33870 147.83545 340.86349 303.04574 186.95158 135.51424\nTachileik  563.95232 919.38755 568.99109 608.76740 750.29555 967.14087\nNarphan    329.31700 273.75350 314.27683 215.97925 248.82845 285.65085\nMongkhet   275.76855 115.58388 273.91673 223.22828 104.98924 222.60577\nHsipaw      52.68195 351.34601  51.46282  90.69766 177.33790 423.77868\nMonghsat   125.25968 275.09705 154.32012 150.98053 127.35225 375.60376\nMongmao    188.29603 485.52853 204.69232 206.57001 335.61300 552.31959\nNansang     92.79567 462.41938 130.04549 199.58124 288.55962 542.16609\nLaukkaing  551.56800 882.51110 580.38112 604.66190 732.68347 954.11795\nPangsang   204.25746 484.14757 228.33583 210.77938 343.30638 548.40662\nNamtu      209.35473 427.95451 225.28268 308.71751 278.02761 525.04057\nMonghpyak  253.26470 536.71695 206.61627 258.04282 370.01575 568.21089\nKonkyan    328.82831 339.01411 310.60810 248.25265 287.87384 380.92091\nMongping   202.99615 194.31049 182.75266 119.86993  65.38727 257.18572\nHopong      91.53795 302.84362  73.45899 106.21031 124.62791 379.37916\nNyaungshwe 169.63695 502.99026 152.15482 219.72196 327.13541 557.32112\nHsihseng   142.36728 329.29477 128.21054 194.64317 162.27126 411.59788\nMongla     354.10985 686.88950 388.40984 411.06668 535.28615 761.48327\nHseni      216.81639 582.53670 229.37894 286.75945 408.23212 648.04408\nKunlong    202.92529 446.53763 204.54010 270.02165 299.36066 539.91284\nHopang     243.00945 561.24281 263.31986 273.50305 408.73288 626.17673\nNamhkan    370.05669 706.47792 392.48568 414.53594 550.62819 771.39688\nKengtung   272.28711 632.54638 279.19573 329.38387 460.39706 692.74693\nLangkho    174.67678 531.08019 180.51419 236.70878 358.95672 597.42714\nMonghsu     84.11238 332.07962  62.60859 107.04894 154.86049 400.71816\nTaunggyi   448.55282 810.74692 450.33382 508.40925 635.94105 866.21117\nPangwaun   312.13429 500.68857 321.80465 257.50434 394.07696 536.95736\nKyethi     210.50453 278.85535 184.23422 222.52947 137.79420 352.06533\nLoilen      58.41263 388.73386 131.56529 176.16001 224.79239 482.18190\nManton     391.54062 109.08779 361.82684 310.20581 195.59882  81.75337\nMongyang   260.39387 558.83162 285.33223 295.60023 414.31237 631.91325\nKunhing    110.55197 398.43973 108.84990 114.03609 238.99570 465.03971\nMongyawng  275.77546 620.04321 281.03383 375.22688 445.78964 700.98284\nTangyan    180.37471 262.66006 166.61820 198.88460 109.08506 348.56123\nNamhsan    218.10003 215.19289 191.32762 196.76188  77.35900 288.66231\n              Lashio   Mongpan    Matman Tachileik   Narphan  Mongkhet\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan    172.33279                                                  \nMatman     628.11049 494.81014                                        \nTachileik  311.95286 411.03849 890.12935                              \nNarphan    525.63854 371.13393 312.05193 760.29566                    \nMongkhet   534.44463 412.17123 203.02855 820.50164 217.28718          \nHsipaw     290.86435 179.52054 344.45451 576.18780 295.40170 253.80950\nMonghsat   377.86793 283.30992 313.59911 677.09508 278.21548 167.98445\nMongmao    214.23677 131.59966 501.59903 472.95568 331.42618 375.35820\nNansang    184.47950 144.77393 458.06573 486.77266 398.13308 360.99219\nLaukkaing  334.65738 435.58047 903.72094 325.06329 708.82887 769.06406\nPangsang   236.72516 140.23910 506.29940 481.31907 316.30314 375.58139\nNamtu      365.88437 352.91394 416.65397 659.56458 494.36143 355.99713\nMonghpyak  262.09281 187.85699 470.46845 444.04411 448.40651 462.63265\nKonkyan    485.51312 365.87588 392.40306 730.92980 158.82353 254.24424\nMongping   454.52548 318.47482 201.65224 727.08969 188.64567 113.80917\nHopong     345.31042 239.43845 291.84351 632.45718 294.40441 212.99485\nNyaungshwe 201.58191 137.29734 460.91883 445.81335 427.94086 417.08639\nHsihseng   369.00833 295.87811 304.02806 658.87060 377.52977 256.70338\nMongla     179.95877 253.20001 708.17595 347.33155 531.46949 574.40292\nHseni       79.41836 120.66550 564.64051 354.90063 474.12297 481.88406\nKunlong    295.23103 288.03320 468.27436 595.70536 413.07823 341.68641\nHopang     170.63913 135.62913 573.55355 403.82035 397.85908 451.51070\nNamhkan    173.27153 240.34131 715.42102 295.91660 536.85519 596.19944\nKengtung    59.85893 142.21554 613.01033 295.90429 505.40025 531.35998\nLangkho    115.18145  94.98486 518.86151 402.33622 420.65204 428.08061\nMonghsu    325.71557 216.25326 308.13805 605.02113 311.92379 247.73318\nTaunggyi   195.14541 319.81385 778.45810 150.84117 684.20905 712.80752\nPangwaun   362.45608 232.52209 523.43600 540.60474 264.64997 407.02947\nKyethi     447.10266 358.89620 233.83079 728.87329 374.90376 233.25039\nLoilen     268.92310 207.25000 406.56282 573.75476 354.79137 284.76895\nManton     646.66493 507.96808  59.52318 910.23039 280.26395 181.33894\nMongyang   209.33700 194.93467 585.61776 448.79027 401.39475 445.40621\nKunhing    255.10832 137.85278 403.66587 532.26397 281.62645 292.49814\nMongyawng  172.70139 275.15989 601.80824 432.10118 572.76394 522.91815\nTangyan    429.84475 340.39128 242.78233 719.84066 348.84991 201.49393\nNamhsan    472.04024 364.77086 180.09747 754.03913 316.54695 170.90848\n              Hsipaw  Monghsat   Mongmao   Nansang Laukkaing  Pangsang\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat   121.78922                                                  \nMongmao    185.99483 247.17708                                        \nNansang    120.24428 201.92690 164.99494                              \nLaukkaing  569.06099 626.44910 404.00848 480.60074                    \nPangsang   205.04337 256.37933  57.60801 193.36162 408.04016          \nNamtu      229.44658 231.78673 365.03882 217.61884 664.06286 392.97391\nMonghpyak  237.67919 356.84917 291.88846 227.52638 565.84279 315.11651\nKonkyan    296.74316 268.25060 281.87425 374.70456 635.92043 274.81900\nMongping   168.92101 140.95392 305.57166 287.36626 708.13447 308.33123\nHopong      62.86179 100.45714 244.16253 167.66291 628.48557 261.51075\nNyaungshwe 169.92664 286.37238 230.45003 131.18943 520.24345 257.77823\nHsihseng   136.54610 153.49551 311.98001 193.53779 670.74564 335.52974\nMongla     373.47509 429.00536 216.24705 289.45119 202.55831 217.88123\nHseni      231.48538 331.22632 184.67099 136.45492 391.74585 214.66375\nKunlong    205.10051 202.31862 224.43391 183.01388 521.88657 258.49342\nHopang     248.72536 317.64824  78.29342 196.47091 331.67199  92.57672\nNamhkan    382.79302 455.10875 223.32205 302.89487 196.46063 231.38484\nKengtung   284.08582 383.72138 207.58055 193.67980 351.48520 229.85484\nLangkho    183.05109 279.52329 134.50170  99.39859 410.41270 167.65920\nMonghsu     58.55724 137.24737 242.43599 153.59962 619.01766 260.52971\nTaunggyi   462.31183 562.88102 387.33906 365.04897 345.98041 405.59730\nPangwaun   298.12447 343.53898 187.40057 326.12960 470.63605 157.48757\nKyethi     195.17677 190.50609 377.89657 273.02385 749.99415 396.89963\nLoilen      98.04789 118.65144 190.26490  94.23028 535.57527 207.94433\nManton     359.60008 317.15603 503.79786 476.55544 907.38406 504.75214\nMongyang   267.10497 312.64797  91.06281 218.49285 326.19219 108.37735\nKunhing     90.77517 165.38834 103.91040 128.20940 500.41640 123.18870\nMongyawng  294.70967 364.40429 296.40789 191.11990 454.80044 336.16703\nTangyan    167.69794 144.59626 347.14183 249.70235 722.40954 364.76893\nNamhsan    194.47928 169.56962 371.71448 294.16284 760.45960 385.65526\n               Namtu Monghpyak   Konkyan  Mongping    Hopong Nyaungshwe\nPindaya                                                                \nYwangan                                                                \nPinlaung                                                               \nMabein                                                                 \nKalaw                                                                  \nPekon                                                                  \nLawksawk                                                               \nNawnghkio                                                              \nKyaukme                                                                \nMuse                                                                   \nLaihka                                                                 \nMongnai                                                                \nMawkmai                                                                \nKutkai                                                                 \nMongton                                                                \nMongyai                                                                \nMongkaing                                                              \nLashio                                                                 \nMongpan                                                                \nMatman                                                                 \nTachileik                                                              \nNarphan                                                                \nMongkhet                                                               \nHsipaw                                                                 \nMonghsat                                                               \nMongmao                                                                \nNansang                                                                \nLaukkaing                                                              \nPangsang                                                               \nNamtu                                                                  \nMonghpyak  346.57799                                                   \nKonkyan    478.37690 463.39594                                         \nMongping   321.66441 354.76537 242.02901                               \nHopong     206.82668 267.95563 304.49287 134.00139                     \nNyaungshwe 271.41464 103.97300 432.35040 319.32583 209.32532           \nHsihseng   131.89940 285.37627 383.49700 199.64389  91.65458  225.80242\nMongla     483.49434 408.03397 468.09747 512.61580 432.31105  347.60273\nHseni      327.41448 200.26876 448.84563 395.58453 286.41193  130.86310\nKunlong    233.60474 357.44661 329.11433 309.05385 219.06817  285.13095\nHopang     408.24516 304.26577 348.18522 379.27212 309.77356  247.19891\nNamhkan    506.32466 379.50202 481.59596 523.74815 444.13246  333.32428\nKengtung   385.33554 221.47613 474.82621 442.80821 340.47382  177.75714\nLangkho    305.03473 200.27496 386.95022 343.96455 239.63685  128.26577\nMonghsu    209.64684 232.17823 331.72187 158.90478  43.40665  173.82799\nTaunggyi   518.72748 334.17439 650.56905 621.53039 513.76415  325.09619\nPangwaun   517.03554 381.95144 263.97576 340.37881 346.00673  352.92324\nKyethi     186.90932 328.16234 400.10989 187.43974 136.49038  288.06872\nLoilen     194.24075 296.99681 334.19820 231.99959 124.74445  206.40432\nManton     448.58230 502.20840 366.66876 200.48082 310.58885  488.79874\nMongyang   413.26052 358.17599 329.39338 387.80686 323.35704  294.29500\nKunhing    296.43996 250.74435 253.74202 212.59619 145.15617  189.97131\nMongyawng  262.24331 285.56475 522.38580 455.59190 326.59925  218.12104\nTangyan    178.69483 335.26416 367.46064 161.67411 106.82328  284.14692\nNamhsan    240.95555 352.70492 352.20115 130.23777 132.70541  315.91750\n            Hsihseng    Mongla     Hseni   Kunlong    Hopang   Namhkan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla     478.66210                                                  \nHseni      312.74375 226.82048                                        \nKunlong    231.85967 346.46200 276.19175                              \nHopang     370.01334 147.02444 162.80878 271.34451                    \nNamhkan    492.09476  77.21355 212.11323 375.73885 146.18632          \nKengtung   370.72441 202.45004  66.12817 317.14187 164.29921 175.63015\nLangkho    276.27441 229.01675  66.66133 224.52741 134.24847 224.40029\nMonghsu     97.82470 424.51868 262.28462 239.89665 301.84458 431.32637\nTaunggyi   528.14240 297.09863 238.19389 471.29032 329.95252 257.29147\nPangwaun   433.06326 319.18643 330.70182 392.45403 206.98364 310.44067\nKyethi      84.04049 556.02500 388.33498 298.55859 440.48114 567.86202\nLoilen     158.84853 338.67408 227.10984 166.53599 242.89326 364.90647\nManton     334.87758 712.51416 584.63341 479.76855 577.52046 721.86149\nMongyang   382.59743 146.66661 210.19929 247.22785  69.25859 167.72448\nKunhing    220.15490 306.47566 206.47448 193.77551 172.96164 314.92119\nMongyawng  309.51462 315.57550 173.86004 240.39800 290.51360 321.21112\nTangyan     70.27241 526.80849 373.07575 268.07983 412.22167 542.64078\nNamhsan    125.74240 564.02740 411.96125 310.40560 440.51555 576.42717\n            Kengtung   Langkho   Monghsu  Taunggyi  Pangwaun    Kyethi\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho    107.16213                                                  \nMonghsu    316.91914 221.84918                                        \nTaunggyi   186.28225 288.27478 486.91951                              \nPangwaun   337.48335 295.38434 343.38498 497.61245                    \nKyethi     444.26274 350.91512 146.61572 599.57407 476.62610          \nLoilen     282.22935 184.10672 131.55208 455.91617 331.69981 232.32965\nManton     631.99123 535.95620 330.76503 803.08034 510.79265 272.03299\nMongyang   217.08047 175.35413 323.95988 374.58247 225.25026 453.86726\nKunhing    245.95083 146.38284 146.78891 429.98509 229.09986 278.95182\nMongyawng  203.87199 186.11584 312.85089 287.73864 475.33116 387.71518\nTangyan    429.95076 332.02048 127.42203 592.65262 447.05580  47.79331\nNamhsan    466.20497 368.20978 153.22576 631.49232 448.58030  68.67929\n              Loilen    Manton  Mongyang   Kunhing Mongyawng   Tangyan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho                                                               \nMonghsu                                                               \nTaunggyi                                                              \nPangwaun                                                              \nKyethi                                                                \nLoilen                                                                \nManton     419.06087                                                  \nMongyang   246.76592 585.70558                                        \nKunhing    130.39336 410.49230 188.89405                              \nMongyawng  261.75211 629.43339 304.21734 295.35984                    \nTangyan    196.60826 271.82672 421.06366 249.74161 377.52279          \nNamhsan    242.15271 210.48485 450.97869 270.79121 430.02019  63.67613\n\n\n\n\n\n\n# Ward.D agglomerative hierarchical clustering ---------------------------------\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D') # build dendrogram with Ward’s method\n\n\n# Plot dendrogram (smaller labels) ---------------------------------------------\nplot(hclust_ward, cex = 0.6) # visual tree of township similarity\n\n\n\n\n\n\n\n\n\n\n\nOne of the challenge in performing hierarchical clustering is to identify stronger clustering structures. The issue can be solved by using use agnes() function of cluster package. It functions like hclus(), however, with the agnes() function we can also get the agglomerative coefficient, which measures the amount of clustering structure found (values closer to 1 suggest strong clustering structure).\nThe code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.\n\n# Compare agglomerative coefficients across linkage methods --------------------\nm &lt;- c(\"average\", \"single\", \"complete\", \"ward\") # candidate methods\nnames(m) &lt;- c(\"average\", \"single\", \"complete\", \"ward\") # name the vector for map_dbl\n\n\nac &lt;- function(x) { cluster::agnes(shan_ict, method = x)$ac } # function returning agglomerative coef\n\n\npurrr::map_dbl(m, ac) # higher (~1) → stronger clustering\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\n\n\n\n\n\n\nNoteObservations:\n\n\n\nWith reference to the output above, we can see that Ward’s method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward’s method will be used.\n\n\n\n\n\nAnother technical challenge face by data analyst in performing clustering analysis is to determine the optimal clusters to retain.\nThere are three commonly used methods to determine the optimal clusters, they are:\n\nElbow Method\n\nAverage Silhouette Method\n\nGap Statistic Method\n\n\n\nThe gap statisticcompares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.\nTo compute the gap statistic, clusGap() of cluster package will be used.\n\n# Gap statistic using hcut() from factoextra -----------------------------------\nset.seed(12345) # reproducibility as per notes\ngap_stat &lt;- cluster::clusGap(shan_ict, FUN = factoextra::hcut, # wrapper around hclust\nnstart = 25, K.max = 10, B = 50) # 25 random starts; up to 10 clusters\n\n\nprint(gap_stat, method = \"firstmax\") # print suggested k (often 1, next best ~6)\n\nClustering Gap statistic [\"clusGap\"] from call:\ncluster::clusGap(x = shan_ict, FUNcluster = factoextra::hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --&gt; Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\nAlso note that the hcut function used is from factoextra package.\nNext, we can visualise the plot by using fviz_gap_stat() of factoextra package.\n\n# Visualise gap statistic curve -------------------------------------------------\nfactoextra::fviz_gap_stat(gap_stat) # plot with error bars\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\nℹ The deprecated feature was likely used in the factoextra package.\n  Please report the issue at &lt;https://github.com/kassambara/factoextra/issues&gt;.\n\n\n\n\n\n\n\n\n\nWith reference to the gap statistic graph above, the recommended number of cluster to retain is 1. However, it is not logical to retain only one cluster. By examine the gap statistic graph, the 6-cluster gives the largest gap statistic and should be the next best cluster to pick.\n\n\n\n\n\n\nNote\n\n\n\nIn addition to these commonly used approaches, the NbClust package, published by Charrad et al., 2014, provides 30 indices for determining the relevant number of clusters and proposes to users the best clustering scheme from the different results obtained by varying all combinations of number of clusters, distance measures, and clustering methods.\n\n\n\n\n\n\nIn the dendrogram displayed above, each leaf corresponds to one observation. As we move up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.\nThe height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are. Note that, conclusions about the proximity of two observations can be drawn only based on the height where branches containing those two observations first are fused. We cannot use the proximity of two observations along the horizontal axis as a criteria of their similarity.\nIt’s also possible to draw the dendrogram with a border around the selected clusters by using rect.hclust() of R stats. The argument border is used to specify the border colors for the rectangles.\n\n# Draw rectangles to highlight k = 6 clusters on Ward dendrogram ----------------\nplot(hclust_ward, cex = 0.6) # redraw base dendrogram\nrect.hclust(hclust_ward, k = 6, border = 2:5) # coloured boxes for six clusters\n\n\n\n\n\n\n\n\n\n\n\n\n# Convert to matrix and draw an interactive cluster heatmap ---------------------\nshan_ict_mat &lt;- data.matrix(shan_ict) # matrix required by heatmaply\n\n\nheatmaply::heatmaply(heatmaply::normalize(shan_ict_mat), # normalise columns to [0,1]\nColv = NA, # keep variables order\ndist_method = \"euclidean\", # distance for rows\nhclust_method = \"ward.D\", # Ward linkage for rows\nseriate = \"OLO\", # optimal leaf ordering\ncolors = Blues, # colour palette per notes\nk_row = 6, # show 6 row clusters\nmargins = c(NA, 200, 60, NA), # wider left/bottom margins for labels\nfontsize_row = 4, # small text for many rows\nfontsize_col = 5, # slightly larger for cols\nmain = \"Geographic Segmentation of Shan State by ICT indicators\",\nxlab = \"ICT Indicators\",\nylab = \"Townships of Shan State\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\nℹ The deprecated feature was likely used in the dendextend package.\n  Please report the issue at &lt;https://github.com/talgalili/dendextend/issues&gt;.\n\n\n\n\n\n\n\n\n\n\n# Cut the Ward dendrogram into 6 groups and append to sf -----------------------\ngroups &lt;- as.factor(cutree(hclust_ward, k = 6)) # factor labels 1..6\n\ngroups\n\n   Mongmit    Pindaya    Ywangan   Pinlaung     Mabein      Kalaw      Pekon \n         1          1          2          1          3          3          1 \n  Lawksawk  Nawnghkio    Kyaukme       Muse     Laihka    Mongnai    Mawkmai \n         3          3          3          4          1          1          5 \n    Kutkai    Mongton    Mongyai  Mongkaing     Lashio    Mongpan     Matman \n         1          1          5          2          3          3          2 \n Tachileik    Narphan   Mongkhet     Hsipaw   Monghsat    Mongmao    Nansang \n         4          5          5          1          5          6          1 \n Laukkaing   Pangsang      Namtu  Monghpyak    Konkyan   Mongping     Hopong \n         4          6          1          3          5          5          1 \nNyaungshwe   Hsihseng     Mongla      Hseni    Kunlong     Hopang    Namhkan \n         3          1          4          3          1          6          4 \n  Kengtung    Langkho    Monghsu   Taunggyi   Pangwaun     Kyethi     Loilen \n         3          3          1          4          6          1          1 \n    Manton   Mongyang    Kunhing  Mongyawng    Tangyan    Namhsan \n         2          6          1          3          1          1 \nLevels: 1 2 3 4 5 6\n\n\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;% # bind as new column\ndplyr::rename(`CLUSTER` = `as.matrix.groups.`) # rename to CLUSTER (exact style)\n\n\n# Map the non-spatial hierarchical clusters ------------------------------------\nqtm(shan_sf_cluster, \"CLUSTER\") # categorical choropleth of clusters\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteObservations:\n\n\n\nThe choropleth map above reveals the clusters are very fragmented. The is one of the major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used.\n\n\n\n\n\n\nIn this section, we will learn how to derive spatially constrained cluster by using skater() method of spdep package.\n\n\n\n# SKATER expects 'sp' polygons; convert sf → sp --------------------------------\nshan_sp &lt;- sf::as_Spatial(shan_sf) # SpatialPolygonsDataFrame object\n\n\n\n\n\n# Build contiguity neighbours (queen) from polygons ----------------------------\n\nshan.nb &lt;- spdep::poly2nb(shan_sp) # list of neighbours by shared borders\n\nsummary(shan.nb) # report links & degree distribution\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\n\n# Plot neighbours atop township boundaries -------------------------------------\ncoords &lt;- sf::st_coordinates(sf::st_centroid(sf::st_geometry(shan_sf))) # centroid coords for each polygon\n\n\nplot(sf::st_geometry(shan_sf), border = grey(.5)) # draw boundaries first (avoid clipping)\nplot(shan.nb, coords, col = \"blue\", add = TRUE) # overlay neighbour graph\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that if we plot the network first and then the boundaries, some of the areas will be clipped. This is because the plotting area is determined by the characteristics of the first plot. In this example, because the boundary map extends further than the graph, we plot it first.\n\n\n\n\n\n\n\n\n# Edge costs as attribute-space dissimilarity between neighbouring townships ----\nlcosts &lt;- spdep::nbcosts(shan.nb, shan_ict)\n\nglimpse(lcosts)\n\nList of 55\n $ : num [1:4] 263 144 431 238\n $ : num [1:3] 257 303 204\n $ : num [1:2] 257 432\n $ : num [1:3] 182 94.6 138.1\n $ : num [1:2] 263 674\n $ : num [1:5] 302.5 182 140 95.7 252.3\n $ : num [1:2] 94.6 139.3\n $ : num [1:9] 204.3 432.2 140 90.8 186.3 ...\n $ : num [1:2] 90.8 157\n $ : num [1:5] 144 186 157 164 348\n $ : num [1:3] 593 705 239\n $ : num [1:5] 523 78.8 157.5 255.8 59.7\n $ : num [1:7] 374.5 131.7 178.1 92.8 203 ...\n $ : num [1:5] 375 462 329 531 389\n $ : num [1:7] 593 580 311 229 205 ...\n $ : num [1:5] 132 200 151 120 237\n $ : num [1:4] 466 177 138 109\n $ : num [1:5] 625 523 424 379 352\n $ : num [1:7] 466.4 290.9 365.9 79.4 170.6 ...\n $ : num [1:3] 178 200 95\n $ : num [1:6] 203 506 202 308 586 ...\n $ : num [1:3] 677 444 432\n $ : num [1:3] 331 316 265\n $ : num [1:5] 203 114 574 531 445\n $ : num [1:8] 249 164 177 424 291 ...\n $ : num [1:5] 151 677 357 141 384\n $ : num [1:5] 331.4 57.6 78.3 187.4 347.1\n $ : num [1:6] 78.8 92.8 462.4 273 94.2 ...\n $ : num [1:4] 580 636 522 332\n $ : num [1:5] 506.3 316.3 57.6 108.4 364.8\n $ : num [1:4] 366 229 449 241\n $ : num [1:5] 444 357 408 221 286\n $ : num [1:3] 705 311 636\n $ : num [1:8] 203 120 202 114 141 ...\n $ : num [1:6] 274.9 157.5 379.4 91.7 513.8 ...\n $ : num [1:5] 138.1 95.7 139.3 225.8 325.1\n $ : num [1:5] 329.3 91.7 225.8 528.1 158.8\n $ : num [1:5] 574 408 202 147 316\n $ : num [1:5] 229.4 79.4 276.2 162.8 584.6\n $ : num [1:4] 205 522 276 271\n $ : num [1:6] 170.6 78.3 331.7 162.8 271.3 ...\n $ : num [1:3] 239 392 722\n $ : num [1:5] 531 384 221 443 202\n $ : num [1:4] 175 531 237 95\n $ : num [1:5] 308 159 147 147 127\n $ : num [1:5] 252 305 514 325 528\n $ : num [1:2] 265 187\n $ : num [1:8] 256 138 352 195 273 ...\n $ : num [1:5] 59.7 388.7 94.2 124.7 158.8\n $ : num [1:8] 431 674 362 647 449 ...\n $ : num [1:4] 586 445 108 147\n $ : num [1:5] 111 128 213 147 279\n $ : num [1:3] 432 286 316\n $ : num [1:8] 109 430 243 347 365 ...\n $ : num [1:5] 238 348 194 241 210\n - attr(*, \"call\")= language spdep::nbcosts(nb = shan.nb, data = shan_ict)\n - attr(*, \"class\")= chr \"nbdist\"\n\n\n\n# Convert neighbour list + costs into a weights list object --------------------\nshan.w &lt;- spdep::nb2listw(shan.nb, lcosts, style = \"B\") # 'B' keeps raw costs (no row standardise)\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004\n\n\n\n\n\n\n\n# Compute Minimum Spanning Tree (MST) over the neighbour graph with edge costs --------------------------\nshan.mst &lt;- spdep::mstree(shan.w) # returns an 'mst' matrix (n-1 edges)\n\n\n# Check its class \nclass(shan.mst); \n\n[1] \"mst\"    \"matrix\"\n\n\n\n# Check its dimension \ndim(shan.mst)\n\n[1] 54  3\n\n\n\nThe dimension is 54 and not 55. This is because the minimum spanning tree consists on n-1 edges (links) in order to traverse all the nodes.\n\n\n# Inspect the content of shan.mst\nhead(shan.mst)\n\n     [,1] [,2]      [,3]\n[1,]   54   48  47.79331\n[2,]   54   17 109.08506\n[3,]   54   45 127.42203\n[4,]   45   52 146.78891\n[5,]   52   13 110.55197\n[6,]   13   28  92.79567\n\n\n\n# Plot MST atop map -------------------------------------------------------------\nplot(sf::st_geometry(shan_sf), border = gray(.5)) # base map\nspdep::plot.mst(shan.mst, coords, col = \"blue\", cex.lab = 0.7, # draw MST links + node ids\ncex.circles = 0.005, add = TRUE)\n\n\n\n\n\n\n\n\n\nThe plot method for the MST include a way to show the observation numbers of the nodes in addition to the edge. As before, we plot this together with the township boundaries. We can see how the initial neighbour list is simplified to just one edge connecting each of the nodes, while passing through all the nodes.\n\n\n\n\n\n# Cut MST into k-1 edges (ncuts = 5 → k = 6 clusters) --------------------------\nclust6 &lt;- spdep::skater(edges = shan.mst[, 1:2], # first 2 columns are node indices\ndata = shan_ict, # attribute data to update SSW\nmethod = \"euclidean\", # distance in attribute space\nncuts = 5) # 6 clusters (k = ncuts + 1)\n\n\n\n\n\n\n\nNote\n\n\n\nThe skater() takes three mandatory arguments:\n\nthe first two columns of the MST matrix (i.e. not the cost),\n\nthe data matrix (to update the costs as units are being grouped), and\nthe number of cuts.\n\nNote: It is set to one less than the number of clusters. So, the value specified is not the number of clusters, but the number of cuts in the graph, one less than the number of clusters.\n\n\n\nstr(clust6) # list; includes $groups (cluster labels)\n\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 52 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 25 13 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 1458\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\n\nThe most interesting component of this list structure is the groups vector containing the labels of the cluster to which each observation belongs (as before, the label itself is arbitary). This is followed by a detailed summary for each of the clusters in the edges.groups list. Sum of squares measures are given as ssto for the total and ssw to show the effect of each of the cuts on the overall criterion.\n\nWe can check the cluster assignment by using the conde chunk below.\n\n# Check the cluster assignment\ncc6 &lt;- clust6$groups; cc6 # vector of cluster assignments\n\n [1] 3 3 6 3 3 3 3 3 3 3 2 1 1 1 2 1 1 1 2 4 1 2 5 1 1 1 2 1 2 2 1 2 2 1 1 3 1 2\n[39] 2 2 2 2 2 4 1 3 2 1 1 1 2 1 2 1 1\n\ncc6\n\n [1] 3 3 6 3 3 3 3 3 3 3 2 1 1 1 2 1 1 1 2 4 1 2 5 1 1 1 2 1 2 2 1 2 2 1 1 3 1 2\n[39] 2 2 2 2 2 4 1 3 2 1 1 1 2 1 2 1 1\n\n\nWe can find out how many observations are in each cluster by means of the table command. Parenthetially, we can also find this as the dimension of each vector in the lists contained in edges.groups. For example, the first list has node with dimension 12, which is also the number of observations in the first cluster.\n\ntable(cc6) # size of each cluster\n\ncc6\n 1  2  3  4  5  6 \n22 18 11  2  1  1 \n\n\nLastly, we can also plot the pruned tree that shows the five clusters on top of the townshop area.\n\n# Visualise the pruned tree coloured by groups ---------------------------------\nplot(sf::st_geometry(shan_sf), border = gray(.5)) # background polygons\nplot(clust6, coords, cex.lab = .7, # SKATER plotting helper\ngroups.colors = c(\"red\", \"green\", \"blue\", \"brown\", \"pink\"),\ncex.circles = 0.005, add = TRUE)\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\n\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below is used to plot the newly derived clusters by using SKATER method.\n\n# Append SKATER groups to sf and map -------------------------------------------\ngroups_mat &lt;- as.matrix(clust6$groups) # coerce to matrix for cbind\n\n\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;% # bind to previous sf\ndplyr::rename(`SP_CLUSTER` = `as.factor.groups_mat.`) # new field name per notes\n\n\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\") # map spatially constrained clusters\n\n\n\n\n\n\n\n\nFor easy comparison, it will be better to place both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other.\n\n# Side-by-side comparison of non-spatial vs spatially constrained clusters -----\nhclust.map &lt;- qtm(shan_sf_cluster, \"CLUSTER\") + tm_borders(alpha = 0.5) # non-spatial clusters\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n\nshclust.map &lt;- qtm(shan_sf_spatialcluster, \"SP_CLUSTER\") + tm_borders(alpha = 0.5) # SKATER clusters\n\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n\ntmap_arrange(hclust.map, shclust.map, asp = NA, ncol = 2) # compare fragmentation vs contiguity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClustGeo implements Ward‑like hierarchical clustering with a mixing parameter alpha ∈ [0,1] combining attribute dissimilarities (D0) and spatial dissimilarities (D1). Use choicealpha() to pick alpha balancing contiguity and attribute fit.\n\n\n\n\n# Run hclustgeo() with attribute-space dissimilarity only -----------------------\nnongeo_cluster &lt;- ClustGeo::hclustgeo(proxmat) # same D0 as from dist()\n\n\nplot(nongeo_cluster, cex = 0.5) # dendrogram\nrect.hclust(nongeo_cluster, k = 6, border = 2:5) # highlight 6 clusters\n\n\n\n\n\n\n\n# Map the non-spatial ClustGeo clusters ----------------------------------------\ngroups &lt;- as.factor(cutree(nongeo_cluster, k = 6)) # cut into 6 groups\n\n\nshan_sf_ngeo_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;% # bind to polygons\ndplyr::rename(`CLUSTER` = `as.matrix.groups.`)\n\n\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\") # categorical map\n\n\n\n\n\n\n\n\n\n\n\n\n# Build spatial distance matrix between polygon centroids ----------------------\ndist &lt;- sf::st_distance(shan_sf, shan_sf) # pairwise great-circle distances\n\n\ndistmat &lt;- stats::as.dist(dist) # convert to 'dist' object for ClustGeo (convert dataframe into matrix)\n\n\n# Choose alpha that trades off contiguity vs attribute fit ---------------------\ncr &lt;- ClustGeo::choicealpha(proxmat, distmat, # D0 and D1 matrices\nrange.alpha = seq(0, 1, 0.1), K = 6, # evaluate alpha from 0..1 for K=6\ngraph = TRUE) # display criterion curves\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# With reference to the plot above, adopt alpha = 0.2 -------------------------------------\nclustG &lt;- ClustGeo::hclustgeo(proxmat, distmat, alpha = 0.2) # combined D0/D1 with alpha=0.2\n\n\n# Cut into 6 groups and map ----------------------------------------------------\ngroups &lt;- as.factor(cutree(clustG, k = 6)) # labels 1..6\n\n\nshan_sf_Gcluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;% # append to polygons\ndplyr::rename(`CLUSTER` = `as.matrix.groups.`)\n\n\nqtm(shan_sf_Gcluster, \"CLUSTER\") # spatially constrained (ClustGeo) map\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Boxplot of RADIO_PR by cluster (non-spatial ClustGeo example) ----------------\nggplot(data = shan_sf_ngeo_cluster, # use non-spatial clusters for example\naes(x = CLUSTER, y = RADIO_PR)) +\ngeom_boxplot()\n\n\n\n\n\n\n\n\n\nThe boxplot reveals Cluster 3 displays the highest mean Radio Ownership Per Thousand Household. This is followed by Cluster 2, 1, 4, 6 and 5.\n\n\n\n\n\n# Parallel coordinates (GGally) to compare all ICT rates by cluster -------------\nggparcoord(data = shan_sf_ngeo_cluster,       # data with cluster labels\n           columns = c(17:21),                # columns of *_PR variables (as in notes)\n           scale = \"globalminmax\",            # same vertical scale 0..1 per global range\n           alphaLines = 0.2,                  # faint lines \n           boxplot = TRUE,                    # add per-variable boxplots in background\n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) +                     # one panel per cluster\n  theme(axis.text.x = element_text(angle = 30))  # improve x-axis label readability\n\n\n\n\n\n\n\n\nThe parallel coordinate plot above reveals that households in Cluster 4 townships tend to own the highest number of TV and mobile-phone. On the other hand, households in Cluster 5 tends to own the lowest of all the five ICT.\nNote that the scale argument of ggparcoor() provide several methods to scale the clustering variables. They are:\n\nstd: univariately, subtract mean and divide by standard deviation.\n\nrobust: univariately, subtract median and divide by median absolute deviation.\n\nuniminmax: univariately, scale so the minimum of the variable is zero, and the maximum is one.\n\nglobalminmax: no scaling is done; the range of the graphs is defined by the global minimum and the global maximum.\n\ncenter: use uniminmax to standardize vertical height, then center each variable at a value specified by the scaleSummary param.\n\ncenterObs: use uniminmax to standardize vertical height, then center each variable at the value of the observation specified by the centerObsID param\n\nThere is no one best scaling method to use. You should explore them and select the one that best meet your analysis need.\nLast but not least, we can also compute the summary statistics such as mean, median, sd, etc to complement the visual interpretation.\nIn the code chunk below, group_by() and summarise() of dplyr are used to derive mean values of the clustering variables.\n\n# Compute cluster-wise means to complement visual inspection -------------------\n\nshan_sf_ngeo_cluster %&gt;% \n  st_set_geometry(NULL) %&gt;%                         # work on attributes only\n  group_by(CLUSTER) %&gt;%                             # aggregate by cluster label\n  summarise(mean_RADIO_PR = mean(RADIO_PR),         # mean Radio per 1000 households\n            mean_TV_PR = mean(TV_PR),               # mean TV per 1000 households\n            mean_LLPHONE_PR = mean(LLPHONE_PR),     # mean Landline per 1000 households\n            mean_MPHONE_PR = mean(MPHONE_PR),       # mean Mobile per 1000 households\n            mean_COMPUTER_PR = mean(COMPUTER_PR))   # mean Computer per 1000 households\n\n# A tibble: 6 × 6\n  CLUSTER mean_RADIO_PR mean_TV_PR mean_LLPHONE_PR mean_MPHONE_PR\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;\n1 1               221.        521.            44.2           246.\n2 2               237.        402.            23.9           134.\n3 3               300.        611.            52.2           392.\n4 4               196.        744.            99.0           651.\n5 5               124.        224.            38.0           132.\n6 6                98.6       499.            74.5           468.\n# ℹ 1 more variable: mean_COMPUTER_PR &lt;dbl&gt;"
  },
  {
    "objectID": "Hands-on_Ex06/hand-on_ex06.html#overview",
    "href": "Hands-on_Ex06/hand-on_ex06.html#overview",
    "title": "Hands-on Ex06",
    "section": "",
    "text": "In this hands‑on exercise, we will learn how to delineate homogeneous regions by using geographically referenced multivariate data. Two major analyses are covered:\n\nhierarchical cluster analysis; and\n\nspatially constrained cluster analysis.\n\n\n\nBy the end of this exercise, we will be able to:\n\nconvert GIS polygon data into R’s simple feature data.frame using sf;\nconvert a simple feature data.frame into SpatialPolygonsDataFrame using sf → sp conversion for SKATER;\nperform cluster analysis using hclust() (Base R) and hclustgeo() (ClustGeo);\nperform spatially constrained clustering using skater() (spdep) and hclustgeo() with spatial dissimilarities; and\nvisualise outputs using ggplot2 and tmap."
  },
  {
    "objectID": "Hands-on_Ex06/hand-on_ex06.html#getting-started",
    "href": "Hands-on_Ex06/hand-on_ex06.html#getting-started",
    "title": "Hands-on Ex06",
    "section": "",
    "text": "Segment Shan State, Myanmar into homogeneous regions at the township level using multiple ICT indicators: Radio, Television, Land line phone, Mobile phone, Computer, and Internet at home."
  },
  {
    "objectID": "Hands-on_Ex06/hand-on_ex06.html#the-data",
    "href": "Hands-on_Ex06/hand-on_ex06.html#the-data",
    "title": "Hands-on Ex06",
    "section": "",
    "text": "Two datasets are used:\n\nMyanmar Township Boundary Data (mynamar_township_boundaries) — ESRI Shapefile; polygons at township level.\nShan-ICT.csv — extract of The 2014 Myanmar Population and Housing Census Myanmar at township level.\n\n\n\n\n# Install and load all packages used in one call -----------------\npacman::p_load(spdep, tmap, sf, ClustGeo, ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)  # loads if installed; installs if missing\n\n\n\n\n\n\n\nNote\n\n\n\nWith tidyverse, we get readr, ggplot2, dplyr, purrr, etc."
  },
  {
    "objectID": "Hands-on_Ex06/hand-on_ex06.html#data-import-and-preparation",
    "href": "Hands-on_Ex06/hand-on_ex06.html#data-import-and-preparation",
    "title": "Hands-on Ex06",
    "section": "",
    "text": "# Read township boundaries shapefile (sf) ---------------------------------------\nshan_sf &lt;- st_read(dsn = \"data/geospatial\",      # folder containing the shapefile\n                   layer = \"myanmar_township_boundaries\") %&gt;%     # shapefile layer name (without .shp)\n  dplyr::filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%  # keep only Shan State parts\n  dplyr::select(c(2:7))                          # keep fields 2..7\n\nReading layer `myanmar_township_boundaries' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex06/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n# Inspect the resulting simple feature data.frame --------------------------------\nshan_sf                                          # prints sf summary (rows, cols, bbox)\n\nSimple feature collection with 55 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 96.15107 ymin: 19.29932 xmax: 101.1699 ymax: 24.15907\nGeodetic CRS:  WGS 84\nFirst 10 features:\n             ST ST_PCODE       DT   DT_PCODE        TS  TS_PCODE\n1  Shan (North)   MMR015  Mongmit MMR015D008   Mongmit MMR015017\n2  Shan (South)   MMR014 Taunggyi MMR014D001   Pindaya MMR014006\n3  Shan (South)   MMR014 Taunggyi MMR014D001   Ywangan MMR014007\n4  Shan (South)   MMR014 Taunggyi MMR014D001  Pinlaung MMR014009\n5  Shan (North)   MMR015  Mongmit MMR015D008    Mabein MMR015018\n6  Shan (South)   MMR014 Taunggyi MMR014D001     Kalaw MMR014005\n7  Shan (South)   MMR014 Taunggyi MMR014D001     Pekon MMR014010\n8  Shan (South)   MMR014 Taunggyi MMR014D001  Lawksawk MMR014008\n9  Shan (North)   MMR015  Kyaukme MMR015D003 Nawnghkio MMR015013\n10 Shan (North)   MMR015  Kyaukme MMR015D003   Kyaukme MMR015012\n                         geometry\n1  MULTIPOLYGON (((96.96001 23...\n2  MULTIPOLYGON (((96.7731 21....\n3  MULTIPOLYGON (((96.78483 21...\n4  MULTIPOLYGON (((96.49518 20...\n5  MULTIPOLYGON (((96.66306 24...\n6  MULTIPOLYGON (((96.49518 20...\n7  MULTIPOLYGON (((97.14738 19...\n8  MULTIPOLYGON (((96.94981 22...\n9  MULTIPOLYGON (((96.75648 22...\n10 MULTIPOLYGON (((96.95498 22...\n\nglimpse(shan_sf)  \n\nRows: 55\nColumns: 7\n$ ST       &lt;chr&gt; \"Shan (North)\", \"Shan (South)\", \"Shan (South)\", \"Shan (South)…\n$ ST_PCODE &lt;chr&gt; \"MMR015\", \"MMR014\", \"MMR014\", \"MMR014\", \"MMR015\", \"MMR014\", \"…\n$ DT       &lt;chr&gt; \"Mongmit\", \"Taunggyi\", \"Taunggyi\", \"Taunggyi\", \"Mongmit\", \"Ta…\n$ DT_PCODE &lt;chr&gt; \"MMR015D008\", \"MMR014D001\", \"MMR014D001\", \"MMR014D001\", \"MMR0…\n$ TS       &lt;chr&gt; \"Mongmit\", \"Pindaya\", \"Ywangan\", \"Pinlaung\", \"Mabein\", \"Kalaw…\n$ TS_PCODE &lt;chr&gt; \"MMR015017\", \"MMR014006\", \"MMR014007\", \"MMR014009\", \"MMR01501…\n$ geometry &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((96.96001 23..., MULTIPOLYGON (((…\n\n\n\n\n\n\n# Read the ICT attributes table (CSV) ------------------------------------------\nict &lt;- readr::read_csv(\"data/aspatial/Shan-ICT.csv\")  # loads as a tibble data.frame\n\nRows: 55 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): District Pcode, District Name, Township Pcode, Township Name\ndbl (7): Total households, Radio, Television, Land line phone, Mobile phone,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Review the summary statistics of raw counts ----------------------------------\nsummary(ict)         \n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0  \n\n\n\n\n\nWe convert raw household counts to per‑thousand‑household penetration rates to remove bias due to township size.\n\n# Derive penetration rates and tidy names --------------------------------------\nict_derived &lt;- ict %&gt;%\n  dplyr::mutate(RADIO_PR    = `Radio`/`Total households` * 1000) %&gt;%            # Radio per 1000 households\n  dplyr::mutate(TV_PR       = `Television`/`Total households` * 1000) %&gt;%       # TV per 1000 households\n  dplyr::mutate(LLPHONE_PR  = `Land line phone`/`Total households` * 1000) %&gt;%  # Landline per 1000 households\n  dplyr::mutate(MPHONE_PR   = `Mobile phone`/`Total households` * 1000) %&gt;%     # Mobile per 1000 households\n  dplyr::mutate(COMPUTER_PR = `Computer`/`Total households` * 1000) %&gt;%         # Computer per 1000 households\n  dplyr::mutate(INTERNET_PR = `Internet at home`/`Total households` * 1000) %&gt;% # Internet per 1000 households\n  dplyr::rename(`DT_PCODE`     = `District Pcode`,                              # harmonise id fields to tidy names\n                `DT`           = `District Name`,\n                `TS_PCODE`     = `Township Pcode`,\n                `TS`           = `Township Name`,\n                `TT_HOUSEHOLDS`= `Total households`,\n                `RADIO`        = `Radio`,\n                `TV`           = `Television`,\n                `LLPHONE`      = `Land line phone`,\n                `MPHONE`       = `Mobile phone`,\n                `COMPUTER`     = `Computer`,\n                `INTERNET`     = `Internet at home`)\n\n\n# Review penetration rates after derivation ------------------------------------\nsummary(ict_derived)     # confirms new *_PR fields       \n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 21.05  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:138.95  \n Median : 3559   Median : 244.0   Median : 316.0   Median :210.95  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :215.68  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:268.07  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :484.52  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :116.0   Min.   :  2.78   Min.   : 36.42   Min.   : 3.278  \n 1st Qu.:450.2   1st Qu.: 22.84   1st Qu.:190.14   1st Qu.:11.832  \n Median :517.2   Median : 37.59   Median :305.27   Median :18.970  \n Mean   :509.5   Mean   : 51.09   Mean   :314.05   Mean   :24.393  \n 3rd Qu.:606.4   3rd Qu.: 69.72   3rd Qu.:428.43   3rd Qu.:29.897  \n Max.   :842.5   Max.   :181.49   Max.   :735.43   Max.   :92.402  \n  INTERNET_PR     \n Min.   :  1.041  \n 1st Qu.:  8.617  \n Median : 22.829  \n Mean   : 30.644  \n 3rd Qu.: 41.281  \n Max.   :117.985  \n\n\n\n\n\n\n\n\nNoteObservation:\n\n\n\nNotice that six new fields have been added into the data.frame. They are RADIO_PR, TV_PR, LLPHONE_PR, MPHONE_PR, COMPUTER_PR, and INTERNET_PR."
  },
  {
    "objectID": "Hands-on_Ex06/hand-on_ex06.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex06/hand-on_ex06.html#exploratory-data-analysis-eda",
    "title": "Hands-on Ex06",
    "section": "",
    "text": "The code chunks below are used to create the data visualisation. They consist of two main parts. First, we will create the individual histograms using the code chunk below.\n\n# Histogram and boxplot for RADIO (raw counts) ---------------------------------\nggplot(data = ict_derived, aes(x = `RADIO`)) +          # choose RADIO (raw) for distribution\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")  # 20 bins; black border; light blue fill\n\n\n\n\n\n\n\nggplot(data = ict_derived, aes(x = `RADIO`)) +          # same variable for outlier check\n  geom_boxplot(color = \"black\", fill = \"light blue\")    # boxplot style\n\n\n\n\n\n\n\n# Histogram and boxplot for RADIO_PR (per-thousand) ----------------------------\nggplot(data = ict_derived, aes(x = `RADIO_PR`)) +       # scaled rate variable\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")  # distribution after scaling\n\n\n\n\n\n\n\nggplot(data = ict_derived, aes(x = `RADIO_PR`)) +       # outlier check on rate\n  geom_boxplot(color = \"black\", fill = \"light blue\")    # single extreme points easily seen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteWhat can you observed from the distributions reveal in the histogram and boxplot?\n\n\n\nFor RADIO (original values)\nHistogram:\n\nThe distribution is highly right-skewed (positively skewed)\n\nMost values are concentrated at the lower end (close to 0–5000)\n\nThere are a few very large values (e.g., ~30,000), suggesting the presence of extreme outliers\n\nBoxplot:\n\nConfirms the positive skewness seen in the histogram\n\nA long whisker extends to the right, and several outliers (dots) appear at high values (&gt;10,000, &gt;30,000).\nThe median is much closer to the lower quartile, reinforcing that most data is clustered at the low end.\n\n\nInterpretation: The RADIO variable has extreme variation with a few very large outliers dominating the scale. Data transformation (e.g., log transform) may be useful to reduce skewness and bring values closer to normality.\n\nFor RADIO_PR (processed/normalized values)\nHistogram:\n\nThe distribution is more uniform and relatively symmetric compared to RADIO\n\nValues spread between 0 and 500, with no extreme concentration at the low end\n\nThe central tendency seems more balanced around 200\n\nBoxplot:\n\nShows a more symmetric spread with a wider interquartile range\n\nOnly one mild outlier (~500)\n\nMedian is near the center of the box, indicating less skewness than RADIO\n\n\nInterpretation: RADIO_PR is much more normalized and balanced compared to RADIO. The transformation/processing (likely standardization or scaling) effectively reduced skewness and limited extreme outlier effects.\n\n\n\nNext, the ggarrange() function of ggpubr package is used to group these histograms together.\n\n# Multiple histograms: create one plot per ICT rate ----------------------------\nradio    &lt;- ggplot(ict_derived, aes(x = `RADIO_PR`))    + geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\ntv       &lt;- ggplot(ict_derived, aes(x = `TV_PR`))       + geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\nllphone  &lt;- ggplot(ict_derived, aes(x = `LLPHONE_PR`))  + geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\nmphone   &lt;- ggplot(ict_derived, aes(x = `MPHONE_PR`))   + geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\ncomputer &lt;- ggplot(ict_derived, aes(x = `COMPUTER_PR`)) + geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\ninternet &lt;- ggplot(ict_derived, aes(x = `INTERNET_PR`)) + geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggpubr::ggarrange(radio, tv, llphone, mphone, computer, internet,  # arrange 6 histograms\n                   ncol = 3, nrow = 2)                             # arrange plots in grid 3x2 \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Join geospatial (shan_sf) with aspatial (ict_derived) by TS_PCODE -------------\nshan_sf &lt;- dplyr::left_join(shan_sf, ict_derived, by = c(\"TS_PCODE\" = \"TS_PCODE\"))  # enrich polygons with ICT\n\n\n# Persist and reload  -----------------------------\n\nreadr::write_rds(shan_sf, \"data/rds/shan_sf.rds\")  # save result to RDS\n\nshan_sf &lt;- readr::read_rds(\"data/rds/shan_sf.rds\") # reload to ensure reproducibility\n\n\n# Quick choropleth of RADIO_PR using tmap (qtm) --------------------------------\nqtm(shan_sf, \"RADIO_PR\")      # quick thematic map for a single variable\n\n\n\n\n\n\n\n\n\n# Compare raw totals vs rate using two side-by-side choropleths -----------------\nTT_HOUSEHOLDS.map &lt;- tm_shape(shan_sf) +                            # base shape: township polygons\n  tm_fill(col = \"TT_HOUSEHOLDS\", n = 5, style = \"jenks\", title = \"Total households\") +\n  tm_borders(alpha = 0.5)                                           # light borders as in notes\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_polygons()`: instead of `style = \"jenks\"`, use fill.scale =\n`tm_scale_intervals()`.\nℹ Migrate the argument(s) 'style', 'n' to 'tm_scale_intervals(&lt;HERE&gt;)'\n[v3-&gt;v4] `tm_polygons()`: use 'fill' for the fill color of polygons/symbols\n(instead of 'col'), and 'col' for the outlines (instead of 'border.col').\n[v3-&gt;v4] `tm_polygons()`: migrate the argument(s) related to the legend of the\nvisual variable `fill` namely 'title' to 'fill.legend = tm_legend(&lt;HERE&gt;)'\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n\nRADIO.map &lt;- tm_shape(shan_sf) +                                   # second map for raw RADIO counts\n  tm_fill(col = \"RADIO\", n = 5, style = \"jenks\", title = \"Number Radio \") +\n  tm_borders(alpha = 0.5)\n\n[v3-&gt;v4] `tm_polygons()`: migrate the argument(s) related to the legend of the\nvisual variable `fill` namely 'title' to 'fill.legend = tm_legend(&lt;HERE&gt;)'\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map, asp = NA, ncol = 2)     # view side-by-side\n\n\n\n\n\n\n\n\n\n# Faceted choropleth for TT_HOUSEHOLDS and RADIO_PR ----------------------------\ntm_shape(shan_sf) +\n  tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"), style = \"jenks\") +   # show both variables as facets\n  tm_facets(sync = TRUE, ncol = 2) +                               # same breaks/legends aligned\n  tm_legend(legend.position = c(\"right\", \"bottom\")) +              # legend position\n  tm_layout(outer.margins = 0, asp = 0)                             # fill layout; ignore aspect lock\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_polygons()`: instead of `style = \"jenks\"`, use fill.scale =\n`tm_scale_intervals()`.\nℹ Migrate the argument(s) 'style' to 'tm_scale_intervals(&lt;HERE&gt;)'\n[v3-&gt;v4] `tm_legend()`: use 'tm_legend()' inside a layer function, e.g.\n'tm_polygons(..., fill.legend = tm_legend())'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteCan you identify the differences?\n\n\n\nWe use style=\"jenks\" so that the classification adapts to the real distribution of households and penetration rates. This produces more meaningful groupings and reveals disparities that fixed intervals might hide. That’s why the bottom maps (with Jenks) highlight differences in adoption (penetration rate) more clearly than the top maps (absolute counts with equal breaks)."
  },
  {
    "objectID": "Hands-on_Ex06/hand-on_ex06.html#correlation-analysis",
    "href": "Hands-on_Ex06/hand-on_ex06.html#correlation-analysis",
    "title": "Hands-on Ex06",
    "section": "",
    "text": "# Compute correlation among penetration-rate variables -------------------------\ncluster_vars.cor &lt;- stats::cor(ict_derived[, 12:17]) # columns 12..17 are *_PR variables\n\n\n# Mixed correlation plot (numbers + ellipses) ----------------------------------\ncorrplot::corrplot.mixed(cluster_vars.cor, # matrix of correlations\nlower = \"ellipse\", # lower triangle as ellipses\nupper = \"number\", # upper triangle shows numeric values\ntl.pos = \"lt\", # variable labels at left-top\ndiag = \"l\", # show diagonal line\ntl.col = \"black\") # black label text\n\n\n\n\n\n\n\n\n\nThe plot usually shows COMPUTER_PR and INTERNET_PR as highly correlated; we will keep only one (COMPUTER_PR) for clustering to avoid redundancy."
  },
  {
    "objectID": "Hands-on_Ex06/hand-on_ex06.html#hierarchy-cluster-analysis",
    "href": "Hands-on_Ex06/hand-on_ex06.html#hierarchy-cluster-analysis",
    "title": "Hands-on Ex06",
    "section": "",
    "text": "# Pull clustering variables from the joined sf and drop geometry ----------------\ncluster_vars &lt;- shan_sf %&gt;%\nsf::st_set_geometry(NULL) %&gt;% # remove geometry columns\ndplyr::select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", # keep town name + selected *_PR vars\n\"MPHONE_PR\", \"COMPUTER_PR\")\n\nhead(cluster_vars, 10) # preview first 10 rows\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\n\n\n\n\n\nNoteObservation\n\n\n\nNotice that the final clustering variables list does not include variable INTERNET_PR because it is highly correlated with variable COMPUTER_PR.\n\n\nNext, we need to change the rows by township name instead of row number by using the code chunk below\n\n# Set township names as row names for clustering display -----------------------\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\" # dendrogram labels use township names\n\nhead(cluster_vars, 10) # verify row names applied\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\n\n\n\n\n\nNoteObservation\n\n\n\nNotice that the row number has been replaced into the township name.\n\n\nNow, we will delete the TS.x field by using the code chunk below.\n\n# Remove the name column from the clustering data.frame ------------------------\n\nshan_ict &lt;- dplyr::select(cluster_vars, c(2:6)) # keep only numeric *_PR fields\n\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\n# Persist to RDS to follow notes ------------------------------------------------\nreadr::write_rds(shan_ict, \"data/rds/shan_ict.rds\") # save numeric matrix as tibble\n\n\n\n\nMultiple variables have different ranges; we standardise before computing distances.\n\n\n\n\n# Min–Max scale each column to [0,1] using heatmaply::normalize -----------------\nshan_ict.std &lt;- heatmaply::normalize(shan_ict) # returns scaled data.frame\nsummary(shan_ict.std) # confirm min=0, max=1 per variable\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\n\n\n\n\n\n\nNoteObservation:\n\n\n\nNotice that the values range of the Min-max standardised clustering variables are 0-1 now.\n\n\n\n\n\n\n# Z-score scale (mean=0, sd=1) -------------------------------------------------\nshan_ict.z &lt;- scale(shan_ict) # matrix with standardized columns\npsych::describe(shan_ict.z) # convenient table incl. sd, skew, kurtosis\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\n\n\n\n\n\n\nNoteObservation:\n\n\n\nNotice the mean and standard deviation of the Z-score standardised clustering variables are 0 and 1 respectively.\n\n\n\n\n\n\n\n\nNote\n\n\n\ndescribe() of psych package is used here instead of summary() of Base R because the earlier provides standard deviation.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nZ-score standardisation method should only be used if we would assume all variables come from some normal distribution.\n\n\n\n\n\nBeside reviewing the summary statistics of the standardised clustering variables, it is also a good practice to visualise their distribution graphical.\nThe code chunk below plot the scaled Radio_PR field.\n\n# Compare histograms for RADIO_PR across raw/minmax/z-score --------------------\nr &lt;- ggplot(ict_derived, aes(x = `RADIO_PR`)) + # raw rate distribution\ngeom_histogram(bins = 20, color = \"black\", fill = \"light blue\") +\nggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std) # cast to data.frame for ggplot\ns &lt;- ggplot(shan_ict_s_df, aes(x = `RADIO_PR`)) + # min-max scaled distribution\ngeom_histogram(bins = 20, color = \"black\", fill = \"light blue\") +\nggtitle(\"Min–Max Standardisation\")\n\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z) # z-scored matrix to data.frame\nz &lt;- ggplot(shan_ict_z_df, aes(x = `RADIO_PR`)) + # z-score distribution\ngeom_histogram(bins = 20, color = \"black\", fill = \"light blue\") +\nggtitle(\"Z-score Standardisation\")\n\n\nggpubr::ggarrange(r, s, z, ncol = 3, nrow = 1) # 3 histograms in one row\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteWhat statistical conclusion can you draw from the histograms above?\n\n\n\nImplications of Standardisation Methods\n\nRaw Values\n\nKeeping raw values may be fine if all variables are measured on the same scale (e.g., all in dollars).\n\nHowever, when variables differ in scale (e.g., RADIO_PR in hundreds vs TV_PR in thousands), models may be biased toward the larger-scale variable.\n\nNot suitable for distance-based methods (kNN, clustering) or optimization algorithms (gradient descent), because large values dominate.\n\nMin–Max Standardisation\n\nScales all values to the fixed interval [0,1].\n\nPreserves the distribution shape and relative distances.\n\nWorks well when features are bounded and we want to keep proportionality (e.g., image pixels, probabilities).\n\nSensitive to outliers: a single extreme value can stretch the range and compress the majority of the data.\n\nZ-score Standardisation\n\nCenters data at mean = 0, scales variance to 1.\n\nUseful for comparing across variables with different scales or units (e.g., comparing exam scores out of 100 vs heights in cm).\n\nLess affected by outliers compared to Min–Max (though still sensitive if outliers are extreme).\n\nParticularly suitable for statistical methods assuming normality or measuring relative deviations (e.g., regression, PCA, clustering).\n\n\nWhen to use which method?\n\nUse Raw Values only if all features are already comparable in scale.\n\nUse Min–Max when working with bounded ranges (e.g., neural networks, image processing).\n\nUse Z-score when the goal is comparability across different units, or when methods assume standardized input (e.g., PCA, k-means, regression).\n\nTakeaway:\nThe histograms confirm that standardisation changes scale but not distributional shape. The choice of method depends on the statistical technique and the role of the variable in the model.\n\n\n\n# Density comparison (same three panels) ---------------------------------------\nr &lt;- ggplot(ict_derived, aes(x = `RADIO_PR`)) + geom_density(color = \"black\", fill = \"light blue\") + ggtitle(\"Raw values without standardisation\")\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std); s &lt;- ggplot(shan_ict_s_df, aes(x = `RADIO_PR`)) + geom_density(color = \"black\", fill = \"light blue\") + ggtitle(\"Min–Max Standardisation\")\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z); z &lt;- ggplot(shan_ict_z_df, aes(x = `RADIO_PR`)) + geom_density(color = \"black\", fill = \"light blue\") + ggtitle(\"Z-score Standardisation\")\n\n\nggpubr::ggarrange(r, s, z, ncol = 3, nrow = 1) # density panels\n\n\n\n\n\n\n\n\n\n\n\nIn R, many packages provide functions to calculate distance matrix. We will compute the proximity matrix by using dist() of R.\ndist() supports six distance proximity calculations, they are: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is euclidean proximity matrix.\nThe code chunk below is used to compute the proximity matrix using euclidean method.\n\n# Euclidean distance among townships based on *_PR variables --------------------\nproxmat &lt;- stats::dist(shan_ict, method = 'euclidean') # produces a 'dist' object\n\nproxmat\n\n             Mongmit   Pindaya   Ywangan  Pinlaung    Mabein     Kalaw\nPindaya    171.86828                                                  \nYwangan    381.88259 257.31610                                        \nPinlaung    57.46286 208.63519 400.05492                              \nMabein     263.37099 313.45776 529.14689 312.66966                    \nKalaw      160.05997 302.51785 499.53297 181.96406 198.14085          \nPekon       59.61977 117.91580 336.50410  94.61225 282.26877 211.91531\nLawksawk   140.11550 204.32952 432.16535 192.57320 130.36525 140.01101\nNawnghkio   89.07103 180.64047 377.87702 139.27495 204.63154 127.74787\nKyaukme    144.02475 311.01487 505.89191 139.67966 264.88283  79.42225\nMuse       563.01629 704.11252 899.44137 571.58335 453.27410 412.46033\nLaihka     141.87227 298.61288 491.83321 101.10150 345.00222 197.34633\nMongnai    115.86190 258.49346 422.71934  64.52387 358.86053 200.34668\nMawkmai    434.92968 437.99577 397.03752 398.11227 693.24602 562.59200\nKutkai      97.61092 212.81775 360.11861  78.07733 340.55064 204.93018\nMongton    192.67961 283.35574 361.23257 163.42143 425.16902 267.87522\nMongyai    256.72744 287.41816 333.12853 220.56339 516.40426 386.74701\nMongkaing  503.61965 481.71125 364.98429 476.29056 747.17454 625.24500\nLashio     251.29457 398.98167 602.17475 262.51735 231.28227 106.69059\nMongpan    193.32063 335.72896 483.68125 192.78316 301.52942 114.69105\nMatman     401.25041 354.39039 255.22031 382.40610 637.53975 537.63884\nTachileik  529.63213 635.51774 807.44220 555.01039 365.32538 373.64459\nNarphan    406.15714 474.50209 452.95769 371.26895 630.34312 463.53759\nMongkhet   349.45980 391.74783 408.97731 305.86058 610.30557 465.52013\nHsipaw     118.18050 245.98884 388.63147  76.55260 366.42787 212.36711\nMonghsat   214.20854 314.71506 432.98028 160.44703 470.48135 317.96188\nMongmao    242.54541 402.21719 542.85957 217.58854 384.91867 195.18913\nNansang    104.91839 275.44246 472.77637  85.49572 287.92364 124.30500\nLaukkaing  568.27732 726.85355 908.82520 563.81750 520.67373 427.77791\nPangsang   272.67383 428.24958 556.82263 244.47146 418.54016 224.03998\nNamtu      179.62251 225.40822 444.66868 170.04533 366.16094 307.27427\nMonghpyak  177.76325 221.30579 367.44835 222.20020 212.69450 167.08436\nKonkyan    403.39082 500.86933 528.12533 365.44693 613.51206 444.75859\nMongping   265.12574 310.64850 337.94020 229.75261 518.16310 375.64739\nHopong     136.93111 223.06050 352.85844  98.14855 398.00917 264.16294\nNyaungshwe  99.38590 216.52463 407.11649 138.12050 210.21337  95.66782\nHsihseng   131.49728 172.00796 342.91035 111.61846 381.20187 287.11074\nMongla     384.30076 549.42389 728.16301 372.59678 406.09124 260.26411\nHseni      189.37188 337.98982 534.44679 204.47572 213.61240  38.52842\nKunlong    224.12169 355.47066 531.63089 194.76257 396.61508 273.01375\nHopang     281.05362 443.26362 596.19312 265.96924 368.55167 185.14704\nNamhkan    386.02794 543.81859 714.43173 382.78835 379.56035 246.39577\nKengtung   246.45691 385.68322 573.23173 263.48638 219.47071  88.29335\nLangkho    164.26299 323.28133 507.78892 168.44228 253.84371  67.19580\nMonghsu    109.15790 198.35391 340.42789  80.86834 367.19820 237.34578\nTaunggyi   399.84278 503.75471 697.98323 429.54386 226.24011 252.26066\nPangwaun   381.51246 512.13162 580.13146 356.37963 523.44632 338.35194\nKyethi     202.92551 175.54012 287.29358 189.47065 442.07679 360.17247\nLoilen     145.48666 293.61143 469.51621  91.56527 375.06406 217.19877\nManton     430.64070 402.42888 306.16379 405.83081 674.01120 560.16577\nMongyang   309.51302 475.93982 630.71590 286.03834 411.88352 233.56349\nKunhing    173.50424 318.23811 449.67218 141.58836 375.82140 197.63683\nMongyawng  214.21738 332.92193 570.56521 235.55497 193.49994 173.43078\nTangyan    195.92520 208.43740 324.77002 169.50567 448.59948 348.06617\nNamhsan    237.78494 228.41073 286.16305 214.33352 488.33873 385.88676\n               Pekon  Lawksawk Nawnghkio   Kyaukme      Muse    Laihka\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk   157.51129                                                  \nNawnghkio  113.15370  90.82891                                        \nKyaukme    202.12206 186.29066 157.04230                              \nMuse       614.56144 510.13288 533.68806 434.75768                    \nLaihka     182.23667 246.74469 211.88187 128.24979 526.65211          \nMongnai    151.60031 241.71260 182.21245 142.45669 571.97975 100.53457\nMawkmai    416.00669 567.52693 495.15047 512.02846 926.93007 429.96554\nKutkai     114.98048 224.64646 147.44053 170.93318 592.90743 144.67198\nMongton    208.14888 311.07742 225.81118 229.28509 634.71074 212.07320\nMongyai    242.52301 391.26989 319.57938 339.27780 763.91399 264.13364\nMongkaing  480.23965 625.18712 546.69447 586.05094 995.66496 522.96309\nLashio     303.80011 220.75270 230.55346 129.95255 313.15288 238.64533\nMongpan    243.30037 228.54223 172.84425 110.37831 447.49969 210.76951\nMatman     368.25761 515.39711 444.05061 505.52285 929.11283 443.25453\nTachileik  573.39528 441.82621 470.45533 429.15493 221.19950 549.08985\nNarphan    416.84901 523.69580 435.59661 420.30003 770.40234 392.32592\nMongkhet   342.08722 487.41102 414.10280 409.03553 816.44931 324.97428\nHsipaw     145.37542 249.35081 176.09570 163.95741 591.03355 128.42987\nMonghsat   225.64279 352.31496 289.83220 253.25370 663.76026 158.93517\nMongmao    293.70625 314.64777 257.76465 146.09228 451.82530 185.99082\nNansang    160.37607 188.78869 151.13185  60.32773 489.35308  78.78999\nLaukkaing  624.82399 548.83928 552.65554 428.74978 149.26996 507.39700\nPangsang   321.81214 345.91486 287.10769 175.35273 460.24292 214.19291\nNamtu      165.02707 260.95300 257.52713 270.87277 659.16927 185.86794\nMonghpyak  190.93173 142.31691  93.03711 217.64419 539.43485 293.22640\nKonkyan    421.48797 520.31264 439.34272 393.79911 704.86973 351.75354\nMongping   259.68288 396.47081 316.14719 330.28984 744.44948 272.82761\nHopong     138.86577 274.91604 204.88286 218.84211 648.68011 157.48857\nNyaungshwe 139.31874 104.17830  43.26545 126.50414 505.88581 201.71653\nHsihseng   105.30573 257.11202 209.88026 250.27059 677.66886 175.89761\nMongla     441.20998 393.18472 381.40808 241.58966 256.80556 315.93218\nHseni      243.98001 171.50398 164.05304  81.20593 381.30567 204.49010\nKunlong    249.36301 318.30406 285.04608 215.63037 547.24297 122.68682\nHopang     336.38582 321.16462 279.84188 154.91633 377.44407 230.78652\nNamhkan    442.77120 379.41126 367.33575 247.81990 238.67060 342.43665\nKengtung   297.67761 209.38215 208.29647 136.23356 330.08211 258.23950\nLangkho    219.21623 190.30257 156.51662  51.67279 413.64173 160.94435\nMonghsu    113.84636 242.04063 170.09168 200.77712 633.21624 163.28926\nTaunggyi   440.66133 304.96838 344.79200 312.60547 250.81471 425.36916\nPangwaun   423.81347 453.02765 381.67478 308.31407 541.97887 351.78203\nKyethi     162.43575 317.74604 267.21607 328.14177 757.16745 255.83275\nLoilen     181.94596 265.29318 219.26405 146.92675 560.43400  59.69478\nManton     403.82131 551.13000 475.77296 522.86003 941.49778 458.30232\nMongyang   363.58788 363.37684 323.32123 188.59489 389.59919 229.71502\nKunhing    213.46379 278.68953 206.15773 145.00266 533.00162 142.03682\nMongyawng  248.43910 179.07229 220.61209 181.55295 422.37358 211.99976\nTangyan    167.79937 323.14701 269.07880 306.78359 736.93741 224.29176\nNamhsan    207.16559 362.84062 299.74967 347.85944 778.52971 273.79672\n             Mongnai   Mawkmai    Kutkai   Mongton   Mongyai Mongkaing\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai    374.50873                                                  \nKutkai      91.15307 364.95519                                        \nMongton    131.67061 313.35220 107.06341                              \nMongyai    203.23607 178.70499 188.94166 159.79790                    \nMongkaing  456.00842 133.29995 428.96133 365.50032 262.84016          \nLashio     270.86983 638.60773 289.82513 347.11584 466.36472 708.65819\nMongpan    178.09554 509.99632 185.18173 200.31803 346.39710 563.56780\nMatman     376.33870 147.83545 340.86349 303.04574 186.95158 135.51424\nTachileik  563.95232 919.38755 568.99109 608.76740 750.29555 967.14087\nNarphan    329.31700 273.75350 314.27683 215.97925 248.82845 285.65085\nMongkhet   275.76855 115.58388 273.91673 223.22828 104.98924 222.60577\nHsipaw      52.68195 351.34601  51.46282  90.69766 177.33790 423.77868\nMonghsat   125.25968 275.09705 154.32012 150.98053 127.35225 375.60376\nMongmao    188.29603 485.52853 204.69232 206.57001 335.61300 552.31959\nNansang     92.79567 462.41938 130.04549 199.58124 288.55962 542.16609\nLaukkaing  551.56800 882.51110 580.38112 604.66190 732.68347 954.11795\nPangsang   204.25746 484.14757 228.33583 210.77938 343.30638 548.40662\nNamtu      209.35473 427.95451 225.28268 308.71751 278.02761 525.04057\nMonghpyak  253.26470 536.71695 206.61627 258.04282 370.01575 568.21089\nKonkyan    328.82831 339.01411 310.60810 248.25265 287.87384 380.92091\nMongping   202.99615 194.31049 182.75266 119.86993  65.38727 257.18572\nHopong      91.53795 302.84362  73.45899 106.21031 124.62791 379.37916\nNyaungshwe 169.63695 502.99026 152.15482 219.72196 327.13541 557.32112\nHsihseng   142.36728 329.29477 128.21054 194.64317 162.27126 411.59788\nMongla     354.10985 686.88950 388.40984 411.06668 535.28615 761.48327\nHseni      216.81639 582.53670 229.37894 286.75945 408.23212 648.04408\nKunlong    202.92529 446.53763 204.54010 270.02165 299.36066 539.91284\nHopang     243.00945 561.24281 263.31986 273.50305 408.73288 626.17673\nNamhkan    370.05669 706.47792 392.48568 414.53594 550.62819 771.39688\nKengtung   272.28711 632.54638 279.19573 329.38387 460.39706 692.74693\nLangkho    174.67678 531.08019 180.51419 236.70878 358.95672 597.42714\nMonghsu     84.11238 332.07962  62.60859 107.04894 154.86049 400.71816\nTaunggyi   448.55282 810.74692 450.33382 508.40925 635.94105 866.21117\nPangwaun   312.13429 500.68857 321.80465 257.50434 394.07696 536.95736\nKyethi     210.50453 278.85535 184.23422 222.52947 137.79420 352.06533\nLoilen      58.41263 388.73386 131.56529 176.16001 224.79239 482.18190\nManton     391.54062 109.08779 361.82684 310.20581 195.59882  81.75337\nMongyang   260.39387 558.83162 285.33223 295.60023 414.31237 631.91325\nKunhing    110.55197 398.43973 108.84990 114.03609 238.99570 465.03971\nMongyawng  275.77546 620.04321 281.03383 375.22688 445.78964 700.98284\nTangyan    180.37471 262.66006 166.61820 198.88460 109.08506 348.56123\nNamhsan    218.10003 215.19289 191.32762 196.76188  77.35900 288.66231\n              Lashio   Mongpan    Matman Tachileik   Narphan  Mongkhet\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan    172.33279                                                  \nMatman     628.11049 494.81014                                        \nTachileik  311.95286 411.03849 890.12935                              \nNarphan    525.63854 371.13393 312.05193 760.29566                    \nMongkhet   534.44463 412.17123 203.02855 820.50164 217.28718          \nHsipaw     290.86435 179.52054 344.45451 576.18780 295.40170 253.80950\nMonghsat   377.86793 283.30992 313.59911 677.09508 278.21548 167.98445\nMongmao    214.23677 131.59966 501.59903 472.95568 331.42618 375.35820\nNansang    184.47950 144.77393 458.06573 486.77266 398.13308 360.99219\nLaukkaing  334.65738 435.58047 903.72094 325.06329 708.82887 769.06406\nPangsang   236.72516 140.23910 506.29940 481.31907 316.30314 375.58139\nNamtu      365.88437 352.91394 416.65397 659.56458 494.36143 355.99713\nMonghpyak  262.09281 187.85699 470.46845 444.04411 448.40651 462.63265\nKonkyan    485.51312 365.87588 392.40306 730.92980 158.82353 254.24424\nMongping   454.52548 318.47482 201.65224 727.08969 188.64567 113.80917\nHopong     345.31042 239.43845 291.84351 632.45718 294.40441 212.99485\nNyaungshwe 201.58191 137.29734 460.91883 445.81335 427.94086 417.08639\nHsihseng   369.00833 295.87811 304.02806 658.87060 377.52977 256.70338\nMongla     179.95877 253.20001 708.17595 347.33155 531.46949 574.40292\nHseni       79.41836 120.66550 564.64051 354.90063 474.12297 481.88406\nKunlong    295.23103 288.03320 468.27436 595.70536 413.07823 341.68641\nHopang     170.63913 135.62913 573.55355 403.82035 397.85908 451.51070\nNamhkan    173.27153 240.34131 715.42102 295.91660 536.85519 596.19944\nKengtung    59.85893 142.21554 613.01033 295.90429 505.40025 531.35998\nLangkho    115.18145  94.98486 518.86151 402.33622 420.65204 428.08061\nMonghsu    325.71557 216.25326 308.13805 605.02113 311.92379 247.73318\nTaunggyi   195.14541 319.81385 778.45810 150.84117 684.20905 712.80752\nPangwaun   362.45608 232.52209 523.43600 540.60474 264.64997 407.02947\nKyethi     447.10266 358.89620 233.83079 728.87329 374.90376 233.25039\nLoilen     268.92310 207.25000 406.56282 573.75476 354.79137 284.76895\nManton     646.66493 507.96808  59.52318 910.23039 280.26395 181.33894\nMongyang   209.33700 194.93467 585.61776 448.79027 401.39475 445.40621\nKunhing    255.10832 137.85278 403.66587 532.26397 281.62645 292.49814\nMongyawng  172.70139 275.15989 601.80824 432.10118 572.76394 522.91815\nTangyan    429.84475 340.39128 242.78233 719.84066 348.84991 201.49393\nNamhsan    472.04024 364.77086 180.09747 754.03913 316.54695 170.90848\n              Hsipaw  Monghsat   Mongmao   Nansang Laukkaing  Pangsang\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat   121.78922                                                  \nMongmao    185.99483 247.17708                                        \nNansang    120.24428 201.92690 164.99494                              \nLaukkaing  569.06099 626.44910 404.00848 480.60074                    \nPangsang   205.04337 256.37933  57.60801 193.36162 408.04016          \nNamtu      229.44658 231.78673 365.03882 217.61884 664.06286 392.97391\nMonghpyak  237.67919 356.84917 291.88846 227.52638 565.84279 315.11651\nKonkyan    296.74316 268.25060 281.87425 374.70456 635.92043 274.81900\nMongping   168.92101 140.95392 305.57166 287.36626 708.13447 308.33123\nHopong      62.86179 100.45714 244.16253 167.66291 628.48557 261.51075\nNyaungshwe 169.92664 286.37238 230.45003 131.18943 520.24345 257.77823\nHsihseng   136.54610 153.49551 311.98001 193.53779 670.74564 335.52974\nMongla     373.47509 429.00536 216.24705 289.45119 202.55831 217.88123\nHseni      231.48538 331.22632 184.67099 136.45492 391.74585 214.66375\nKunlong    205.10051 202.31862 224.43391 183.01388 521.88657 258.49342\nHopang     248.72536 317.64824  78.29342 196.47091 331.67199  92.57672\nNamhkan    382.79302 455.10875 223.32205 302.89487 196.46063 231.38484\nKengtung   284.08582 383.72138 207.58055 193.67980 351.48520 229.85484\nLangkho    183.05109 279.52329 134.50170  99.39859 410.41270 167.65920\nMonghsu     58.55724 137.24737 242.43599 153.59962 619.01766 260.52971\nTaunggyi   462.31183 562.88102 387.33906 365.04897 345.98041 405.59730\nPangwaun   298.12447 343.53898 187.40057 326.12960 470.63605 157.48757\nKyethi     195.17677 190.50609 377.89657 273.02385 749.99415 396.89963\nLoilen      98.04789 118.65144 190.26490  94.23028 535.57527 207.94433\nManton     359.60008 317.15603 503.79786 476.55544 907.38406 504.75214\nMongyang   267.10497 312.64797  91.06281 218.49285 326.19219 108.37735\nKunhing     90.77517 165.38834 103.91040 128.20940 500.41640 123.18870\nMongyawng  294.70967 364.40429 296.40789 191.11990 454.80044 336.16703\nTangyan    167.69794 144.59626 347.14183 249.70235 722.40954 364.76893\nNamhsan    194.47928 169.56962 371.71448 294.16284 760.45960 385.65526\n               Namtu Monghpyak   Konkyan  Mongping    Hopong Nyaungshwe\nPindaya                                                                \nYwangan                                                                \nPinlaung                                                               \nMabein                                                                 \nKalaw                                                                  \nPekon                                                                  \nLawksawk                                                               \nNawnghkio                                                              \nKyaukme                                                                \nMuse                                                                   \nLaihka                                                                 \nMongnai                                                                \nMawkmai                                                                \nKutkai                                                                 \nMongton                                                                \nMongyai                                                                \nMongkaing                                                              \nLashio                                                                 \nMongpan                                                                \nMatman                                                                 \nTachileik                                                              \nNarphan                                                                \nMongkhet                                                               \nHsipaw                                                                 \nMonghsat                                                               \nMongmao                                                                \nNansang                                                                \nLaukkaing                                                              \nPangsang                                                               \nNamtu                                                                  \nMonghpyak  346.57799                                                   \nKonkyan    478.37690 463.39594                                         \nMongping   321.66441 354.76537 242.02901                               \nHopong     206.82668 267.95563 304.49287 134.00139                     \nNyaungshwe 271.41464 103.97300 432.35040 319.32583 209.32532           \nHsihseng   131.89940 285.37627 383.49700 199.64389  91.65458  225.80242\nMongla     483.49434 408.03397 468.09747 512.61580 432.31105  347.60273\nHseni      327.41448 200.26876 448.84563 395.58453 286.41193  130.86310\nKunlong    233.60474 357.44661 329.11433 309.05385 219.06817  285.13095\nHopang     408.24516 304.26577 348.18522 379.27212 309.77356  247.19891\nNamhkan    506.32466 379.50202 481.59596 523.74815 444.13246  333.32428\nKengtung   385.33554 221.47613 474.82621 442.80821 340.47382  177.75714\nLangkho    305.03473 200.27496 386.95022 343.96455 239.63685  128.26577\nMonghsu    209.64684 232.17823 331.72187 158.90478  43.40665  173.82799\nTaunggyi   518.72748 334.17439 650.56905 621.53039 513.76415  325.09619\nPangwaun   517.03554 381.95144 263.97576 340.37881 346.00673  352.92324\nKyethi     186.90932 328.16234 400.10989 187.43974 136.49038  288.06872\nLoilen     194.24075 296.99681 334.19820 231.99959 124.74445  206.40432\nManton     448.58230 502.20840 366.66876 200.48082 310.58885  488.79874\nMongyang   413.26052 358.17599 329.39338 387.80686 323.35704  294.29500\nKunhing    296.43996 250.74435 253.74202 212.59619 145.15617  189.97131\nMongyawng  262.24331 285.56475 522.38580 455.59190 326.59925  218.12104\nTangyan    178.69483 335.26416 367.46064 161.67411 106.82328  284.14692\nNamhsan    240.95555 352.70492 352.20115 130.23777 132.70541  315.91750\n            Hsihseng    Mongla     Hseni   Kunlong    Hopang   Namhkan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla     478.66210                                                  \nHseni      312.74375 226.82048                                        \nKunlong    231.85967 346.46200 276.19175                              \nHopang     370.01334 147.02444 162.80878 271.34451                    \nNamhkan    492.09476  77.21355 212.11323 375.73885 146.18632          \nKengtung   370.72441 202.45004  66.12817 317.14187 164.29921 175.63015\nLangkho    276.27441 229.01675  66.66133 224.52741 134.24847 224.40029\nMonghsu     97.82470 424.51868 262.28462 239.89665 301.84458 431.32637\nTaunggyi   528.14240 297.09863 238.19389 471.29032 329.95252 257.29147\nPangwaun   433.06326 319.18643 330.70182 392.45403 206.98364 310.44067\nKyethi      84.04049 556.02500 388.33498 298.55859 440.48114 567.86202\nLoilen     158.84853 338.67408 227.10984 166.53599 242.89326 364.90647\nManton     334.87758 712.51416 584.63341 479.76855 577.52046 721.86149\nMongyang   382.59743 146.66661 210.19929 247.22785  69.25859 167.72448\nKunhing    220.15490 306.47566 206.47448 193.77551 172.96164 314.92119\nMongyawng  309.51462 315.57550 173.86004 240.39800 290.51360 321.21112\nTangyan     70.27241 526.80849 373.07575 268.07983 412.22167 542.64078\nNamhsan    125.74240 564.02740 411.96125 310.40560 440.51555 576.42717\n            Kengtung   Langkho   Monghsu  Taunggyi  Pangwaun    Kyethi\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho    107.16213                                                  \nMonghsu    316.91914 221.84918                                        \nTaunggyi   186.28225 288.27478 486.91951                              \nPangwaun   337.48335 295.38434 343.38498 497.61245                    \nKyethi     444.26274 350.91512 146.61572 599.57407 476.62610          \nLoilen     282.22935 184.10672 131.55208 455.91617 331.69981 232.32965\nManton     631.99123 535.95620 330.76503 803.08034 510.79265 272.03299\nMongyang   217.08047 175.35413 323.95988 374.58247 225.25026 453.86726\nKunhing    245.95083 146.38284 146.78891 429.98509 229.09986 278.95182\nMongyawng  203.87199 186.11584 312.85089 287.73864 475.33116 387.71518\nTangyan    429.95076 332.02048 127.42203 592.65262 447.05580  47.79331\nNamhsan    466.20497 368.20978 153.22576 631.49232 448.58030  68.67929\n              Loilen    Manton  Mongyang   Kunhing Mongyawng   Tangyan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho                                                               \nMonghsu                                                               \nTaunggyi                                                              \nPangwaun                                                              \nKyethi                                                                \nLoilen                                                                \nManton     419.06087                                                  \nMongyang   246.76592 585.70558                                        \nKunhing    130.39336 410.49230 188.89405                              \nMongyawng  261.75211 629.43339 304.21734 295.35984                    \nTangyan    196.60826 271.82672 421.06366 249.74161 377.52279          \nNamhsan    242.15271 210.48485 450.97869 270.79121 430.02019  63.67613\n\n\n\n\n\n\n# Ward.D agglomerative hierarchical clustering ---------------------------------\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D') # build dendrogram with Ward’s method\n\n\n# Plot dendrogram (smaller labels) ---------------------------------------------\nplot(hclust_ward, cex = 0.6) # visual tree of township similarity\n\n\n\n\n\n\n\n\n\n\n\nOne of the challenge in performing hierarchical clustering is to identify stronger clustering structures. The issue can be solved by using use agnes() function of cluster package. It functions like hclus(), however, with the agnes() function we can also get the agglomerative coefficient, which measures the amount of clustering structure found (values closer to 1 suggest strong clustering structure).\nThe code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.\n\n# Compare agglomerative coefficients across linkage methods --------------------\nm &lt;- c(\"average\", \"single\", \"complete\", \"ward\") # candidate methods\nnames(m) &lt;- c(\"average\", \"single\", \"complete\", \"ward\") # name the vector for map_dbl\n\n\nac &lt;- function(x) { cluster::agnes(shan_ict, method = x)$ac } # function returning agglomerative coef\n\n\npurrr::map_dbl(m, ac) # higher (~1) → stronger clustering\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\n\n\n\n\n\n\nNoteObservations:\n\n\n\nWith reference to the output above, we can see that Ward’s method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward’s method will be used.\n\n\n\n\n\nAnother technical challenge face by data analyst in performing clustering analysis is to determine the optimal clusters to retain.\nThere are three commonly used methods to determine the optimal clusters, they are:\n\nElbow Method\n\nAverage Silhouette Method\n\nGap Statistic Method\n\n\n\nThe gap statisticcompares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.\nTo compute the gap statistic, clusGap() of cluster package will be used.\n\n# Gap statistic using hcut() from factoextra -----------------------------------\nset.seed(12345) # reproducibility as per notes\ngap_stat &lt;- cluster::clusGap(shan_ict, FUN = factoextra::hcut, # wrapper around hclust\nnstart = 25, K.max = 10, B = 50) # 25 random starts; up to 10 clusters\n\n\nprint(gap_stat, method = \"firstmax\") # print suggested k (often 1, next best ~6)\n\nClustering Gap statistic [\"clusGap\"] from call:\ncluster::clusGap(x = shan_ict, FUNcluster = factoextra::hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --&gt; Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\nAlso note that the hcut function used is from factoextra package.\nNext, we can visualise the plot by using fviz_gap_stat() of factoextra package.\n\n# Visualise gap statistic curve -------------------------------------------------\nfactoextra::fviz_gap_stat(gap_stat) # plot with error bars\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\nℹ The deprecated feature was likely used in the factoextra package.\n  Please report the issue at &lt;https://github.com/kassambara/factoextra/issues&gt;.\n\n\n\n\n\n\n\n\n\nWith reference to the gap statistic graph above, the recommended number of cluster to retain is 1. However, it is not logical to retain only one cluster. By examine the gap statistic graph, the 6-cluster gives the largest gap statistic and should be the next best cluster to pick.\n\n\n\n\n\n\nNote\n\n\n\nIn addition to these commonly used approaches, the NbClust package, published by Charrad et al., 2014, provides 30 indices for determining the relevant number of clusters and proposes to users the best clustering scheme from the different results obtained by varying all combinations of number of clusters, distance measures, and clustering methods.\n\n\n\n\n\n\nIn the dendrogram displayed above, each leaf corresponds to one observation. As we move up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.\nThe height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are. Note that, conclusions about the proximity of two observations can be drawn only based on the height where branches containing those two observations first are fused. We cannot use the proximity of two observations along the horizontal axis as a criteria of their similarity.\nIt’s also possible to draw the dendrogram with a border around the selected clusters by using rect.hclust() of R stats. The argument border is used to specify the border colors for the rectangles.\n\n# Draw rectangles to highlight k = 6 clusters on Ward dendrogram ----------------\nplot(hclust_ward, cex = 0.6) # redraw base dendrogram\nrect.hclust(hclust_ward, k = 6, border = 2:5) # coloured boxes for six clusters\n\n\n\n\n\n\n\n\n\n\n\n\n# Convert to matrix and draw an interactive cluster heatmap ---------------------\nshan_ict_mat &lt;- data.matrix(shan_ict) # matrix required by heatmaply\n\n\nheatmaply::heatmaply(heatmaply::normalize(shan_ict_mat), # normalise columns to [0,1]\nColv = NA, # keep variables order\ndist_method = \"euclidean\", # distance for rows\nhclust_method = \"ward.D\", # Ward linkage for rows\nseriate = \"OLO\", # optimal leaf ordering\ncolors = Blues, # colour palette per notes\nk_row = 6, # show 6 row clusters\nmargins = c(NA, 200, 60, NA), # wider left/bottom margins for labels\nfontsize_row = 4, # small text for many rows\nfontsize_col = 5, # slightly larger for cols\nmain = \"Geographic Segmentation of Shan State by ICT indicators\",\nxlab = \"ICT Indicators\",\nylab = \"Townships of Shan State\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\nℹ The deprecated feature was likely used in the dendextend package.\n  Please report the issue at &lt;https://github.com/talgalili/dendextend/issues&gt;.\n\n\n\n\n\n\n\n\n\n\n# Cut the Ward dendrogram into 6 groups and append to sf -----------------------\ngroups &lt;- as.factor(cutree(hclust_ward, k = 6)) # factor labels 1..6\n\ngroups\n\n   Mongmit    Pindaya    Ywangan   Pinlaung     Mabein      Kalaw      Pekon \n         1          1          2          1          3          3          1 \n  Lawksawk  Nawnghkio    Kyaukme       Muse     Laihka    Mongnai    Mawkmai \n         3          3          3          4          1          1          5 \n    Kutkai    Mongton    Mongyai  Mongkaing     Lashio    Mongpan     Matman \n         1          1          5          2          3          3          2 \n Tachileik    Narphan   Mongkhet     Hsipaw   Monghsat    Mongmao    Nansang \n         4          5          5          1          5          6          1 \n Laukkaing   Pangsang      Namtu  Monghpyak    Konkyan   Mongping     Hopong \n         4          6          1          3          5          5          1 \nNyaungshwe   Hsihseng     Mongla      Hseni    Kunlong     Hopang    Namhkan \n         3          1          4          3          1          6          4 \n  Kengtung    Langkho    Monghsu   Taunggyi   Pangwaun     Kyethi     Loilen \n         3          3          1          4          6          1          1 \n    Manton   Mongyang    Kunhing  Mongyawng    Tangyan    Namhsan \n         2          6          1          3          1          1 \nLevels: 1 2 3 4 5 6\n\n\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;% # bind as new column\ndplyr::rename(`CLUSTER` = `as.matrix.groups.`) # rename to CLUSTER (exact style)\n\n\n# Map the non-spatial hierarchical clusters ------------------------------------\nqtm(shan_sf_cluster, \"CLUSTER\") # categorical choropleth of clusters\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteObservations:\n\n\n\nThe choropleth map above reveals the clusters are very fragmented. The is one of the major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used."
  },
  {
    "objectID": "Hands-on_Ex06/hand-on_ex06.html#spatially-constrained-clustering-skater-approach",
    "href": "Hands-on_Ex06/hand-on_ex06.html#spatially-constrained-clustering-skater-approach",
    "title": "Hands-on Ex06",
    "section": "",
    "text": "In this section, we will learn how to derive spatially constrained cluster by using skater() method of spdep package.\n\n\n\n# SKATER expects 'sp' polygons; convert sf → sp --------------------------------\nshan_sp &lt;- sf::as_Spatial(shan_sf) # SpatialPolygonsDataFrame object\n\n\n\n\n\n# Build contiguity neighbours (queen) from polygons ----------------------------\n\nshan.nb &lt;- spdep::poly2nb(shan_sp) # list of neighbours by shared borders\n\nsummary(shan.nb) # report links & degree distribution\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\n\n# Plot neighbours atop township boundaries -------------------------------------\ncoords &lt;- sf::st_coordinates(sf::st_centroid(sf::st_geometry(shan_sf))) # centroid coords for each polygon\n\n\nplot(sf::st_geometry(shan_sf), border = grey(.5)) # draw boundaries first (avoid clipping)\nplot(shan.nb, coords, col = \"blue\", add = TRUE) # overlay neighbour graph\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that if we plot the network first and then the boundaries, some of the areas will be clipped. This is because the plotting area is determined by the characteristics of the first plot. In this example, because the boundary map extends further than the graph, we plot it first.\n\n\n\n\n\n\n\n\n# Edge costs as attribute-space dissimilarity between neighbouring townships ----\nlcosts &lt;- spdep::nbcosts(shan.nb, shan_ict)\n\nglimpse(lcosts)\n\nList of 55\n $ : num [1:4] 263 144 431 238\n $ : num [1:3] 257 303 204\n $ : num [1:2] 257 432\n $ : num [1:3] 182 94.6 138.1\n $ : num [1:2] 263 674\n $ : num [1:5] 302.5 182 140 95.7 252.3\n $ : num [1:2] 94.6 139.3\n $ : num [1:9] 204.3 432.2 140 90.8 186.3 ...\n $ : num [1:2] 90.8 157\n $ : num [1:5] 144 186 157 164 348\n $ : num [1:3] 593 705 239\n $ : num [1:5] 523 78.8 157.5 255.8 59.7\n $ : num [1:7] 374.5 131.7 178.1 92.8 203 ...\n $ : num [1:5] 375 462 329 531 389\n $ : num [1:7] 593 580 311 229 205 ...\n $ : num [1:5] 132 200 151 120 237\n $ : num [1:4] 466 177 138 109\n $ : num [1:5] 625 523 424 379 352\n $ : num [1:7] 466.4 290.9 365.9 79.4 170.6 ...\n $ : num [1:3] 178 200 95\n $ : num [1:6] 203 506 202 308 586 ...\n $ : num [1:3] 677 444 432\n $ : num [1:3] 331 316 265\n $ : num [1:5] 203 114 574 531 445\n $ : num [1:8] 249 164 177 424 291 ...\n $ : num [1:5] 151 677 357 141 384\n $ : num [1:5] 331.4 57.6 78.3 187.4 347.1\n $ : num [1:6] 78.8 92.8 462.4 273 94.2 ...\n $ : num [1:4] 580 636 522 332\n $ : num [1:5] 506.3 316.3 57.6 108.4 364.8\n $ : num [1:4] 366 229 449 241\n $ : num [1:5] 444 357 408 221 286\n $ : num [1:3] 705 311 636\n $ : num [1:8] 203 120 202 114 141 ...\n $ : num [1:6] 274.9 157.5 379.4 91.7 513.8 ...\n $ : num [1:5] 138.1 95.7 139.3 225.8 325.1\n $ : num [1:5] 329.3 91.7 225.8 528.1 158.8\n $ : num [1:5] 574 408 202 147 316\n $ : num [1:5] 229.4 79.4 276.2 162.8 584.6\n $ : num [1:4] 205 522 276 271\n $ : num [1:6] 170.6 78.3 331.7 162.8 271.3 ...\n $ : num [1:3] 239 392 722\n $ : num [1:5] 531 384 221 443 202\n $ : num [1:4] 175 531 237 95\n $ : num [1:5] 308 159 147 147 127\n $ : num [1:5] 252 305 514 325 528\n $ : num [1:2] 265 187\n $ : num [1:8] 256 138 352 195 273 ...\n $ : num [1:5] 59.7 388.7 94.2 124.7 158.8\n $ : num [1:8] 431 674 362 647 449 ...\n $ : num [1:4] 586 445 108 147\n $ : num [1:5] 111 128 213 147 279\n $ : num [1:3] 432 286 316\n $ : num [1:8] 109 430 243 347 365 ...\n $ : num [1:5] 238 348 194 241 210\n - attr(*, \"call\")= language spdep::nbcosts(nb = shan.nb, data = shan_ict)\n - attr(*, \"class\")= chr \"nbdist\"\n\n\n\n# Convert neighbour list + costs into a weights list object --------------------\nshan.w &lt;- spdep::nb2listw(shan.nb, lcosts, style = \"B\") # 'B' keeps raw costs (no row standardise)\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004\n\n\n\n\n\n\n\n# Compute Minimum Spanning Tree (MST) over the neighbour graph with edge costs --------------------------\nshan.mst &lt;- spdep::mstree(shan.w) # returns an 'mst' matrix (n-1 edges)\n\n\n# Check its class \nclass(shan.mst); \n\n[1] \"mst\"    \"matrix\"\n\n\n\n# Check its dimension \ndim(shan.mst)\n\n[1] 54  3\n\n\n\nThe dimension is 54 and not 55. This is because the minimum spanning tree consists on n-1 edges (links) in order to traverse all the nodes.\n\n\n# Inspect the content of shan.mst\nhead(shan.mst)\n\n     [,1] [,2]      [,3]\n[1,]   54   48  47.79331\n[2,]   54   17 109.08506\n[3,]   54   45 127.42203\n[4,]   45   52 146.78891\n[5,]   52   13 110.55197\n[6,]   13   28  92.79567\n\n\n\n# Plot MST atop map -------------------------------------------------------------\nplot(sf::st_geometry(shan_sf), border = gray(.5)) # base map\nspdep::plot.mst(shan.mst, coords, col = \"blue\", cex.lab = 0.7, # draw MST links + node ids\ncex.circles = 0.005, add = TRUE)\n\n\n\n\n\n\n\n\n\nThe plot method for the MST include a way to show the observation numbers of the nodes in addition to the edge. As before, we plot this together with the township boundaries. We can see how the initial neighbour list is simplified to just one edge connecting each of the nodes, while passing through all the nodes.\n\n\n\n\n\n# Cut MST into k-1 edges (ncuts = 5 → k = 6 clusters) --------------------------\nclust6 &lt;- spdep::skater(edges = shan.mst[, 1:2], # first 2 columns are node indices\ndata = shan_ict, # attribute data to update SSW\nmethod = \"euclidean\", # distance in attribute space\nncuts = 5) # 6 clusters (k = ncuts + 1)\n\n\n\n\n\n\n\nNote\n\n\n\nThe skater() takes three mandatory arguments:\n\nthe first two columns of the MST matrix (i.e. not the cost),\n\nthe data matrix (to update the costs as units are being grouped), and\nthe number of cuts.\n\nNote: It is set to one less than the number of clusters. So, the value specified is not the number of clusters, but the number of cuts in the graph, one less than the number of clusters.\n\n\n\nstr(clust6) # list; includes $groups (cluster labels)\n\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 52 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 25 13 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 1458\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\n\nThe most interesting component of this list structure is the groups vector containing the labels of the cluster to which each observation belongs (as before, the label itself is arbitary). This is followed by a detailed summary for each of the clusters in the edges.groups list. Sum of squares measures are given as ssto for the total and ssw to show the effect of each of the cuts on the overall criterion.\n\nWe can check the cluster assignment by using the conde chunk below.\n\n# Check the cluster assignment\ncc6 &lt;- clust6$groups; cc6 # vector of cluster assignments\n\n [1] 3 3 6 3 3 3 3 3 3 3 2 1 1 1 2 1 1 1 2 4 1 2 5 1 1 1 2 1 2 2 1 2 2 1 1 3 1 2\n[39] 2 2 2 2 2 4 1 3 2 1 1 1 2 1 2 1 1\n\ncc6\n\n [1] 3 3 6 3 3 3 3 3 3 3 2 1 1 1 2 1 1 1 2 4 1 2 5 1 1 1 2 1 2 2 1 2 2 1 1 3 1 2\n[39] 2 2 2 2 2 4 1 3 2 1 1 1 2 1 2 1 1\n\n\nWe can find out how many observations are in each cluster by means of the table command. Parenthetially, we can also find this as the dimension of each vector in the lists contained in edges.groups. For example, the first list has node with dimension 12, which is also the number of observations in the first cluster.\n\ntable(cc6) # size of each cluster\n\ncc6\n 1  2  3  4  5  6 \n22 18 11  2  1  1 \n\n\nLastly, we can also plot the pruned tree that shows the five clusters on top of the townshop area.\n\n# Visualise the pruned tree coloured by groups ---------------------------------\nplot(sf::st_geometry(shan_sf), border = gray(.5)) # background polygons\nplot(clust6, coords, cex.lab = .7, # SKATER plotting helper\ngroups.colors = c(\"red\", \"green\", \"blue\", \"brown\", \"pink\"),\ncex.circles = 0.005, add = TRUE)\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\n\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below is used to plot the newly derived clusters by using SKATER method.\n\n# Append SKATER groups to sf and map -------------------------------------------\ngroups_mat &lt;- as.matrix(clust6$groups) # coerce to matrix for cbind\n\n\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;% # bind to previous sf\ndplyr::rename(`SP_CLUSTER` = `as.factor.groups_mat.`) # new field name per notes\n\n\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\") # map spatially constrained clusters\n\n\n\n\n\n\n\n\nFor easy comparison, it will be better to place both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other.\n\n# Side-by-side comparison of non-spatial vs spatially constrained clusters -----\nhclust.map &lt;- qtm(shan_sf_cluster, \"CLUSTER\") + tm_borders(alpha = 0.5) # non-spatial clusters\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n\nshclust.map &lt;- qtm(shan_sf_spatialcluster, \"SP_CLUSTER\") + tm_borders(alpha = 0.5) # SKATER clusters\n\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n\ntmap_arrange(hclust.map, shclust.map, asp = NA, ncol = 2) # compare fragmentation vs contiguity"
  },
  {
    "objectID": "Hands-on_Ex06/hand-on_ex06.html#spatially-constrained-clustering-clustgeo-method",
    "href": "Hands-on_Ex06/hand-on_ex06.html#spatially-constrained-clustering-clustgeo-method",
    "title": "Hands-on Ex06",
    "section": "",
    "text": "ClustGeo implements Ward‑like hierarchical clustering with a mixing parameter alpha ∈ [0,1] combining attribute dissimilarities (D0) and spatial dissimilarities (D1). Use choicealpha() to pick alpha balancing contiguity and attribute fit.\n\n\n\n\n# Run hclustgeo() with attribute-space dissimilarity only -----------------------\nnongeo_cluster &lt;- ClustGeo::hclustgeo(proxmat) # same D0 as from dist()\n\n\nplot(nongeo_cluster, cex = 0.5) # dendrogram\nrect.hclust(nongeo_cluster, k = 6, border = 2:5) # highlight 6 clusters\n\n\n\n\n\n\n\n# Map the non-spatial ClustGeo clusters ----------------------------------------\ngroups &lt;- as.factor(cutree(nongeo_cluster, k = 6)) # cut into 6 groups\n\n\nshan_sf_ngeo_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;% # bind to polygons\ndplyr::rename(`CLUSTER` = `as.matrix.groups.`)\n\n\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\") # categorical map\n\n\n\n\n\n\n\n\n\n\n\n\n# Build spatial distance matrix between polygon centroids ----------------------\ndist &lt;- sf::st_distance(shan_sf, shan_sf) # pairwise great-circle distances\n\n\ndistmat &lt;- stats::as.dist(dist) # convert to 'dist' object for ClustGeo (convert dataframe into matrix)\n\n\n# Choose alpha that trades off contiguity vs attribute fit ---------------------\ncr &lt;- ClustGeo::choicealpha(proxmat, distmat, # D0 and D1 matrices\nrange.alpha = seq(0, 1, 0.1), K = 6, # evaluate alpha from 0..1 for K=6\ngraph = TRUE) # display criterion curves\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# With reference to the plot above, adopt alpha = 0.2 -------------------------------------\nclustG &lt;- ClustGeo::hclustgeo(proxmat, distmat, alpha = 0.2) # combined D0/D1 with alpha=0.2\n\n\n# Cut into 6 groups and map ----------------------------------------------------\ngroups &lt;- as.factor(cutree(clustG, k = 6)) # labels 1..6\n\n\nshan_sf_Gcluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;% # append to polygons\ndplyr::rename(`CLUSTER` = `as.matrix.groups.`)\n\n\nqtm(shan_sf_Gcluster, \"CLUSTER\") # spatially constrained (ClustGeo) map"
  },
  {
    "objectID": "Hands-on_Ex06/hand-on_ex06.html#visual-interpretation-of-clusters",
    "href": "Hands-on_Ex06/hand-on_ex06.html#visual-interpretation-of-clusters",
    "title": "Hands-on Ex06",
    "section": "",
    "text": "# Boxplot of RADIO_PR by cluster (non-spatial ClustGeo example) ----------------\nggplot(data = shan_sf_ngeo_cluster, # use non-spatial clusters for example\naes(x = CLUSTER, y = RADIO_PR)) +\ngeom_boxplot()\n\n\n\n\n\n\n\n\n\nThe boxplot reveals Cluster 3 displays the highest mean Radio Ownership Per Thousand Household. This is followed by Cluster 2, 1, 4, 6 and 5.\n\n\n\n\n\n# Parallel coordinates (GGally) to compare all ICT rates by cluster -------------\nggparcoord(data = shan_sf_ngeo_cluster,       # data with cluster labels\n           columns = c(17:21),                # columns of *_PR variables (as in notes)\n           scale = \"globalminmax\",            # same vertical scale 0..1 per global range\n           alphaLines = 0.2,                  # faint lines \n           boxplot = TRUE,                    # add per-variable boxplots in background\n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) +                     # one panel per cluster\n  theme(axis.text.x = element_text(angle = 30))  # improve x-axis label readability\n\n\n\n\n\n\n\n\nThe parallel coordinate plot above reveals that households in Cluster 4 townships tend to own the highest number of TV and mobile-phone. On the other hand, households in Cluster 5 tends to own the lowest of all the five ICT.\nNote that the scale argument of ggparcoor() provide several methods to scale the clustering variables. They are:\n\nstd: univariately, subtract mean and divide by standard deviation.\n\nrobust: univariately, subtract median and divide by median absolute deviation.\n\nuniminmax: univariately, scale so the minimum of the variable is zero, and the maximum is one.\n\nglobalminmax: no scaling is done; the range of the graphs is defined by the global minimum and the global maximum.\n\ncenter: use uniminmax to standardize vertical height, then center each variable at a value specified by the scaleSummary param.\n\ncenterObs: use uniminmax to standardize vertical height, then center each variable at the value of the observation specified by the centerObsID param\n\nThere is no one best scaling method to use. You should explore them and select the one that best meet your analysis need.\nLast but not least, we can also compute the summary statistics such as mean, median, sd, etc to complement the visual interpretation.\nIn the code chunk below, group_by() and summarise() of dplyr are used to derive mean values of the clustering variables.\n\n# Compute cluster-wise means to complement visual inspection -------------------\n\nshan_sf_ngeo_cluster %&gt;% \n  st_set_geometry(NULL) %&gt;%                         # work on attributes only\n  group_by(CLUSTER) %&gt;%                             # aggregate by cluster label\n  summarise(mean_RADIO_PR = mean(RADIO_PR),         # mean Radio per 1000 households\n            mean_TV_PR = mean(TV_PR),               # mean TV per 1000 households\n            mean_LLPHONE_PR = mean(LLPHONE_PR),     # mean Landline per 1000 households\n            mean_MPHONE_PR = mean(MPHONE_PR),       # mean Mobile per 1000 households\n            mean_COMPUTER_PR = mean(COMPUTER_PR))   # mean Computer per 1000 households\n\n# A tibble: 6 × 6\n  CLUSTER mean_RADIO_PR mean_TV_PR mean_LLPHONE_PR mean_MPHONE_PR\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;\n1 1               221.        521.            44.2           246.\n2 2               237.        402.            23.9           134.\n3 3               300.        611.            52.2           392.\n4 4               196.        744.            99.0           651.\n5 5               124.        224.            38.0           132.\n6 6                98.6       499.            74.5           468.\n# ℹ 1 more variable: mean_COMPUTER_PR &lt;dbl&gt;"
  },
  {
    "objectID": "Take-home_Ex02/take-home_ex02.html#introduction",
    "href": "Take-home_Ex02/take-home_ex02.html#introduction",
    "title": "Take-home Ex02: Analyzing Neighborhood Bus Mobility and Emerging Urban Trends",
    "section": "1 Introduction",
    "text": "1 Introduction\nPublic transport is the backbone of Singapore’s urban mobility system, linking homes, workplaces and commercial centres into an integrated city network. Within this system, public buses remain the most extensive and inclusive mode, serving both central and peripheral areas. As Singapore advances toward the Land Transport Master Plan 2040, analysing spatial and temporal variations in bus passenger movement is essential for informed planning. Descriptive statistics and heat maps offer only surface patterns and cannot reveal the deeper spatial relationships among travel zones.\nThis study applies Global and Local Measures of Spatial Autocorrelation (G/LMSA), including Global and Local Moran I, and Getis Ord Gi Star, to identify clusters and outliers in bus trip intensity across Singapore. These indicators reveal neighbourhoods of consistently high or low ridership and pinpoint areas that diverge from surrounding conditions. To incorporate the temporal dimension, the study employs Emerging Hot Spot Analysis (EMSA) using the Gi Star statistic together with the Mann Kendall (KM) trend test to assess how hot and cold spots evolve during morning, evening and weekend periods.\nThe results will provide empirical evidence for improving bus network design, enhancing accessibility and promoting a more efficient and equitable transport system that supports sustainable urban development."
  },
  {
    "objectID": "Take-home_Ex02/take-home_ex02.html#research-questions",
    "href": "Take-home_Ex02/take-home_ex02.html#research-questions",
    "title": "Take-home Ex02: Analyzing Neighborhood Bus Mobility and Emerging Urban Trends",
    "section": "2 Research Questions",
    "text": "2 Research Questions\nThe present study aims to examine spatial and temporal patterns of public bus mobility in Singapore through the application of local spatial statistical methods. Building upon the objectives outlined in the exercise, the research is guided by four interrelated questions that connect theoretical analysis with practical urban transport planning.\nRQ1 – Spatial Distribution: Where do bus trips concentrate across the city during weekday morning, weekday evening and weekend periods, and what does this reveal about overall mobility intensity?\nRQ2 – Local Spatial Clustering: Which areas display statistically significant clusters or outliers of bus trip intensity as detected by Local Moran I, and Getis Ord Gi Star (Gi*)?\nRQ3 – Temporal Evolution: How do the identified hot and cold spots change over time, and what categories of emerging, intensifying, diminishing or sporadic patterns can be observed through the Mann Kendall trend analysis?\nRQ4 – Policy and Planning Implications: How can the identified spatial and temporal patterns of bus ridership inform the design of transport policies, allocation of resources and long-term planning for an efficient and inclusive public transport network?\nTogether these questions structure the analytical framework and ensure direct alignment between the study objectives and subsequent methods."
  },
  {
    "objectID": "Take-home_Ex02/take-home_ex02.html#the-data",
    "href": "Take-home_Ex02/take-home_ex02.html#the-data",
    "title": "Take-home Ex02: Analyzing Neighborhood Bus Mobility and Emerging Urban Trends",
    "section": "3 The Data",
    "text": "3 The Data\nThis study uses official datasets from national agencies to analyse spatial and temporal patterns of bus mobility in Singapore. The Land Transport Authority (LTA) DataMall Passenger Volume OD Bus dataset provides detailed records of passenger trips between bus stops, including origin code, destination code, day type, hour and total trip volume. The LTA Bus Stop layer supplies the geographic locations and attributes of all active bus stops, while the Urban Redevelopment Authority (URA) Master Plan 2019 Subzone Boundary defines the official spatial units for aggregation and mapping.\nAll spatial data are projected to the Singapore SVY21 coordinate system (EPSG 3414) to preserve distance accuracy. The datasets are cleaned and joined in the R environment to generate analytical hexagonal zones containing at least one bus stop. These integrated data support the computation of local spatial statistics and the identification of emerging patterns in public bus ridership.\n\n# --- 3.1 Create data source table --------------------------------------------\n\n# Load knitr (already part of pacman::p_load in setup)\npacman::p_load(knitr)\n\n# Create a data frame listing all datasets used in the study\ndata_sources &lt;- data.frame(\n  Dataset_Name = c(\n    \"LTA Passenger Volume OD Bus\",\n    \"LTA Bus Stop Location\",\n    \"URA Master Plan 2019 Subzone Boundary\",\n    \"Coordinate Reference System\"\n  ),\n  Description = c(\n    \"Passenger trips by origin, destination, day type and hour.\",\n    \"Geographic location and attributes of all operational bus stops.\",\n    \"Official planning boundaries for spatial aggregation and mapping.\",\n    \"Projected Singapore SVY21 system ensuring metric distance accuracy.\"\n  ),\n  Format = c(\"CSV\", \"Shapefile\", \"KML / GeoJSON\", \"EPSG 3414\"),\n  Source = c(\n    \"LTA DataMall\",\n    \"LTA DataMall\",\n    \"data.gov.sg (URA)\",\n    \"Singapore Land Authority\"\n  )\n)\n\n# Render the table in Quarto / R Markdown output\nkable(\n  data_sources,\n  caption = \"Table 1: Data Sources for Bus Mobility Analysis in Singapore\",\n  align = \"llll\"\n)\n\n\nTable 1: Data Sources for Bus Mobility Analysis in Singapore\n\n\n\n\n\n\n\n\nDataset_Name\nDescription\nFormat\nSource\n\n\n\n\nLTA Passenger Volume OD Bus\nPassenger trips by origin, destination, day type and hour.\nCSV\nLTA DataMall\n\n\nLTA Bus Stop Location\nGeographic location and attributes of all operational bus stops.\nShapefile\nLTA DataMall\n\n\nURA Master Plan 2019 Subzone Boundary\nOfficial planning boundaries for spatial aggregation and mapping.\nKML / GeoJSON\ndata.gov.sg (URA)\n\n\nCoordinate Reference System\nProjected Singapore SVY21 system ensuring metric distance accuracy.\nEPSG 3414\nSingapore Land Authority"
  },
  {
    "objectID": "Take-home_Ex02/take-home_ex02.html#setup-the-environment",
    "href": "Take-home_Ex02/take-home_ex02.html#setup-the-environment",
    "title": "Take-home Ex02: Analyzing Neighborhood Bus Mobility and Emerging Urban Trends",
    "section": "4 Setup the Environment",
    "text": "4 Setup the Environment\nA consistent analytical environment ensures reproducibility and transparency in spatial data analysis. This section defines the R environment used in the study. All scripts were executed in RStudio using packages that support data wrangling, spatial statistics and visualisation. The pacman package is used to automate installation and loading of required libraries. Each library serves a specific purpose within the analytical workflow, and a random seed is set to guarantee consistent statistical outputs across repeated runs.\n\n# --- 4.1 Load and install required packages ----------------------------------\n\nif (!require(pacman)) install.packages(\"pacman\")  \n# Checks whether 'pacman' is already installed. \n# If missing, it installs the package so that subsequent commands can run.\n\npacman::p_load(                           \n  tidyverse,  # Provides data manipulation and plotting tools (dplyr, ggplot2, readr).\n  stats,      # Base R toolbox for statistical tests, distributions, and modelling.\n  sf,         # Handles spatial vector data such as points, lines, and polygons.\n  spdep,      # Core spatial dependence utilities for spatial neighbour weights, and models.\n  sfdep,      # Performs spatial dependence analysis (Moran I, Gi* and related statistics).\n  tmap,       # Creates static and interactive thematic maps for visualisation.\n  ggplot2,    # Grammar of graphics plotting used for your diagnostics and faceted bar charts.\n  plotly,     # Adds interactivity to ggplot maps and statistical plots.\n  Kendall,    # Performs the Mann Kendall trend test for temporal trend detection.\n  classInt,   # Breaks generators for choropleths.\n  tibble,     # Modern data frame with cleaner printing and safer subsetting for pipelines.\n  purrr,      # Functional programming mappers like map and pmap to run EHSA across multiple periods.\n  knitr,      # Enables dynamic report generation in Quarto or R Markdown.\n  kableExtra  # Enhances table formatting for publication-quality outputs.\n)\n\n# --- 4.2 Reproducibility setting ---------------------------------------------\n\nset.seed(626)  \n# Establishes a fixed random seed so that random processes \n# (for example, simulation-based significance tests) produce identical results on each run."
  },
  {
    "objectID": "Take-home_Ex02/take-home_ex02.html#section",
    "href": "Take-home_Ex02/take-home_ex02.html#section",
    "title": "Take-home Ex02: Analyzing Neighborhood Bus Mobility and Emerging Urban Trends",
    "section": "7 ",
    "text": "7"
  },
  {
    "objectID": "Hands-on_Ex05/hand-on_ex05b.html",
    "href": "Hands-on_Ex05/hand-on_ex05b.html",
    "title": "Hands-on Ex5b",
    "section": "",
    "text": "We will import geospatial and aspatial data for Hunan Province (county level), join attributes, visualise a regional indicator (GDP per capita, GDPPC), build contiguity and distance spatial weights, and compute two local spatial statistics:\n\nLocal Moran’s I (LISA) for cluster/outlier detection.\nGetis–Ord Gi* for Hot/Cold Spot analysis (HCSA).\n\nWe will then create choropleths for I values, \\(p\\)-values, LISA clusters (\\(p &lt; 0.05%\\)), and HCSA clusters (\\(p &lt; 0.05\\)), plus Moran scatterplots (raw and standardised).\n\n\n\n\n\nIn spatial policy, one of the main development objective of the local govenment and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.(https://en.wikipedia.org/wiki/Hunan)\n\n\n\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan province administrative boundary layer at county level (Geospatial). This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv (Aspatial): This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n\n\n# load packages (installs missing ones, then attaches)\npacman::p_load(sf, sfdep, tmap, tidyverse)  # sf for spatial data; sfdep for spatial stats;\n                                            # tmap for mapping; tidyverse for wrangling/ggplot\n\n\n\n\n\n\n# --- 10.3.1 Import shapefile into R environment -----------------------------\n\nhunan &lt;- \n  st_read(                      # read a spatial layer from disk\n    dsn   = \"data/geospatial\",  # folder containing the shapefile set\n    layer = \"Hunan\"             # layer name (without .shp)\n  ) %&gt;% \n  \n  # reproject from WGS84 to UTM zone 50N (EPSG:32650)\n  # (projected CRS is recommended for spatial analysis)\n  st_transform(crs = 32650)        \n\nReading layer `Hunan' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex05/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe raw data is in WGS 84 geographic coordinates system. For geospatial analysis, it is appropriate to use projected coordinates system. In the code chunk above, st_transform() is used to transform Hunan geospatial data from WGS 84 to UTM zone 50N (i.e. EPSG: 32650).\n\n\n\n# --- 10.3.2 Import CSV into R environment ----------------------------------\n\nhunan2012 &lt;- \n  readr::read_csv(\"data/aspatial/Hunan_2012.csv\")  # read the attribute table (tabular CSV)\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n# --- 10.3.3 Join attributes into the sf object ------------------------------\n\nhunan &lt;- \n  left_join(hunan, hunan2012) %&gt;%  # left join by the shared key column(s) (kept from shapefile)\n  select(1:4, 7, 15)               # keep only the columns used in this exercise (as per lesson)\n\nJoining with `by = join_by(County)`\n\n\n\n\n\nequal &lt;- tm_shape(hunan) +\n  tm_polygons(fill = \"GDPPC\",\n              fill.scale = tm_scale_intervals(\n                style = \"equal\",\n                n = 5,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                title = \"GDPPC\",\n                position = tm_pos_in(\n                  \"left\", \"bottom\"))) + \n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_polygons(fill = \"GDPPC\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                title = \"GDPPC\",\n                position = tm_pos_in(\n                  \"left\", \"bottom\"))) + \n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Quantile interval classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteDoes the plot above reveal any outliers or clusters?\n\n\n\n\nThe Equal interval map (left) spreads values evenly across 5 fixed ranges. Because the distribution of GDPPC is skewed, many counties fall into the lower classes, and the map appears very light with only a few darker areas. This makes it difficult to visually spot clear clusters or outliers, since most counties look similar and variation is compressed.\nThe Quantile map (right) divides the counties into 5 groups with equal counts per group. Here, differences are more apparent — some dark blue areas (highest quantile) are grouped together, while very light areas (lowest quantile) are also visible. This gives a stronger sense that there may be regional clustering of high and low GDPPC, but it’s only suggestive.\n\nAnswer: The plots hint at spatial variation, but do not confirm outliers or clusters statistically. Especially in the quantile map, you can see that richer counties cluster in the east, while poorer ones appear in the west/south. Still, formal spatial autocorrelation tests (Moran’s I, LISA) are needed to verify.\n\n\n\n\n\n\n\n\nNoteDoes the plot above indicate the presence of hot spots or cold spots?\n\n\n\n\nBy visual impression only, the dark blue patches in the quantile map (eastern and central counties) could be potential hot spots (high GDPPC areas adjacent to each other).\nConversely, lighter patches (western/southern counties) could be cold spots (low GDPPC areas grouped together).\nHowever, these impressions are not reliable evidence — classification maps can exaggerate or understate differences depending on method.\n\nAnswer: The quantile map suggests possible hot spots in central/eastern Hunan and cold spots in western/southern areas, but the equal interval map is less informative. These are hypotheses only — the next step is to compute Local Moran’s I and Gi* to confirm whether these patterns are statistically significant.\n\n\n\nIn summary: The classification maps are useful exploratory tools. Quantile classification reveals stronger visual contrasts, hinting at clusters of rich and poor counties. But to answer definitively about outliers or hot/cold spots, we must proceed to LISA (Local Moran’s I) and HCSA (Getis–Ord Gi) analyses.\n\n\n\n\n\n\n\n\n# Create Queen-contiguity neighbours and W-style weights (row-standardised)\nwm_q &lt;- hunan %&gt;% \n  mutate(\n    nb = st_contiguity(geometry),   # build a neighbours list from touching polygons (Queen)\n    wt = st_weights(nb, style = \"W\"), # row-standardised weights (sum of weights = 1 per region)\n    .before = 1                     # place the new columns at the beginning (professor's style)\n  )\n\n# Inspect the neighbour structure (how many neighbours per county)\nsummary(wm_q$nb)  # prints count distribution, min/max, and average links\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbour.\n\n\n\n\nlisa &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nlocal_moran() function returns a matrix of values whose columns are:\n\nli: the local Moran’s I statistics\nE.li: the expectation of local moran statistic under the randomisation hypothesis\nVar.li: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\n\nglimpse(lisa)\n\nRows: 88\nColumns: 21\n$ ii           &lt;dbl&gt; -1.468468e-03, 2.587817e-02, -1.198765e-02, 1.022468e-03,…\n$ eii          &lt;dbl&gt; -8.148464e-04, -9.932206e-03, -2.929856e-02, -9.398322e-0…\n$ var_ii       &lt;dbl&gt; 4.589734e-04, 1.136942e-02, 9.800257e-02, 4.136778e-06, 1…\n$ z_ii         &lt;dbl&gt; -0.03050932, 0.33584570, 0.05529697, 0.54891935, 0.270022…\n$ p_ii         &lt;dbl&gt; 9.756609e-01, 7.369872e-01, 9.559019e-01, 5.830608e-01, 7…\n$ p_ii_sim     &lt;dbl&gt; 0.84, 0.98, 0.68, 0.52, 0.68, 0.86, 0.06, 0.06, 0.02, 0.2…\n$ p_folded_sim &lt;dbl&gt; 0.42, 0.49, 0.34, 0.26, 0.34, 0.43, 0.03, 0.03, 0.01, 0.1…\n$ skewness     &lt;dbl&gt; -0.6165755, -0.9102915, 0.7574819, 0.9515344, 0.7445666, …\n$ kurtosis     &lt;dbl&gt; -0.5321037, 0.4113895, -0.1561211, 0.8700892, 0.1347678, …\n$ mean         &lt;fct&gt; Low-High, Low-Low, High-Low, High-High, High-High, High-L…\n$ median       &lt;fct&gt; High-High, High-High, High-High, High-High, High-High, Hi…\n$ pysal        &lt;fct&gt; Low-High, Low-Low, High-Low, High-High, High-High, High-L…\n$ nb           &lt;nb&gt; &lt;2, 3, 4, 57, 85&gt;, &lt;1, 57, 58, 78, 85&gt;, &lt;1, 4, 5, 85&gt;, &lt;1,…\n$ wt           &lt;list&gt; &lt;0.2, 0.2, 0.2, 0.2, 0.2&gt;, &lt;0.2, 0.2, 0.2, 0.2, 0.2&gt;, &lt;0…\n$ NAME_2       &lt;chr&gt; \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"C…\n$ ID_3         &lt;int&gt; 21098, 21100, 21101, 21102, 21103, 21104, 21109, 21110, 2…\n$ NAME_3       &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", …\n$ ENGTYPE_3    &lt;chr&gt; \"County\", \"County\", \"County City\", \"County\", \"County\", \"C…\n$ County       &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", …\n$ GDPPC        &lt;dbl&gt; 23667, 20981, 34592, 24473, 25554, 27137, 63118, 62202, 7…\n$ geometry     &lt;POLYGON [m]&gt; POLYGON ((22320.48 3301894,..., POLYGON ((35522.9…\n\n\n\n\n\ntm_shape(lisa) +\n  tm_polygons(fill = \"ii\",\n              fill.scale = tm_scale_intervals(\n                style = \"pretty\",\n                n = 5,\n                values = \"brewer.RdBu\"),\n              fill.legend = tm_legend(\n                title = \"Local Morans'I\",\n                position = tm_pos_out())) + \n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Loal Morans'I of GDPPC (Queen's method)\")\n\n[scale] tm_polygons:() the data variable assigned to 'fill' contains positive and negative values, so midpoint is set to 0. Set 'midpoint = NA' in 'fill.scale = tm_scale_intervals(&lt;HERE&gt;)' to use all visual values (e.g. colors)\n\n\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"brewer.RdBu\" is\nnamed \"rd_bu\" (in long format \"brewer.rd_bu\")\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(lisa) +\n  tm_polygons(fill = \"p_ii\", \n              fill.scale = tm_scale_intervals(\n                breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n                values = \"-brewer.Reds\"),\n              fill.legend = tm_legend(\n                title = \"p-value\",\n      position = tm_pos_out())) + \n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"p-values of Loal Moran's I of GDPPC (Queen's method)\")\n\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"-brewer.Reds\" is\nnamed \"reds\" (in long format \"brewer.reds\")\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\n\n\n\n\nii.map &lt;- tm_shape(lisa) +\n  tm_polygons(fill = \"ii\",\n              fill.scale = tm_scale_intervals(\n                style = \"pretty\",\n                n = 5,\n                values = \"brewer.RdBu\"),\n              fill.legend = tm_legend(\n                title = \"Local Moran's I\",\n                position = tm_pos_in(\n                  \"left\", \"bottom\"))) + \n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Loal Moran's I of GDPPC (Queen's method)\")\n\np_ii.map &lt;- tm_shape(lisa) +\n  tm_polygons(fill = \"p_ii\", \n              fill.scale = tm_scale_intervals(\n                breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n                values = \"-brewer.Reds\"),\n              fill.legend = tm_legend(\n                title = \"p-value\",\n      position = tm_pos_in(\"left\", \"bottom\")\n    )) + \n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"p-values of Loal Moran's I of GDPPC (Queen's method)\")\n\ntmap_arrange(ii.map, p_ii.map, asp=1, ncol=2)\n\n[scale] tm_polygons:() the data variable assigned to 'fill' contains positive and negative values, so midpoint is set to 0. Set 'midpoint = NA' in 'fill.scale = tm_scale_intervals(&lt;HERE&gt;)' to use all visual values (e.g. colors)\n\n\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"brewer.RdBu\" is\nnamed \"rd_bu\" (in long format \"brewer.rd_bu\")\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"-brewer.Reds\" is\nnamed \"reds\" (in long format \"brewer.reds\")\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# --- Compute spatial lag for GDPPC (needed for Moran scatterplot) -----------\n\nlisa &lt;- lisa %&gt;%\n  mutate(lag_GDPPC = st_lag(\n    GDPPC, nb, wt),\n    .before = 1) %&gt;%\n  unnest(lag_GDPPC)\n\n\n# --- Moran scatterplot (raw values) ----------------------------------------\n\nggplot(data = lisa, \n       aes(x = GDPPC, \n           y = lag_GDPPC)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", \n              se = FALSE, \n              color = \"red\") +\n  labs(x = \"GDPPC\",\n       y = \"Spatial Lag of GDPPC\",\n       title = \"Moran Scatterplot\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nggplot(data = lisa, \n       aes(x = GDPPC, \n           y = lag_GDPPC, \n           color = mean)) +\n  geom_point(size = 2) +\n  geom_smooth(method = \"lm\", \n              se = FALSE, \n              color = \"black\") +\n  geom_hline(yintercept=mean(lisa$lag_GDPPC), lty=2) + \n    geom_vline(xintercept=mean(lisa$GDPPC), lty=2) +\n  scale_color_manual(\n    values = c(\"High-High\" = \"red\", \n               \"Low-Low\" = \"blue\",\n               \"Low-High\" = \"lightblue\", \n               \"High-Low\" = \"pink\")) +\n  labs(x = \"GDPPC\",\n       y = \"Spatial Lag of GDPPC\",\n       title = \"Moran Scatterplot with LISA Quadrants\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Standardise GDPPC and its spatial lag (z-scores)\nlisa &lt;- lisa %&gt;%\n  mutate(\n    z_GDPPC     = scale(GDPPC),                # centre & scale GDPPC\n    z_lag_GDPPC = scale(lag_GDPPC),            # centre & scale spatial lag\n    .before = 1\n  )\n\n\n# Standardised Moran scatterplot with LISA quadrants\nggplot(data = lisa,\n       aes(x = z_GDPPC, y = z_lag_GDPPC, color = mean)) +\n  geom_point(size = 2) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\") +\n  geom_hline(yintercept = mean(lisa$z_lag_GDPPC), lty = 2) +\n  geom_vline(xintercept = mean(lisa$z_GDPPC),      lty = 2) +\n  scale_color_manual(values = c(\"High-High\" = \"red\",\n                                \"Low-Low\"  = \"blue\",\n                                \"Low-High\" = \"lightblue\",\n                                \"High-Low\" = \"pink\")) +\n  labs(x = \"Standardised GDPPC\",\n       y = \"Standardised Spatial Lag of GDPPC\",\n       title = \"Standardised Moran Scatterplot with LISA Quadrants\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Significance threshold used by the professor\nsignif &lt;- 0.05\n\n\n\n\n\n# Build the display class for the LISA cluster map (keep only significant locations)\nlisa &lt;- lisa %&gt;%\n  mutate(\n    LISA_cluster = ifelse(p_ii &lt; signif, as.character(mean), \"Insignificant\"),\n    LISA_cluster = factor(LISA_cluster,\n                          levels = c(\"Insignificant\",\"Low-Low\",\"Low-High\",\"High-Low\",\"High-High\"))\n  )\n\n\nlisa_map &lt;- tm_shape(lisa) +\n  tm_polygons(\n    fill = \"LISA_cluster\",\n    fill.scale = tm_scale_categorical(\n      values = c(\"grey80\",  # Insignificant\n                 \"blue\",    # Low-Low\n                 \"lightblue\", # Low-High\n                 \"pink\",    # High-Low\n                 \"red\")     # High-High\n    ),\n    fill.legend = tm_legend(title = \"LISA Cluster\",\n                            position = tm_pos_in(\"left\",\"bottom\"))\n  ) +\n  tm_borders() +\n  tm_title(\"Local Moran's I Clusters (p &lt; 0.05)\")\n\nlisa_map\n\n\n\n\n\n\n\n\n\n# --- Side-by-side visualisation: Local Moran's I map + LISA Cluster map ----\n# Assumes `lisa` already exists from 10.4.3/10.4.4 and contains:\n#  - ii       : Local Moran's I statistic\n#  - p_ii     : permutation p-values\n#  - mean     : LISA quadrant label (High-High, Low-Low, etc.)\n#  - LISA_cluster : factor with levels c(\"Insignificant\",\"Low-Low\",\"Low-High\",\"High-Low\",\"High-High\")\n\n# 1) Choropleth of Local Moran's I (Queen's method), using a diverging palette\nii.map &lt;- tm_shape(lisa) +                                           # provide sf object\n  tm_polygons(fill = \"ii\",                                           # map the I statistic\n              fill.scale = tm_scale_intervals(                       # classing method and palette\n                style = \"pretty\",                                    # 'pretty' breaks (as in slides)\n                n = 5,                                               # 5 classes\n                values = \"brewer.RdBu\"                               # diverging red–blue palette\n              ),\n              fill.legend = tm_legend(                               # legend style\n                title = \"Local Moran's I\",\n                position = tm_pos_in(\"left\",\"bottom\")                # inside, left–bottom\n              )) +\n  tm_borders(fill_alpha = 0.5) +                                     # light border/fill alpha\n  tm_title(\"Loal Moran's I of GDPPC (Queen's method)\")               # title (kept as in slide)\n\n# 2) Choropleth of LISA clusters (significant at p &lt; 0.05)\nlisa_map &lt;- tm_shape(lisa) +                                         # same sf object\n  tm_polygons(\n    fill = \"LISA_cluster\",                                           # categorical cluster label\n    fill.scale = tm_scale_categorical(                               # fixed colours per category\n      values = c(\"grey80\",  # Insignificant\n                 \"blue\",    # Low-Low\n                 \"lightblue\", # Low-High\n                 \"pink\",    # High-Low\n                 \"red\")     # High-High\n    ),\n    fill.legend = tm_legend(                                         # legend style\n      title = \"LISA Cluster\",\n      position = tm_pos_in(\"left\",\"bottom\")\n    )\n  ) +\n  tm_borders() +                                                     # polygon borders\n  tm_title(\"Local Moran's I Clusters (p &lt; 0.05)\")                    # map title\n\n# 3) Arrange the two maps side by side for comparison\ntmap_arrange(ii.map, lisa_map, asp = 1, ncol = 2)                    # equal aspect; two columns\n\n[scale] tm_polygons:() the data variable assigned to 'fill' contains positive and negative values, so midpoint is set to 0. Set 'midpoint = NA' in 'fill.scale = tm_scale_intervals(&lt;HERE&gt;)' to use all visual values (e.g. colors)\n\n\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"brewer.RdBu\" is\nnamed \"rd_bu\" (in long format \"brewer.rd_bu\")\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteWhat statistical observations can you draw from the LISA map above?\n\n\n\nStatistical observations from the LISA map\nThe Local Moran’s I cluster map provides strong evidence of spatial dependence in the distribution of GDP per capita across Hunan Province. Statistically significant High–High clusters are observed in the central–eastern part of the province, where wealthy counties are located adjacent to one another. These red-shaded areas indicate local hot spots, confirming that high economic performance is not evenly dispersed but instead forms concentrated pockets of prosperity. Conversely, Low–Low clusters are identified in the western counties, representing cold spots where underdeveloped regions are spatially concentrated. These blue-shaded areas highlight localised disadvantage, suggesting that peripheral regions may be experiencing persistent economic stagnation.\nIn addition, a small number of outlier counties appear as High–Low or Low–High clusters, where individual counties deviate from the economic profile of their surrounding neighbours. Although fewer in number, these outliers are statistically meaningful, as they reveal local anomalies that would otherwise be masked in global measures of autocorrelation. A substantial portion of the province, however, remains statistically insignificant (grey areas), indicating that GDP variation in these counties does not depart significantly from spatial randomness.\nTaken together, the LISA results reinforce the conclusion that GDP per capita in Hunan is not randomly distributed. Instead, there is evidence of spatial clustering, with distinct patterns of prosperity in the east and central regions and concentrated underdevelopment in the west. These findings highlight the importance of spatial context in understanding regional inequality and provide a quantitative basis for targeted policy interventions.\n\n\n\n\n\n\n\n\n\n\n\n\nct &lt;- critical_threshold(st_geometry(hunan))   # ensure ≥ 1 neighbour\n\nWarning in spdep::knn2nb(spdep::knearneigh(pnts, k)): neighbour object has 25\nsub-graphs\n\nct\n\n[1] 60799.91\n\n\n\n\n\n\nhunan_fdw &lt;- hunan %&gt;%\n  mutate(\n    nb = include_self(st_dist_band(st_geometry(geometry), upper = ct)),\n    wt = st_weights(nb, style = \"W\"),\n    .before = 1\n  )\n\n! Polygon provided. Using point on surface.\n\n\n\n\n\n\nhunan_adw &lt;- hunan %&gt;%\n  mutate(nb = include_self(\n    st_knn(\n      st_geometry(geometry),\n      k = 6)),\n    wt = st_weights(\n      nb, style = \"W\"),\n    .before = 1)\n\n! Polygon provided. Using point on surface.\n\n\n\n\n\n\n\nHCSA_fdw &lt;- hunan_fdw %&gt;%\n  mutate(\n    gistar = local_gstar_perm(\n      GDPPC, nb, wt, nsim = 99),\n    .before = 1) %&gt;%\n  unnest(gistar)\n\n\n\n\n\n\n\ntm_shape(HCSA_fdw) +\n  tm_polygons(fill = \"gi_star\",\n              fill.scale = tm_scale_intervals(\n                style = \"pretty\",\n                n = 6,\n                values = \"brewer.rd_bu\"),\n              fill.legend = tm_legend(\n                title = \"Gi*\",\n                position = tm_pos_out())) + \n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Gi* of GDPPC (Fixed Bandwidth d = 60799.91m)\")\n\n[scale] tm_polygons:() the data variable assigned to 'fill' contains positive and negative values, so midpoint is set to 0. Set 'midpoint = NA' in 'fill.scale = tm_scale_intervals(&lt;HERE&gt;)' to use all visual values (e.g. colors)\n\n\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(HCSA_fdw) +\n  tm_polygons(fill = \"p_sim\", \n              fill.scale = tm_scale_intervals(\n                breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n                values = \"-brewer.Reds\"),\n              fill.legend = tm_legend(\n                title = \"simulated p-value\",\n      position = tm_pos_out())) + \n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"p-values of local Gi* of GDPPC (Fixed distance)\")\n\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"-brewer.Reds\" is\nnamed \"reds\" (in long format \"brewer.reds\")\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\n\n\n\n\nGi_star_map &lt;- tm_shape(HCSA_fdw) +\n  tm_polygons(fill = \"gi_star\",\n              fill.scale = tm_scale_intervals(\n                style = \"pretty\",\n                n = 5,\n                values = \"-brewer.rd_bu\"),\n              fill.legend = tm_legend(\n                title = \"local Gi*\",\n                position = tm_pos_in(\n                  \"left\", \"bottom\"))) + \n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Local Gi* of GDPPC\")\n\np_values_map &lt;- tm_shape(HCSA_fdw) +\n  tm_polygons(fill = \"p_sim\", \n              fill.scale = tm_scale_intervals(\n                breaks = c(0, 0.001, 0.01, 0.05, 0.1, 1),\n                values = \"-brewer.reds\"),\n              fill.legend = tm_legend(\n                title = \"p-value\",\n      position = tm_pos_in(\"left\", \"bottom\")\n    )) + \n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"p-values of local Gi* of GDPPC (fixed distance)\")\n\ntmap_arrange(Gi_star_map, p_values_map, asp=1, ncol=2)\n\n[scale] tm_polygons:() the data variable assigned to 'fill' contains positive and negative values, so midpoint is set to 0. Set 'midpoint = NA' in 'fill.scale = tm_scale_intervals(&lt;HERE&gt;)' to use all visual values (e.g. colors)\n\n\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\n\n\n\n\nHCSA_fdw &lt;- HCSA_fdw %&gt;%\n  mutate(HCSA_cluster = case_when(\n    p_sim &gt; 0.05 ~ \"Insignificant\",\n    p_sim &lt;= 0.05 & cluster == \"High\" ~ \"Hot spot\",\n    p_sim &lt;= 0.05 & cluster == \"Low\"  ~ \"Cold spot\",\n    TRUE ~ \"Other\"),\n    HCSA_cluster = factor(\n      HCSA_cluster,\n      levels = c(\"Insignificant\", \"Hot spot\", \"Cold spot\")\n    ),\n    .before = 1\n  )\n\n\nHCSA_map &lt;- tm_shape(HCSA_fdw) + \n  tm_polygons(\n    fill = \"HCSA_cluster\",\n    fill.scale = tm_scale_categorical(\n      values = c(\n        \"grey80\",      # Insignificant\n        \"red\",        # Low-Low\n        \"blue\"          # High-High\n      )\n    ),\n    fill.legend = tm_legend(\n      title = \"HSCA Cluster\",\n      position = tm_pos_in(\"left\", \"bottom\"))\n  ) +\n  tm_borders() +\n  tm_title(\"HCSA Clusters (p &lt; 0.05)\")\nHCSA_map\n\n\n\n\n\n\n\n\n\ntmap_arrange(Gi_star_map, HCSA_map, asp=1, ncol=2)\n\n[scale] tm_polygons:() the data variable assigned to 'fill' contains positive and negative values, so midpoint is set to 0. Set 'midpoint = NA' in 'fill.scale = tm_scale_intervals(&lt;HERE&gt;)' to use all visual values (e.g. colors)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteWhat statistical observations can you draw from the HCSA map above?\n\n\n\nStatistical observations from the HCSA map\nThe Hot Spot and Cold Spot Analysis (HCSA) using the Getis-Ord Gi* statistic reveals statistically significant spatial clusters of GDP per capita across Hunan Province. The hot spots (red areas) are clearly concentrated in the eastern and central counties, where GDP per capita values are significantly higher than would be expected under spatial randomness. These locations are not only economically prosperous on their own but are also surrounded by neighbouring counties with similarly high values, reinforcing spatial clustering of wealth.\nIn contrast, the cold spots (blue areas) are located primarily in the western and southern parts of the province. These areas exhibit significantly low GDP per capita values and are surrounded by other low-value counties, forming concentrated zones of economic disadvantage. The identification of cold spots highlights the persistence of underdevelopment in certain regions, particularly those more remote from the provincial economic core.\nThe remaining counties (grey) are classified as statistically insignificant, meaning their GDP per capita patterns do not deviate sufficiently from spatial randomness to be considered clustered.\nOverall, the Gi* analysis provides complementary evidence to the LISA results: economic prosperity in Hunan is highly clustered in the east and central regions, while underdevelopment is concentrated in the west and periphery. This reinforces the presence of spatial inequality, suggesting the need for regionally targeted development strategies to reduce the widening gap between hot spots of prosperity and cold spots of persistent poverty."
  },
  {
    "objectID": "Hands-on_Ex05/hand-on_ex05b.html#overview",
    "href": "Hands-on_Ex05/hand-on_ex05b.html#overview",
    "title": "Hands-on Ex5b",
    "section": "",
    "text": "We will import geospatial and aspatial data for Hunan Province (county level), join attributes, visualise a regional indicator (GDP per capita, GDPPC), build contiguity and distance spatial weights, and compute two local spatial statistics:\n\nLocal Moran’s I (LISA) for cluster/outlier detection.\nGetis–Ord Gi* for Hot/Cold Spot analysis (HCSA).\n\nWe will then create choropleths for I values, \\(p\\)-values, LISA clusters (\\(p &lt; 0.05%\\)), and HCSA clusters (\\(p &lt; 0.05\\)), plus Moran scatterplots (raw and standardised)."
  },
  {
    "objectID": "Hands-on_Ex05/hand-on_ex05b.html#getting-started",
    "href": "Hands-on_Ex05/hand-on_ex05b.html#getting-started",
    "title": "Hands-on Ex5b",
    "section": "",
    "text": "In spatial policy, one of the main development objective of the local govenment and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.(https://en.wikipedia.org/wiki/Hunan)\n\n\n\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan province administrative boundary layer at county level (Geospatial). This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv (Aspatial): This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n\n\n# load packages (installs missing ones, then attaches)\npacman::p_load(sf, sfdep, tmap, tidyverse)  # sf for spatial data; sfdep for spatial stats;\n                                            # tmap for mapping; tidyverse for wrangling/ggplot"
  },
  {
    "objectID": "Hands-on_Ex05/hand-on_ex05b.html#getting-the-data-into-r",
    "href": "Hands-on_Ex05/hand-on_ex05b.html#getting-the-data-into-r",
    "title": "Hands-on Ex5b",
    "section": "",
    "text": "# --- 10.3.1 Import shapefile into R environment -----------------------------\n\nhunan &lt;- \n  st_read(                      # read a spatial layer from disk\n    dsn   = \"data/geospatial\",  # folder containing the shapefile set\n    layer = \"Hunan\"             # layer name (without .shp)\n  ) %&gt;% \n  \n  # reproject from WGS84 to UTM zone 50N (EPSG:32650)\n  # (projected CRS is recommended for spatial analysis)\n  st_transform(crs = 32650)        \n\nReading layer `Hunan' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex05/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe raw data is in WGS 84 geographic coordinates system. For geospatial analysis, it is appropriate to use projected coordinates system. In the code chunk above, st_transform() is used to transform Hunan geospatial data from WGS 84 to UTM zone 50N (i.e. EPSG: 32650).\n\n\n\n# --- 10.3.2 Import CSV into R environment ----------------------------------\n\nhunan2012 &lt;- \n  readr::read_csv(\"data/aspatial/Hunan_2012.csv\")  # read the attribute table (tabular CSV)\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n# --- 10.3.3 Join attributes into the sf object ------------------------------\n\nhunan &lt;- \n  left_join(hunan, hunan2012) %&gt;%  # left join by the shared key column(s) (kept from shapefile)\n  select(1:4, 7, 15)               # keep only the columns used in this exercise (as per lesson)\n\nJoining with `by = join_by(County)`\n\n\n\n\n\nequal &lt;- tm_shape(hunan) +\n  tm_polygons(fill = \"GDPPC\",\n              fill.scale = tm_scale_intervals(\n                style = \"equal\",\n                n = 5,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                title = \"GDPPC\",\n                position = tm_pos_in(\n                  \"left\", \"bottom\"))) + \n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_polygons(fill = \"GDPPC\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                title = \"GDPPC\",\n                position = tm_pos_in(\n                  \"left\", \"bottom\"))) + \n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Quantile interval classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteDoes the plot above reveal any outliers or clusters?\n\n\n\n\nThe Equal interval map (left) spreads values evenly across 5 fixed ranges. Because the distribution of GDPPC is skewed, many counties fall into the lower classes, and the map appears very light with only a few darker areas. This makes it difficult to visually spot clear clusters or outliers, since most counties look similar and variation is compressed.\nThe Quantile map (right) divides the counties into 5 groups with equal counts per group. Here, differences are more apparent — some dark blue areas (highest quantile) are grouped together, while very light areas (lowest quantile) are also visible. This gives a stronger sense that there may be regional clustering of high and low GDPPC, but it’s only suggestive.\n\nAnswer: The plots hint at spatial variation, but do not confirm outliers or clusters statistically. Especially in the quantile map, you can see that richer counties cluster in the east, while poorer ones appear in the west/south. Still, formal spatial autocorrelation tests (Moran’s I, LISA) are needed to verify.\n\n\n\n\n\n\n\n\nNoteDoes the plot above indicate the presence of hot spots or cold spots?\n\n\n\n\nBy visual impression only, the dark blue patches in the quantile map (eastern and central counties) could be potential hot spots (high GDPPC areas adjacent to each other).\nConversely, lighter patches (western/southern counties) could be cold spots (low GDPPC areas grouped together).\nHowever, these impressions are not reliable evidence — classification maps can exaggerate or understate differences depending on method.\n\nAnswer: The quantile map suggests possible hot spots in central/eastern Hunan and cold spots in western/southern areas, but the equal interval map is less informative. These are hypotheses only — the next step is to compute Local Moran’s I and Gi* to confirm whether these patterns are statistically significant.\n\n\n\nIn summary: The classification maps are useful exploratory tools. Quantile classification reveals stronger visual contrasts, hinting at clusters of rich and poor counties. But to answer definitively about outliers or hot/cold spots, we must proceed to LISA (Local Moran’s I) and HCSA (Getis–Ord Gi) analyses."
  },
  {
    "objectID": "Hands-on_Ex05/hand-on_ex05b.html#local-indicators-of-spatial-association-lisa",
    "href": "Hands-on_Ex05/hand-on_ex05b.html#local-indicators-of-spatial-association-lisa",
    "title": "Hands-on Ex5b",
    "section": "",
    "text": "# Create Queen-contiguity neighbours and W-style weights (row-standardised)\nwm_q &lt;- hunan %&gt;% \n  mutate(\n    nb = st_contiguity(geometry),   # build a neighbours list from touching polygons (Queen)\n    wt = st_weights(nb, style = \"W\"), # row-standardised weights (sum of weights = 1 per region)\n    .before = 1                     # place the new columns at the beginning (professor's style)\n  )\n\n# Inspect the neighbour structure (how many neighbours per county)\nsummary(wm_q$nb)  # prints count distribution, min/max, and average links\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbour.\n\n\n\n\nlisa &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nlocal_moran() function returns a matrix of values whose columns are:\n\nli: the local Moran’s I statistics\nE.li: the expectation of local moran statistic under the randomisation hypothesis\nVar.li: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\n\nglimpse(lisa)\n\nRows: 88\nColumns: 21\n$ ii           &lt;dbl&gt; -1.468468e-03, 2.587817e-02, -1.198765e-02, 1.022468e-03,…\n$ eii          &lt;dbl&gt; -8.148464e-04, -9.932206e-03, -2.929856e-02, -9.398322e-0…\n$ var_ii       &lt;dbl&gt; 4.589734e-04, 1.136942e-02, 9.800257e-02, 4.136778e-06, 1…\n$ z_ii         &lt;dbl&gt; -0.03050932, 0.33584570, 0.05529697, 0.54891935, 0.270022…\n$ p_ii         &lt;dbl&gt; 9.756609e-01, 7.369872e-01, 9.559019e-01, 5.830608e-01, 7…\n$ p_ii_sim     &lt;dbl&gt; 0.84, 0.98, 0.68, 0.52, 0.68, 0.86, 0.06, 0.06, 0.02, 0.2…\n$ p_folded_sim &lt;dbl&gt; 0.42, 0.49, 0.34, 0.26, 0.34, 0.43, 0.03, 0.03, 0.01, 0.1…\n$ skewness     &lt;dbl&gt; -0.6165755, -0.9102915, 0.7574819, 0.9515344, 0.7445666, …\n$ kurtosis     &lt;dbl&gt; -0.5321037, 0.4113895, -0.1561211, 0.8700892, 0.1347678, …\n$ mean         &lt;fct&gt; Low-High, Low-Low, High-Low, High-High, High-High, High-L…\n$ median       &lt;fct&gt; High-High, High-High, High-High, High-High, High-High, Hi…\n$ pysal        &lt;fct&gt; Low-High, Low-Low, High-Low, High-High, High-High, High-L…\n$ nb           &lt;nb&gt; &lt;2, 3, 4, 57, 85&gt;, &lt;1, 57, 58, 78, 85&gt;, &lt;1, 4, 5, 85&gt;, &lt;1,…\n$ wt           &lt;list&gt; &lt;0.2, 0.2, 0.2, 0.2, 0.2&gt;, &lt;0.2, 0.2, 0.2, 0.2, 0.2&gt;, &lt;0…\n$ NAME_2       &lt;chr&gt; \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"C…\n$ ID_3         &lt;int&gt; 21098, 21100, 21101, 21102, 21103, 21104, 21109, 21110, 2…\n$ NAME_3       &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", …\n$ ENGTYPE_3    &lt;chr&gt; \"County\", \"County\", \"County City\", \"County\", \"County\", \"C…\n$ County       &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", …\n$ GDPPC        &lt;dbl&gt; 23667, 20981, 34592, 24473, 25554, 27137, 63118, 62202, 7…\n$ geometry     &lt;POLYGON [m]&gt; POLYGON ((22320.48 3301894,..., POLYGON ((35522.9…\n\n\n\n\n\ntm_shape(lisa) +\n  tm_polygons(fill = \"ii\",\n              fill.scale = tm_scale_intervals(\n                style = \"pretty\",\n                n = 5,\n                values = \"brewer.RdBu\"),\n              fill.legend = tm_legend(\n                title = \"Local Morans'I\",\n                position = tm_pos_out())) + \n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Loal Morans'I of GDPPC (Queen's method)\")\n\n[scale] tm_polygons:() the data variable assigned to 'fill' contains positive and negative values, so midpoint is set to 0. Set 'midpoint = NA' in 'fill.scale = tm_scale_intervals(&lt;HERE&gt;)' to use all visual values (e.g. colors)\n\n\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"brewer.RdBu\" is\nnamed \"rd_bu\" (in long format \"brewer.rd_bu\")\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(lisa) +\n  tm_polygons(fill = \"p_ii\", \n              fill.scale = tm_scale_intervals(\n                breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n                values = \"-brewer.Reds\"),\n              fill.legend = tm_legend(\n                title = \"p-value\",\n      position = tm_pos_out())) + \n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"p-values of Loal Moran's I of GDPPC (Queen's method)\")\n\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"-brewer.Reds\" is\nnamed \"reds\" (in long format \"brewer.reds\")\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\n\n\n\n\nii.map &lt;- tm_shape(lisa) +\n  tm_polygons(fill = \"ii\",\n              fill.scale = tm_scale_intervals(\n                style = \"pretty\",\n                n = 5,\n                values = \"brewer.RdBu\"),\n              fill.legend = tm_legend(\n                title = \"Local Moran's I\",\n                position = tm_pos_in(\n                  \"left\", \"bottom\"))) + \n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Loal Moran's I of GDPPC (Queen's method)\")\n\np_ii.map &lt;- tm_shape(lisa) +\n  tm_polygons(fill = \"p_ii\", \n              fill.scale = tm_scale_intervals(\n                breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n                values = \"-brewer.Reds\"),\n              fill.legend = tm_legend(\n                title = \"p-value\",\n      position = tm_pos_in(\"left\", \"bottom\")\n    )) + \n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"p-values of Loal Moran's I of GDPPC (Queen's method)\")\n\ntmap_arrange(ii.map, p_ii.map, asp=1, ncol=2)\n\n[scale] tm_polygons:() the data variable assigned to 'fill' contains positive and negative values, so midpoint is set to 0. Set 'midpoint = NA' in 'fill.scale = tm_scale_intervals(&lt;HERE&gt;)' to use all visual values (e.g. colors)\n\n\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"brewer.RdBu\" is\nnamed \"rd_bu\" (in long format \"brewer.rd_bu\")\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"-brewer.Reds\" is\nnamed \"reds\" (in long format \"brewer.reds\")\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# --- Compute spatial lag for GDPPC (needed for Moran scatterplot) -----------\n\nlisa &lt;- lisa %&gt;%\n  mutate(lag_GDPPC = st_lag(\n    GDPPC, nb, wt),\n    .before = 1) %&gt;%\n  unnest(lag_GDPPC)\n\n\n# --- Moran scatterplot (raw values) ----------------------------------------\n\nggplot(data = lisa, \n       aes(x = GDPPC, \n           y = lag_GDPPC)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", \n              se = FALSE, \n              color = \"red\") +\n  labs(x = \"GDPPC\",\n       y = \"Spatial Lag of GDPPC\",\n       title = \"Moran Scatterplot\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nggplot(data = lisa, \n       aes(x = GDPPC, \n           y = lag_GDPPC, \n           color = mean)) +\n  geom_point(size = 2) +\n  geom_smooth(method = \"lm\", \n              se = FALSE, \n              color = \"black\") +\n  geom_hline(yintercept=mean(lisa$lag_GDPPC), lty=2) + \n    geom_vline(xintercept=mean(lisa$GDPPC), lty=2) +\n  scale_color_manual(\n    values = c(\"High-High\" = \"red\", \n               \"Low-Low\" = \"blue\",\n               \"Low-High\" = \"lightblue\", \n               \"High-Low\" = \"pink\")) +\n  labs(x = \"GDPPC\",\n       y = \"Spatial Lag of GDPPC\",\n       title = \"Moran Scatterplot with LISA Quadrants\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Standardise GDPPC and its spatial lag (z-scores)\nlisa &lt;- lisa %&gt;%\n  mutate(\n    z_GDPPC     = scale(GDPPC),                # centre & scale GDPPC\n    z_lag_GDPPC = scale(lag_GDPPC),            # centre & scale spatial lag\n    .before = 1\n  )\n\n\n# Standardised Moran scatterplot with LISA quadrants\nggplot(data = lisa,\n       aes(x = z_GDPPC, y = z_lag_GDPPC, color = mean)) +\n  geom_point(size = 2) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\") +\n  geom_hline(yintercept = mean(lisa$z_lag_GDPPC), lty = 2) +\n  geom_vline(xintercept = mean(lisa$z_GDPPC),      lty = 2) +\n  scale_color_manual(values = c(\"High-High\" = \"red\",\n                                \"Low-Low\"  = \"blue\",\n                                \"Low-High\" = \"lightblue\",\n                                \"High-Low\" = \"pink\")) +\n  labs(x = \"Standardised GDPPC\",\n       y = \"Standardised Spatial Lag of GDPPC\",\n       title = \"Standardised Moran Scatterplot with LISA Quadrants\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Significance threshold used by the professor\nsignif &lt;- 0.05\n\n\n\n\n\n# Build the display class for the LISA cluster map (keep only significant locations)\nlisa &lt;- lisa %&gt;%\n  mutate(\n    LISA_cluster = ifelse(p_ii &lt; signif, as.character(mean), \"Insignificant\"),\n    LISA_cluster = factor(LISA_cluster,\n                          levels = c(\"Insignificant\",\"Low-Low\",\"Low-High\",\"High-Low\",\"High-High\"))\n  )\n\n\nlisa_map &lt;- tm_shape(lisa) +\n  tm_polygons(\n    fill = \"LISA_cluster\",\n    fill.scale = tm_scale_categorical(\n      values = c(\"grey80\",  # Insignificant\n                 \"blue\",    # Low-Low\n                 \"lightblue\", # Low-High\n                 \"pink\",    # High-Low\n                 \"red\")     # High-High\n    ),\n    fill.legend = tm_legend(title = \"LISA Cluster\",\n                            position = tm_pos_in(\"left\",\"bottom\"))\n  ) +\n  tm_borders() +\n  tm_title(\"Local Moran's I Clusters (p &lt; 0.05)\")\n\nlisa_map\n\n\n\n\n\n\n\n\n\n# --- Side-by-side visualisation: Local Moran's I map + LISA Cluster map ----\n# Assumes `lisa` already exists from 10.4.3/10.4.4 and contains:\n#  - ii       : Local Moran's I statistic\n#  - p_ii     : permutation p-values\n#  - mean     : LISA quadrant label (High-High, Low-Low, etc.)\n#  - LISA_cluster : factor with levels c(\"Insignificant\",\"Low-Low\",\"Low-High\",\"High-Low\",\"High-High\")\n\n# 1) Choropleth of Local Moran's I (Queen's method), using a diverging palette\nii.map &lt;- tm_shape(lisa) +                                           # provide sf object\n  tm_polygons(fill = \"ii\",                                           # map the I statistic\n              fill.scale = tm_scale_intervals(                       # classing method and palette\n                style = \"pretty\",                                    # 'pretty' breaks (as in slides)\n                n = 5,                                               # 5 classes\n                values = \"brewer.RdBu\"                               # diverging red–blue palette\n              ),\n              fill.legend = tm_legend(                               # legend style\n                title = \"Local Moran's I\",\n                position = tm_pos_in(\"left\",\"bottom\")                # inside, left–bottom\n              )) +\n  tm_borders(fill_alpha = 0.5) +                                     # light border/fill alpha\n  tm_title(\"Loal Moran's I of GDPPC (Queen's method)\")               # title (kept as in slide)\n\n# 2) Choropleth of LISA clusters (significant at p &lt; 0.05)\nlisa_map &lt;- tm_shape(lisa) +                                         # same sf object\n  tm_polygons(\n    fill = \"LISA_cluster\",                                           # categorical cluster label\n    fill.scale = tm_scale_categorical(                               # fixed colours per category\n      values = c(\"grey80\",  # Insignificant\n                 \"blue\",    # Low-Low\n                 \"lightblue\", # Low-High\n                 \"pink\",    # High-Low\n                 \"red\")     # High-High\n    ),\n    fill.legend = tm_legend(                                         # legend style\n      title = \"LISA Cluster\",\n      position = tm_pos_in(\"left\",\"bottom\")\n    )\n  ) +\n  tm_borders() +                                                     # polygon borders\n  tm_title(\"Local Moran's I Clusters (p &lt; 0.05)\")                    # map title\n\n# 3) Arrange the two maps side by side for comparison\ntmap_arrange(ii.map, lisa_map, asp = 1, ncol = 2)                    # equal aspect; two columns\n\n[scale] tm_polygons:() the data variable assigned to 'fill' contains positive and negative values, so midpoint is set to 0. Set 'midpoint = NA' in 'fill.scale = tm_scale_intervals(&lt;HERE&gt;)' to use all visual values (e.g. colors)\n\n\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"brewer.RdBu\" is\nnamed \"rd_bu\" (in long format \"brewer.rd_bu\")\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteWhat statistical observations can you draw from the LISA map above?\n\n\n\nStatistical observations from the LISA map\nThe Local Moran’s I cluster map provides strong evidence of spatial dependence in the distribution of GDP per capita across Hunan Province. Statistically significant High–High clusters are observed in the central–eastern part of the province, where wealthy counties are located adjacent to one another. These red-shaded areas indicate local hot spots, confirming that high economic performance is not evenly dispersed but instead forms concentrated pockets of prosperity. Conversely, Low–Low clusters are identified in the western counties, representing cold spots where underdeveloped regions are spatially concentrated. These blue-shaded areas highlight localised disadvantage, suggesting that peripheral regions may be experiencing persistent economic stagnation.\nIn addition, a small number of outlier counties appear as High–Low or Low–High clusters, where individual counties deviate from the economic profile of their surrounding neighbours. Although fewer in number, these outliers are statistically meaningful, as they reveal local anomalies that would otherwise be masked in global measures of autocorrelation. A substantial portion of the province, however, remains statistically insignificant (grey areas), indicating that GDP variation in these counties does not depart significantly from spatial randomness.\nTaken together, the LISA results reinforce the conclusion that GDP per capita in Hunan is not randomly distributed. Instead, there is evidence of spatial clustering, with distinct patterns of prosperity in the east and central regions and concentrated underdevelopment in the west. These findings highlight the importance of spatial context in understanding regional inequality and provide a quantitative basis for targeted policy interventions."
  },
  {
    "objectID": "Hands-on_Ex05/hand-on_ex05b.html#hot-spots-and-cold-spots-analysis-hcsa",
    "href": "Hands-on_Ex05/hand-on_ex05b.html#hot-spots-and-cold-spots-analysis-hcsa",
    "title": "Hands-on Ex5b",
    "section": "",
    "text": "ct &lt;- critical_threshold(st_geometry(hunan))   # ensure ≥ 1 neighbour\n\nWarning in spdep::knn2nb(spdep::knearneigh(pnts, k)): neighbour object has 25\nsub-graphs\n\nct\n\n[1] 60799.91\n\n\n\n\n\n\nhunan_fdw &lt;- hunan %&gt;%\n  mutate(\n    nb = include_self(st_dist_band(st_geometry(geometry), upper = ct)),\n    wt = st_weights(nb, style = \"W\"),\n    .before = 1\n  )\n\n! Polygon provided. Using point on surface.\n\n\n\n\n\n\nhunan_adw &lt;- hunan %&gt;%\n  mutate(nb = include_self(\n    st_knn(\n      st_geometry(geometry),\n      k = 6)),\n    wt = st_weights(\n      nb, style = \"W\"),\n    .before = 1)\n\n! Polygon provided. Using point on surface.\n\n\n\n\n\n\n\nHCSA_fdw &lt;- hunan_fdw %&gt;%\n  mutate(\n    gistar = local_gstar_perm(\n      GDPPC, nb, wt, nsim = 99),\n    .before = 1) %&gt;%\n  unnest(gistar)\n\n\n\n\n\n\n\ntm_shape(HCSA_fdw) +\n  tm_polygons(fill = \"gi_star\",\n              fill.scale = tm_scale_intervals(\n                style = \"pretty\",\n                n = 6,\n                values = \"brewer.rd_bu\"),\n              fill.legend = tm_legend(\n                title = \"Gi*\",\n                position = tm_pos_out())) + \n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Gi* of GDPPC (Fixed Bandwidth d = 60799.91m)\")\n\n[scale] tm_polygons:() the data variable assigned to 'fill' contains positive and negative values, so midpoint is set to 0. Set 'midpoint = NA' in 'fill.scale = tm_scale_intervals(&lt;HERE&gt;)' to use all visual values (e.g. colors)\n\n\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(HCSA_fdw) +\n  tm_polygons(fill = \"p_sim\", \n              fill.scale = tm_scale_intervals(\n                breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n                values = \"-brewer.Reds\"),\n              fill.legend = tm_legend(\n                title = \"simulated p-value\",\n      position = tm_pos_out())) + \n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"p-values of local Gi* of GDPPC (Fixed distance)\")\n\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"-brewer.Reds\" is\nnamed \"reds\" (in long format \"brewer.reds\")\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\n\n\n\n\nGi_star_map &lt;- tm_shape(HCSA_fdw) +\n  tm_polygons(fill = \"gi_star\",\n              fill.scale = tm_scale_intervals(\n                style = \"pretty\",\n                n = 5,\n                values = \"-brewer.rd_bu\"),\n              fill.legend = tm_legend(\n                title = \"local Gi*\",\n                position = tm_pos_in(\n                  \"left\", \"bottom\"))) + \n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Local Gi* of GDPPC\")\n\np_values_map &lt;- tm_shape(HCSA_fdw) +\n  tm_polygons(fill = \"p_sim\", \n              fill.scale = tm_scale_intervals(\n                breaks = c(0, 0.001, 0.01, 0.05, 0.1, 1),\n                values = \"-brewer.reds\"),\n              fill.legend = tm_legend(\n                title = \"p-value\",\n      position = tm_pos_in(\"left\", \"bottom\")\n    )) + \n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"p-values of local Gi* of GDPPC (fixed distance)\")\n\ntmap_arrange(Gi_star_map, p_values_map, asp=1, ncol=2)\n\n[scale] tm_polygons:() the data variable assigned to 'fill' contains positive and negative values, so midpoint is set to 0. Set 'midpoint = NA' in 'fill.scale = tm_scale_intervals(&lt;HERE&gt;)' to use all visual values (e.g. colors)\n\n\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\n\n\n\n\nHCSA_fdw &lt;- HCSA_fdw %&gt;%\n  mutate(HCSA_cluster = case_when(\n    p_sim &gt; 0.05 ~ \"Insignificant\",\n    p_sim &lt;= 0.05 & cluster == \"High\" ~ \"Hot spot\",\n    p_sim &lt;= 0.05 & cluster == \"Low\"  ~ \"Cold spot\",\n    TRUE ~ \"Other\"),\n    HCSA_cluster = factor(\n      HCSA_cluster,\n      levels = c(\"Insignificant\", \"Hot spot\", \"Cold spot\")\n    ),\n    .before = 1\n  )\n\n\nHCSA_map &lt;- tm_shape(HCSA_fdw) + \n  tm_polygons(\n    fill = \"HCSA_cluster\",\n    fill.scale = tm_scale_categorical(\n      values = c(\n        \"grey80\",      # Insignificant\n        \"red\",        # Low-Low\n        \"blue\"          # High-High\n      )\n    ),\n    fill.legend = tm_legend(\n      title = \"HSCA Cluster\",\n      position = tm_pos_in(\"left\", \"bottom\"))\n  ) +\n  tm_borders() +\n  tm_title(\"HCSA Clusters (p &lt; 0.05)\")\nHCSA_map\n\n\n\n\n\n\n\n\n\ntmap_arrange(Gi_star_map, HCSA_map, asp=1, ncol=2)\n\n[scale] tm_polygons:() the data variable assigned to 'fill' contains positive and negative values, so midpoint is set to 0. Set 'midpoint = NA' in 'fill.scale = tm_scale_intervals(&lt;HERE&gt;)' to use all visual values (e.g. colors)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteWhat statistical observations can you draw from the HCSA map above?\n\n\n\nStatistical observations from the HCSA map\nThe Hot Spot and Cold Spot Analysis (HCSA) using the Getis-Ord Gi* statistic reveals statistically significant spatial clusters of GDP per capita across Hunan Province. The hot spots (red areas) are clearly concentrated in the eastern and central counties, where GDP per capita values are significantly higher than would be expected under spatial randomness. These locations are not only economically prosperous on their own but are also surrounded by neighbouring counties with similarly high values, reinforcing spatial clustering of wealth.\nIn contrast, the cold spots (blue areas) are located primarily in the western and southern parts of the province. These areas exhibit significantly low GDP per capita values and are surrounded by other low-value counties, forming concentrated zones of economic disadvantage. The identification of cold spots highlights the persistence of underdevelopment in certain regions, particularly those more remote from the provincial economic core.\nThe remaining counties (grey) are classified as statistically insignificant, meaning their GDP per capita patterns do not deviate sufficiently from spatial randomness to be considered clustered.\nOverall, the Gi* analysis provides complementary evidence to the LISA results: economic prosperity in Hunan is highly clustered in the east and central regions, while underdevelopment is concentrated in the west and periphery. This reinforces the presence of spatial inequality, suggesting the need for regionally targeted development strategies to reduce the widening gap between hot spots of prosperity and cold spots of persistent poverty."
  },
  {
    "objectID": "In-Class_Ex05/in-class_ex05.html",
    "href": "In-Class_Ex05/in-class_ex05.html",
    "title": "In-class Exercise 5a: Global and Local Measures of Spatial Autocorrelation using sfdep methods",
    "section": "",
    "text": "Introducing sfdep:\n\nsfdep creates an sf and tidyverse friendly interface to the package as well as introduces new functionality that is not present in spdep.\nsfdep utilizes list columns extensively to make this interface possible.”\n\n\n\n\n\n\nFour R packages will be used for this in-class exercise, they are: sf, sfdep, tmap and tidyverse.\n\npacman::p_load(sf, sfdep, tmap, tidyverse)\n\n\n\n\n\nFor the purpose of this in-class exercise, the Hunan data sets will be used. There are two data sets in this use case, they are:\n\nHunan, a geospatial data set in ESRI shapefile format, and\nHunan_2012, an attribute data set in csv format.\n\n\nhunan &lt;- st_read(dsn = \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex05/data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex05/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nImport Hunan_2012.csv into R environment as an tibble data frame.\n\nhunan2012 &lt;- read_csv(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex05/data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nhunan_GDPPC &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor the purpose of this exercise, we only retain column 1 to 4, column 7 and column 15. You should examine the output sf data.frame to learn know what are these fields.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIn order to retain the geospatial properties, the left data frame must the sf data.frame (i.e. hunan)\n\n\n\n\n\nPlot a choropleth map showing the distribution of GDPPC of Hunan Province.\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\ntm_shape(hunan_GDPPC) +\n  tm_fill(\"GDPPC\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_layout(main.title = \"Distribution of GDP per capita by county, Hunan Province\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_fill()`: instead of `style = \"quantile\"`, use fill.scale =\n`tm_scale_intervals()`.\nℹ Migrate the argument(s) 'style', 'palette' (rename to 'values') to\n  'tm_scale_intervals(&lt;HERE&gt;)'[v3-&gt;v4] `tm_fill()`: migrate the argument(s) related to the legend of the\nvisual variable `fill` namely 'title' to 'fill.legend = tm_legend(&lt;HERE&gt;)'[v3-&gt;v4] `tm_layout()`: use `tm_title()` instead of `tm_layout(main.title = )`[v3-&gt;v4] `tm_borders()`: use 'fill' for the fill color of polygons/symbols\n(instead of 'col'), and 'col' for the outlines (instead of 'border.col').[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.! `tm_scale_bar()` is deprecated. Please use `tm_scalebar()` instead.[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"Blues\" is named\n\"brewer.blues\"Multiple palettes called \"blues\" found: \"brewer.blues\", \"matplotlib.blues\". The first one, \"brewer.blues\", is returned.\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwm_q &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1) \n\nNotice that st_weights() provides tree arguments, they are:\n\nnb: A neighbor list object as created by st_neighbors().\n\nstyle: Default “W” for row standardized weights. This value can also be “B”, “C”, “U”, “minmax”, and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nallow_zero: If TRUE, assigns zero as lagged value to zone without neighbors.\n\n\n\n\n\nwm_q\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb\n1                 2, 3, 4, 57, 85\n2               1, 57, 58, 78, 85\n3                     1, 4, 5, 85\n4                      1, 3, 5, 6\n5                     3, 4, 6, 85\n6                4, 5, 69, 75, 85\n7                  67, 71, 74, 84\n8       9, 46, 47, 56, 78, 80, 86\n9           8, 66, 68, 78, 84, 86\n10 16, 17, 19, 20, 22, 70, 72, 73\n                                                                            wt\n1                                                      0.2, 0.2, 0.2, 0.2, 0.2\n2                                                      0.2, 0.2, 0.2, 0.2, 0.2\n3                                                       0.25, 0.25, 0.25, 0.25\n4                                                       0.25, 0.25, 0.25, 0.25\n5                                                       0.25, 0.25, 0.25, 0.25\n6                                                      0.2, 0.2, 0.2, 0.2, 0.2\n7                                                       0.25, 0.25, 0.25, 0.25\n8  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n9             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n10                      0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734...\n\n\n\n\n\nIn the code chunk below, global_moran() function is used to compute the Moran’s I value. Different from spdep package, the output is a tibble data.frame.\n\nmoranI &lt;- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\n\n\n\nIn general, Moran’s I test will be performed instead of just computing the Moran’s I statistics. With sfdep package, Moran’s I test can be performed by using global_moran_test() as shown in the code chunk below.\n\nglobal_moran_test(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\n\n\nTip\n\n\n\n\nThe default for alternative argument is “two.sided”. Other supported arguments are “greater” or “less”. randomization, and\n\nBy default the randomization argument is TRUE. If FALSE, under the assumption of normality.\n\n\n\n\n\n\nIn practice, Monte carlo simulation should be used to perform the statistical test. For sfdep, it is supported by globel_moran_perm()\n\n\nIt is always a good practice to use set.seed() before performing simulation. This is o ensure that the computation is reproducible.\n\nset.seed(1234)\n\n\n\n\nNext, global_moran_perm() is used to perform Monte Carlo simulation.\n\nglobal_moran_perm(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\nThe statistical report on previous tab shows that the p-value is smaller than alpha value of 0.05. Hence, we have enough statistical evidence to reject the null hypothesis that the spatial distribution of GPD per capita are resemble random distribution (i.e. independent from spatial). Because the Moran’s I statistics is greater than 0. We can infer that the spatial distribution shows sign of clustering.\n\nThe numbers of simulation is alway equal to nsim + 1. This mean in nsim = 99. This mean 100 simulation will be performed.\n\n\n\n\n\nLISA map is a categorical map showing outliers and clusters. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two type of clusters namely: High-High and Low-Low cluaters. In fact, LISA map is an interpreted map by combining local Moran’s I of geographical areas and their respective p-values.\n\n\nIn this section, you will learn how to compute Local Moran’s I of GDPPC at county level by using local_moran() of sfdep package.\n\nlisa &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nlisa\n\nSimple feature collection with 88 features and 20 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 21\n         ii        eii     var_ii    z_ii    p_ii p_ii_sim p_folded_sim skewness\n      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1 -0.00147  0.00177   0.000418   -0.158  0.874       0.82         0.41   -0.812\n 2  0.0259   0.00641   0.0105      0.190  0.849       0.96         0.48   -1.09 \n 3 -0.0120  -0.0374    0.102       0.0796 0.937       0.76         0.38    0.824\n 4  0.00102 -0.0000349 0.00000437  0.506  0.613       0.64         0.32    1.04 \n 5  0.0148  -0.00340   0.00165     0.449  0.654       0.5          0.25    1.64 \n 6 -0.0388  -0.00339   0.00545    -0.480  0.631       0.82         0.41    0.614\n 7  3.37    -0.198     1.41        3.00   0.00266     0.08         0.04    1.46 \n 8  1.56    -0.265     0.804       2.04   0.0417      0.08         0.04    0.459\n 9  4.42     0.0450    1.79        3.27   0.00108     0.02         0.01    0.746\n10 -0.399   -0.0505    0.0859     -1.19   0.234       0.28         0.14   -0.685\n# ℹ 78 more rows\n# ℹ 13 more variables: kurtosis &lt;dbl&gt;, mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;,\n#   nb &lt;nb&gt;, wt &lt;list&gt;, NAME_2 &lt;chr&gt;, ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;,\n#   ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;, geometry &lt;POLYGON [°]&gt;\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\ntm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(\n    main.title = \"local Moran's I of GDPPC\",\n    main.title.size = 2)\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.[v3-&gt;v4] `tm_view()`: use set_zoom_limits instead of set.zoom.limits[v3-&gt;v4] `tm_layout()`: use `tm_title()` instead of `tm_layout(main.title = )`[scale] tm_polygons:() the data variable assigned to 'fill' contains positive and negative values, so midpoint is set to 0. Set 'midpoint = NA' in 'fill.scale = tm_scale_intervals(&lt;HERE&gt;)' to use all visual values (e.g. colors)\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, tmap functions are used prepare a choropleth map by using value in the p_ii_sim field.\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\ntm_shape(lisa) +\n  tm_fill(\"p_ii_sim\") + \n  tm_borders(alpha = 0.5) +\n   tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 2)\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.[v3-&gt;v4] `tm_layout()`: use `tm_title()` instead of `tm_layout(main.title = )`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nFor p-values, the appropriate classification should be 0.001, 0.01, 0.05 and not significant instead of using default classification scheme.\n\n\n\n\n\nFor effective comparison, it will be better for us to plot both maps next to each other.\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 0.8)\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.[v3-&gt;v4] `tm_view()`: use set_zoom_limits instead of set.zoom.limits[v3-&gt;v4] `tm_layout()`: use `tm_title()` instead of `tm_layout(main.title = )`\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n[v3-&gt;v4] `tm_layout()`: use `tm_title()` instead of `tm_layout(main.title = )`\n\ntmap_arrange(map1, map2, ncol = 2)\n\n[scale] tm_polygons:() the data variable assigned to 'fill' contains positive and negative values, so midpoint is set to 0. Set 'midpoint = NA' in 'fill.scale = tm_scale_intervals(&lt;HERE&gt;)' to use all visual values (e.g. colors)\n\n\n\n\n\n\n\n\n\n\n\n\nIn lisa sf data.frame, we can find three fields contain the LISA categories. They are mean, median and pysal. In general, classification in mean will be used as shown in the code chunk below.\n\nlisa_sig &lt;- lisa  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n\n\n\n\n\n\n\n\n\n\n\n\n\nHCSA uses spatial weights to identify locations of statistically significant hot spots and cold spots in an spatially weighted attribute that are in proximity to one another based on a calculated distance. The analysis groups features when similar high (hot) or low (cold) values are found in a cluster. The polygon features usually represent administration boundaries or a custom grid structure.\n\n\nAs usual, we will need to derive a spatial weight matrix before we can compute local Gi* statistics. Code chunk below will be used to derive a spatial weight matrix by using sfdep functions and tidyverse approach.\n\nwm_idw &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = include_self(\n    st_contiguity(geometry)),\n    wts = st_inverse_distance(nb, \n                              geometry, \n                              scale = 1,\n                              alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wts = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\n\n\nGi* and local Gi* are distance-based spatial statistics. Hence, distance methods instead of contiguity methods should be used to derive the spatial weight matrix.\nSince we are going to compute Gi* statistics, include_self() is used.\n\n\n\n\n\nNow, we will compute the local Gi* by using the code chunk below.\n\nHCSA &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\nHCSA\n\nSimple feature collection with 88 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 19\n    gi_star cluster     e_gi  var_gi std_dev p_value p_sim p_folded_sim skewness\n      &lt;dbl&gt; &lt;fct&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.261   Low     0.00126  1.07e-7  0.283  7.78e-1  0.66         0.33    0.783\n 2 -0.276   Low     0.000969 4.76e-8 -0.123  9.02e-1  0.98         0.49    0.713\n 3  0.00573 High    0.00156  2.53e-7 -0.0571 9.54e-1  0.78         0.39    0.972\n 4  0.528   High    0.00155  2.97e-7  0.321  7.48e-1  0.56         0.28    0.942\n 5  0.466   High    0.00137  2.76e-7  0.386  7.00e-1  0.52         0.26    1.32 \n 6 -0.445   High    0.000992 7.08e-8 -0.588  5.57e-1  0.68         0.34    0.692\n 7  2.99    High    0.000700 4.05e-8  3.13   1.74e-3  0.04         0.02    0.975\n 8  2.04    High    0.00152  1.58e-7  1.77   7.59e-2  0.16         0.08    1.26 \n 9  4.42    High    0.00130  1.18e-7  4.22   2.39e-5  0.02         0.01    1.20 \n10  1.21    Low     0.00175  1.25e-7  1.49   1.36e-1  0.18         0.09    0.408\n# ℹ 78 more rows\n# ℹ 10 more variables: kurtosis &lt;dbl&gt;, nb &lt;nb&gt;, wts &lt;list&gt;, NAME_2 &lt;chr&gt;,\n#   ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;, ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;,\n#   geometry &lt;POLYGON [°]&gt;\n\n\n\n\n\nIn the code chunk below, tmap functions are used to plot the local Gi* (i.e. gi_star) at the province level.\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.[v3-&gt;v4] `tm_view()`: use set_zoom_limits instead of set.zoom.limits[scale] tm_polygons:() the data variable assigned to 'fill' contains positive and negative values, so midpoint is set to 0. Set 'midpoint = NA' in 'fill.scale = tm_scale_intervals(&lt;HERE&gt;)' to use all visual values (e.g. colors)\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, tmap functions are used to plot the p-values of local Gi* (i.e. p_sim) at the province level.\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") + \n  tm_borders(alpha = 0.5)\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n\n\n\n\n\n\n\n\n\n\n\n\nFor effective comparison, you can plot both maps next to each other as shown below.\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\nmap1 &lt;- tm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of GDPPC\",\n            main.title.size = 0.8)\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.[v3-&gt;v4] `tm_view()`: use set_zoom_limits instead of set.zoom.limits[v3-&gt;v4] `tm_layout()`: use `tm_title()` instead of `tm_layout(main.title = )`\n\nmap2 &lt;- tm_shape(HCSA) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n[v3-&gt;v4] `tm_layout()`: use `tm_title()` instead of `tm_layout(main.title = )`\n\ntmap_arrange(map1, map2, ncol = 2)\n\n[scale] tm_polygons:() the data variable assigned to 'fill' contains positive and negative values, so midpoint is set to 0. Set 'midpoint = NA' in 'fill.scale = tm_scale_intervals(&lt;HERE&gt;)' to use all visual values (e.g. colors)\n\n\n\n\n\n\n\n\n\n\n\n\nNow, we are ready to plot the significant (i.e. p-values less than 0.05) hot spot and cold spot areas by using appropriate tmap functions as shown below.\n\nHCSA_sig &lt;- HCSA  %&gt;%\n  filter(p_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4)\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteObservation:\n\n\n\nFigure above reveals that there is one hot spot area and two cold spot areas. Interestingly, the hot spot areas coincide with the High-high cluster identifies by using local Moran’s I method in the earlier sub-section."
  },
  {
    "objectID": "In-Class_Ex05/in-class_ex05.html#overview",
    "href": "In-Class_Ex05/in-class_ex05.html#overview",
    "title": "In-class Exercise 5a: Global and Local Measures of Spatial Autocorrelation using sfdep methods",
    "section": "",
    "text": "Introducing sfdep:\n\nsfdep creates an sf and tidyverse friendly interface to the package as well as introduces new functionality that is not present in spdep.\nsfdep utilizes list columns extensively to make this interface possible.”"
  },
  {
    "objectID": "In-Class_Ex05/in-class_ex05.html#getting-started",
    "href": "In-Class_Ex05/in-class_ex05.html#getting-started",
    "title": "In-class Exercise 5a: Global and Local Measures of Spatial Autocorrelation using sfdep methods",
    "section": "",
    "text": "Four R packages will be used for this in-class exercise, they are: sf, sfdep, tmap and tidyverse.\n\npacman::p_load(sf, sfdep, tmap, tidyverse)"
  },
  {
    "objectID": "In-Class_Ex05/in-class_ex05.html#the-data",
    "href": "In-Class_Ex05/in-class_ex05.html#the-data",
    "title": "In-class Exercise 5a: Global and Local Measures of Spatial Autocorrelation using sfdep methods",
    "section": "",
    "text": "For the purpose of this in-class exercise, the Hunan data sets will be used. There are two data sets in this use case, they are:\n\nHunan, a geospatial data set in ESRI shapefile format, and\nHunan_2012, an attribute data set in csv format.\n\n\nhunan &lt;- st_read(dsn = \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex05/data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex05/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-Class_Ex05/in-class_ex05.html#importing-attribute-table",
    "href": "In-Class_Ex05/in-class_ex05.html#importing-attribute-table",
    "title": "In-class Exercise 5a: Global and Local Measures of Spatial Autocorrelation using sfdep methods",
    "section": "",
    "text": "Import Hunan_2012.csv into R environment as an tibble data frame.\n\nhunan2012 &lt;- read_csv(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex05/data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "In-Class_Ex05/in-class_ex05.html#combining-both-data-frame-by-using-left-join",
    "href": "In-Class_Ex05/in-class_ex05.html#combining-both-data-frame-by-using-left-join",
    "title": "In-class Exercise 5a: Global and Local Measures of Spatial Autocorrelation using sfdep methods",
    "section": "",
    "text": "hunan_GDPPC &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor the purpose of this exercise, we only retain column 1 to 4, column 7 and column 15. You should examine the output sf data.frame to learn know what are these fields.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIn order to retain the geospatial properties, the left data frame must the sf data.frame (i.e. hunan)"
  },
  {
    "objectID": "In-Class_Ex05/in-class_ex05.html#plotting-a-choropleth-map",
    "href": "In-Class_Ex05/in-class_ex05.html#plotting-a-choropleth-map",
    "title": "In-class Exercise 5a: Global and Local Measures of Spatial Autocorrelation using sfdep methods",
    "section": "",
    "text": "Plot a choropleth map showing the distribution of GDPPC of Hunan Province.\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\ntm_shape(hunan_GDPPC) +\n  tm_fill(\"GDPPC\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_layout(main.title = \"Distribution of GDP per capita by county, Hunan Province\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_fill()`: instead of `style = \"quantile\"`, use fill.scale =\n`tm_scale_intervals()`.\nℹ Migrate the argument(s) 'style', 'palette' (rename to 'values') to\n  'tm_scale_intervals(&lt;HERE&gt;)'[v3-&gt;v4] `tm_fill()`: migrate the argument(s) related to the legend of the\nvisual variable `fill` namely 'title' to 'fill.legend = tm_legend(&lt;HERE&gt;)'[v3-&gt;v4] `tm_layout()`: use `tm_title()` instead of `tm_layout(main.title = )`[v3-&gt;v4] `tm_borders()`: use 'fill' for the fill color of polygons/symbols\n(instead of 'col'), and 'col' for the outlines (instead of 'border.col').[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.! `tm_scale_bar()` is deprecated. Please use `tm_scalebar()` instead.[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"Blues\" is named\n\"brewer.blues\"Multiple palettes called \"blues\" found: \"brewer.blues\", \"matplotlib.blues\". The first one, \"brewer.blues\", is returned.\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling."
  },
  {
    "objectID": "In-Class_Ex05/in-class_ex05.html#global-measures-of-spatial-association",
    "href": "In-Class_Ex05/in-class_ex05.html#global-measures-of-spatial-association",
    "title": "In-class Exercise 5a: Global and Local Measures of Spatial Autocorrelation using sfdep methods",
    "section": "",
    "text": "wm_q &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1) \n\nNotice that st_weights() provides tree arguments, they are:\n\nnb: A neighbor list object as created by st_neighbors().\n\nstyle: Default “W” for row standardized weights. This value can also be “B”, “C”, “U”, “minmax”, and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nallow_zero: If TRUE, assigns zero as lagged value to zone without neighbors.\n\n\n\n\n\nwm_q\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb\n1                 2, 3, 4, 57, 85\n2               1, 57, 58, 78, 85\n3                     1, 4, 5, 85\n4                      1, 3, 5, 6\n5                     3, 4, 6, 85\n6                4, 5, 69, 75, 85\n7                  67, 71, 74, 84\n8       9, 46, 47, 56, 78, 80, 86\n9           8, 66, 68, 78, 84, 86\n10 16, 17, 19, 20, 22, 70, 72, 73\n                                                                            wt\n1                                                      0.2, 0.2, 0.2, 0.2, 0.2\n2                                                      0.2, 0.2, 0.2, 0.2, 0.2\n3                                                       0.25, 0.25, 0.25, 0.25\n4                                                       0.25, 0.25, 0.25, 0.25\n5                                                       0.25, 0.25, 0.25, 0.25\n6                                                      0.2, 0.2, 0.2, 0.2, 0.2\n7                                                       0.25, 0.25, 0.25, 0.25\n8  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n9             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n10                      0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734...\n\n\n\n\n\nIn the code chunk below, global_moran() function is used to compute the Moran’s I value. Different from spdep package, the output is a tibble data.frame.\n\nmoranI &lt;- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\n\n\n\nIn general, Moran’s I test will be performed instead of just computing the Moran’s I statistics. With sfdep package, Moran’s I test can be performed by using global_moran_test() as shown in the code chunk below.\n\nglobal_moran_test(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\n\n\nTip\n\n\n\n\nThe default for alternative argument is “two.sided”. Other supported arguments are “greater” or “less”. randomization, and\n\nBy default the randomization argument is TRUE. If FALSE, under the assumption of normality.\n\n\n\n\n\n\nIn practice, Monte carlo simulation should be used to perform the statistical test. For sfdep, it is supported by globel_moran_perm()\n\n\nIt is always a good practice to use set.seed() before performing simulation. This is o ensure that the computation is reproducible.\n\nset.seed(1234)\n\n\n\n\nNext, global_moran_perm() is used to perform Monte Carlo simulation.\n\nglobal_moran_perm(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\nThe statistical report on previous tab shows that the p-value is smaller than alpha value of 0.05. Hence, we have enough statistical evidence to reject the null hypothesis that the spatial distribution of GPD per capita are resemble random distribution (i.e. independent from spatial). Because the Moran’s I statistics is greater than 0. We can infer that the spatial distribution shows sign of clustering.\n\nThe numbers of simulation is alway equal to nsim + 1. This mean in nsim = 99. This mean 100 simulation will be performed."
  },
  {
    "objectID": "In-Class_Ex05/in-class_ex05.html#lisa-map",
    "href": "In-Class_Ex05/in-class_ex05.html#lisa-map",
    "title": "In-class Exercise 5a: Global and Local Measures of Spatial Autocorrelation using sfdep methods",
    "section": "",
    "text": "LISA map is a categorical map showing outliers and clusters. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two type of clusters namely: High-High and Low-Low cluaters. In fact, LISA map is an interpreted map by combining local Moran’s I of geographical areas and their respective p-values.\n\n\nIn this section, you will learn how to compute Local Moran’s I of GDPPC at county level by using local_moran() of sfdep package.\n\nlisa &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nlisa\n\nSimple feature collection with 88 features and 20 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 21\n         ii        eii     var_ii    z_ii    p_ii p_ii_sim p_folded_sim skewness\n      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1 -0.00147  0.00177   0.000418   -0.158  0.874       0.82         0.41   -0.812\n 2  0.0259   0.00641   0.0105      0.190  0.849       0.96         0.48   -1.09 \n 3 -0.0120  -0.0374    0.102       0.0796 0.937       0.76         0.38    0.824\n 4  0.00102 -0.0000349 0.00000437  0.506  0.613       0.64         0.32    1.04 \n 5  0.0148  -0.00340   0.00165     0.449  0.654       0.5          0.25    1.64 \n 6 -0.0388  -0.00339   0.00545    -0.480  0.631       0.82         0.41    0.614\n 7  3.37    -0.198     1.41        3.00   0.00266     0.08         0.04    1.46 \n 8  1.56    -0.265     0.804       2.04   0.0417      0.08         0.04    0.459\n 9  4.42     0.0450    1.79        3.27   0.00108     0.02         0.01    0.746\n10 -0.399   -0.0505    0.0859     -1.19   0.234       0.28         0.14   -0.685\n# ℹ 78 more rows\n# ℹ 13 more variables: kurtosis &lt;dbl&gt;, mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;,\n#   nb &lt;nb&gt;, wt &lt;list&gt;, NAME_2 &lt;chr&gt;, ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;,\n#   ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;, geometry &lt;POLYGON [°]&gt;\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\ntm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(\n    main.title = \"local Moran's I of GDPPC\",\n    main.title.size = 2)\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.[v3-&gt;v4] `tm_view()`: use set_zoom_limits instead of set.zoom.limits[v3-&gt;v4] `tm_layout()`: use `tm_title()` instead of `tm_layout(main.title = )`[scale] tm_polygons:() the data variable assigned to 'fill' contains positive and negative values, so midpoint is set to 0. Set 'midpoint = NA' in 'fill.scale = tm_scale_intervals(&lt;HERE&gt;)' to use all visual values (e.g. colors)\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, tmap functions are used prepare a choropleth map by using value in the p_ii_sim field.\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\ntm_shape(lisa) +\n  tm_fill(\"p_ii_sim\") + \n  tm_borders(alpha = 0.5) +\n   tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 2)\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.[v3-&gt;v4] `tm_layout()`: use `tm_title()` instead of `tm_layout(main.title = )`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nFor p-values, the appropriate classification should be 0.001, 0.01, 0.05 and not significant instead of using default classification scheme.\n\n\n\n\n\nFor effective comparison, it will be better for us to plot both maps next to each other.\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 0.8)\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.[v3-&gt;v4] `tm_view()`: use set_zoom_limits instead of set.zoom.limits[v3-&gt;v4] `tm_layout()`: use `tm_title()` instead of `tm_layout(main.title = )`\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n[v3-&gt;v4] `tm_layout()`: use `tm_title()` instead of `tm_layout(main.title = )`\n\ntmap_arrange(map1, map2, ncol = 2)\n\n[scale] tm_polygons:() the data variable assigned to 'fill' contains positive and negative values, so midpoint is set to 0. Set 'midpoint = NA' in 'fill.scale = tm_scale_intervals(&lt;HERE&gt;)' to use all visual values (e.g. colors)\n\n\n\n\n\n\n\n\n\n\n\n\nIn lisa sf data.frame, we can find three fields contain the LISA categories. They are mean, median and pysal. In general, classification in mean will be used as shown in the code chunk below.\n\nlisa_sig &lt;- lisa  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`."
  },
  {
    "objectID": "In-Class_Ex05/in-class_ex05.html#hot-spot-and-cold-spot-area-analysis-hcsa",
    "href": "In-Class_Ex05/in-class_ex05.html#hot-spot-and-cold-spot-area-analysis-hcsa",
    "title": "In-class Exercise 5a: Global and Local Measures of Spatial Autocorrelation using sfdep methods",
    "section": "",
    "text": "HCSA uses spatial weights to identify locations of statistically significant hot spots and cold spots in an spatially weighted attribute that are in proximity to one another based on a calculated distance. The analysis groups features when similar high (hot) or low (cold) values are found in a cluster. The polygon features usually represent administration boundaries or a custom grid structure.\n\n\nAs usual, we will need to derive a spatial weight matrix before we can compute local Gi* statistics. Code chunk below will be used to derive a spatial weight matrix by using sfdep functions and tidyverse approach.\n\nwm_idw &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = include_self(\n    st_contiguity(geometry)),\n    wts = st_inverse_distance(nb, \n                              geometry, \n                              scale = 1,\n                              alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wts = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\n\n\nGi* and local Gi* are distance-based spatial statistics. Hence, distance methods instead of contiguity methods should be used to derive the spatial weight matrix.\nSince we are going to compute Gi* statistics, include_self() is used.\n\n\n\n\n\nNow, we will compute the local Gi* by using the code chunk below.\n\nHCSA &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\nHCSA\n\nSimple feature collection with 88 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 19\n    gi_star cluster     e_gi  var_gi std_dev p_value p_sim p_folded_sim skewness\n      &lt;dbl&gt; &lt;fct&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.261   Low     0.00126  1.07e-7  0.283  7.78e-1  0.66         0.33    0.783\n 2 -0.276   Low     0.000969 4.76e-8 -0.123  9.02e-1  0.98         0.49    0.713\n 3  0.00573 High    0.00156  2.53e-7 -0.0571 9.54e-1  0.78         0.39    0.972\n 4  0.528   High    0.00155  2.97e-7  0.321  7.48e-1  0.56         0.28    0.942\n 5  0.466   High    0.00137  2.76e-7  0.386  7.00e-1  0.52         0.26    1.32 \n 6 -0.445   High    0.000992 7.08e-8 -0.588  5.57e-1  0.68         0.34    0.692\n 7  2.99    High    0.000700 4.05e-8  3.13   1.74e-3  0.04         0.02    0.975\n 8  2.04    High    0.00152  1.58e-7  1.77   7.59e-2  0.16         0.08    1.26 \n 9  4.42    High    0.00130  1.18e-7  4.22   2.39e-5  0.02         0.01    1.20 \n10  1.21    Low     0.00175  1.25e-7  1.49   1.36e-1  0.18         0.09    0.408\n# ℹ 78 more rows\n# ℹ 10 more variables: kurtosis &lt;dbl&gt;, nb &lt;nb&gt;, wts &lt;list&gt;, NAME_2 &lt;chr&gt;,\n#   ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;, ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;,\n#   geometry &lt;POLYGON [°]&gt;\n\n\n\n\n\nIn the code chunk below, tmap functions are used to plot the local Gi* (i.e. gi_star) at the province level.\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.[v3-&gt;v4] `tm_view()`: use set_zoom_limits instead of set.zoom.limits[scale] tm_polygons:() the data variable assigned to 'fill' contains positive and negative values, so midpoint is set to 0. Set 'midpoint = NA' in 'fill.scale = tm_scale_intervals(&lt;HERE&gt;)' to use all visual values (e.g. colors)\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, tmap functions are used to plot the p-values of local Gi* (i.e. p_sim) at the province level.\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") + \n  tm_borders(alpha = 0.5)\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n\n\n\n\n\n\n\n\n\n\n\n\nFor effective comparison, you can plot both maps next to each other as shown below.\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\nmap1 &lt;- tm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of GDPPC\",\n            main.title.size = 0.8)\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.[v3-&gt;v4] `tm_view()`: use set_zoom_limits instead of set.zoom.limits[v3-&gt;v4] `tm_layout()`: use `tm_title()` instead of `tm_layout(main.title = )`\n\nmap2 &lt;- tm_shape(HCSA) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n[v3-&gt;v4] `tm_layout()`: use `tm_title()` instead of `tm_layout(main.title = )`\n\ntmap_arrange(map1, map2, ncol = 2)\n\n[scale] tm_polygons:() the data variable assigned to 'fill' contains positive and negative values, so midpoint is set to 0. Set 'midpoint = NA' in 'fill.scale = tm_scale_intervals(&lt;HERE&gt;)' to use all visual values (e.g. colors)\n\n\n\n\n\n\n\n\n\n\n\n\nNow, we are ready to plot the significant (i.e. p-values less than 0.05) hot spot and cold spot areas by using appropriate tmap functions as shown below.\n\nHCSA_sig &lt;- HCSA  %&gt;%\n  filter(p_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4)\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteObservation:\n\n\n\nFigure above reveals that there is one hot spot area and two cold spot areas. Interestingly, the hot spot areas coincide with the High-high cluster identifies by using local Moran’s I method in the earlier sub-section."
  },
  {
    "objectID": "Hands-on_Ex03/Hand-on_Ex03.html",
    "href": "Hands-on_Ex03/Hand-on_Ex03.html",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "A spatio-temporal point process is a random collection of events identified by both time and location, such as disease cases, species sightings, or natural disasters. With the rise of geographically and temporally indexed data, analyzing these patterns has become increasingly important across many fields. In the past decade, several R methods and packages have been developed to support such analyses. This hands-on exercise demonstrates how these tools can be combined in a guided way, using forest fire events in Kepulauan Bangka Belitung, Indonesia (from 1 January to 31 December 2023) as a real-world case study to illustrate the procedures and interpretations.\n\n\n\n\n\nThe specific questions we would like to answer are:\n\nAre the locations of forest fire in Kepulauan Bangka Belitung spatial and spatio-temporally independent?\nIf the answer is NO, where and when the observed forest fire locations tend to cluster?\n\nA detailed discussion of the results, together with explicit insights and implications, is provided in Section 6.11 Discussion of Results (Answer to the Research Question).\n\n\n\n\nKnow what files you’ll use and where they come from.\n\nforestfires.csv: point events (each row = a fire). Has longitude, latitude, and date/time fields from MODIS.\nKepulauan_Bangka_Belitung shapefile: the study region polygon (administrative boundary). We’ll read only the Kepulauan Bangka Belitung subset for 2023 analyses.\n\n\n\n\nLoad all libraries used in this hands-on exercise.\n\npacman::p_load(sf,        # read, write, and transform spatial vector data\n               terra,      \n               spatstat,  # used for performing Spatial Point Patterns Analysis such as kcross, Lcross, etc\n               sparr,     # spatio-temporal kernel density estimation (STKDE)\n               tmap,      # cartographic visualisation for quick maps\n               tidyverse  # readr (CSV), dplyr (mutate/select), ggplot, etc.\n               )\n\n\n\n\n\n\nFirst. read the Kepulauan Bangka Belitung boundary, clean geometry, and set projected CRS.\n\n# Read the shapefile from the data folder -----------------------------------------------------\nkbb_sf &lt;- st_read(dsn = \"data/rds/BATAS_DESA_DESEMBER_2019_DUKCAPIL_BANGKA_BELITUNG\",    # folder containing the shapefile\n                  layer = \"BATAS_DESA_DESEMBER_2019_DUKCAPIL_BANGKA_BELITUNG\") %&gt;%       # shapefile base name (no .shp)\n  st_union() %&gt;%                       # dissolve internal boundaries into one polygon\n  st_zm(drop = TRUE, what = \"ZM\") %&gt;%  # drop Z/M dimensions if present (keeps 2D)\n  st_transform(crs = 32748)            # reproject to EPSG:32748 (UTM Zone 48S in meters)\n\nReading layer `BATAS_DESA_DESEMBER_2019_DUKCAPIL_BANGKA_BELITUNG' from data source `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex03/Data/rds/BATAS_DESA_DESEMBER_2019_DUKCAPIL_BANGKA_BELITUNG' \n  using driver `ESRI Shapefile'\nSimple feature collection with 391 features and 161 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 105.1081 ymin: -3.416903 xmax: 108.848 ymax: -1.501757\nGeodetic CRS:  WGS 84\n\n\n\n\n\nNext, convert the polygon (kb) to an observation window (owin) for point-pattern analysis.\n\n# Convert the sf polygon to an 'owin' (spatstat window) \nkbb_owin &lt;- as.owin(kbb_sf)      # turns the sf polygon into a spatstat window for ppp usage\nkbb_owin                         \n\nwindow: polygonal boundary\nenclosing rectangle: [512017.1, 928107.3] x [9621818, 9833989] units\n\n\n\n# Quick check that conversion succeeded\nclass(kbb_owin) \n\n[1] \"owin\"\n\n\n\n\n\n\nNext read the CSV, make it spatial, reproject to meters, and build helpful time fields.\n\nfire_sf &lt;- read_csv(\"data/rds/modis_2023_Indonesia.csv\")    %&gt;%  # load the event table\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %&gt;%  # turn lon/lat cols into points (WGS84)\n  st_transform(crs = 32748)   # project to meters to match the study area\n\nRows: 52156 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (4): acq_time, satellite, instrument, daynight\ndbl  (10): latitude, longitude, brightness, scan, track, confidence, version...\ndate  (1): acq_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n# Add day-of-year and month fields used later\nfire_sf &lt;- fire_sf %&gt;% \n  mutate(DayofYear = yday(acq_date)) %&gt;%     # numeric day 1..365 from acquisition date\n  mutate(Month_num = month(acq_date)) %&gt;%    # numeric month 1..12\n  mutate(Month_fac = month(acq_date, label = TRUE, abbr = FALSE))  # factor month with full names (Jan..Dec)\n\n\n\n\n\n\nPlot one map with all 2023 fires over the study region\n\n# Bigger figure when rendering (Quarto/knitr)\n\n# Clip fire points so only those inside kbb_sf remain \nfire_sf &lt;- sf::st_intersection(fire_sf, kbb_sf)\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n# Build a quick overall point map with tmap \ntmap_mode(\"plot\")                                         # use static plotting mode\n\nℹ tmap mode set to \"plot\".\n\ntm_shape(kbb_sf) +                                        # add study area polygon layer\n  tm_polygons(col = \"grey85\", border.col = \"grey40\") +    # light fill, subtle border\n  tm_shape(fire_sf) +                                     # add fire points\n  tm_symbols(size = 0.5, col = \"red\") +                   # small red dots\n  tm_credits(\n    \"Forest Fire Points in 2023 (Kepulauan Bangka Belitung)\",\n    position = c(\"center\", \"top\"),    # center horizontally, top vertically\n    size = 1.2,                       # enlarge title text\n    fontface = 2                      # bold\n  ) +\n  tm_layout(\n    frame = TRUE,\n    # outer.margins = c(0.1, 0.05, 0.1, 0.05) # top, right, bottom, left (gives space for title)\n    inner.margins = 0.05                      # uncomment to maximize map area even more\n  )\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_polygons()`: use 'fill' for the fill color of polygons/symbols\n(instead of 'col'), and 'col' for the outlines (instead of 'border.col').\n\n\n\n\n\n\n\n\n\n\n\n\nNext, 12 small multiples (one map per month) like the practical guide.\n\n# Faceted monthly point maps \ntm_shape(kbb_sf) +\n  tm_polygons(col = \"grey85\", border.col = \"grey50\") +\n  tm_shape(fire_sf) +\n  tm_symbols(size = 0.1, col = \"red\") +\n  tm_facets(by = \"Month_fac\", ncol = 4) +                          # 4 columns x 3 rows facet layout\n  tm_layout(\n            frame = TRUE)\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will learn how to compute STKDE by using spattemp.density() of sparr package.\n\n\nWe need to keep only the mark (month) needed by ppp() and the geometry.\n\n# Keep only the monthly mark and geometry for ppp creation \nfire_month &lt;- fire_sf %&gt;% \n  dplyr::select(Month_num)     # ppp requires a numeric/character mark column and geometry\n\n\n\n\nNext, we need to convert to a spatstat ppp (planar point pattern) object.\n\n# Convert sf points to ppp (planar point pattern) \nfire_month_ppp &lt;- as.ppp(fire_month)   # create ppp with coordinates and 'Month_num' as the mark\nfire_month_ppp   # print basic info to confirm number of points/window box\n\nMarked planar point pattern: 899 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [521564.1, 862416.4] x [9642001, 9828767] units\n\n\n\n# Sanity checks on the ppp \nsummary(fire_month_ppp)   # detailed summary (intensity, mark stats, window box)\n\nMarked planar point pattern:  899 points\nAverage intensity 1.412198e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.644  10.000  12.000 \n\nWindow: rectangle = [521564.1, 862416.4] x [9642001, 9828767] units\n                    (340900 x 186800 units)\nWindow area = 63659700000 square units\n\nany(duplicated(fire_month_ppp)) # TRUE if any exact duplicate point events; expect FALSE per notes\n\n[1] FALSE\n\n\n\n# Check if there are duplicated point events by using the code chunk below.\nany(duplicated(fire_month_ppp))\n\n[1] FALSE\n\n\n\n\n\nNext, we need to clip/assign the point pattern to the study window.\n\n# Attach/clip the ppp to our study-area window \nfire_month_owin &lt;- fire_month_ppp[kbb_owin]  # ensure points are analysed within the polygon boundary\nsummary(fire_month_owin)   # verify marks, counts, window area\n\nMarked planar point pattern:  899 points\nAverage intensity 5.380183e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.644  10.000  12.000 \n\nWindow: polygonal boundary\n319 separate polygons (40 holes)\n                   vertices         area relative.area\npolygon 1              9026  1.15464e+10      6.91e-01\npolygon 2                19  1.26217e+04      7.55e-07\npolygon 3 (hole)          3 -1.80096e-01     -1.08e-11\npolygon 4 (hole)          3 -9.26944e-01     -5.55e-11\npolygon 5 (hole)          3 -1.07382e+03     -6.43e-08\npolygon 6 (hole)          3 -6.41537e+02     -3.84e-08\npolygon 7                23  9.26156e+04      5.54e-06\npolygon 8                30  3.37146e+04      2.02e-06\npolygon 9                54  3.25211e+05      1.95e-05\npolygon 10               33  1.30244e+06      7.79e-05\npolygon 11 (hole)         4 -9.57353e+02     -5.73e-08\npolygon 12 (hole)         4 -2.84738e+02     -1.70e-08\npolygon 13 (hole)         3 -1.38747e+02     -8.30e-09\npolygon 14 (hole)         4 -5.31445e+02     -3.18e-08\npolygon 15 (hole)         3 -6.42241e+02     -3.84e-08\npolygon 16 (hole)         6 -1.13809e+02     -6.81e-09\npolygon 17 (hole)         4 -2.10482e+02     -1.26e-08\npolygon 18 (hole)         4 -9.54892e+01     -5.71e-09\npolygon 19 (hole)         4 -6.47895e+01     -3.88e-09\npolygon 20 (hole)         4 -7.10903e+01     -4.25e-09\npolygon 21 (hole)         4 -2.18071e+02     -1.31e-08\npolygon 22 (hole)         4 -4.44993e+01     -2.66e-09\npolygon 23 (hole)         4 -4.90009e+01     -2.93e-09\npolygon 24 (hole)         4 -6.48299e+01     -3.88e-09\npolygon 25 (hole)         4 -2.36910e+02     -1.42e-08\npolygon 26 (hole)         4 -3.07205e+01     -1.84e-09\npolygon 27 (hole)         4 -5.24443e+01     -3.14e-09\npolygon 28 (hole)         5 -6.64298e+01     -3.98e-09\npolygon 29 (hole)         4 -6.08287e+01     -3.64e-09\npolygon 30 (hole)         4 -1.12681e+02     -6.74e-09\npolygon 31              132  1.16480e+06      6.97e-05\npolygon 32 (hole)         4 -9.56157e+01     -5.72e-09\npolygon 33               68  1.91291e+05      1.14e-05\npolygon 34 (hole)         4 -5.31171e+02     -3.18e-08\npolygon 35 (hole)         3 -1.76143e+00     -1.05e-10\npolygon 36              116  1.51984e+05      9.10e-06\npolygon 37               95  1.14322e+05      6.84e-06\npolygon 38               21  4.51914e+03      2.70e-07\npolygon 39               24  1.18511e+04      7.09e-07\npolygon 40              130  1.52296e+05      9.11e-06\npolygon 41               36  1.07878e+04      6.46e-07\npolygon 42               54  3.46932e+05      2.08e-05\npolygon 43               71  2.15798e+05      1.29e-05\npolygon 44               12  1.76977e+03      1.06e-07\npolygon 45               75  1.05557e+05      6.32e-06\npolygon 46               17  4.22421e+03      2.53e-07\npolygon 47              116  1.64725e+05      9.86e-06\npolygon 48               36  1.15582e+04      6.92e-07\npolygon 49               15  3.48567e+03      2.09e-07\npolygon 50              325  3.08585e+06      1.85e-04\npolygon 51 (hole)         4 -2.57635e+02     -1.54e-08\npolygon 52              191  2.36948e+06      1.42e-04\npolygon 53               75  8.81673e+04      5.28e-06\npolygon 54               49  6.13133e+04      3.67e-06\npolygon 55              117  7.65040e+04      4.58e-06\npolygon 56                5  1.73964e+04      1.04e-06\npolygon 57             6115  4.61702e+09      2.76e-01\npolygon 58                4  6.35998e+03      3.81e-07\npolygon 59               16  1.18306e+05      7.08e-06\npolygon 60                5  2.11525e+04      1.27e-06\npolygon 61               11  3.52792e+04      2.11e-06\npolygon 62               13  6.20254e+04      3.71e-06\npolygon 63                8  1.23192e+04      7.37e-07\npolygon 64                5  1.08320e+04      6.48e-07\npolygon 65                5  9.14438e+03      5.47e-07\npolygon 66                6  9.61120e+03      5.75e-07\npolygon 67               31  1.54535e+06      9.25e-05\npolygon 68                9  2.89834e+04      1.73e-06\npolygon 69               10  2.76357e+04      1.65e-06\npolygon 70               12  8.99515e+04      5.38e-06\npolygon 71               15  5.42889e+04      3.25e-06\npolygon 72                8  1.58645e+04      9.49e-07\npolygon 73                6  1.35398e+04      8.10e-07\npolygon 74                4  4.29102e+03      2.57e-07\npolygon 75               23  1.76942e+05      1.06e-05\npolygon 76               44  4.35606e+04      2.61e-06\npolygon 77                5  6.83234e+03      4.09e-07\npolygon 78                5  6.67728e+03      4.00e-07\npolygon 79                5  2.24964e+03      1.35e-07\npolygon 80                7  2.62416e+04      1.57e-06\npolygon 81                9  1.19857e+04      7.17e-07\npolygon 82                8  2.25169e+04      1.35e-06\npolygon 83                6  1.21525e+04      7.27e-07\npolygon 84                5  8.76352e+03      5.24e-07\npolygon 85                9  2.28019e+04      1.36e-06\npolygon 86                6  9.21428e+03      5.51e-07\npolygon 87               49  1.00151e+05      5.99e-06\npolygon 88                5  4.45695e+03      2.67e-07\npolygon 89                4  2.90460e+03      1.74e-07\npolygon 90                4  3.68683e+03      2.21e-07\npolygon 91               64  9.90797e+04      5.93e-06\npolygon 92                5  3.03789e+03      1.82e-07\npolygon 93                6  1.05164e+04      6.29e-07\npolygon 94               12  9.48365e+03      5.68e-07\npolygon 95               13  6.95068e+04      4.16e-06\npolygon 96               34  2.01269e+05      1.20e-05\npolygon 97              222  1.23410e+06      7.39e-05\npolygon 98                4  2.60388e+03      1.56e-07\npolygon 99                7  8.47934e+03      5.07e-07\npolygon 100               5  8.09538e+03      4.84e-07\npolygon 101              93  2.08256e+05      1.25e-05\npolygon 102              16  7.78971e+04      4.66e-06\npolygon 103              24  1.58864e+04      9.51e-07\npolygon 104               4  8.84658e+02      5.29e-08\npolygon 105              42  4.25525e+04      2.55e-06\npolygon 106               5  4.40655e+03      2.64e-07\npolygon 107               4  2.45366e+03      1.47e-07\npolygon 108               5  4.70713e+03      2.82e-07\npolygon 109             214  2.22664e+06      1.33e-04\npolygon 110              60  5.44949e+04      3.26e-06\npolygon 111               6  4.54843e+03      2.72e-07\npolygon 112               6  1.47384e+04      8.82e-07\npolygon 113               6  1.35534e+04      8.11e-07\npolygon 114              51  9.00778e+04      5.39e-06\npolygon 115               4  1.53560e+03      9.19e-08\npolygon 116 (hole)        3 -3.48195e+02     -2.08e-08\npolygon 117              32  4.34406e+04      2.60e-06\npolygon 118             144  5.46612e+05      3.27e-05\npolygon 119              36  7.39285e+04      4.42e-06\npolygon 120              42  9.17456e+04      5.49e-06\npolygon 121             141  1.10139e+06      6.59e-05\npolygon 122              94  2.55406e+05      1.53e-05\npolygon 123              71  3.74605e+04      2.24e-06\npolygon 124              72  9.11248e+05      5.45e-05\npolygon 125 (hole)        3 -2.91215e+01     -1.74e-09\npolygon 126               5  4.23910e+03      2.54e-07\npolygon 127              47  1.10186e+05      6.59e-06\npolygon 128               6  1.00636e+04      6.02e-07\npolygon 129 (hole)        3 -3.94431e+01     -2.36e-09\npolygon 130               4  1.41401e+02      8.46e-09\npolygon 131              32  2.34725e+04      1.40e-06\npolygon 132               5  3.61887e+02      2.17e-08\npolygon 133 (hole)        3 -2.90329e+03     -1.74e-07\npolygon 134             120  3.80494e+05      2.28e-05\npolygon 135              19  3.13628e+04      1.88e-06\npolygon 136              42  1.21238e+05      7.26e-06\npolygon 137              24  3.83277e+04      2.29e-06\npolygon 138              88  4.56947e+05      2.73e-05\npolygon 139              20  1.78310e+04      1.07e-06\npolygon 140              20  2.39227e+04      1.43e-06\npolygon 141               5  6.65825e+03      3.98e-07\npolygon 142               5  5.41759e+03      3.24e-07\npolygon 143              53  4.55018e+05      2.72e-05\npolygon 144             263  1.76197e+07      1.05e-03\npolygon 145 (hole)        4 -3.70130e+03     -2.22e-07\npolygon 146               4  6.79585e+03      4.07e-07\npolygon 147              15  5.74657e+03      3.44e-07\npolygon 148              25  2.16665e+05      1.30e-05\npolygon 149               9  7.99755e+03      4.79e-07\npolygon 150               8  3.28848e+03      1.97e-07\npolygon 151              10  1.13482e+04      6.79e-07\npolygon 152              45  1.05243e+05      6.30e-06\npolygon 153               7  4.67607e+03      2.80e-07\npolygon 154             533  4.88598e+07      2.92e-03\npolygon 155             641  1.19875e+08      7.17e-03\npolygon 156              68  3.72768e+06      2.23e-04\npolygon 157              10  1.01914e+05      6.10e-06\npolygon 158              19  8.26881e+04      4.95e-06\npolygon 159              17  4.00986e+04      2.40e-06\npolygon 160              11  4.05798e+04      2.43e-06\npolygon 161             111  1.46838e+06      8.79e-05\npolygon 162             112  3.73964e+06      2.24e-04\npolygon 163              19  1.91730e+04      1.15e-06\npolygon 164              73  3.61914e+06      2.17e-04\npolygon 165              10  3.05707e+04      1.83e-06\npolygon 166               6  1.62989e+04      9.75e-07\npolygon 167              81  2.65465e+05      1.59e-05\npolygon 168               8  2.09366e+04      1.25e-06\npolygon 169               9  2.23138e+04      1.34e-06\npolygon 170              11  1.96456e+04      1.18e-06\npolygon 171 (hole)        3 -4.90052e+02     -2.93e-08\npolygon 172             145  7.13727e+06      4.27e-04\npolygon 173              60  1.45353e+05      8.70e-06\npolygon 174 (hole)        4 -3.71089e+02     -2.22e-08\npolygon 175              74  2.06447e+06      1.24e-04\npolygon 176              36  2.65019e+04      1.59e-06\npolygon 177             931  2.12400e+08      1.27e-02\npolygon 178 (hole)        4 -1.54888e+02     -9.27e-09\npolygon 179              25  2.21142e+05      1.32e-05\npolygon 180               6  6.87439e+03      4.11e-07\npolygon 181              31  1.67778e+06      1.00e-04\npolygon 182               7  9.00046e+03      5.39e-07\npolygon 183              12  6.30886e+04      3.78e-06\npolygon 184             202  2.25185e+07      1.35e-03\npolygon 185              46  2.39825e+06      1.44e-04\npolygon 186              25  1.05566e+04      6.32e-07\npolygon 187               8  4.61437e+04      2.76e-06\npolygon 188               7  3.16305e+04      1.89e-06\npolygon 189               5  6.49689e+03      3.89e-07\npolygon 190              12  2.17421e+04      1.30e-06\npolygon 191               5  7.19819e+03      4.31e-07\npolygon 192              11  6.58157e+05      3.94e-05\npolygon 193             159  1.11857e+06      6.69e-05\npolygon 194             104  3.97323e+05      2.38e-05\npolygon 195              14  3.77571e+05      2.26e-05\npolygon 196              27  1.21314e+06      7.26e-05\npolygon 197              69  7.97787e+04      4.77e-06\npolygon 198              51  6.46735e+04      3.87e-06\npolygon 199              71  7.20054e+04      4.31e-06\npolygon 200              46  3.29862e+04      1.97e-06\npolygon 201              52  3.88477e+04      2.32e-06\npolygon 202              59  5.31603e+06      3.18e-04\npolygon 203 (hole)        3 -3.70978e+01     -2.22e-09\npolygon 204              48  1.76671e+06      1.06e-04\npolygon 205              34  5.03002e+04      3.01e-06\npolygon 206              46  1.83138e+04      1.10e-06\npolygon 207              18  5.28224e+03      3.16e-07\npolygon 208             244  3.09431e+06      1.85e-04\npolygon 209              28  1.99131e+05      1.19e-05\npolygon 210              21  4.52072e+05      2.71e-05\npolygon 211              14  5.66637e+04      3.39e-06\npolygon 212              12  1.09825e+05      6.57e-06\npolygon 213              15  1.37135e+06      8.21e-05\npolygon 214               6  1.22312e+05      7.32e-06\npolygon 215              43  2.41150e+05      1.44e-05\npolygon 216               7  2.79840e+04      1.67e-06\npolygon 217              46  1.72671e+06      1.03e-04\npolygon 218              13  6.36540e+04      3.81e-06\npolygon 219              11  7.02064e+05      4.20e-05\npolygon 220              47  9.13826e+05      5.47e-05\npolygon 221 (hole)        4 -3.82299e+03     -2.29e-07\npolygon 222              62  3.95149e+06      2.36e-04\npolygon 223               9  4.34659e+05      2.60e-05\npolygon 224              14  4.20832e+04      2.52e-06\npolygon 225              18  5.12063e+03      3.06e-07\npolygon 226              31  7.44741e+05      4.46e-05\npolygon 227              18  4.11233e+05      2.46e-05\npolygon 228 (hole)        3 -5.32643e+02     -3.19e-08\npolygon 229              23  7.71654e+03      4.62e-07\npolygon 230               8  3.86022e+04      2.31e-06\npolygon 231             168  7.46341e+06      4.47e-04\npolygon 232               4  9.19978e+03      5.51e-07\npolygon 233              14  2.75390e+05      1.65e-05\npolygon 234               9  9.63798e+03      5.77e-07\npolygon 235               9  6.16361e+04      3.69e-06\npolygon 236              10  1.04975e+05      6.28e-06\npolygon 237               8  8.75225e+04      5.24e-06\npolygon 238               5  1.84001e+04      1.10e-06\npolygon 239               5  3.30315e+03      1.98e-07\npolygon 240              13  3.15610e+04      1.89e-06\npolygon 241              67  3.93597e+05      2.36e-05\npolygon 242               4  2.83740e+03      1.70e-07\npolygon 243              15  4.86091e+03      2.91e-07\npolygon 244               4  1.26784e+03      7.59e-08\npolygon 245               8  1.67287e+04      1.00e-06\npolygon 246              12  2.45858e+04      1.47e-06\npolygon 247              12  5.95789e+04      3.57e-06\npolygon 248              12  2.14651e+03      1.28e-07\npolygon 249              14  4.30849e+03      2.58e-07\npolygon 250              16  7.75733e+03      4.64e-07\npolygon 251 (hole)        4 -2.56408e+03     -1.53e-07\npolygon 252              10  1.75648e+03      1.05e-07\npolygon 253              34  3.85386e+06      2.31e-04\npolygon 254               9  3.55249e+03      2.13e-07\npolygon 255              15  1.39816e+04      8.37e-07\npolygon 256              16  4.56059e+05      2.73e-05\npolygon 257              26  1.42631e+04      8.54e-07\npolygon 258              36  2.65697e+04      1.59e-06\npolygon 259              19  4.48214e+03      2.68e-07\npolygon 260              96  5.26087e+05      3.15e-05\npolygon 261              60  1.00635e+05      6.02e-06\npolygon 262              31  7.13046e+04      4.27e-06\npolygon 263              84  1.37245e+06      8.21e-05\npolygon 264             178  8.26947e+05      4.95e-05\npolygon 265              58  1.98953e+05      1.19e-05\npolygon 266             115  3.13297e+05      1.87e-05\npolygon 267             132  4.76047e+05      2.85e-05\npolygon 268             102  1.63410e+07      9.78e-04\npolygon 269              18  6.36647e+03      3.81e-07\npolygon 270              10  7.72550e+03      4.62e-07\npolygon 271             204  1.42141e+06      8.51e-05\npolygon 272             125  2.33639e+06      1.40e-04\npolygon 273              30  2.58819e+04      1.55e-06\npolygon 274              24  2.06403e+04      1.24e-06\npolygon 275              87  1.25178e+06      7.49e-05\npolygon 276              38  4.04777e+04      2.42e-06\npolygon 277              10  5.04036e+04      3.02e-06\npolygon 278               6  1.12482e+04      6.73e-07\npolygon 279              40  1.56825e+05      9.39e-06\npolygon 280              63  5.25132e+04      3.14e-06\npolygon 281               8  1.11128e+04      6.65e-07\npolygon 282               9  1.49650e+03      8.96e-08\npolygon 283              13  4.50724e+03      2.70e-07\npolygon 284              41  4.12892e+04      2.47e-06\npolygon 285               7  3.03545e+03      1.82e-07\npolygon 286              19  7.54584e+03      4.52e-07\npolygon 287              16  8.29528e+03      4.96e-07\npolygon 288              26  5.16293e+05      3.09e-05\npolygon 289              13  9.23979e+04      5.53e-06\npolygon 290              25  4.18391e+04      2.50e-06\npolygon 291               7  3.85120e+03      2.30e-07\npolygon 292              82  4.38489e+05      2.62e-05\npolygon 293             163  3.46322e+06      2.07e-04\npolygon 294              11  5.22182e+03      3.13e-07\npolygon 295              13  3.28208e+04      1.96e-06\npolygon 296               6  3.00920e+04      1.80e-06\npolygon 297               6  1.13309e+04      6.78e-07\npolygon 298              13  2.03134e+05      1.22e-05\npolygon 299              36  2.87112e+04      1.72e-06\npolygon 300               6  1.13102e+04      6.77e-07\npolygon 301              13  4.04370e+03      2.42e-07\npolygon 302              44  1.67056e+05      1.00e-05\npolygon 303              11  6.66250e+04      3.99e-06\npolygon 304             129  2.29313e+06      1.37e-04\npolygon 305               6  7.23372e+04      4.33e-06\npolygon 306              19  6.36948e+03      3.81e-07\npolygon 307             106  1.06881e+06      6.40e-05\npolygon 308               9  2.30443e+04      1.38e-06\npolygon 309              29  9.02725e+03      5.40e-07\npolygon 310              68  1.08514e+05      6.49e-06\npolygon 311              64  2.19772e+05      1.32e-05\npolygon 312              25  2.58054e+05      1.54e-05\npolygon 313              26  4.59967e+04      2.75e-06\npolygon 314              57  8.30317e+04      4.97e-06\npolygon 315              83  1.13991e+06      6.82e-05\npolygon 316              11  3.01692e+04      1.81e-06\npolygon 317              14  1.30445e+05      7.81e-06\npolygon 318              22  2.37053e+05      1.42e-05\npolygon 319              22  1.84800e+05      1.11e-05\nenclosing rectangle: [512017.1, 928107.3] x [9621818, 9833989] units\n                     (416100 x 212200 units)\nWindow area = 16709500000 square units\nFraction of frame area: 0.189\n\n\n\n# Visual check that points and window align\nplot(fire_month_owin)   # base plot; circles show mark values (here: months 1..12)\n\n\n\n\n\n\n\n\n\n\n\nSubsequently, we will estimate spatio-temporal kernel density over space (meters) and discrete time (months).\n\n# Compute STKDE using sparr::spattemp.density \nst_kde &lt;- sparr::spattemp.density(fire_month_owin)  # uses default bandwidths; time is Month_num (1..12)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(st_kde)                                     # see chosen bandwidths h (space) and lambda (time), bounds, range\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 19155.99 (spatial)\n  lambda = 0.0264 (temporal)\n\nNo. of observations\n  899 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512017.1, 928107.3] x [9621818, 9833989]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [1.201154e-39, 6.369146e-10]\n\n\n\n\n\nThereafter, we will reproduce month-specific density maps for July–December example.\n\n# Plot a subset of months (e.g., 7..12) with a fixed legend range for comparability \ntims &lt;- c(7,8,9,10,11,12)      # months to display (Jul..Dec), matches the sample figure\npar(mfcol = c(2,3))            # 2 rows x 3 columns panel\nfor(i in tims){                # loop through the selected months\n  plot(st_kde, i,              # draw the STKDE slice at month 'i'\n       override.par = FALSE,   # keep mfcol settings\n       fix.range = TRUE,       # use common color scale across panels for fair comparison\n       main = paste(\"KDE at month\", i))  # panel title\n}\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will repeat the workflow but using Day of Year (1..365) as the temporal mark.\n\n\n\n# Create a ppp whose mark is DayofYear (1..365) ----------------------------------------------\nfire_yday_ppp &lt;- fire_sf %&gt;% \n  dplyr::select(DayofYear) %&gt;%     # keep only the DOY mark and geometry\n  as.ppp()                         # convert to ppp object\n\n\n\n\n\n# Attach the owin (study window) to the DayofYear ppp \nfire_yday_owin &lt;- fire_yday_ppp[kbb_owin] # ensure points are constrained to study polygon\nsummary(fire_yday_owin)    # confirm counts, mark summary, window stats\n\nMarked planar point pattern:  899 points\nAverage intensity 5.380183e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   10.0   219.0   260.0   247.7   288.0   360.0 \n\nWindow: polygonal boundary\n319 separate polygons (40 holes)\n                   vertices         area relative.area\npolygon 1              9026  1.15464e+10      6.91e-01\npolygon 2                19  1.26217e+04      7.55e-07\npolygon 3 (hole)          3 -1.80096e-01     -1.08e-11\npolygon 4 (hole)          3 -9.26944e-01     -5.55e-11\npolygon 5 (hole)          3 -1.07382e+03     -6.43e-08\npolygon 6 (hole)          3 -6.41537e+02     -3.84e-08\npolygon 7                23  9.26156e+04      5.54e-06\npolygon 8                30  3.37146e+04      2.02e-06\npolygon 9                54  3.25211e+05      1.95e-05\npolygon 10               33  1.30244e+06      7.79e-05\npolygon 11 (hole)         4 -9.57353e+02     -5.73e-08\npolygon 12 (hole)         4 -2.84738e+02     -1.70e-08\npolygon 13 (hole)         3 -1.38747e+02     -8.30e-09\npolygon 14 (hole)         4 -5.31445e+02     -3.18e-08\npolygon 15 (hole)         3 -6.42241e+02     -3.84e-08\npolygon 16 (hole)         6 -1.13809e+02     -6.81e-09\npolygon 17 (hole)         4 -2.10482e+02     -1.26e-08\npolygon 18 (hole)         4 -9.54892e+01     -5.71e-09\npolygon 19 (hole)         4 -6.47895e+01     -3.88e-09\npolygon 20 (hole)         4 -7.10903e+01     -4.25e-09\npolygon 21 (hole)         4 -2.18071e+02     -1.31e-08\npolygon 22 (hole)         4 -4.44993e+01     -2.66e-09\npolygon 23 (hole)         4 -4.90009e+01     -2.93e-09\npolygon 24 (hole)         4 -6.48299e+01     -3.88e-09\npolygon 25 (hole)         4 -2.36910e+02     -1.42e-08\npolygon 26 (hole)         4 -3.07205e+01     -1.84e-09\npolygon 27 (hole)         4 -5.24443e+01     -3.14e-09\npolygon 28 (hole)         5 -6.64298e+01     -3.98e-09\npolygon 29 (hole)         4 -6.08287e+01     -3.64e-09\npolygon 30 (hole)         4 -1.12681e+02     -6.74e-09\npolygon 31              132  1.16480e+06      6.97e-05\npolygon 32 (hole)         4 -9.56157e+01     -5.72e-09\npolygon 33               68  1.91291e+05      1.14e-05\npolygon 34 (hole)         4 -5.31171e+02     -3.18e-08\npolygon 35 (hole)         3 -1.76143e+00     -1.05e-10\npolygon 36              116  1.51984e+05      9.10e-06\npolygon 37               95  1.14322e+05      6.84e-06\npolygon 38               21  4.51914e+03      2.70e-07\npolygon 39               24  1.18511e+04      7.09e-07\npolygon 40              130  1.52296e+05      9.11e-06\npolygon 41               36  1.07878e+04      6.46e-07\npolygon 42               54  3.46932e+05      2.08e-05\npolygon 43               71  2.15798e+05      1.29e-05\npolygon 44               12  1.76977e+03      1.06e-07\npolygon 45               75  1.05557e+05      6.32e-06\npolygon 46               17  4.22421e+03      2.53e-07\npolygon 47              116  1.64725e+05      9.86e-06\npolygon 48               36  1.15582e+04      6.92e-07\npolygon 49               15  3.48567e+03      2.09e-07\npolygon 50              325  3.08585e+06      1.85e-04\npolygon 51 (hole)         4 -2.57635e+02     -1.54e-08\npolygon 52              191  2.36948e+06      1.42e-04\npolygon 53               75  8.81673e+04      5.28e-06\npolygon 54               49  6.13133e+04      3.67e-06\npolygon 55              117  7.65040e+04      4.58e-06\npolygon 56                5  1.73964e+04      1.04e-06\npolygon 57             6115  4.61702e+09      2.76e-01\npolygon 58                4  6.35998e+03      3.81e-07\npolygon 59               16  1.18306e+05      7.08e-06\npolygon 60                5  2.11525e+04      1.27e-06\npolygon 61               11  3.52792e+04      2.11e-06\npolygon 62               13  6.20254e+04      3.71e-06\npolygon 63                8  1.23192e+04      7.37e-07\npolygon 64                5  1.08320e+04      6.48e-07\npolygon 65                5  9.14438e+03      5.47e-07\npolygon 66                6  9.61120e+03      5.75e-07\npolygon 67               31  1.54535e+06      9.25e-05\npolygon 68                9  2.89834e+04      1.73e-06\npolygon 69               10  2.76357e+04      1.65e-06\npolygon 70               12  8.99515e+04      5.38e-06\npolygon 71               15  5.42889e+04      3.25e-06\npolygon 72                8  1.58645e+04      9.49e-07\npolygon 73                6  1.35398e+04      8.10e-07\npolygon 74                4  4.29102e+03      2.57e-07\npolygon 75               23  1.76942e+05      1.06e-05\npolygon 76               44  4.35606e+04      2.61e-06\npolygon 77                5  6.83234e+03      4.09e-07\npolygon 78                5  6.67728e+03      4.00e-07\npolygon 79                5  2.24964e+03      1.35e-07\npolygon 80                7  2.62416e+04      1.57e-06\npolygon 81                9  1.19857e+04      7.17e-07\npolygon 82                8  2.25169e+04      1.35e-06\npolygon 83                6  1.21525e+04      7.27e-07\npolygon 84                5  8.76352e+03      5.24e-07\npolygon 85                9  2.28019e+04      1.36e-06\npolygon 86                6  9.21428e+03      5.51e-07\npolygon 87               49  1.00151e+05      5.99e-06\npolygon 88                5  4.45695e+03      2.67e-07\npolygon 89                4  2.90460e+03      1.74e-07\npolygon 90                4  3.68683e+03      2.21e-07\npolygon 91               64  9.90797e+04      5.93e-06\npolygon 92                5  3.03789e+03      1.82e-07\npolygon 93                6  1.05164e+04      6.29e-07\npolygon 94               12  9.48365e+03      5.68e-07\npolygon 95               13  6.95068e+04      4.16e-06\npolygon 96               34  2.01269e+05      1.20e-05\npolygon 97              222  1.23410e+06      7.39e-05\npolygon 98                4  2.60388e+03      1.56e-07\npolygon 99                7  8.47934e+03      5.07e-07\npolygon 100               5  8.09538e+03      4.84e-07\npolygon 101              93  2.08256e+05      1.25e-05\npolygon 102              16  7.78971e+04      4.66e-06\npolygon 103              24  1.58864e+04      9.51e-07\npolygon 104               4  8.84658e+02      5.29e-08\npolygon 105              42  4.25525e+04      2.55e-06\npolygon 106               5  4.40655e+03      2.64e-07\npolygon 107               4  2.45366e+03      1.47e-07\npolygon 108               5  4.70713e+03      2.82e-07\npolygon 109             214  2.22664e+06      1.33e-04\npolygon 110              60  5.44949e+04      3.26e-06\npolygon 111               6  4.54843e+03      2.72e-07\npolygon 112               6  1.47384e+04      8.82e-07\npolygon 113               6  1.35534e+04      8.11e-07\npolygon 114              51  9.00778e+04      5.39e-06\npolygon 115               4  1.53560e+03      9.19e-08\npolygon 116 (hole)        3 -3.48195e+02     -2.08e-08\npolygon 117              32  4.34406e+04      2.60e-06\npolygon 118             144  5.46612e+05      3.27e-05\npolygon 119              36  7.39285e+04      4.42e-06\npolygon 120              42  9.17456e+04      5.49e-06\npolygon 121             141  1.10139e+06      6.59e-05\npolygon 122              94  2.55406e+05      1.53e-05\npolygon 123              71  3.74605e+04      2.24e-06\npolygon 124              72  9.11248e+05      5.45e-05\npolygon 125 (hole)        3 -2.91215e+01     -1.74e-09\npolygon 126               5  4.23910e+03      2.54e-07\npolygon 127              47  1.10186e+05      6.59e-06\npolygon 128               6  1.00636e+04      6.02e-07\npolygon 129 (hole)        3 -3.94431e+01     -2.36e-09\npolygon 130               4  1.41401e+02      8.46e-09\npolygon 131              32  2.34725e+04      1.40e-06\npolygon 132               5  3.61887e+02      2.17e-08\npolygon 133 (hole)        3 -2.90329e+03     -1.74e-07\npolygon 134             120  3.80494e+05      2.28e-05\npolygon 135              19  3.13628e+04      1.88e-06\npolygon 136              42  1.21238e+05      7.26e-06\npolygon 137              24  3.83277e+04      2.29e-06\npolygon 138              88  4.56947e+05      2.73e-05\npolygon 139              20  1.78310e+04      1.07e-06\npolygon 140              20  2.39227e+04      1.43e-06\npolygon 141               5  6.65825e+03      3.98e-07\npolygon 142               5  5.41759e+03      3.24e-07\npolygon 143              53  4.55018e+05      2.72e-05\npolygon 144             263  1.76197e+07      1.05e-03\npolygon 145 (hole)        4 -3.70130e+03     -2.22e-07\npolygon 146               4  6.79585e+03      4.07e-07\npolygon 147              15  5.74657e+03      3.44e-07\npolygon 148              25  2.16665e+05      1.30e-05\npolygon 149               9  7.99755e+03      4.79e-07\npolygon 150               8  3.28848e+03      1.97e-07\npolygon 151              10  1.13482e+04      6.79e-07\npolygon 152              45  1.05243e+05      6.30e-06\npolygon 153               7  4.67607e+03      2.80e-07\npolygon 154             533  4.88598e+07      2.92e-03\npolygon 155             641  1.19875e+08      7.17e-03\npolygon 156              68  3.72768e+06      2.23e-04\npolygon 157              10  1.01914e+05      6.10e-06\npolygon 158              19  8.26881e+04      4.95e-06\npolygon 159              17  4.00986e+04      2.40e-06\npolygon 160              11  4.05798e+04      2.43e-06\npolygon 161             111  1.46838e+06      8.79e-05\npolygon 162             112  3.73964e+06      2.24e-04\npolygon 163              19  1.91730e+04      1.15e-06\npolygon 164              73  3.61914e+06      2.17e-04\npolygon 165              10  3.05707e+04      1.83e-06\npolygon 166               6  1.62989e+04      9.75e-07\npolygon 167              81  2.65465e+05      1.59e-05\npolygon 168               8  2.09366e+04      1.25e-06\npolygon 169               9  2.23138e+04      1.34e-06\npolygon 170              11  1.96456e+04      1.18e-06\npolygon 171 (hole)        3 -4.90052e+02     -2.93e-08\npolygon 172             145  7.13727e+06      4.27e-04\npolygon 173              60  1.45353e+05      8.70e-06\npolygon 174 (hole)        4 -3.71089e+02     -2.22e-08\npolygon 175              74  2.06447e+06      1.24e-04\npolygon 176              36  2.65019e+04      1.59e-06\npolygon 177             931  2.12400e+08      1.27e-02\npolygon 178 (hole)        4 -1.54888e+02     -9.27e-09\npolygon 179              25  2.21142e+05      1.32e-05\npolygon 180               6  6.87439e+03      4.11e-07\npolygon 181              31  1.67778e+06      1.00e-04\npolygon 182               7  9.00046e+03      5.39e-07\npolygon 183              12  6.30886e+04      3.78e-06\npolygon 184             202  2.25185e+07      1.35e-03\npolygon 185              46  2.39825e+06      1.44e-04\npolygon 186              25  1.05566e+04      6.32e-07\npolygon 187               8  4.61437e+04      2.76e-06\npolygon 188               7  3.16305e+04      1.89e-06\npolygon 189               5  6.49689e+03      3.89e-07\npolygon 190              12  2.17421e+04      1.30e-06\npolygon 191               5  7.19819e+03      4.31e-07\npolygon 192              11  6.58157e+05      3.94e-05\npolygon 193             159  1.11857e+06      6.69e-05\npolygon 194             104  3.97323e+05      2.38e-05\npolygon 195              14  3.77571e+05      2.26e-05\npolygon 196              27  1.21314e+06      7.26e-05\npolygon 197              69  7.97787e+04      4.77e-06\npolygon 198              51  6.46735e+04      3.87e-06\npolygon 199              71  7.20054e+04      4.31e-06\npolygon 200              46  3.29862e+04      1.97e-06\npolygon 201              52  3.88477e+04      2.32e-06\npolygon 202              59  5.31603e+06      3.18e-04\npolygon 203 (hole)        3 -3.70978e+01     -2.22e-09\npolygon 204              48  1.76671e+06      1.06e-04\npolygon 205              34  5.03002e+04      3.01e-06\npolygon 206              46  1.83138e+04      1.10e-06\npolygon 207              18  5.28224e+03      3.16e-07\npolygon 208             244  3.09431e+06      1.85e-04\npolygon 209              28  1.99131e+05      1.19e-05\npolygon 210              21  4.52072e+05      2.71e-05\npolygon 211              14  5.66637e+04      3.39e-06\npolygon 212              12  1.09825e+05      6.57e-06\npolygon 213              15  1.37135e+06      8.21e-05\npolygon 214               6  1.22312e+05      7.32e-06\npolygon 215              43  2.41150e+05      1.44e-05\npolygon 216               7  2.79840e+04      1.67e-06\npolygon 217              46  1.72671e+06      1.03e-04\npolygon 218              13  6.36540e+04      3.81e-06\npolygon 219              11  7.02064e+05      4.20e-05\npolygon 220              47  9.13826e+05      5.47e-05\npolygon 221 (hole)        4 -3.82299e+03     -2.29e-07\npolygon 222              62  3.95149e+06      2.36e-04\npolygon 223               9  4.34659e+05      2.60e-05\npolygon 224              14  4.20832e+04      2.52e-06\npolygon 225              18  5.12063e+03      3.06e-07\npolygon 226              31  7.44741e+05      4.46e-05\npolygon 227              18  4.11233e+05      2.46e-05\npolygon 228 (hole)        3 -5.32643e+02     -3.19e-08\npolygon 229              23  7.71654e+03      4.62e-07\npolygon 230               8  3.86022e+04      2.31e-06\npolygon 231             168  7.46341e+06      4.47e-04\npolygon 232               4  9.19978e+03      5.51e-07\npolygon 233              14  2.75390e+05      1.65e-05\npolygon 234               9  9.63798e+03      5.77e-07\npolygon 235               9  6.16361e+04      3.69e-06\npolygon 236              10  1.04975e+05      6.28e-06\npolygon 237               8  8.75225e+04      5.24e-06\npolygon 238               5  1.84001e+04      1.10e-06\npolygon 239               5  3.30315e+03      1.98e-07\npolygon 240              13  3.15610e+04      1.89e-06\npolygon 241              67  3.93597e+05      2.36e-05\npolygon 242               4  2.83740e+03      1.70e-07\npolygon 243              15  4.86091e+03      2.91e-07\npolygon 244               4  1.26784e+03      7.59e-08\npolygon 245               8  1.67287e+04      1.00e-06\npolygon 246              12  2.45858e+04      1.47e-06\npolygon 247              12  5.95789e+04      3.57e-06\npolygon 248              12  2.14651e+03      1.28e-07\npolygon 249              14  4.30849e+03      2.58e-07\npolygon 250              16  7.75733e+03      4.64e-07\npolygon 251 (hole)        4 -2.56408e+03     -1.53e-07\npolygon 252              10  1.75648e+03      1.05e-07\npolygon 253              34  3.85386e+06      2.31e-04\npolygon 254               9  3.55249e+03      2.13e-07\npolygon 255              15  1.39816e+04      8.37e-07\npolygon 256              16  4.56059e+05      2.73e-05\npolygon 257              26  1.42631e+04      8.54e-07\npolygon 258              36  2.65697e+04      1.59e-06\npolygon 259              19  4.48214e+03      2.68e-07\npolygon 260              96  5.26087e+05      3.15e-05\npolygon 261              60  1.00635e+05      6.02e-06\npolygon 262              31  7.13046e+04      4.27e-06\npolygon 263              84  1.37245e+06      8.21e-05\npolygon 264             178  8.26947e+05      4.95e-05\npolygon 265              58  1.98953e+05      1.19e-05\npolygon 266             115  3.13297e+05      1.87e-05\npolygon 267             132  4.76047e+05      2.85e-05\npolygon 268             102  1.63410e+07      9.78e-04\npolygon 269              18  6.36647e+03      3.81e-07\npolygon 270              10  7.72550e+03      4.62e-07\npolygon 271             204  1.42141e+06      8.51e-05\npolygon 272             125  2.33639e+06      1.40e-04\npolygon 273              30  2.58819e+04      1.55e-06\npolygon 274              24  2.06403e+04      1.24e-06\npolygon 275              87  1.25178e+06      7.49e-05\npolygon 276              38  4.04777e+04      2.42e-06\npolygon 277              10  5.04036e+04      3.02e-06\npolygon 278               6  1.12482e+04      6.73e-07\npolygon 279              40  1.56825e+05      9.39e-06\npolygon 280              63  5.25132e+04      3.14e-06\npolygon 281               8  1.11128e+04      6.65e-07\npolygon 282               9  1.49650e+03      8.96e-08\npolygon 283              13  4.50724e+03      2.70e-07\npolygon 284              41  4.12892e+04      2.47e-06\npolygon 285               7  3.03545e+03      1.82e-07\npolygon 286              19  7.54584e+03      4.52e-07\npolygon 287              16  8.29528e+03      4.96e-07\npolygon 288              26  5.16293e+05      3.09e-05\npolygon 289              13  9.23979e+04      5.53e-06\npolygon 290              25  4.18391e+04      2.50e-06\npolygon 291               7  3.85120e+03      2.30e-07\npolygon 292              82  4.38489e+05      2.62e-05\npolygon 293             163  3.46322e+06      2.07e-04\npolygon 294              11  5.22182e+03      3.13e-07\npolygon 295              13  3.28208e+04      1.96e-06\npolygon 296               6  3.00920e+04      1.80e-06\npolygon 297               6  1.13309e+04      6.78e-07\npolygon 298              13  2.03134e+05      1.22e-05\npolygon 299              36  2.87112e+04      1.72e-06\npolygon 300               6  1.13102e+04      6.77e-07\npolygon 301              13  4.04370e+03      2.42e-07\npolygon 302              44  1.67056e+05      1.00e-05\npolygon 303              11  6.66250e+04      3.99e-06\npolygon 304             129  2.29313e+06      1.37e-04\npolygon 305               6  7.23372e+04      4.33e-06\npolygon 306              19  6.36948e+03      3.81e-07\npolygon 307             106  1.06881e+06      6.40e-05\npolygon 308               9  2.30443e+04      1.38e-06\npolygon 309              29  9.02725e+03      5.40e-07\npolygon 310              68  1.08514e+05      6.49e-06\npolygon 311              64  2.19772e+05      1.32e-05\npolygon 312              25  2.58054e+05      1.54e-05\npolygon 313              26  4.59967e+04      2.75e-06\npolygon 314              57  8.30317e+04      4.97e-06\npolygon 315              83  1.13991e+06      6.82e-05\npolygon 316              11  3.01692e+04      1.81e-06\npolygon 317              14  1.30445e+05      7.81e-06\npolygon 318              22  2.37053e+05      1.42e-05\npolygon 319              22  1.84800e+05      1.11e-05\nenclosing rectangle: [512017.1, 928107.3] x [9621818, 9833989] units\n                     (416100 x 212200 units)\nWindow area = 16709500000 square units\nFraction of frame area: 0.189\n\n\n\n\n\nWe aim to compute STKDE with default bandwidths and plot.\n\n# Compute STKDE using default bandwidth selection (gives baseline) \nkde_yday &lt;- spattemp.density(\n  fire_yday_owin        # ppp with DayofYear marks and study window\n)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(kde_yday)       # examine space/time bandwidths (h, lambda) and density range\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 19155.99 (spatial)\n  lambda = 6.4456 (temporal)\n\nNo. of observations\n  899 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512017.1, 928107.3] x [9621818, 9833989]\n\nTemporal bound\n  [10, 360]\n\nEvaluation\n  128 x 128 x 351 trivariate lattice\n  Density range: [1.594274e-28, 1.857482e-12]\n\n\n\n# Visualise the density surface aggregated over time (default plot) \nplot(kde_yday)     # continuous surface over the region with legend\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhy this step? Default bandwidths are generic. In this section, want to improve them by bootstrap MISE using BOOT.spattemp(), which estimates a scalar spatial bandwidth (h, meters) and a scalar temporal bandwidth (lambda, in DOY units) suited to our data.\n\n# For reproducibility of the bootstrap selection \nset.seed(1234)    # fixed seed so results are repeatable in class\n\n# Run bootstrap bandwidth selection (may take some time) \nBOOT.spattemp(fire_yday_owin)   # prints many trial (h, lambda) and the final pair at bottom\n\nInitialising...Done.\nOptimising...\nh = 19155.99 \b; lambda = 15.11399 \nh = 21071.59 \b; lambda = 15.11399 \nh = 19155.99 \b; lambda = 1930.713 \nh = 19634.89 \b; lambda = 972.9137 \nh = 19874.34 \b; lambda = 494.0138 \nh = 19994.07 \b; lambda = 254.5639 \nh = 20053.93 \b; lambda = 134.8389 \nh = 20083.86 \b; lambda = 74.97647 \nh = 20098.83 \b; lambda = 45.04523 \nh = 20106.31 \b; lambda = 30.07961 \nh = 20121.28 \b; lambda = 0.1483655 \nh = 20110.05 \b; lambda = 22.5968 \nh = 22025.65 \b; lambda = 22.5968 \nh = 23460.48 \b; lambda = 26.3382 \nh = 22498.94 \b; lambda = 33.82101 \nh = 21428.43 \b; lambda = 19.79074 \nh = 24778.86 \b; lambda = 23.53215 \nh = 27113.26 \b; lambda = 23.99982 \nh = 29145.31 \b; lambda = 30.54728 \nh = 27216.09 \b; lambda = 27.85815 \nh = 30868.87 \b; lambda = 25.51977 \nh = 34573.07 \b; lambda = 25.11055 \nh = 34470.24 \b; lambda = 21.25223 \nh = 38097.31 \b; lambda = 17.94927 \nh = 45557.12 \b; lambda = 19.06 \nh = 54779.04 \b; lambda = 16.59009 \nh = 49081.36 \b; lambda = 11.89872 \nh = 45454.29 \b; lambda = 15.20168 \nh = 38200.14 \b; lambda = 21.80759 \nh = 43640.75 \b; lambda = 16.85315 \nh = 51100.56 \b; lambda = 17.96388 \nh = 47849.75 \b; lambda = 17.96023 \nh = 49766.11 \b; lambda = 20.16708 \nh = 45172.09 \b; lambda = 17.68163 \nh = 42879.46 \b; lambda = 18.7814 \nh = 44122.03 \b; lambda = 18.57611 \nh = 44507.06 \b; lambda = 19.95447 \nh = 44673.32 \b; lambda = 19.38626 \nDone.\n\n\n          h      lambda \n44673.31732    19.38626 \n\n# Note the final recommended h and lambda reported by the function output.\n\n\n\nWe will re-run STKDE using the recommended bandwidths.\n\n# Refit STKDE using the bootstrap MISE recommended bandwidths \nkde_yday &lt;- spattemp.density(\n  fire_yday_owin,     # the DayofYear ppp constrained by the study window\n  h      = 45000,     # spatial bandwidth in meters (per improved selection)\n  lambda = 19         # temporal bandwidth in days-of-year (per improved selection)\n)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(kde_yday)     # verify the bandwidths and evaluation grid\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 45000 (spatial)\n  lambda = 19 (temporal)\n\nNo. of observations\n  899 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512017.1, 928107.3] x [9621818, 9833989]\n\nTemporal bound\n  [10, 360]\n\nEvaluation\n  128 x 128 x 351 trivariate lattice\n  Density range: [3.902314e-16, 9.815536e-13]\n\n\n\n\n\nFinally, we display the final improved surface.\n\n# Plot the improved STKDE surface\nplot(kde_yday)   # shows the density surface with color bar; higher values = higher intensity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe spatio-temporal kernel density estimation (STKDE) provides clear evidence that the locations of forest fires in Kepulauan Bangka Belitung are not spatially or spatio-temporally independent. If the events were independent, the density surfaces would be flat and homogeneous across space and time. Instead, the STKDE outputs reveal distinct peaks, rejecting the null hypothesis of independence.\nThe bootstrap-based bandwidth selection process identified an optimal smoothing window of h ≈ 44.7 km (spatial) and λ ≈ 19.4 days (temporal). These parameters indicate that fire events tend to cluster within a radius of ~45 km and persist across approximately three-week periods. The density range produced, from very low background values (~1.2e-39) to sharp peaks (~6.4e-10), confirms substantial clustering intensity.\nThe spatial clustering is most pronounced in southern and central Bangka and in eastern Belitung, where the STKDE consistently highlights hotspots of higher fire intensity. These locations repeatedly emerge in the density surfaces, showing that fire events are concentrated in specific sub-regions rather than being uniformly distributed.\nTemporally, clustering is most evident during the July–October period, corresponding to the dry season. The monthly KDE plots demonstrate that fire intensity builds steadily in July, peaks in September, and declines toward the year’s end. This seasonality shows that fire occurrence is not equally likely throughout the year but is instead conditioned by climatic and land-surface factors linked to the dry months.\nThe implications of these findings are important for both science and policy. Spatial dependence means that fire risk is localized, and mitigation resources should be concentrated in the fire-prone regions identified by the STKDE. Temporal dependence means that efforts should be time-targeted, with enhanced monitoring and preventive measures deployed during the critical dry-season window. This combination of spatial and temporal clustering suggests that forest fires in Bangka Belitung are shaped by systematic environmental drivers, not by random chance.\nIn summary, the STKDE results demonstrate that forest fire events are spatially and spatio-temporally dependent. They cluster within ~45 km regions and persist across ~3-week intervals, with the highest concentrations observed in southern/central Bangka and eastern Belitung during the July–October dry season."
  },
  {
    "objectID": "Hands-on_Ex03/Hand-on_Ex03.html#overview",
    "href": "Hands-on_Ex03/Hand-on_Ex03.html#overview",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "A spatio-temporal point process is a random collection of events identified by both time and location, such as disease cases, species sightings, or natural disasters. With the rise of geographically and temporally indexed data, analyzing these patterns has become increasingly important across many fields. In the past decade, several R methods and packages have been developed to support such analyses. This hands-on exercise demonstrates how these tools can be combined in a guided way, using forest fire events in Kepulauan Bangka Belitung, Indonesia (from 1 January to 31 December 2023) as a real-world case study to illustrate the procedures and interpretations."
  },
  {
    "objectID": "Hands-on_Ex03/Hand-on_Ex03.html#learning-outcome",
    "href": "Hands-on_Ex03/Hand-on_Ex03.html#learning-outcome",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "The specific questions we would like to answer are:\n\nAre the locations of forest fire in Kepulauan Bangka Belitung spatial and spatio-temporally independent?\nIf the answer is NO, where and when the observed forest fire locations tend to cluster?\n\nA detailed discussion of the results, together with explicit insights and implications, is provided in Section 6.11 Discussion of Results (Answer to the Research Question)."
  },
  {
    "objectID": "Hands-on_Ex03/Hand-on_Ex03.html#the-data",
    "href": "Hands-on_Ex03/Hand-on_Ex03.html#the-data",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "Know what files you’ll use and where they come from.\n\nforestfires.csv: point events (each row = a fire). Has longitude, latitude, and date/time fields from MODIS.\nKepulauan_Bangka_Belitung shapefile: the study region polygon (administrative boundary). We’ll read only the Kepulauan Bangka Belitung subset for 2023 analyses."
  },
  {
    "objectID": "Hands-on_Ex03/Hand-on_Ex03.html#installing-and-loading-the-r-packages",
    "href": "Hands-on_Ex03/Hand-on_Ex03.html#installing-and-loading-the-r-packages",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "Load all libraries used in this hands-on exercise.\n\npacman::p_load(sf,        # read, write, and transform spatial vector data\n               terra,      \n               spatstat,  # used for performing Spatial Point Patterns Analysis such as kcross, Lcross, etc\n               sparr,     # spatio-temporal kernel density estimation (STKDE)\n               tmap,      # cartographic visualisation for quick maps\n               tidyverse  # readr (CSV), dplyr (mutate/select), ggplot, etc.\n               )"
  },
  {
    "objectID": "Hands-on_Ex03/Hand-on_Ex03.html#importing-and-preparing-study-area",
    "href": "Hands-on_Ex03/Hand-on_Ex03.html#importing-and-preparing-study-area",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "First. read the Kepulauan Bangka Belitung boundary, clean geometry, and set projected CRS.\n\n# Read the shapefile from the data folder -----------------------------------------------------\nkbb_sf &lt;- st_read(dsn = \"data/rds/BATAS_DESA_DESEMBER_2019_DUKCAPIL_BANGKA_BELITUNG\",    # folder containing the shapefile\n                  layer = \"BATAS_DESA_DESEMBER_2019_DUKCAPIL_BANGKA_BELITUNG\") %&gt;%       # shapefile base name (no .shp)\n  st_union() %&gt;%                       # dissolve internal boundaries into one polygon\n  st_zm(drop = TRUE, what = \"ZM\") %&gt;%  # drop Z/M dimensions if present (keeps 2D)\n  st_transform(crs = 32748)            # reproject to EPSG:32748 (UTM Zone 48S in meters)\n\nReading layer `BATAS_DESA_DESEMBER_2019_DUKCAPIL_BANGKA_BELITUNG' from data source `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex03/Data/rds/BATAS_DESA_DESEMBER_2019_DUKCAPIL_BANGKA_BELITUNG' \n  using driver `ESRI Shapefile'\nSimple feature collection with 391 features and 161 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 105.1081 ymin: -3.416903 xmax: 108.848 ymax: -1.501757\nGeodetic CRS:  WGS 84\n\n\n\n\n\nNext, convert the polygon (kb) to an observation window (owin) for point-pattern analysis.\n\n# Convert the sf polygon to an 'owin' (spatstat window) \nkbb_owin &lt;- as.owin(kbb_sf)      # turns the sf polygon into a spatstat window for ppp usage\nkbb_owin                         \n\nwindow: polygonal boundary\nenclosing rectangle: [512017.1, 928107.3] x [9621818, 9833989] units\n\n\n\n# Quick check that conversion succeeded\nclass(kbb_owin) \n\n[1] \"owin\""
  },
  {
    "objectID": "Hands-on_Ex03/Hand-on_Ex03.html#importing-and-preparing-forest-fire-data",
    "href": "Hands-on_Ex03/Hand-on_Ex03.html#importing-and-preparing-forest-fire-data",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "Next read the CSV, make it spatial, reproject to meters, and build helpful time fields.\n\nfire_sf &lt;- read_csv(\"data/rds/modis_2023_Indonesia.csv\")    %&gt;%  # load the event table\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %&gt;%  # turn lon/lat cols into points (WGS84)\n  st_transform(crs = 32748)   # project to meters to match the study area\n\nRows: 52156 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (4): acq_time, satellite, instrument, daynight\ndbl  (10): latitude, longitude, brightness, scan, track, confidence, version...\ndate  (1): acq_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n# Add day-of-year and month fields used later\nfire_sf &lt;- fire_sf %&gt;% \n  mutate(DayofYear = yday(acq_date)) %&gt;%     # numeric day 1..365 from acquisition date\n  mutate(Month_num = month(acq_date)) %&gt;%    # numeric month 1..12\n  mutate(Month_fac = month(acq_date, label = TRUE, abbr = FALSE))  # factor month with full names (Jan..Dec)"
  },
  {
    "objectID": "Hands-on_Ex03/Hand-on_Ex03.html#visualising-the-fire-points",
    "href": "Hands-on_Ex03/Hand-on_Ex03.html#visualising-the-fire-points",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "Plot one map with all 2023 fires over the study region\n\n# Bigger figure when rendering (Quarto/knitr)\n\n# Clip fire points so only those inside kbb_sf remain \nfire_sf &lt;- sf::st_intersection(fire_sf, kbb_sf)\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n# Build a quick overall point map with tmap \ntmap_mode(\"plot\")                                         # use static plotting mode\n\nℹ tmap mode set to \"plot\".\n\ntm_shape(kbb_sf) +                                        # add study area polygon layer\n  tm_polygons(col = \"grey85\", border.col = \"grey40\") +    # light fill, subtle border\n  tm_shape(fire_sf) +                                     # add fire points\n  tm_symbols(size = 0.5, col = \"red\") +                   # small red dots\n  tm_credits(\n    \"Forest Fire Points in 2023 (Kepulauan Bangka Belitung)\",\n    position = c(\"center\", \"top\"),    # center horizontally, top vertically\n    size = 1.2,                       # enlarge title text\n    fontface = 2                      # bold\n  ) +\n  tm_layout(\n    frame = TRUE,\n    # outer.margins = c(0.1, 0.05, 0.1, 0.05) # top, right, bottom, left (gives space for title)\n    inner.margins = 0.05                      # uncomment to maximize map area even more\n  )\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_polygons()`: use 'fill' for the fill color of polygons/symbols\n(instead of 'col'), and 'col' for the outlines (instead of 'border.col').\n\n\n\n\n\n\n\n\n\n\n\n\nNext, 12 small multiples (one map per month) like the practical guide.\n\n# Faceted monthly point maps \ntm_shape(kbb_sf) +\n  tm_polygons(col = \"grey85\", border.col = \"grey50\") +\n  tm_shape(fire_sf) +\n  tm_symbols(size = 0.1, col = \"red\") +\n  tm_facets(by = \"Month_fac\", ncol = 4) +                          # 4 columns x 3 rows facet layout\n  tm_layout(\n            frame = TRUE)\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────"
  },
  {
    "objectID": "Hands-on_Ex03/Hand-on_Ex03.html#computing-stkde-by-month",
    "href": "Hands-on_Ex03/Hand-on_Ex03.html#computing-stkde-by-month",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "In this section, we will learn how to compute STKDE by using spattemp.density() of sparr package.\n\n\nWe need to keep only the mark (month) needed by ppp() and the geometry.\n\n# Keep only the monthly mark and geometry for ppp creation \nfire_month &lt;- fire_sf %&gt;% \n  dplyr::select(Month_num)     # ppp requires a numeric/character mark column and geometry\n\n\n\n\nNext, we need to convert to a spatstat ppp (planar point pattern) object.\n\n# Convert sf points to ppp (planar point pattern) \nfire_month_ppp &lt;- as.ppp(fire_month)   # create ppp with coordinates and 'Month_num' as the mark\nfire_month_ppp   # print basic info to confirm number of points/window box\n\nMarked planar point pattern: 899 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [521564.1, 862416.4] x [9642001, 9828767] units\n\n\n\n# Sanity checks on the ppp \nsummary(fire_month_ppp)   # detailed summary (intensity, mark stats, window box)\n\nMarked planar point pattern:  899 points\nAverage intensity 1.412198e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.644  10.000  12.000 \n\nWindow: rectangle = [521564.1, 862416.4] x [9642001, 9828767] units\n                    (340900 x 186800 units)\nWindow area = 63659700000 square units\n\nany(duplicated(fire_month_ppp)) # TRUE if any exact duplicate point events; expect FALSE per notes\n\n[1] FALSE\n\n\n\n# Check if there are duplicated point events by using the code chunk below.\nany(duplicated(fire_month_ppp))\n\n[1] FALSE\n\n\n\n\n\nNext, we need to clip/assign the point pattern to the study window.\n\n# Attach/clip the ppp to our study-area window \nfire_month_owin &lt;- fire_month_ppp[kbb_owin]  # ensure points are analysed within the polygon boundary\nsummary(fire_month_owin)   # verify marks, counts, window area\n\nMarked planar point pattern:  899 points\nAverage intensity 5.380183e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.644  10.000  12.000 \n\nWindow: polygonal boundary\n319 separate polygons (40 holes)\n                   vertices         area relative.area\npolygon 1              9026  1.15464e+10      6.91e-01\npolygon 2                19  1.26217e+04      7.55e-07\npolygon 3 (hole)          3 -1.80096e-01     -1.08e-11\npolygon 4 (hole)          3 -9.26944e-01     -5.55e-11\npolygon 5 (hole)          3 -1.07382e+03     -6.43e-08\npolygon 6 (hole)          3 -6.41537e+02     -3.84e-08\npolygon 7                23  9.26156e+04      5.54e-06\npolygon 8                30  3.37146e+04      2.02e-06\npolygon 9                54  3.25211e+05      1.95e-05\npolygon 10               33  1.30244e+06      7.79e-05\npolygon 11 (hole)         4 -9.57353e+02     -5.73e-08\npolygon 12 (hole)         4 -2.84738e+02     -1.70e-08\npolygon 13 (hole)         3 -1.38747e+02     -8.30e-09\npolygon 14 (hole)         4 -5.31445e+02     -3.18e-08\npolygon 15 (hole)         3 -6.42241e+02     -3.84e-08\npolygon 16 (hole)         6 -1.13809e+02     -6.81e-09\npolygon 17 (hole)         4 -2.10482e+02     -1.26e-08\npolygon 18 (hole)         4 -9.54892e+01     -5.71e-09\npolygon 19 (hole)         4 -6.47895e+01     -3.88e-09\npolygon 20 (hole)         4 -7.10903e+01     -4.25e-09\npolygon 21 (hole)         4 -2.18071e+02     -1.31e-08\npolygon 22 (hole)         4 -4.44993e+01     -2.66e-09\npolygon 23 (hole)         4 -4.90009e+01     -2.93e-09\npolygon 24 (hole)         4 -6.48299e+01     -3.88e-09\npolygon 25 (hole)         4 -2.36910e+02     -1.42e-08\npolygon 26 (hole)         4 -3.07205e+01     -1.84e-09\npolygon 27 (hole)         4 -5.24443e+01     -3.14e-09\npolygon 28 (hole)         5 -6.64298e+01     -3.98e-09\npolygon 29 (hole)         4 -6.08287e+01     -3.64e-09\npolygon 30 (hole)         4 -1.12681e+02     -6.74e-09\npolygon 31              132  1.16480e+06      6.97e-05\npolygon 32 (hole)         4 -9.56157e+01     -5.72e-09\npolygon 33               68  1.91291e+05      1.14e-05\npolygon 34 (hole)         4 -5.31171e+02     -3.18e-08\npolygon 35 (hole)         3 -1.76143e+00     -1.05e-10\npolygon 36              116  1.51984e+05      9.10e-06\npolygon 37               95  1.14322e+05      6.84e-06\npolygon 38               21  4.51914e+03      2.70e-07\npolygon 39               24  1.18511e+04      7.09e-07\npolygon 40              130  1.52296e+05      9.11e-06\npolygon 41               36  1.07878e+04      6.46e-07\npolygon 42               54  3.46932e+05      2.08e-05\npolygon 43               71  2.15798e+05      1.29e-05\npolygon 44               12  1.76977e+03      1.06e-07\npolygon 45               75  1.05557e+05      6.32e-06\npolygon 46               17  4.22421e+03      2.53e-07\npolygon 47              116  1.64725e+05      9.86e-06\npolygon 48               36  1.15582e+04      6.92e-07\npolygon 49               15  3.48567e+03      2.09e-07\npolygon 50              325  3.08585e+06      1.85e-04\npolygon 51 (hole)         4 -2.57635e+02     -1.54e-08\npolygon 52              191  2.36948e+06      1.42e-04\npolygon 53               75  8.81673e+04      5.28e-06\npolygon 54               49  6.13133e+04      3.67e-06\npolygon 55              117  7.65040e+04      4.58e-06\npolygon 56                5  1.73964e+04      1.04e-06\npolygon 57             6115  4.61702e+09      2.76e-01\npolygon 58                4  6.35998e+03      3.81e-07\npolygon 59               16  1.18306e+05      7.08e-06\npolygon 60                5  2.11525e+04      1.27e-06\npolygon 61               11  3.52792e+04      2.11e-06\npolygon 62               13  6.20254e+04      3.71e-06\npolygon 63                8  1.23192e+04      7.37e-07\npolygon 64                5  1.08320e+04      6.48e-07\npolygon 65                5  9.14438e+03      5.47e-07\npolygon 66                6  9.61120e+03      5.75e-07\npolygon 67               31  1.54535e+06      9.25e-05\npolygon 68                9  2.89834e+04      1.73e-06\npolygon 69               10  2.76357e+04      1.65e-06\npolygon 70               12  8.99515e+04      5.38e-06\npolygon 71               15  5.42889e+04      3.25e-06\npolygon 72                8  1.58645e+04      9.49e-07\npolygon 73                6  1.35398e+04      8.10e-07\npolygon 74                4  4.29102e+03      2.57e-07\npolygon 75               23  1.76942e+05      1.06e-05\npolygon 76               44  4.35606e+04      2.61e-06\npolygon 77                5  6.83234e+03      4.09e-07\npolygon 78                5  6.67728e+03      4.00e-07\npolygon 79                5  2.24964e+03      1.35e-07\npolygon 80                7  2.62416e+04      1.57e-06\npolygon 81                9  1.19857e+04      7.17e-07\npolygon 82                8  2.25169e+04      1.35e-06\npolygon 83                6  1.21525e+04      7.27e-07\npolygon 84                5  8.76352e+03      5.24e-07\npolygon 85                9  2.28019e+04      1.36e-06\npolygon 86                6  9.21428e+03      5.51e-07\npolygon 87               49  1.00151e+05      5.99e-06\npolygon 88                5  4.45695e+03      2.67e-07\npolygon 89                4  2.90460e+03      1.74e-07\npolygon 90                4  3.68683e+03      2.21e-07\npolygon 91               64  9.90797e+04      5.93e-06\npolygon 92                5  3.03789e+03      1.82e-07\npolygon 93                6  1.05164e+04      6.29e-07\npolygon 94               12  9.48365e+03      5.68e-07\npolygon 95               13  6.95068e+04      4.16e-06\npolygon 96               34  2.01269e+05      1.20e-05\npolygon 97              222  1.23410e+06      7.39e-05\npolygon 98                4  2.60388e+03      1.56e-07\npolygon 99                7  8.47934e+03      5.07e-07\npolygon 100               5  8.09538e+03      4.84e-07\npolygon 101              93  2.08256e+05      1.25e-05\npolygon 102              16  7.78971e+04      4.66e-06\npolygon 103              24  1.58864e+04      9.51e-07\npolygon 104               4  8.84658e+02      5.29e-08\npolygon 105              42  4.25525e+04      2.55e-06\npolygon 106               5  4.40655e+03      2.64e-07\npolygon 107               4  2.45366e+03      1.47e-07\npolygon 108               5  4.70713e+03      2.82e-07\npolygon 109             214  2.22664e+06      1.33e-04\npolygon 110              60  5.44949e+04      3.26e-06\npolygon 111               6  4.54843e+03      2.72e-07\npolygon 112               6  1.47384e+04      8.82e-07\npolygon 113               6  1.35534e+04      8.11e-07\npolygon 114              51  9.00778e+04      5.39e-06\npolygon 115               4  1.53560e+03      9.19e-08\npolygon 116 (hole)        3 -3.48195e+02     -2.08e-08\npolygon 117              32  4.34406e+04      2.60e-06\npolygon 118             144  5.46612e+05      3.27e-05\npolygon 119              36  7.39285e+04      4.42e-06\npolygon 120              42  9.17456e+04      5.49e-06\npolygon 121             141  1.10139e+06      6.59e-05\npolygon 122              94  2.55406e+05      1.53e-05\npolygon 123              71  3.74605e+04      2.24e-06\npolygon 124              72  9.11248e+05      5.45e-05\npolygon 125 (hole)        3 -2.91215e+01     -1.74e-09\npolygon 126               5  4.23910e+03      2.54e-07\npolygon 127              47  1.10186e+05      6.59e-06\npolygon 128               6  1.00636e+04      6.02e-07\npolygon 129 (hole)        3 -3.94431e+01     -2.36e-09\npolygon 130               4  1.41401e+02      8.46e-09\npolygon 131              32  2.34725e+04      1.40e-06\npolygon 132               5  3.61887e+02      2.17e-08\npolygon 133 (hole)        3 -2.90329e+03     -1.74e-07\npolygon 134             120  3.80494e+05      2.28e-05\npolygon 135              19  3.13628e+04      1.88e-06\npolygon 136              42  1.21238e+05      7.26e-06\npolygon 137              24  3.83277e+04      2.29e-06\npolygon 138              88  4.56947e+05      2.73e-05\npolygon 139              20  1.78310e+04      1.07e-06\npolygon 140              20  2.39227e+04      1.43e-06\npolygon 141               5  6.65825e+03      3.98e-07\npolygon 142               5  5.41759e+03      3.24e-07\npolygon 143              53  4.55018e+05      2.72e-05\npolygon 144             263  1.76197e+07      1.05e-03\npolygon 145 (hole)        4 -3.70130e+03     -2.22e-07\npolygon 146               4  6.79585e+03      4.07e-07\npolygon 147              15  5.74657e+03      3.44e-07\npolygon 148              25  2.16665e+05      1.30e-05\npolygon 149               9  7.99755e+03      4.79e-07\npolygon 150               8  3.28848e+03      1.97e-07\npolygon 151              10  1.13482e+04      6.79e-07\npolygon 152              45  1.05243e+05      6.30e-06\npolygon 153               7  4.67607e+03      2.80e-07\npolygon 154             533  4.88598e+07      2.92e-03\npolygon 155             641  1.19875e+08      7.17e-03\npolygon 156              68  3.72768e+06      2.23e-04\npolygon 157              10  1.01914e+05      6.10e-06\npolygon 158              19  8.26881e+04      4.95e-06\npolygon 159              17  4.00986e+04      2.40e-06\npolygon 160              11  4.05798e+04      2.43e-06\npolygon 161             111  1.46838e+06      8.79e-05\npolygon 162             112  3.73964e+06      2.24e-04\npolygon 163              19  1.91730e+04      1.15e-06\npolygon 164              73  3.61914e+06      2.17e-04\npolygon 165              10  3.05707e+04      1.83e-06\npolygon 166               6  1.62989e+04      9.75e-07\npolygon 167              81  2.65465e+05      1.59e-05\npolygon 168               8  2.09366e+04      1.25e-06\npolygon 169               9  2.23138e+04      1.34e-06\npolygon 170              11  1.96456e+04      1.18e-06\npolygon 171 (hole)        3 -4.90052e+02     -2.93e-08\npolygon 172             145  7.13727e+06      4.27e-04\npolygon 173              60  1.45353e+05      8.70e-06\npolygon 174 (hole)        4 -3.71089e+02     -2.22e-08\npolygon 175              74  2.06447e+06      1.24e-04\npolygon 176              36  2.65019e+04      1.59e-06\npolygon 177             931  2.12400e+08      1.27e-02\npolygon 178 (hole)        4 -1.54888e+02     -9.27e-09\npolygon 179              25  2.21142e+05      1.32e-05\npolygon 180               6  6.87439e+03      4.11e-07\npolygon 181              31  1.67778e+06      1.00e-04\npolygon 182               7  9.00046e+03      5.39e-07\npolygon 183              12  6.30886e+04      3.78e-06\npolygon 184             202  2.25185e+07      1.35e-03\npolygon 185              46  2.39825e+06      1.44e-04\npolygon 186              25  1.05566e+04      6.32e-07\npolygon 187               8  4.61437e+04      2.76e-06\npolygon 188               7  3.16305e+04      1.89e-06\npolygon 189               5  6.49689e+03      3.89e-07\npolygon 190              12  2.17421e+04      1.30e-06\npolygon 191               5  7.19819e+03      4.31e-07\npolygon 192              11  6.58157e+05      3.94e-05\npolygon 193             159  1.11857e+06      6.69e-05\npolygon 194             104  3.97323e+05      2.38e-05\npolygon 195              14  3.77571e+05      2.26e-05\npolygon 196              27  1.21314e+06      7.26e-05\npolygon 197              69  7.97787e+04      4.77e-06\npolygon 198              51  6.46735e+04      3.87e-06\npolygon 199              71  7.20054e+04      4.31e-06\npolygon 200              46  3.29862e+04      1.97e-06\npolygon 201              52  3.88477e+04      2.32e-06\npolygon 202              59  5.31603e+06      3.18e-04\npolygon 203 (hole)        3 -3.70978e+01     -2.22e-09\npolygon 204              48  1.76671e+06      1.06e-04\npolygon 205              34  5.03002e+04      3.01e-06\npolygon 206              46  1.83138e+04      1.10e-06\npolygon 207              18  5.28224e+03      3.16e-07\npolygon 208             244  3.09431e+06      1.85e-04\npolygon 209              28  1.99131e+05      1.19e-05\npolygon 210              21  4.52072e+05      2.71e-05\npolygon 211              14  5.66637e+04      3.39e-06\npolygon 212              12  1.09825e+05      6.57e-06\npolygon 213              15  1.37135e+06      8.21e-05\npolygon 214               6  1.22312e+05      7.32e-06\npolygon 215              43  2.41150e+05      1.44e-05\npolygon 216               7  2.79840e+04      1.67e-06\npolygon 217              46  1.72671e+06      1.03e-04\npolygon 218              13  6.36540e+04      3.81e-06\npolygon 219              11  7.02064e+05      4.20e-05\npolygon 220              47  9.13826e+05      5.47e-05\npolygon 221 (hole)        4 -3.82299e+03     -2.29e-07\npolygon 222              62  3.95149e+06      2.36e-04\npolygon 223               9  4.34659e+05      2.60e-05\npolygon 224              14  4.20832e+04      2.52e-06\npolygon 225              18  5.12063e+03      3.06e-07\npolygon 226              31  7.44741e+05      4.46e-05\npolygon 227              18  4.11233e+05      2.46e-05\npolygon 228 (hole)        3 -5.32643e+02     -3.19e-08\npolygon 229              23  7.71654e+03      4.62e-07\npolygon 230               8  3.86022e+04      2.31e-06\npolygon 231             168  7.46341e+06      4.47e-04\npolygon 232               4  9.19978e+03      5.51e-07\npolygon 233              14  2.75390e+05      1.65e-05\npolygon 234               9  9.63798e+03      5.77e-07\npolygon 235               9  6.16361e+04      3.69e-06\npolygon 236              10  1.04975e+05      6.28e-06\npolygon 237               8  8.75225e+04      5.24e-06\npolygon 238               5  1.84001e+04      1.10e-06\npolygon 239               5  3.30315e+03      1.98e-07\npolygon 240              13  3.15610e+04      1.89e-06\npolygon 241              67  3.93597e+05      2.36e-05\npolygon 242               4  2.83740e+03      1.70e-07\npolygon 243              15  4.86091e+03      2.91e-07\npolygon 244               4  1.26784e+03      7.59e-08\npolygon 245               8  1.67287e+04      1.00e-06\npolygon 246              12  2.45858e+04      1.47e-06\npolygon 247              12  5.95789e+04      3.57e-06\npolygon 248              12  2.14651e+03      1.28e-07\npolygon 249              14  4.30849e+03      2.58e-07\npolygon 250              16  7.75733e+03      4.64e-07\npolygon 251 (hole)        4 -2.56408e+03     -1.53e-07\npolygon 252              10  1.75648e+03      1.05e-07\npolygon 253              34  3.85386e+06      2.31e-04\npolygon 254               9  3.55249e+03      2.13e-07\npolygon 255              15  1.39816e+04      8.37e-07\npolygon 256              16  4.56059e+05      2.73e-05\npolygon 257              26  1.42631e+04      8.54e-07\npolygon 258              36  2.65697e+04      1.59e-06\npolygon 259              19  4.48214e+03      2.68e-07\npolygon 260              96  5.26087e+05      3.15e-05\npolygon 261              60  1.00635e+05      6.02e-06\npolygon 262              31  7.13046e+04      4.27e-06\npolygon 263              84  1.37245e+06      8.21e-05\npolygon 264             178  8.26947e+05      4.95e-05\npolygon 265              58  1.98953e+05      1.19e-05\npolygon 266             115  3.13297e+05      1.87e-05\npolygon 267             132  4.76047e+05      2.85e-05\npolygon 268             102  1.63410e+07      9.78e-04\npolygon 269              18  6.36647e+03      3.81e-07\npolygon 270              10  7.72550e+03      4.62e-07\npolygon 271             204  1.42141e+06      8.51e-05\npolygon 272             125  2.33639e+06      1.40e-04\npolygon 273              30  2.58819e+04      1.55e-06\npolygon 274              24  2.06403e+04      1.24e-06\npolygon 275              87  1.25178e+06      7.49e-05\npolygon 276              38  4.04777e+04      2.42e-06\npolygon 277              10  5.04036e+04      3.02e-06\npolygon 278               6  1.12482e+04      6.73e-07\npolygon 279              40  1.56825e+05      9.39e-06\npolygon 280              63  5.25132e+04      3.14e-06\npolygon 281               8  1.11128e+04      6.65e-07\npolygon 282               9  1.49650e+03      8.96e-08\npolygon 283              13  4.50724e+03      2.70e-07\npolygon 284              41  4.12892e+04      2.47e-06\npolygon 285               7  3.03545e+03      1.82e-07\npolygon 286              19  7.54584e+03      4.52e-07\npolygon 287              16  8.29528e+03      4.96e-07\npolygon 288              26  5.16293e+05      3.09e-05\npolygon 289              13  9.23979e+04      5.53e-06\npolygon 290              25  4.18391e+04      2.50e-06\npolygon 291               7  3.85120e+03      2.30e-07\npolygon 292              82  4.38489e+05      2.62e-05\npolygon 293             163  3.46322e+06      2.07e-04\npolygon 294              11  5.22182e+03      3.13e-07\npolygon 295              13  3.28208e+04      1.96e-06\npolygon 296               6  3.00920e+04      1.80e-06\npolygon 297               6  1.13309e+04      6.78e-07\npolygon 298              13  2.03134e+05      1.22e-05\npolygon 299              36  2.87112e+04      1.72e-06\npolygon 300               6  1.13102e+04      6.77e-07\npolygon 301              13  4.04370e+03      2.42e-07\npolygon 302              44  1.67056e+05      1.00e-05\npolygon 303              11  6.66250e+04      3.99e-06\npolygon 304             129  2.29313e+06      1.37e-04\npolygon 305               6  7.23372e+04      4.33e-06\npolygon 306              19  6.36948e+03      3.81e-07\npolygon 307             106  1.06881e+06      6.40e-05\npolygon 308               9  2.30443e+04      1.38e-06\npolygon 309              29  9.02725e+03      5.40e-07\npolygon 310              68  1.08514e+05      6.49e-06\npolygon 311              64  2.19772e+05      1.32e-05\npolygon 312              25  2.58054e+05      1.54e-05\npolygon 313              26  4.59967e+04      2.75e-06\npolygon 314              57  8.30317e+04      4.97e-06\npolygon 315              83  1.13991e+06      6.82e-05\npolygon 316              11  3.01692e+04      1.81e-06\npolygon 317              14  1.30445e+05      7.81e-06\npolygon 318              22  2.37053e+05      1.42e-05\npolygon 319              22  1.84800e+05      1.11e-05\nenclosing rectangle: [512017.1, 928107.3] x [9621818, 9833989] units\n                     (416100 x 212200 units)\nWindow area = 16709500000 square units\nFraction of frame area: 0.189\n\n\n\n# Visual check that points and window align\nplot(fire_month_owin)   # base plot; circles show mark values (here: months 1..12)\n\n\n\n\n\n\n\n\n\n\n\nSubsequently, we will estimate spatio-temporal kernel density over space (meters) and discrete time (months).\n\n# Compute STKDE using sparr::spattemp.density \nst_kde &lt;- sparr::spattemp.density(fire_month_owin)  # uses default bandwidths; time is Month_num (1..12)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(st_kde)                                     # see chosen bandwidths h (space) and lambda (time), bounds, range\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 19155.99 (spatial)\n  lambda = 0.0264 (temporal)\n\nNo. of observations\n  899 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512017.1, 928107.3] x [9621818, 9833989]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [1.201154e-39, 6.369146e-10]\n\n\n\n\n\nThereafter, we will reproduce month-specific density maps for July–December example.\n\n# Plot a subset of months (e.g., 7..12) with a fixed legend range for comparability \ntims &lt;- c(7,8,9,10,11,12)      # months to display (Jul..Dec), matches the sample figure\npar(mfcol = c(2,3))            # 2 rows x 3 columns panel\nfor(i in tims){                # loop through the selected months\n  plot(st_kde, i,              # draw the STKDE slice at month 'i'\n       override.par = FALSE,   # keep mfcol settings\n       fix.range = TRUE,       # use common color scale across panels for fair comparison\n       main = paste(\"KDE at month\", i))  # panel title\n}"
  },
  {
    "objectID": "Hands-on_Ex03/Hand-on_Ex03.html#computing-stkde-by-day-of-year",
    "href": "Hands-on_Ex03/Hand-on_Ex03.html#computing-stkde-by-day-of-year",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "In this section, we will repeat the workflow but using Day of Year (1..365) as the temporal mark.\n\n\n\n# Create a ppp whose mark is DayofYear (1..365) ----------------------------------------------\nfire_yday_ppp &lt;- fire_sf %&gt;% \n  dplyr::select(DayofYear) %&gt;%     # keep only the DOY mark and geometry\n  as.ppp()                         # convert to ppp object\n\n\n\n\n\n# Attach the owin (study window) to the DayofYear ppp \nfire_yday_owin &lt;- fire_yday_ppp[kbb_owin] # ensure points are constrained to study polygon\nsummary(fire_yday_owin)    # confirm counts, mark summary, window stats\n\nMarked planar point pattern:  899 points\nAverage intensity 5.380183e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   10.0   219.0   260.0   247.7   288.0   360.0 \n\nWindow: polygonal boundary\n319 separate polygons (40 holes)\n                   vertices         area relative.area\npolygon 1              9026  1.15464e+10      6.91e-01\npolygon 2                19  1.26217e+04      7.55e-07\npolygon 3 (hole)          3 -1.80096e-01     -1.08e-11\npolygon 4 (hole)          3 -9.26944e-01     -5.55e-11\npolygon 5 (hole)          3 -1.07382e+03     -6.43e-08\npolygon 6 (hole)          3 -6.41537e+02     -3.84e-08\npolygon 7                23  9.26156e+04      5.54e-06\npolygon 8                30  3.37146e+04      2.02e-06\npolygon 9                54  3.25211e+05      1.95e-05\npolygon 10               33  1.30244e+06      7.79e-05\npolygon 11 (hole)         4 -9.57353e+02     -5.73e-08\npolygon 12 (hole)         4 -2.84738e+02     -1.70e-08\npolygon 13 (hole)         3 -1.38747e+02     -8.30e-09\npolygon 14 (hole)         4 -5.31445e+02     -3.18e-08\npolygon 15 (hole)         3 -6.42241e+02     -3.84e-08\npolygon 16 (hole)         6 -1.13809e+02     -6.81e-09\npolygon 17 (hole)         4 -2.10482e+02     -1.26e-08\npolygon 18 (hole)         4 -9.54892e+01     -5.71e-09\npolygon 19 (hole)         4 -6.47895e+01     -3.88e-09\npolygon 20 (hole)         4 -7.10903e+01     -4.25e-09\npolygon 21 (hole)         4 -2.18071e+02     -1.31e-08\npolygon 22 (hole)         4 -4.44993e+01     -2.66e-09\npolygon 23 (hole)         4 -4.90009e+01     -2.93e-09\npolygon 24 (hole)         4 -6.48299e+01     -3.88e-09\npolygon 25 (hole)         4 -2.36910e+02     -1.42e-08\npolygon 26 (hole)         4 -3.07205e+01     -1.84e-09\npolygon 27 (hole)         4 -5.24443e+01     -3.14e-09\npolygon 28 (hole)         5 -6.64298e+01     -3.98e-09\npolygon 29 (hole)         4 -6.08287e+01     -3.64e-09\npolygon 30 (hole)         4 -1.12681e+02     -6.74e-09\npolygon 31              132  1.16480e+06      6.97e-05\npolygon 32 (hole)         4 -9.56157e+01     -5.72e-09\npolygon 33               68  1.91291e+05      1.14e-05\npolygon 34 (hole)         4 -5.31171e+02     -3.18e-08\npolygon 35 (hole)         3 -1.76143e+00     -1.05e-10\npolygon 36              116  1.51984e+05      9.10e-06\npolygon 37               95  1.14322e+05      6.84e-06\npolygon 38               21  4.51914e+03      2.70e-07\npolygon 39               24  1.18511e+04      7.09e-07\npolygon 40              130  1.52296e+05      9.11e-06\npolygon 41               36  1.07878e+04      6.46e-07\npolygon 42               54  3.46932e+05      2.08e-05\npolygon 43               71  2.15798e+05      1.29e-05\npolygon 44               12  1.76977e+03      1.06e-07\npolygon 45               75  1.05557e+05      6.32e-06\npolygon 46               17  4.22421e+03      2.53e-07\npolygon 47              116  1.64725e+05      9.86e-06\npolygon 48               36  1.15582e+04      6.92e-07\npolygon 49               15  3.48567e+03      2.09e-07\npolygon 50              325  3.08585e+06      1.85e-04\npolygon 51 (hole)         4 -2.57635e+02     -1.54e-08\npolygon 52              191  2.36948e+06      1.42e-04\npolygon 53               75  8.81673e+04      5.28e-06\npolygon 54               49  6.13133e+04      3.67e-06\npolygon 55              117  7.65040e+04      4.58e-06\npolygon 56                5  1.73964e+04      1.04e-06\npolygon 57             6115  4.61702e+09      2.76e-01\npolygon 58                4  6.35998e+03      3.81e-07\npolygon 59               16  1.18306e+05      7.08e-06\npolygon 60                5  2.11525e+04      1.27e-06\npolygon 61               11  3.52792e+04      2.11e-06\npolygon 62               13  6.20254e+04      3.71e-06\npolygon 63                8  1.23192e+04      7.37e-07\npolygon 64                5  1.08320e+04      6.48e-07\npolygon 65                5  9.14438e+03      5.47e-07\npolygon 66                6  9.61120e+03      5.75e-07\npolygon 67               31  1.54535e+06      9.25e-05\npolygon 68                9  2.89834e+04      1.73e-06\npolygon 69               10  2.76357e+04      1.65e-06\npolygon 70               12  8.99515e+04      5.38e-06\npolygon 71               15  5.42889e+04      3.25e-06\npolygon 72                8  1.58645e+04      9.49e-07\npolygon 73                6  1.35398e+04      8.10e-07\npolygon 74                4  4.29102e+03      2.57e-07\npolygon 75               23  1.76942e+05      1.06e-05\npolygon 76               44  4.35606e+04      2.61e-06\npolygon 77                5  6.83234e+03      4.09e-07\npolygon 78                5  6.67728e+03      4.00e-07\npolygon 79                5  2.24964e+03      1.35e-07\npolygon 80                7  2.62416e+04      1.57e-06\npolygon 81                9  1.19857e+04      7.17e-07\npolygon 82                8  2.25169e+04      1.35e-06\npolygon 83                6  1.21525e+04      7.27e-07\npolygon 84                5  8.76352e+03      5.24e-07\npolygon 85                9  2.28019e+04      1.36e-06\npolygon 86                6  9.21428e+03      5.51e-07\npolygon 87               49  1.00151e+05      5.99e-06\npolygon 88                5  4.45695e+03      2.67e-07\npolygon 89                4  2.90460e+03      1.74e-07\npolygon 90                4  3.68683e+03      2.21e-07\npolygon 91               64  9.90797e+04      5.93e-06\npolygon 92                5  3.03789e+03      1.82e-07\npolygon 93                6  1.05164e+04      6.29e-07\npolygon 94               12  9.48365e+03      5.68e-07\npolygon 95               13  6.95068e+04      4.16e-06\npolygon 96               34  2.01269e+05      1.20e-05\npolygon 97              222  1.23410e+06      7.39e-05\npolygon 98                4  2.60388e+03      1.56e-07\npolygon 99                7  8.47934e+03      5.07e-07\npolygon 100               5  8.09538e+03      4.84e-07\npolygon 101              93  2.08256e+05      1.25e-05\npolygon 102              16  7.78971e+04      4.66e-06\npolygon 103              24  1.58864e+04      9.51e-07\npolygon 104               4  8.84658e+02      5.29e-08\npolygon 105              42  4.25525e+04      2.55e-06\npolygon 106               5  4.40655e+03      2.64e-07\npolygon 107               4  2.45366e+03      1.47e-07\npolygon 108               5  4.70713e+03      2.82e-07\npolygon 109             214  2.22664e+06      1.33e-04\npolygon 110              60  5.44949e+04      3.26e-06\npolygon 111               6  4.54843e+03      2.72e-07\npolygon 112               6  1.47384e+04      8.82e-07\npolygon 113               6  1.35534e+04      8.11e-07\npolygon 114              51  9.00778e+04      5.39e-06\npolygon 115               4  1.53560e+03      9.19e-08\npolygon 116 (hole)        3 -3.48195e+02     -2.08e-08\npolygon 117              32  4.34406e+04      2.60e-06\npolygon 118             144  5.46612e+05      3.27e-05\npolygon 119              36  7.39285e+04      4.42e-06\npolygon 120              42  9.17456e+04      5.49e-06\npolygon 121             141  1.10139e+06      6.59e-05\npolygon 122              94  2.55406e+05      1.53e-05\npolygon 123              71  3.74605e+04      2.24e-06\npolygon 124              72  9.11248e+05      5.45e-05\npolygon 125 (hole)        3 -2.91215e+01     -1.74e-09\npolygon 126               5  4.23910e+03      2.54e-07\npolygon 127              47  1.10186e+05      6.59e-06\npolygon 128               6  1.00636e+04      6.02e-07\npolygon 129 (hole)        3 -3.94431e+01     -2.36e-09\npolygon 130               4  1.41401e+02      8.46e-09\npolygon 131              32  2.34725e+04      1.40e-06\npolygon 132               5  3.61887e+02      2.17e-08\npolygon 133 (hole)        3 -2.90329e+03     -1.74e-07\npolygon 134             120  3.80494e+05      2.28e-05\npolygon 135              19  3.13628e+04      1.88e-06\npolygon 136              42  1.21238e+05      7.26e-06\npolygon 137              24  3.83277e+04      2.29e-06\npolygon 138              88  4.56947e+05      2.73e-05\npolygon 139              20  1.78310e+04      1.07e-06\npolygon 140              20  2.39227e+04      1.43e-06\npolygon 141               5  6.65825e+03      3.98e-07\npolygon 142               5  5.41759e+03      3.24e-07\npolygon 143              53  4.55018e+05      2.72e-05\npolygon 144             263  1.76197e+07      1.05e-03\npolygon 145 (hole)        4 -3.70130e+03     -2.22e-07\npolygon 146               4  6.79585e+03      4.07e-07\npolygon 147              15  5.74657e+03      3.44e-07\npolygon 148              25  2.16665e+05      1.30e-05\npolygon 149               9  7.99755e+03      4.79e-07\npolygon 150               8  3.28848e+03      1.97e-07\npolygon 151              10  1.13482e+04      6.79e-07\npolygon 152              45  1.05243e+05      6.30e-06\npolygon 153               7  4.67607e+03      2.80e-07\npolygon 154             533  4.88598e+07      2.92e-03\npolygon 155             641  1.19875e+08      7.17e-03\npolygon 156              68  3.72768e+06      2.23e-04\npolygon 157              10  1.01914e+05      6.10e-06\npolygon 158              19  8.26881e+04      4.95e-06\npolygon 159              17  4.00986e+04      2.40e-06\npolygon 160              11  4.05798e+04      2.43e-06\npolygon 161             111  1.46838e+06      8.79e-05\npolygon 162             112  3.73964e+06      2.24e-04\npolygon 163              19  1.91730e+04      1.15e-06\npolygon 164              73  3.61914e+06      2.17e-04\npolygon 165              10  3.05707e+04      1.83e-06\npolygon 166               6  1.62989e+04      9.75e-07\npolygon 167              81  2.65465e+05      1.59e-05\npolygon 168               8  2.09366e+04      1.25e-06\npolygon 169               9  2.23138e+04      1.34e-06\npolygon 170              11  1.96456e+04      1.18e-06\npolygon 171 (hole)        3 -4.90052e+02     -2.93e-08\npolygon 172             145  7.13727e+06      4.27e-04\npolygon 173              60  1.45353e+05      8.70e-06\npolygon 174 (hole)        4 -3.71089e+02     -2.22e-08\npolygon 175              74  2.06447e+06      1.24e-04\npolygon 176              36  2.65019e+04      1.59e-06\npolygon 177             931  2.12400e+08      1.27e-02\npolygon 178 (hole)        4 -1.54888e+02     -9.27e-09\npolygon 179              25  2.21142e+05      1.32e-05\npolygon 180               6  6.87439e+03      4.11e-07\npolygon 181              31  1.67778e+06      1.00e-04\npolygon 182               7  9.00046e+03      5.39e-07\npolygon 183              12  6.30886e+04      3.78e-06\npolygon 184             202  2.25185e+07      1.35e-03\npolygon 185              46  2.39825e+06      1.44e-04\npolygon 186              25  1.05566e+04      6.32e-07\npolygon 187               8  4.61437e+04      2.76e-06\npolygon 188               7  3.16305e+04      1.89e-06\npolygon 189               5  6.49689e+03      3.89e-07\npolygon 190              12  2.17421e+04      1.30e-06\npolygon 191               5  7.19819e+03      4.31e-07\npolygon 192              11  6.58157e+05      3.94e-05\npolygon 193             159  1.11857e+06      6.69e-05\npolygon 194             104  3.97323e+05      2.38e-05\npolygon 195              14  3.77571e+05      2.26e-05\npolygon 196              27  1.21314e+06      7.26e-05\npolygon 197              69  7.97787e+04      4.77e-06\npolygon 198              51  6.46735e+04      3.87e-06\npolygon 199              71  7.20054e+04      4.31e-06\npolygon 200              46  3.29862e+04      1.97e-06\npolygon 201              52  3.88477e+04      2.32e-06\npolygon 202              59  5.31603e+06      3.18e-04\npolygon 203 (hole)        3 -3.70978e+01     -2.22e-09\npolygon 204              48  1.76671e+06      1.06e-04\npolygon 205              34  5.03002e+04      3.01e-06\npolygon 206              46  1.83138e+04      1.10e-06\npolygon 207              18  5.28224e+03      3.16e-07\npolygon 208             244  3.09431e+06      1.85e-04\npolygon 209              28  1.99131e+05      1.19e-05\npolygon 210              21  4.52072e+05      2.71e-05\npolygon 211              14  5.66637e+04      3.39e-06\npolygon 212              12  1.09825e+05      6.57e-06\npolygon 213              15  1.37135e+06      8.21e-05\npolygon 214               6  1.22312e+05      7.32e-06\npolygon 215              43  2.41150e+05      1.44e-05\npolygon 216               7  2.79840e+04      1.67e-06\npolygon 217              46  1.72671e+06      1.03e-04\npolygon 218              13  6.36540e+04      3.81e-06\npolygon 219              11  7.02064e+05      4.20e-05\npolygon 220              47  9.13826e+05      5.47e-05\npolygon 221 (hole)        4 -3.82299e+03     -2.29e-07\npolygon 222              62  3.95149e+06      2.36e-04\npolygon 223               9  4.34659e+05      2.60e-05\npolygon 224              14  4.20832e+04      2.52e-06\npolygon 225              18  5.12063e+03      3.06e-07\npolygon 226              31  7.44741e+05      4.46e-05\npolygon 227              18  4.11233e+05      2.46e-05\npolygon 228 (hole)        3 -5.32643e+02     -3.19e-08\npolygon 229              23  7.71654e+03      4.62e-07\npolygon 230               8  3.86022e+04      2.31e-06\npolygon 231             168  7.46341e+06      4.47e-04\npolygon 232               4  9.19978e+03      5.51e-07\npolygon 233              14  2.75390e+05      1.65e-05\npolygon 234               9  9.63798e+03      5.77e-07\npolygon 235               9  6.16361e+04      3.69e-06\npolygon 236              10  1.04975e+05      6.28e-06\npolygon 237               8  8.75225e+04      5.24e-06\npolygon 238               5  1.84001e+04      1.10e-06\npolygon 239               5  3.30315e+03      1.98e-07\npolygon 240              13  3.15610e+04      1.89e-06\npolygon 241              67  3.93597e+05      2.36e-05\npolygon 242               4  2.83740e+03      1.70e-07\npolygon 243              15  4.86091e+03      2.91e-07\npolygon 244               4  1.26784e+03      7.59e-08\npolygon 245               8  1.67287e+04      1.00e-06\npolygon 246              12  2.45858e+04      1.47e-06\npolygon 247              12  5.95789e+04      3.57e-06\npolygon 248              12  2.14651e+03      1.28e-07\npolygon 249              14  4.30849e+03      2.58e-07\npolygon 250              16  7.75733e+03      4.64e-07\npolygon 251 (hole)        4 -2.56408e+03     -1.53e-07\npolygon 252              10  1.75648e+03      1.05e-07\npolygon 253              34  3.85386e+06      2.31e-04\npolygon 254               9  3.55249e+03      2.13e-07\npolygon 255              15  1.39816e+04      8.37e-07\npolygon 256              16  4.56059e+05      2.73e-05\npolygon 257              26  1.42631e+04      8.54e-07\npolygon 258              36  2.65697e+04      1.59e-06\npolygon 259              19  4.48214e+03      2.68e-07\npolygon 260              96  5.26087e+05      3.15e-05\npolygon 261              60  1.00635e+05      6.02e-06\npolygon 262              31  7.13046e+04      4.27e-06\npolygon 263              84  1.37245e+06      8.21e-05\npolygon 264             178  8.26947e+05      4.95e-05\npolygon 265              58  1.98953e+05      1.19e-05\npolygon 266             115  3.13297e+05      1.87e-05\npolygon 267             132  4.76047e+05      2.85e-05\npolygon 268             102  1.63410e+07      9.78e-04\npolygon 269              18  6.36647e+03      3.81e-07\npolygon 270              10  7.72550e+03      4.62e-07\npolygon 271             204  1.42141e+06      8.51e-05\npolygon 272             125  2.33639e+06      1.40e-04\npolygon 273              30  2.58819e+04      1.55e-06\npolygon 274              24  2.06403e+04      1.24e-06\npolygon 275              87  1.25178e+06      7.49e-05\npolygon 276              38  4.04777e+04      2.42e-06\npolygon 277              10  5.04036e+04      3.02e-06\npolygon 278               6  1.12482e+04      6.73e-07\npolygon 279              40  1.56825e+05      9.39e-06\npolygon 280              63  5.25132e+04      3.14e-06\npolygon 281               8  1.11128e+04      6.65e-07\npolygon 282               9  1.49650e+03      8.96e-08\npolygon 283              13  4.50724e+03      2.70e-07\npolygon 284              41  4.12892e+04      2.47e-06\npolygon 285               7  3.03545e+03      1.82e-07\npolygon 286              19  7.54584e+03      4.52e-07\npolygon 287              16  8.29528e+03      4.96e-07\npolygon 288              26  5.16293e+05      3.09e-05\npolygon 289              13  9.23979e+04      5.53e-06\npolygon 290              25  4.18391e+04      2.50e-06\npolygon 291               7  3.85120e+03      2.30e-07\npolygon 292              82  4.38489e+05      2.62e-05\npolygon 293             163  3.46322e+06      2.07e-04\npolygon 294              11  5.22182e+03      3.13e-07\npolygon 295              13  3.28208e+04      1.96e-06\npolygon 296               6  3.00920e+04      1.80e-06\npolygon 297               6  1.13309e+04      6.78e-07\npolygon 298              13  2.03134e+05      1.22e-05\npolygon 299              36  2.87112e+04      1.72e-06\npolygon 300               6  1.13102e+04      6.77e-07\npolygon 301              13  4.04370e+03      2.42e-07\npolygon 302              44  1.67056e+05      1.00e-05\npolygon 303              11  6.66250e+04      3.99e-06\npolygon 304             129  2.29313e+06      1.37e-04\npolygon 305               6  7.23372e+04      4.33e-06\npolygon 306              19  6.36948e+03      3.81e-07\npolygon 307             106  1.06881e+06      6.40e-05\npolygon 308               9  2.30443e+04      1.38e-06\npolygon 309              29  9.02725e+03      5.40e-07\npolygon 310              68  1.08514e+05      6.49e-06\npolygon 311              64  2.19772e+05      1.32e-05\npolygon 312              25  2.58054e+05      1.54e-05\npolygon 313              26  4.59967e+04      2.75e-06\npolygon 314              57  8.30317e+04      4.97e-06\npolygon 315              83  1.13991e+06      6.82e-05\npolygon 316              11  3.01692e+04      1.81e-06\npolygon 317              14  1.30445e+05      7.81e-06\npolygon 318              22  2.37053e+05      1.42e-05\npolygon 319              22  1.84800e+05      1.11e-05\nenclosing rectangle: [512017.1, 928107.3] x [9621818, 9833989] units\n                     (416100 x 212200 units)\nWindow area = 16709500000 square units\nFraction of frame area: 0.189\n\n\n\n\n\nWe aim to compute STKDE with default bandwidths and plot.\n\n# Compute STKDE using default bandwidth selection (gives baseline) \nkde_yday &lt;- spattemp.density(\n  fire_yday_owin        # ppp with DayofYear marks and study window\n)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(kde_yday)       # examine space/time bandwidths (h, lambda) and density range\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 19155.99 (spatial)\n  lambda = 6.4456 (temporal)\n\nNo. of observations\n  899 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512017.1, 928107.3] x [9621818, 9833989]\n\nTemporal bound\n  [10, 360]\n\nEvaluation\n  128 x 128 x 351 trivariate lattice\n  Density range: [1.594274e-28, 1.857482e-12]\n\n\n\n# Visualise the density surface aggregated over time (default plot) \nplot(kde_yday)     # continuous surface over the region with legend"
  },
  {
    "objectID": "Hands-on_Ex03/Hand-on_Ex03.html#computing-stkde-by-day-of-year-improved-method",
    "href": "Hands-on_Ex03/Hand-on_Ex03.html#computing-stkde-by-day-of-year-improved-method",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "Why this step? Default bandwidths are generic. In this section, want to improve them by bootstrap MISE using BOOT.spattemp(), which estimates a scalar spatial bandwidth (h, meters) and a scalar temporal bandwidth (lambda, in DOY units) suited to our data.\n\n# For reproducibility of the bootstrap selection \nset.seed(1234)    # fixed seed so results are repeatable in class\n\n# Run bootstrap bandwidth selection (may take some time) \nBOOT.spattemp(fire_yday_owin)   # prints many trial (h, lambda) and the final pair at bottom\n\nInitialising...Done.\nOptimising...\nh = 19155.99 \b; lambda = 15.11399 \nh = 21071.59 \b; lambda = 15.11399 \nh = 19155.99 \b; lambda = 1930.713 \nh = 19634.89 \b; lambda = 972.9137 \nh = 19874.34 \b; lambda = 494.0138 \nh = 19994.07 \b; lambda = 254.5639 \nh = 20053.93 \b; lambda = 134.8389 \nh = 20083.86 \b; lambda = 74.97647 \nh = 20098.83 \b; lambda = 45.04523 \nh = 20106.31 \b; lambda = 30.07961 \nh = 20121.28 \b; lambda = 0.1483655 \nh = 20110.05 \b; lambda = 22.5968 \nh = 22025.65 \b; lambda = 22.5968 \nh = 23460.48 \b; lambda = 26.3382 \nh = 22498.94 \b; lambda = 33.82101 \nh = 21428.43 \b; lambda = 19.79074 \nh = 24778.86 \b; lambda = 23.53215 \nh = 27113.26 \b; lambda = 23.99982 \nh = 29145.31 \b; lambda = 30.54728 \nh = 27216.09 \b; lambda = 27.85815 \nh = 30868.87 \b; lambda = 25.51977 \nh = 34573.07 \b; lambda = 25.11055 \nh = 34470.24 \b; lambda = 21.25223 \nh = 38097.31 \b; lambda = 17.94927 \nh = 45557.12 \b; lambda = 19.06 \nh = 54779.04 \b; lambda = 16.59009 \nh = 49081.36 \b; lambda = 11.89872 \nh = 45454.29 \b; lambda = 15.20168 \nh = 38200.14 \b; lambda = 21.80759 \nh = 43640.75 \b; lambda = 16.85315 \nh = 51100.56 \b; lambda = 17.96388 \nh = 47849.75 \b; lambda = 17.96023 \nh = 49766.11 \b; lambda = 20.16708 \nh = 45172.09 \b; lambda = 17.68163 \nh = 42879.46 \b; lambda = 18.7814 \nh = 44122.03 \b; lambda = 18.57611 \nh = 44507.06 \b; lambda = 19.95447 \nh = 44673.32 \b; lambda = 19.38626 \nDone.\n\n\n          h      lambda \n44673.31732    19.38626 \n\n# Note the final recommended h and lambda reported by the function output.\n\n\n\nWe will re-run STKDE using the recommended bandwidths.\n\n# Refit STKDE using the bootstrap MISE recommended bandwidths \nkde_yday &lt;- spattemp.density(\n  fire_yday_owin,     # the DayofYear ppp constrained by the study window\n  h      = 45000,     # spatial bandwidth in meters (per improved selection)\n  lambda = 19         # temporal bandwidth in days-of-year (per improved selection)\n)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(kde_yday)     # verify the bandwidths and evaluation grid\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 45000 (spatial)\n  lambda = 19 (temporal)\n\nNo. of observations\n  899 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512017.1, 928107.3] x [9621818, 9833989]\n\nTemporal bound\n  [10, 360]\n\nEvaluation\n  128 x 128 x 351 trivariate lattice\n  Density range: [3.902314e-16, 9.815536e-13]\n\n\n\n\n\nFinally, we display the final improved surface.\n\n# Plot the improved STKDE surface\nplot(kde_yday)   # shows the density surface with color bar; higher values = higher intensity"
  },
  {
    "objectID": "Hands-on_Ex03/Hand-on_Ex03.html#discussion-of-results-answer-to-the-research-question",
    "href": "Hands-on_Ex03/Hand-on_Ex03.html#discussion-of-results-answer-to-the-research-question",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "The spatio-temporal kernel density estimation (STKDE) provides clear evidence that the locations of forest fires in Kepulauan Bangka Belitung are not spatially or spatio-temporally independent. If the events were independent, the density surfaces would be flat and homogeneous across space and time. Instead, the STKDE outputs reveal distinct peaks, rejecting the null hypothesis of independence.\nThe bootstrap-based bandwidth selection process identified an optimal smoothing window of h ≈ 44.7 km (spatial) and λ ≈ 19.4 days (temporal). These parameters indicate that fire events tend to cluster within a radius of ~45 km and persist across approximately three-week periods. The density range produced, from very low background values (~1.2e-39) to sharp peaks (~6.4e-10), confirms substantial clustering intensity.\nThe spatial clustering is most pronounced in southern and central Bangka and in eastern Belitung, where the STKDE consistently highlights hotspots of higher fire intensity. These locations repeatedly emerge in the density surfaces, showing that fire events are concentrated in specific sub-regions rather than being uniformly distributed.\nTemporally, clustering is most evident during the July–October period, corresponding to the dry season. The monthly KDE plots demonstrate that fire intensity builds steadily in July, peaks in September, and declines toward the year’s end. This seasonality shows that fire occurrence is not equally likely throughout the year but is instead conditioned by climatic and land-surface factors linked to the dry months.\nThe implications of these findings are important for both science and policy. Spatial dependence means that fire risk is localized, and mitigation resources should be concentrated in the fire-prone regions identified by the STKDE. Temporal dependence means that efforts should be time-targeted, with enhanced monitoring and preventive measures deployed during the critical dry-season window. This combination of spatial and temporal clustering suggests that forest fires in Bangka Belitung are shaped by systematic environmental drivers, not by random chance.\nIn summary, the STKDE results demonstrate that forest fire events are spatially and spatio-temporally dependent. They cluster within ~45 km regions and persist across ~3-week intervals, with the highest concentrations observed in southern/central Bangka and eastern Belitung during the July–October dry season."
  },
  {
    "objectID": "Hands-on_Ex04/hand-on_ex04.html",
    "href": "Hands-on_Ex04/hand-on_ex04.html",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to compute spatial weights using R.\nBy the end to this hands-on exercise, we will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\n\nimport csv file using appropriate function of readr package,\n\nperform relational join using appropriate join function of dplyr package,\n\ncompute spatial weights using appropriate functions of spdep package, and calculate spatially lagged variables using appropriate functions of spdep package.\n\n\n\n\nTwo data sets will be used in this hands-on exercise, they are: - Hunan county boundary layer. This is a geospatial data set in ESRI shapefile format. - Hunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n# \"pacman\" automatically installs and loads packages if not already installed.\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)\n\n\n\n\n\n\n\n\n# Read the Hunan county polygons as an sf object (modern spatial class)\nhunan &lt;- sf::st_read(dsn = \"data/geospatial\", layer = \"Hunan\")  # dsn = folder, layer = shapefile basename\n\nReading layer `Hunan' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex04/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n# Inspect the basic structure to confirm geometry + fields\nprint(hunan)    # shows feature count, geometry type, CRS, attributes\n\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n     NAME_2  ID_3    NAME_3   ENGTYPE_3 Shape_Leng Shape_Area    County\n1   Changde 21098   Anxiang      County   1.869074 0.10056190   Anxiang\n2   Changde 21100   Hanshou      County   2.360691 0.19978745   Hanshou\n3   Changde 21101    Jinshi County City   1.425620 0.05302413    Jinshi\n4   Changde 21102        Li      County   3.474325 0.18908121        Li\n5   Changde 21103     Linli      County   2.289506 0.11450357     Linli\n6   Changde 21104    Shimen      County   4.171918 0.37194707    Shimen\n7  Changsha 21109   Liuyang County City   4.060579 0.46016789   Liuyang\n8  Changsha 21110 Ningxiang      County   3.323754 0.26614198 Ningxiang\n9  Changsha 21111 Wangcheng      County   2.292093 0.13049161 Wangcheng\n10 Chenzhou 21112     Anren      County   2.240739 0.13343936     Anren\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734...\n\n\n\n\n\n\n# Read county-level attributes (e.g., GDPPC) for 2012\nhunan2012 &lt;- readr::read_csv(\"data/aspatial/Hunan_2012.csv\")   # creates a regular tibble/data.frame\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Peek at columns so we know what to join\ndplyr::glimpse(hunan2012)   # confirms column names such as County, GDPPC, etc.\n\nRows: 88\nColumns: 29\n$ County      &lt;chr&gt; \"Anhua\", \"Anren\", \"Anxiang\", \"Baojing\", \"Chaling\", \"Changn…\n$ City        &lt;chr&gt; \"Yiyang\", \"Chenzhou\", \"Changde\", \"Hunan West\", \"Zhuzhou\", …\n$ avg_wage    &lt;dbl&gt; 30544, 28058, 31935, 30843, 31251, 28518, 54540, 28597, 33…\n$ deposite    &lt;dbl&gt; 10967.0, 4598.9, 5517.2, 2250.0, 8241.4, 10860.0, 24332.0,…\n$ FAI         &lt;dbl&gt; 6831.7, 6386.1, 3541.0, 1005.4, 6508.4, 7920.0, 33624.0, 1…\n$ Gov_Rev     &lt;dbl&gt; 456.72, 220.57, 243.64, 192.59, 620.19, 769.86, 5350.00, 1…\n$ Gov_Exp     &lt;dbl&gt; 2703.0, 1454.7, 1779.5, 1379.1, 1947.0, 2631.6, 7885.5, 11…\n$ GDP         &lt;dbl&gt; 13225.0, 4941.2, 12482.0, 4087.9, 11585.0, 19886.0, 88009.…\n$ GDPPC       &lt;dbl&gt; 14567, 12761, 23667, 14563, 20078, 24418, 88656, 10132, 17…\n$ GIO         &lt;dbl&gt; 9276.90, 4189.20, 5108.90, 3623.50, 9157.70, 37392.00, 513…\n$ Loan        &lt;dbl&gt; 3954.90, 2555.30, 2806.90, 1253.70, 4287.40, 4242.80, 4053…\n$ NIPCR       &lt;dbl&gt; 3528.3, 3271.8, 7693.7, 4191.3, 3887.7, 9528.0, 17070.0, 3…\n$ Bed         &lt;dbl&gt; 2718, 970, 1931, 927, 1449, 3605, 3310, 582, 2170, 2179, 1…\n$ Emp         &lt;dbl&gt; 494.310, 290.820, 336.390, 195.170, 330.290, 548.610, 670.…\n$ EmpR        &lt;dbl&gt; 441.4, 255.4, 270.5, 145.6, 299.0, 415.1, 452.0, 127.6, 21…\n$ EmpRT       &lt;dbl&gt; 338.0, 99.4, 205.9, 116.4, 154.0, 273.7, 219.4, 94.4, 174.…\n$ Pri_Stu     &lt;dbl&gt; 54.175, 33.171, 19.584, 19.249, 33.906, 81.831, 59.151, 18…\n$ Sec_Stu     &lt;dbl&gt; 32.830, 17.505, 17.819, 11.831, 20.548, 44.485, 39.685, 7.…\n$ Household   &lt;dbl&gt; 290.4, 104.6, 148.1, 73.2, 148.7, 211.2, 300.3, 76.1, 139.…\n$ Household_R &lt;dbl&gt; 234.5, 121.9, 135.4, 69.9, 139.4, 211.7, 248.4, 59.6, 110.…\n$ NOIP        &lt;dbl&gt; 101, 34, 53, 18, 106, 115, 214, 17, 55, 70, 44, 84, 74, 17…\n$ Pop_R       &lt;dbl&gt; 670.3, 243.2, 346.0, 184.1, 301.6, 448.2, 475.1, 189.6, 31…\n$ RSCG        &lt;dbl&gt; 5760.60, 2386.40, 3957.90, 768.04, 4009.50, 5220.40, 22604…\n$ Pop_T       &lt;dbl&gt; 910.8, 388.7, 528.3, 281.3, 578.4, 816.3, 998.6, 256.7, 45…\n$ Agri        &lt;dbl&gt; 4942.253, 2357.764, 4524.410, 1118.561, 3793.550, 6430.782…\n$ Service     &lt;dbl&gt; 5414.5, 3814.1, 14100.0, 541.8, 5444.0, 13074.6, 17726.6, …\n$ Disp_Inc    &lt;dbl&gt; 12373, 16072, 16610, 13455, 20461, 20868, 183252, 12379, 1…\n$ RORP        &lt;dbl&gt; 0.7359464, 0.6256753, 0.6549309, 0.6544614, 0.5214385, 0.5…\n$ ROREmp      &lt;dbl&gt; 0.8929619, 0.8782065, 0.8041262, 0.7460163, 0.9052651, 0.7…\n\n\n\n\n\n\n# Left join: keep all polygons and bring matching columns from hunan2012 by common key(s)\nhunan &lt;- dplyr::left_join(hunan, hunan2012) %&gt;%   # merge attributes into polygons\n  dplyr::select(1:4, 7, 15)      # reproduce Prof’s column subset (indices from slides)\n\nJoining with `by = join_by(County)`\n\n# Inspect and verify that GDPPC is now present alongside geometry\nhead(hunan)   # should list fields incl. County, GDPPC, geometry\n\nSimple feature collection with 6 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667\n2 Changde 21100 Hanshou      County Hanshou 20981\n3 Changde 21101  Jinshi County City  Jinshi 34592\n4 Changde 21102      Li      County      Li 24473\n5 Changde 21103   Linli      County   Linli 25554\n6 Changde 21104  Shimen      County  Shimen 27137\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\n\n\n\n\n\n# Prepare a simple basemap with names (quick tmap)\nbasemap &lt;- tmap::tm_shape(hunan) +                        # tell tmap what to draw (the polygons)\n  tmap::tm_polygons() +                                   # draw filled polygons\n  tmap::tm_text(\"NAME_3\", size = 0.5)                     # label polygons with county names (field matches slides)\n\n# Choropleth of GDPPC \ngdppc_map &lt;- tmap::qtm(hunan, \"GDPPC\") +                  # quick thematic map of GDPPC\n  tmap::tm_layout(legend.position = c(\"left\", \"bottom\"))  # put legend bottom-left to match the slides\n\n# Show basemap and GDPPC side-by-side\ntmap::tmap_arrange(basemap, gdppc_map, asp = 1, ncol = 2) # arrange 2 maps in one row, square aspect\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will learn how to use poly2nb() of spdep package to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If we look at the documentation, we will see that we can pass a “queen” argument that takes TRUE or FALSE as options. If we do not specify this argument the default is set to TRUE, that is, if we don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\n\n\n\n# Build a neighbours list where polygons touching at edges OR corners are neighbours\nwm_q &lt;- spdep::poly2nb(hunan, queen = TRUE)    # queen = TRUE includes corner touches\nsummary(wm_q)   # prints number of regions, links, and link distribution\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n# Explore neighbours of polygon 1 (IDs are row positions of neighbours)\nwm_q[[1]]   # e.g., returns integer vector like c(2, 3, 4, 57, 85)\n\n[1]  2  3  4 57 85\n\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\n\nWe can retrieve the county name of Polygon ID=1 by using the code chunk below:\n\n# Retrieve county name for polygon ID = 1\nhunan$County[1]   # should print the county name for ID 1\n\n[1] \"Anxiang\"\n\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\n\nTo reveal the county names of the five neighboring polygons, the code chunk will be used:\n\n# Retrieve the county names of polygon 1’s neighbours\nhunan$NAME_3[c(2, 3, 4, 57, 85)]    # show human-readable names for the neighbour IDs\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these five countries by using the code chunk below:\n\n# Pull the neighbours’ GDPPC values for polygon 1\nnb1_ids  &lt;- wm_q[[1]]               # save neighbour indices for clarity\nnb1_gdppc &lt;- hunan$GDPPC[nb1_ids]   # vector of GDPPC values for those neighbours\nnb1_gdppc                           # print to compare with slide values\n\n[1] 20981 34592 24473 21311 22879\n\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.\n\nWe can display the complete weight matrix by using str().\n\n# View the full list structure (long print, but matches slide)\nstr(wm_q)   # shows, for each region, the integer IDs of its neighbours\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language spdep::poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"snap\")= num 9e-08\n - attr(*, \"sym\")= logi TRUE\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : num 1\n  ..$ comp.id: num [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\nBe warned: The output might cut across several pages. Save the trees if we are going to print out the report.\n\n\n\n\n# Build neighbours list where polygons are neighbours only if they share an EDGE (no corner-only)\nwm_r &lt;- spdep::poly2nb(hunan, queen = FALSE)  # rook definition\nsummary(wm_r)                                 # compare to queen: usually slightly fewer links\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connect area unit has 10 neighbours. There are two area units with only one heighbours.\n\n\n\n\n\n# Compute polygon centroids for plotting the graph over the map\n# We extract numeric (lon, lat) from the POINT geometry returned by st_centroid()\nlongitude &lt;- purrr::map_dbl(hunan$geometry, ~ sf::st_centroid(.x)[[1]])  # [[1]] = x (lon)\nlatitude  &lt;- purrr::map_dbl(hunan$geometry, ~ sf::st_centroid(.x)[[2]])  # [[2]] = y (lat)\ncoords    &lt;- cbind(longitude, latitude)                                  # combine into a two-column matrix as required by spdep\nhead(coords)                                                             # quick check\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n\n\n# Plot: Queen contiguity graph\nplot(hunan$geometry, border = \"lightgrey\")                       # draw county outlines\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\") # overlay neighbour links + nodes in red\n\n\n\n\n\n\n\n\n\n\n\n\n# Plot: Rook contiguity graph\nplot(hunan$geometry, border = \"lightgrey\")                       # reset blank map\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\") # overlay rook links\n\n\n\n\n\n\n\n\n\n\n\n\n# Side-by-side comparison (Queen vs Rook)\npar(mfrow = c(1, 2))    # 1 row, 2 plots\nplot(hunan$geometry, border = \"lightgrey\", main = \"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\nplot(hunan$geometry, border = \"lightgrey\", main = \"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))    # reset layout\n\n\n\n\n\n\nIn this section, we will learn how to derive distance-based weight matrices by using dnearneigh() of spdep package.\nThe function identifies neighbours of region points by Euclidean distance with a distance band with lower d1= and upper d2= bounds controlled by the bounds= argument. If unprojected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and longlat=TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\n\n\n\n# 1) Compute first-nearest neighbours (1-NN) from the centroid coordinates\nk1 &lt;- spdep::knn2nb(spdep::knearneigh(coords))  # returns an nb object where each region has 1 NN\n\nWarning in spdep::knn2nb(spdep::knearneigh(coords)): neighbour object has 25\nsub-graphs\n\n\n\n# 2) Get the distances of those NN relationships (in km if longlat = TRUE)\nk1dists &lt;- unlist(spdep::nbdists(k1, coords, longlat = TRUE)) # lengths of the 88 NN edges as a numeric vector\n\n\n# 3) Summarise to find a safe upper bound for a distance band\nsummary(k1dists)   # Max ≈ 61.79 km in the slide → choose 62 km as cutoff\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n\n\n\n# Build neighbours where ANY pair of centroids within 62 km are linked\nwm_d62 &lt;- spdep::dnearneigh(coords, d1 = 0, d2 = 62, longlat = TRUE)  # 0 lower bound; 62 km upper bound from previous step\nwm_d62                                                                # print nb object summary like in slide\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\n\n\n\n\n\nNoteQuiz:\n\n\n\nWhat does “Average number of links: 3.681818” mean?\nOn average, each region has ~3.682 neighbours under the 62 km rule. Numerically, it equals total_links / number_of_regions = 324 / 88 ≈ 3.681818.\n\n\n\n# Show the internal list structure (optional)\nstr(wm_d62)   # each element lists neighbour indices for that region\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language spdep::dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : num 1\n  ..$ comp.id: num [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep.\n\n# Cross-tab: how many regions have 1, 2, 3, ... neighbours under 62 km?\ntable(hunan$County, spdep::card(wm_d62))   # card() = neighbour count (degree) for each region\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\n# Connected components check: is the graph fully connected?\nn_comp &lt;- spdep::n.comp.nb(wm_d62)  # counts connected subgraphs\nn_comp$nc                           # should be 1 = fully connected (as in slide)\n\n[1] 1\n\ntable(n_comp$comp.id)               # how many nodes in each component (expect 88 in id=1)\n\n\n 1 \n88 \n\n\n\n\nNow, we will plot the distance weight matrix by using the code chunk below.\n\n# Plot fixed-distance links (black) and 1-NN links (red) on top of the map\nplot(hunan$geometry, border = \"lightgrey\")                 # outline map\nplot(wm_d62, coords, add = TRUE)                           # distance-band neighbours (default black)\nplot(k1, coords, add = TRUE, col = \"red\", length = 0.08)   # 1-NN links in red with short arrowheads\n\n\n\n\n\n\n\n\n\n# Side-by-side: 1-NN vs distance band\npar(mfrow = c(1, 2))\nplot(hunan$geometry, border = \"lightgrey\", main = \"1st nearest neighbours\")\nplot(k1, coords, add = TRUE, col = \"red\", length = 0.08)\nplot(hunan$geometry, border = \"lightgrey\", main = \"Distance link (&lt;=62 km)\")\nplot(wm_d62, coords, add = TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\n\n\n\n\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\n# Force exactly k neighbours per region (here k = 6 per the slide)\nknn6 &lt;- spdep::knn2nb(spdep::knearneigh(coords, k = 6))    # asymmetric possible (A near B not equal B near A)\nknn6                                                       # prints summary: \"Average number of links: 6\"\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nSimilarly, we can display the content of the matrix by using str().\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language spdep::knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : num 1\n  ..$ comp.id: num [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\n\nWe can plot the weight matrix using the code chunk below.\n\n# Visualise the kNN(6) graph\nplot(hunan$geometry, border = \"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will learn how to derive a spatial weight matrix based on Inversed Distance method.\n\n# Compute distances ONLY for pairs that are QUEEN neighbours (wm_q) to avoid all-pairs blow-up\ndist_q &lt;- spdep::nbdists(wm_q, coords, longlat = TRUE)  # a list: element i contains distances to i's neighbours\nids    &lt;- lapply(dist_q, function(x) 1 / (x))           # convert distances to inverse-distance weights\nids    # print few entries to match slide’s example\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034\n\n\n\n\n\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\n# Build a row-standardised (style=\"W\") weights list from Queen neighbours\n# Each neighbour gets equal weight so that each row sums to 1 (average of neighbours).\nrswm_q &lt;- spdep::nb2listw(wm_q, style = \"W\", zero.policy = TRUE)   # zero.policy=TRUE avoids errors if any lonely nodes\nrswm_q    # shows \"Weights style: W\" + summary\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n# Inspect weights for a specific polygon (example in slide used index 10)\nrswm_q$weights[[10]]   # e.g., 8 neighbours → each weight = 1/8 = 0.125\n\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\n\n# Row-standardised distance weights using the inverse-distance 'glist' (Professor used style=\"B\" list)\nrswm_ids &lt;- spdep::nb2listw(wm_q, glist = ids, style = \"B\", zero.policy = TRUE)  # weights stored as provided (not re-scaled to 1)\nrswm_ids    # print characteristics; style B = basic weights\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\n# Summarise the distribution of all (unstandardised) IDW weights\nsummary(unlist(rswm_ids$weights))   # min/median/mean/... like the slide\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338 \n\n\n\n\n\nIn this section, we will learn how to create four different spatial lagged variables, they are: - spatial lag with row-standardized weights, - spatial lag as a sum of neighbouring values, - spatial window average, and - spatial window sum.\n\n\n\n# Compute spatial lag of GDPPC using row-standardised W (this is the neighbours' AVERAGE GDPPC)\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag    # matches slide numbers order\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nRecalled in the previous section, we retrieved the GDPPC of these five countries by using the code chunk below:\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\n\n\n\n\n\nNoteQuestion:\n\n\n\nCan you see the meaning of Spatial lag with row-standardized weights now?\n\nWith row-standardised W, each neighbour gets weight 1 / (#neighbours).\n\nlag GDPPC is therefore the average GDPPC of each county’s neighbours, not its own GDPPC.\n\nHigh values in a county surrounded by high-GDPPC neighbours turn the lag map dark even if the county’s own GDPPC is modest, and vice versa.\n\n\n\nWe can append the spatially lag GDPPC values onto hunan sf data frame by using the code chunk below:\n\n# Append lag column back to sf for mapping and tabulation\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below:\n\n# Map: GDPPC vs lag(GDPPC) side-by-side for visual comparison\ngdppc_map   &lt;- tmap::qtm(hunan, \"GDPPC\")       # original values\nlag_gdppc_m &lt;- tmap::qtm(hunan, \"lag GDPPC\")   # neighbour average\ntmap::tmap_arrange(gdppc_map, lag_gdppc_m, asp = 1, ncol = 2) # compare patterns\n\n\n\n\n\n\n\n\n\n\n\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply, which we have been using to manipulate the neighbors structure throughout the past notebooks. Basically it applies a function across each value in the neighbors structure.\n\n# Build a \"binary\" weights list (each neighbour = 1), still using the Queen neighbours\nb_weights  &lt;- lapply(wm_q, function(x) 0 * x + 1)                    # for each neighbour ID vector, make a same-length vector of 1s\nb_weights2 &lt;- spdep::nb2listw(wm_q, glist = b_weights, style = \"B\")  # store those 1s as raw weights (no row standardisation)\nb_weights2                                                           # check characteristics (Weights style: B)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\n\n# Compute the spatial lag as a SUM of neighbour GDPPC (not an average)\nlag_sum &lt;- list(hunan$NAME_3, spdep::lag.listw(b_weights2, hunan$GDPPC))  # returns the summed values, paired with names\nlag.res &lt;- as.data.frame(lag_sum)                                         # convert list → data.frame\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")                         # name columns as in slide\n\nLet’s investigate the result by using the code chunck below:\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\n\n\n\n\n\n\nNoteQuestion:\n\n\n\nCan you understand the meaning of Spatial lag as a sum of neighboring values now?\nlag_sum GDPPC is the total GDPPC of neighbours, so counties with many neighbours (or neighbours with large GDPPC) stand out more than in the averaged lag.\n\n\nNext, we will append the lag_sum GDPPC field into hunan sf data frame by using the code chunk below.\n\nhunan &lt;- dplyr::left_join(hunan, lag.res, by = \"NAME_3\")   \n\nNow, we can plot both the GDPPC and Spatial Lag Sum GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- spdep::include.self(wm_q)    # neighbour list with self included\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNotice that the Number of nonzero links, Percentage nonzero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909\nLet us take a good look at the neighbour list of area [1] by using the code chunk below:\n\nwm_qs[[1]]  # first county now lists itself plus prior neighbours\n\n[1]  1  2  3  4 57 85\n\n\nNotice that now [1] has six neighbours instead of five.\nNow we obtain weights with nb2listw()\n\n# Convert to weights (row-standardised) so we compute an average including self\nwm_qs_w &lt;- spdep::nb2listw(wm_qs)                                               # default style = \"W\" (row-standardised) on the expanded list\nwm_qs_w   \n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable.\n\n# Compute window-average lag of GDPPC (includes county itself in the mean)\nlag_w_avg_gdppc &lt;- spdep::lag.listw(wm_qs_w, hunan$GDPPC)   # average of (self + neighbours)\nlag_w_avg_gdppc     \n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, we will convert the lag variable listw object into a data frame by using as.data.frame().\n\n# Convert and join back for tables/maps\nlag.list.wm_qs   &lt;- list(hunan$NAME_3, lag_w_avg_gdppc)        # pair names with values\nlag_wm_qs.res    &lt;- as.data.frame(lag.list.wm_qs)              # to data.frame\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\") # final column names\n\nNote: The third command line on the code chunk above renames the field names of lag_wm_q1.res object into NAME_3 and lag_window_avg GDPPC respectively.\nNext, the code chunk below will be used to append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- dplyr::left_join(hunan, lag_wm_qs.res, by = \"NAME_3\")  # attach to sf\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below:\n\n# Quick table comparing lag (neighbour average) vs window average (self + neighbours average)\nhunan %&gt;%\n  dplyr::select(\"County\", \"lag GDPPC\", \"lag_window_avg GDPPC\") %&gt;%\n  knitr::kable()  \n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.\n\n# Map comparison: lag (avg of neighbours) vs window avg (self+neighbours)\nw_avg_gdppc &lt;- tmap::qtm(hunan, \"lag_window_avg GDPPC\")\ntmap::tmap_arrange(lag_gdppc_m, w_avg_gdppc, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWindow average dampens extremes because each county’s own value is blended with its neighbours’. Border counties with few neighbours change more when we include “self”.\n\n\nNote: For more effective comparison, it is advisable to use the core tmap mapping functions.\n\n\n\n\n# Start from neighbour list that includes self\nwm_qs &lt;- spdep::include.self(wm_q)                                          # ensure self is included\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\n\n# Create binary weights for the self-included list (all ones)\nb_weights_qs  &lt;- lapply(wm_qs, function(x) 0 * x + 1)                       # vector of 1s for each neighbour including self\nb_weights2_qs &lt;- spdep::nb2listw(wm_qs, glist = b_weights_qs, style = \"B\")  # store as raw (binary) weights\nb_weights2_qs                                                               # confirm characteristics\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\n\n# Compute window SUM lag (self + neighbours summed)\nw_sum_gdppc &lt;- list(hunan$NAME_3, spdep::lag.listw(b_weights2_qs, hunan$GDPPC))  # list of names + sums\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)                                    # to data.frame\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")                          # rename to match slide\n\n\nhunan &lt;- dplyr::left_join(hunan, w_sum_gdppc.res, by = \"NAME_3\")                 # attach to sf\n\n\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex04/hand-on_ex04.html#overview",
    "href": "Hands-on_Ex04/hand-on_ex04.html#overview",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to compute spatial weights using R.\nBy the end to this hands-on exercise, we will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\n\nimport csv file using appropriate function of readr package,\n\nperform relational join using appropriate join function of dplyr package,\n\ncompute spatial weights using appropriate functions of spdep package, and calculate spatially lagged variables using appropriate functions of spdep package."
  },
  {
    "objectID": "Hands-on_Ex04/hand-on_ex04.html#the-data",
    "href": "Hands-on_Ex04/hand-on_ex04.html#the-data",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "Two data sets will be used in this hands-on exercise, they are: - Hunan county boundary layer. This is a geospatial data set in ESRI shapefile format. - Hunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n# \"pacman\" automatically installs and loads packages if not already installed.\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex04/hand-on_ex04.html#getting-the-data-into-r-environment",
    "href": "Hands-on_Ex04/hand-on_ex04.html#getting-the-data-into-r-environment",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "# Read the Hunan county polygons as an sf object (modern spatial class)\nhunan &lt;- sf::st_read(dsn = \"data/geospatial\", layer = \"Hunan\")  # dsn = folder, layer = shapefile basename\n\nReading layer `Hunan' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex04/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n# Inspect the basic structure to confirm geometry + fields\nprint(hunan)    # shows feature count, geometry type, CRS, attributes\n\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n     NAME_2  ID_3    NAME_3   ENGTYPE_3 Shape_Leng Shape_Area    County\n1   Changde 21098   Anxiang      County   1.869074 0.10056190   Anxiang\n2   Changde 21100   Hanshou      County   2.360691 0.19978745   Hanshou\n3   Changde 21101    Jinshi County City   1.425620 0.05302413    Jinshi\n4   Changde 21102        Li      County   3.474325 0.18908121        Li\n5   Changde 21103     Linli      County   2.289506 0.11450357     Linli\n6   Changde 21104    Shimen      County   4.171918 0.37194707    Shimen\n7  Changsha 21109   Liuyang County City   4.060579 0.46016789   Liuyang\n8  Changsha 21110 Ningxiang      County   3.323754 0.26614198 Ningxiang\n9  Changsha 21111 Wangcheng      County   2.292093 0.13049161 Wangcheng\n10 Chenzhou 21112     Anren      County   2.240739 0.13343936     Anren\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734...\n\n\n\n\n\n\n# Read county-level attributes (e.g., GDPPC) for 2012\nhunan2012 &lt;- readr::read_csv(\"data/aspatial/Hunan_2012.csv\")   # creates a regular tibble/data.frame\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Peek at columns so we know what to join\ndplyr::glimpse(hunan2012)   # confirms column names such as County, GDPPC, etc.\n\nRows: 88\nColumns: 29\n$ County      &lt;chr&gt; \"Anhua\", \"Anren\", \"Anxiang\", \"Baojing\", \"Chaling\", \"Changn…\n$ City        &lt;chr&gt; \"Yiyang\", \"Chenzhou\", \"Changde\", \"Hunan West\", \"Zhuzhou\", …\n$ avg_wage    &lt;dbl&gt; 30544, 28058, 31935, 30843, 31251, 28518, 54540, 28597, 33…\n$ deposite    &lt;dbl&gt; 10967.0, 4598.9, 5517.2, 2250.0, 8241.4, 10860.0, 24332.0,…\n$ FAI         &lt;dbl&gt; 6831.7, 6386.1, 3541.0, 1005.4, 6508.4, 7920.0, 33624.0, 1…\n$ Gov_Rev     &lt;dbl&gt; 456.72, 220.57, 243.64, 192.59, 620.19, 769.86, 5350.00, 1…\n$ Gov_Exp     &lt;dbl&gt; 2703.0, 1454.7, 1779.5, 1379.1, 1947.0, 2631.6, 7885.5, 11…\n$ GDP         &lt;dbl&gt; 13225.0, 4941.2, 12482.0, 4087.9, 11585.0, 19886.0, 88009.…\n$ GDPPC       &lt;dbl&gt; 14567, 12761, 23667, 14563, 20078, 24418, 88656, 10132, 17…\n$ GIO         &lt;dbl&gt; 9276.90, 4189.20, 5108.90, 3623.50, 9157.70, 37392.00, 513…\n$ Loan        &lt;dbl&gt; 3954.90, 2555.30, 2806.90, 1253.70, 4287.40, 4242.80, 4053…\n$ NIPCR       &lt;dbl&gt; 3528.3, 3271.8, 7693.7, 4191.3, 3887.7, 9528.0, 17070.0, 3…\n$ Bed         &lt;dbl&gt; 2718, 970, 1931, 927, 1449, 3605, 3310, 582, 2170, 2179, 1…\n$ Emp         &lt;dbl&gt; 494.310, 290.820, 336.390, 195.170, 330.290, 548.610, 670.…\n$ EmpR        &lt;dbl&gt; 441.4, 255.4, 270.5, 145.6, 299.0, 415.1, 452.0, 127.6, 21…\n$ EmpRT       &lt;dbl&gt; 338.0, 99.4, 205.9, 116.4, 154.0, 273.7, 219.4, 94.4, 174.…\n$ Pri_Stu     &lt;dbl&gt; 54.175, 33.171, 19.584, 19.249, 33.906, 81.831, 59.151, 18…\n$ Sec_Stu     &lt;dbl&gt; 32.830, 17.505, 17.819, 11.831, 20.548, 44.485, 39.685, 7.…\n$ Household   &lt;dbl&gt; 290.4, 104.6, 148.1, 73.2, 148.7, 211.2, 300.3, 76.1, 139.…\n$ Household_R &lt;dbl&gt; 234.5, 121.9, 135.4, 69.9, 139.4, 211.7, 248.4, 59.6, 110.…\n$ NOIP        &lt;dbl&gt; 101, 34, 53, 18, 106, 115, 214, 17, 55, 70, 44, 84, 74, 17…\n$ Pop_R       &lt;dbl&gt; 670.3, 243.2, 346.0, 184.1, 301.6, 448.2, 475.1, 189.6, 31…\n$ RSCG        &lt;dbl&gt; 5760.60, 2386.40, 3957.90, 768.04, 4009.50, 5220.40, 22604…\n$ Pop_T       &lt;dbl&gt; 910.8, 388.7, 528.3, 281.3, 578.4, 816.3, 998.6, 256.7, 45…\n$ Agri        &lt;dbl&gt; 4942.253, 2357.764, 4524.410, 1118.561, 3793.550, 6430.782…\n$ Service     &lt;dbl&gt; 5414.5, 3814.1, 14100.0, 541.8, 5444.0, 13074.6, 17726.6, …\n$ Disp_Inc    &lt;dbl&gt; 12373, 16072, 16610, 13455, 20461, 20868, 183252, 12379, 1…\n$ RORP        &lt;dbl&gt; 0.7359464, 0.6256753, 0.6549309, 0.6544614, 0.5214385, 0.5…\n$ ROREmp      &lt;dbl&gt; 0.8929619, 0.8782065, 0.8041262, 0.7460163, 0.9052651, 0.7…\n\n\n\n\n\n\n# Left join: keep all polygons and bring matching columns from hunan2012 by common key(s)\nhunan &lt;- dplyr::left_join(hunan, hunan2012) %&gt;%   # merge attributes into polygons\n  dplyr::select(1:4, 7, 15)      # reproduce Prof’s column subset (indices from slides)\n\nJoining with `by = join_by(County)`\n\n# Inspect and verify that GDPPC is now present alongside geometry\nhead(hunan)   # should list fields incl. County, GDPPC, geometry\n\nSimple feature collection with 6 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667\n2 Changde 21100 Hanshou      County Hanshou 20981\n3 Changde 21101  Jinshi County City  Jinshi 34592\n4 Changde 21102      Li      County      Li 24473\n5 Changde 21103   Linli      County   Linli 25554\n6 Changde 21104  Shimen      County  Shimen 27137\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675..."
  },
  {
    "objectID": "Hands-on_Ex04/hand-on_ex04.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex04/hand-on_ex04.html#visualising-regional-development-indicator",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "# Prepare a simple basemap with names (quick tmap)\nbasemap &lt;- tmap::tm_shape(hunan) +                        # tell tmap what to draw (the polygons)\n  tmap::tm_polygons() +                                   # draw filled polygons\n  tmap::tm_text(\"NAME_3\", size = 0.5)                     # label polygons with county names (field matches slides)\n\n# Choropleth of GDPPC \ngdppc_map &lt;- tmap::qtm(hunan, \"GDPPC\") +                  # quick thematic map of GDPPC\n  tmap::tm_layout(legend.position = c(\"left\", \"bottom\"))  # put legend bottom-left to match the slides\n\n# Show basemap and GDPPC side-by-side\ntmap::tmap_arrange(basemap, gdppc_map, asp = 1, ncol = 2) # arrange 2 maps in one row, square aspect"
  },
  {
    "objectID": "Hands-on_Ex04/hand-on_ex04.html#contiguity-spatial-weights-queen-and-rook",
    "href": "Hands-on_Ex04/hand-on_ex04.html#contiguity-spatial-weights-queen-and-rook",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "In this section, we will learn how to use poly2nb() of spdep package to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If we look at the documentation, we will see that we can pass a “queen” argument that takes TRUE or FALSE as options. If we do not specify this argument the default is set to TRUE, that is, if we don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\n\n\n\n# Build a neighbours list where polygons touching at edges OR corners are neighbours\nwm_q &lt;- spdep::poly2nb(hunan, queen = TRUE)    # queen = TRUE includes corner touches\nsummary(wm_q)   # prints number of regions, links, and link distribution\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n# Explore neighbours of polygon 1 (IDs are row positions of neighbours)\nwm_q[[1]]   # e.g., returns integer vector like c(2, 3, 4, 57, 85)\n\n[1]  2  3  4 57 85\n\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\n\nWe can retrieve the county name of Polygon ID=1 by using the code chunk below:\n\n# Retrieve county name for polygon ID = 1\nhunan$County[1]   # should print the county name for ID 1\n\n[1] \"Anxiang\"\n\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\n\nTo reveal the county names of the five neighboring polygons, the code chunk will be used:\n\n# Retrieve the county names of polygon 1’s neighbours\nhunan$NAME_3[c(2, 3, 4, 57, 85)]    # show human-readable names for the neighbour IDs\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these five countries by using the code chunk below:\n\n# Pull the neighbours’ GDPPC values for polygon 1\nnb1_ids  &lt;- wm_q[[1]]               # save neighbour indices for clarity\nnb1_gdppc &lt;- hunan$GDPPC[nb1_ids]   # vector of GDPPC values for those neighbours\nnb1_gdppc                           # print to compare with slide values\n\n[1] 20981 34592 24473 21311 22879\n\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.\n\nWe can display the complete weight matrix by using str().\n\n# View the full list structure (long print, but matches slide)\nstr(wm_q)   # shows, for each region, the integer IDs of its neighbours\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language spdep::poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"snap\")= num 9e-08\n - attr(*, \"sym\")= logi TRUE\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : num 1\n  ..$ comp.id: num [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\nBe warned: The output might cut across several pages. Save the trees if we are going to print out the report.\n\n\n\n\n# Build neighbours list where polygons are neighbours only if they share an EDGE (no corner-only)\nwm_r &lt;- spdep::poly2nb(hunan, queen = FALSE)  # rook definition\nsummary(wm_r)                                 # compare to queen: usually slightly fewer links\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connect area unit has 10 neighbours. There are two area units with only one heighbours.\n\n\n\n\n\n# Compute polygon centroids for plotting the graph over the map\n# We extract numeric (lon, lat) from the POINT geometry returned by st_centroid()\nlongitude &lt;- purrr::map_dbl(hunan$geometry, ~ sf::st_centroid(.x)[[1]])  # [[1]] = x (lon)\nlatitude  &lt;- purrr::map_dbl(hunan$geometry, ~ sf::st_centroid(.x)[[2]])  # [[2]] = y (lat)\ncoords    &lt;- cbind(longitude, latitude)                                  # combine into a two-column matrix as required by spdep\nhead(coords)                                                             # quick check\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n\n\n# Plot: Queen contiguity graph\nplot(hunan$geometry, border = \"lightgrey\")                       # draw county outlines\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\") # overlay neighbour links + nodes in red\n\n\n\n\n\n\n\n\n\n\n\n\n# Plot: Rook contiguity graph\nplot(hunan$geometry, border = \"lightgrey\")                       # reset blank map\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\") # overlay rook links\n\n\n\n\n\n\n\n\n\n\n\n\n# Side-by-side comparison (Queen vs Rook)\npar(mfrow = c(1, 2))    # 1 row, 2 plots\nplot(hunan$geometry, border = \"lightgrey\", main = \"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\nplot(hunan$geometry, border = \"lightgrey\", main = \"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))    # reset layout"
  },
  {
    "objectID": "Hands-on_Ex04/hand-on_ex04.html#distance-based-neighbours",
    "href": "Hands-on_Ex04/hand-on_ex04.html#distance-based-neighbours",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "In this section, we will learn how to derive distance-based weight matrices by using dnearneigh() of spdep package.\nThe function identifies neighbours of region points by Euclidean distance with a distance band with lower d1= and upper d2= bounds controlled by the bounds= argument. If unprojected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and longlat=TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\n\n\n\n# 1) Compute first-nearest neighbours (1-NN) from the centroid coordinates\nk1 &lt;- spdep::knn2nb(spdep::knearneigh(coords))  # returns an nb object where each region has 1 NN\n\nWarning in spdep::knn2nb(spdep::knearneigh(coords)): neighbour object has 25\nsub-graphs\n\n\n\n# 2) Get the distances of those NN relationships (in km if longlat = TRUE)\nk1dists &lt;- unlist(spdep::nbdists(k1, coords, longlat = TRUE)) # lengths of the 88 NN edges as a numeric vector\n\n\n# 3) Summarise to find a safe upper bound for a distance band\nsummary(k1dists)   # Max ≈ 61.79 km in the slide → choose 62 km as cutoff\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n\n\n\n# Build neighbours where ANY pair of centroids within 62 km are linked\nwm_d62 &lt;- spdep::dnearneigh(coords, d1 = 0, d2 = 62, longlat = TRUE)  # 0 lower bound; 62 km upper bound from previous step\nwm_d62                                                                # print nb object summary like in slide\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\n\n\n\n\n\nNoteQuiz:\n\n\n\nWhat does “Average number of links: 3.681818” mean?\nOn average, each region has ~3.682 neighbours under the 62 km rule. Numerically, it equals total_links / number_of_regions = 324 / 88 ≈ 3.681818.\n\n\n\n# Show the internal list structure (optional)\nstr(wm_d62)   # each element lists neighbour indices for that region\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language spdep::dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : num 1\n  ..$ comp.id: num [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep.\n\n# Cross-tab: how many regions have 1, 2, 3, ... neighbours under 62 km?\ntable(hunan$County, spdep::card(wm_d62))   # card() = neighbour count (degree) for each region\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\n# Connected components check: is the graph fully connected?\nn_comp &lt;- spdep::n.comp.nb(wm_d62)  # counts connected subgraphs\nn_comp$nc                           # should be 1 = fully connected (as in slide)\n\n[1] 1\n\ntable(n_comp$comp.id)               # how many nodes in each component (expect 88 in id=1)\n\n\n 1 \n88 \n\n\n\n\nNow, we will plot the distance weight matrix by using the code chunk below.\n\n# Plot fixed-distance links (black) and 1-NN links (red) on top of the map\nplot(hunan$geometry, border = \"lightgrey\")                 # outline map\nplot(wm_d62, coords, add = TRUE)                           # distance-band neighbours (default black)\nplot(k1, coords, add = TRUE, col = \"red\", length = 0.08)   # 1-NN links in red with short arrowheads\n\n\n\n\n\n\n\n\n\n# Side-by-side: 1-NN vs distance band\npar(mfrow = c(1, 2))\nplot(hunan$geometry, border = \"lightgrey\", main = \"1st nearest neighbours\")\nplot(k1, coords, add = TRUE, col = \"red\", length = 0.08)\nplot(hunan$geometry, border = \"lightgrey\", main = \"Distance link (&lt;=62 km)\")\nplot(wm_d62, coords, add = TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\n\n\n\n\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\n# Force exactly k neighbours per region (here k = 6 per the slide)\nknn6 &lt;- spdep::knn2nb(spdep::knearneigh(coords, k = 6))    # asymmetric possible (A near B not equal B near A)\nknn6                                                       # prints summary: \"Average number of links: 6\"\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nSimilarly, we can display the content of the matrix by using str().\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language spdep::knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : num 1\n  ..$ comp.id: num [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\n\nWe can plot the weight matrix using the code chunk below.\n\n# Visualise the kNN(6) graph\nplot(hunan$geometry, border = \"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex04/hand-on_ex04.html#weights-based-on-inverse-distance-idw-on-queen-neighbours",
    "href": "Hands-on_Ex04/hand-on_ex04.html#weights-based-on-inverse-distance-idw-on-queen-neighbours",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "In this section, we will learn how to derive a spatial weight matrix based on Inversed Distance method.\n\n# Compute distances ONLY for pairs that are QUEEN neighbours (wm_q) to avoid all-pairs blow-up\ndist_q &lt;- spdep::nbdists(wm_q, coords, longlat = TRUE)  # a list: element i contains distances to i's neighbours\nids    &lt;- lapply(dist_q, function(x) 1 / (x))           # convert distances to inverse-distance weights\nids    # print few entries to match slide’s example\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034"
  },
  {
    "objectID": "Hands-on_Ex04/hand-on_ex04.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex04/hand-on_ex04.html#row-standardised-weights-matrix",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "Next, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\n# Build a row-standardised (style=\"W\") weights list from Queen neighbours\n# Each neighbour gets equal weight so that each row sums to 1 (average of neighbours).\nrswm_q &lt;- spdep::nb2listw(wm_q, style = \"W\", zero.policy = TRUE)   # zero.policy=TRUE avoids errors if any lonely nodes\nrswm_q    # shows \"Weights style: W\" + summary\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n# Inspect weights for a specific polygon (example in slide used index 10)\nrswm_q$weights[[10]]   # e.g., 8 neighbours → each weight = 1/8 = 0.125\n\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\n\n# Row-standardised distance weights using the inverse-distance 'glist' (Professor used style=\"B\" list)\nrswm_ids &lt;- spdep::nb2listw(wm_q, glist = ids, style = \"B\", zero.policy = TRUE)  # weights stored as provided (not re-scaled to 1)\nrswm_ids    # print characteristics; style B = basic weights\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\n# Summarise the distribution of all (unstandardised) IDW weights\nsummary(unlist(rswm_ids$weights))   # min/median/mean/... like the slide\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "Hands-on_Ex04/hand-on_ex04.html#applications-of-the-spatial-weight-matrix",
    "href": "Hands-on_Ex04/hand-on_ex04.html#applications-of-the-spatial-weight-matrix",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "In this section, we will learn how to create four different spatial lagged variables, they are: - spatial lag with row-standardized weights, - spatial lag as a sum of neighbouring values, - spatial window average, and - spatial window sum.\n\n\n\n# Compute spatial lag of GDPPC using row-standardised W (this is the neighbours' AVERAGE GDPPC)\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag    # matches slide numbers order\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nRecalled in the previous section, we retrieved the GDPPC of these five countries by using the code chunk below:\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\n\n\n\n\n\nNoteQuestion:\n\n\n\nCan you see the meaning of Spatial lag with row-standardized weights now?\n\nWith row-standardised W, each neighbour gets weight 1 / (#neighbours).\n\nlag GDPPC is therefore the average GDPPC of each county’s neighbours, not its own GDPPC.\n\nHigh values in a county surrounded by high-GDPPC neighbours turn the lag map dark even if the county’s own GDPPC is modest, and vice versa.\n\n\n\nWe can append the spatially lag GDPPC values onto hunan sf data frame by using the code chunk below:\n\n# Append lag column back to sf for mapping and tabulation\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below:\n\n# Map: GDPPC vs lag(GDPPC) side-by-side for visual comparison\ngdppc_map   &lt;- tmap::qtm(hunan, \"GDPPC\")       # original values\nlag_gdppc_m &lt;- tmap::qtm(hunan, \"lag GDPPC\")   # neighbour average\ntmap::tmap_arrange(gdppc_map, lag_gdppc_m, asp = 1, ncol = 2) # compare patterns\n\n\n\n\n\n\n\n\n\n\n\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply, which we have been using to manipulate the neighbors structure throughout the past notebooks. Basically it applies a function across each value in the neighbors structure.\n\n# Build a \"binary\" weights list (each neighbour = 1), still using the Queen neighbours\nb_weights  &lt;- lapply(wm_q, function(x) 0 * x + 1)                    # for each neighbour ID vector, make a same-length vector of 1s\nb_weights2 &lt;- spdep::nb2listw(wm_q, glist = b_weights, style = \"B\")  # store those 1s as raw weights (no row standardisation)\nb_weights2                                                           # check characteristics (Weights style: B)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\n\n# Compute the spatial lag as a SUM of neighbour GDPPC (not an average)\nlag_sum &lt;- list(hunan$NAME_3, spdep::lag.listw(b_weights2, hunan$GDPPC))  # returns the summed values, paired with names\nlag.res &lt;- as.data.frame(lag_sum)                                         # convert list → data.frame\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")                         # name columns as in slide\n\nLet’s investigate the result by using the code chunck below:\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\n\n\n\n\n\n\nNoteQuestion:\n\n\n\nCan you understand the meaning of Spatial lag as a sum of neighboring values now?\nlag_sum GDPPC is the total GDPPC of neighbours, so counties with many neighbours (or neighbours with large GDPPC) stand out more than in the averaged lag.\n\n\nNext, we will append the lag_sum GDPPC field into hunan sf data frame by using the code chunk below.\n\nhunan &lt;- dplyr::left_join(hunan, lag.res, by = \"NAME_3\")   \n\nNow, we can plot both the GDPPC and Spatial Lag Sum GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- spdep::include.self(wm_q)    # neighbour list with self included\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNotice that the Number of nonzero links, Percentage nonzero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909\nLet us take a good look at the neighbour list of area [1] by using the code chunk below:\n\nwm_qs[[1]]  # first county now lists itself plus prior neighbours\n\n[1]  1  2  3  4 57 85\n\n\nNotice that now [1] has six neighbours instead of five.\nNow we obtain weights with nb2listw()\n\n# Convert to weights (row-standardised) so we compute an average including self\nwm_qs_w &lt;- spdep::nb2listw(wm_qs)                                               # default style = \"W\" (row-standardised) on the expanded list\nwm_qs_w   \n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable.\n\n# Compute window-average lag of GDPPC (includes county itself in the mean)\nlag_w_avg_gdppc &lt;- spdep::lag.listw(wm_qs_w, hunan$GDPPC)   # average of (self + neighbours)\nlag_w_avg_gdppc     \n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, we will convert the lag variable listw object into a data frame by using as.data.frame().\n\n# Convert and join back for tables/maps\nlag.list.wm_qs   &lt;- list(hunan$NAME_3, lag_w_avg_gdppc)        # pair names with values\nlag_wm_qs.res    &lt;- as.data.frame(lag.list.wm_qs)              # to data.frame\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\") # final column names\n\nNote: The third command line on the code chunk above renames the field names of lag_wm_q1.res object into NAME_3 and lag_window_avg GDPPC respectively.\nNext, the code chunk below will be used to append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- dplyr::left_join(hunan, lag_wm_qs.res, by = \"NAME_3\")  # attach to sf\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below:\n\n# Quick table comparing lag (neighbour average) vs window average (self + neighbours average)\nhunan %&gt;%\n  dplyr::select(\"County\", \"lag GDPPC\", \"lag_window_avg GDPPC\") %&gt;%\n  knitr::kable()  \n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.\n\n# Map comparison: lag (avg of neighbours) vs window avg (self+neighbours)\nw_avg_gdppc &lt;- tmap::qtm(hunan, \"lag_window_avg GDPPC\")\ntmap::tmap_arrange(lag_gdppc_m, w_avg_gdppc, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWindow average dampens extremes because each county’s own value is blended with its neighbours’. Border counties with few neighbours change more when we include “self”.\n\n\nNote: For more effective comparison, it is advisable to use the core tmap mapping functions.\n\n\n\n\n# Start from neighbour list that includes self\nwm_qs &lt;- spdep::include.self(wm_q)                                          # ensure self is included\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\n\n# Create binary weights for the self-included list (all ones)\nb_weights_qs  &lt;- lapply(wm_qs, function(x) 0 * x + 1)                       # vector of 1s for each neighbour including self\nb_weights2_qs &lt;- spdep::nb2listw(wm_qs, glist = b_weights_qs, style = \"B\")  # store as raw (binary) weights\nb_weights2_qs                                                               # confirm characteristics\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\n\n# Compute window SUM lag (self + neighbours summed)\nw_sum_gdppc &lt;- list(hunan$NAME_3, spdep::lag.listw(b_weights2_qs, hunan$GDPPC))  # list of names + sums\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)                                    # to data.frame\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")                          # rename to match slide\n\n\nhunan &lt;- dplyr::left_join(hunan, w_sum_gdppc.res, by = \"NAME_3\")                 # attach to sf\n\n\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "In-Class_Ex04/in-class_ex04.html",
    "href": "In-Class_Ex04/in-class_ex04.html",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel method",
    "section": "",
    "text": "Using the step we leanred from previous hands-in, install and load the necessary R packages in R environment.\n\npacman::p_load(sf, ggstatsplot, tmap, tidyverse, knitr, GWmodel)"
  },
  {
    "objectID": "In-Class_Ex04/in-class_ex04.html#loading-the-package",
    "href": "In-Class_Ex04/in-class_ex04.html#loading-the-package",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel method",
    "section": "",
    "text": "Using the step we leanred from previous hands-in, install and load the necessary R packages in R environment.\n\npacman::p_load(sf, ggstatsplot, tmap, tidyverse, knitr, GWmodel)"
  },
  {
    "objectID": "In-Class_Ex04/in-class_ex04.html#preparing-the-data",
    "href": "In-Class_Ex04/in-class_ex04.html#preparing-the-data",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel method",
    "section": "Preparing the Data",
    "text": "Preparing the Data\nUsing the steps we learned from previous hands-on, complete the following tasks:\n\nimport Hunan shapefile and parse it into a sf polygon feature object.\n\nimport Hunan_2012.csv file parse it into a tibble data.frame.\n\njoin Hunan and Hunan_2012 data.frames.\n\n\nImporting Hunan shapefile\n\nhunan_sf &lt;- st_read(dsn = \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex04/data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex04/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nImporting Hunan 2012 table\n\n# hunan2012 &lt;- read_csv(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex04/data/aspatial/Hunan_2012.csv\")\n\nhunan2012 &lt;- read.csv(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex04/data/aspatial/Hunan_2012.csv\",\n                      stringsAsFactors = FALSE, check.names = FALSE)\n\n\n\nJoining Hunan and Hunan_2012\n\nhunan_sf &lt;- left_join(hunan_sf, hunan2012) %&gt;%\n  select(1:3, 7, 15, 16, 31, 32)"
  },
  {
    "objectID": "In-Class_Ex04/in-class_ex04.html#mapping-gdppc",
    "href": "In-Class_Ex04/in-class_ex04.html#mapping-gdppc",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel method",
    "section": "Mapping GDPPC",
    "text": "Mapping GDPPC\nUsing the steps we learned from Hands-on Exercise 5, prepare a choropleth map showing the geographic distribution of GDPPC of Hunan Province.\n\nbasemap &lt;- tm_shape(hunan_sf) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc &lt;- qtm(hunan_sf, \"GDPPC\")\n\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "In-Class_Ex04/in-class_ex04.html#converting-to-spatialpolygondataframe",
    "href": "In-Class_Ex04/in-class_ex04.html#converting-to-spatialpolygondataframe",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel method",
    "section": "Converting to SpatialPolygonDataFrame",
    "text": "Converting to SpatialPolygonDataFrame\nNote: GWmodel presently is built around the older sp and not sf formats for handling spatial data in R.\n\nhunan_sp &lt;- hunan_sf %&gt;%\n  as_Spatial()"
  },
  {
    "objectID": "In-Class_Ex04/in-class_ex04.html#geographically-weighted-summary-statistics-with-adaptive-bandwidth",
    "href": "In-Class_Ex04/in-class_ex04.html#geographically-weighted-summary-statistics-with-adaptive-bandwidth",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel method",
    "section": "Geographically Weighted Summary Statistics with adaptive bandwidth",
    "text": "Geographically Weighted Summary Statistics with adaptive bandwidth\n\nDetermine adaptive bandwidth\n\nCross-validation\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1, \n             data = hunan_sp,\n             approach = \"CV\",\n             adaptive = TRUE, \n             kernel = \"bisquare\", \n             longlat = T)\n\nAdaptive bandwidth: 62 CV score: 15515442343 \nAdaptive bandwidth: 46 CV score: 14937956887 \nAdaptive bandwidth: 36 CV score: 14408561608 \nAdaptive bandwidth: 29 CV score: 14198527496 \nAdaptive bandwidth: 26 CV score: 13898800611 \nAdaptive bandwidth: 22 CV score: 13662299974 \nAdaptive bandwidth: 22 CV score: 13662299974 \n\nbw_CV\n\n[1] 22\n\n\n\n\nAIC\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1, \n             data = hunan_sp,\n             approach =\"AIC\",\n             adaptive = TRUE, \n             kernel = \"bisquare\", \n             longlat = T)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\nbw_AIC\n\n[1] 22\n\n\n\n\n\nComputing geographically wieghted summary statistics\n\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T)\n\n\n\nPreparing the output data\nCode chunk below is used to extract SDF data table from gwss object output from gwss(). It will be converted into data.frame by using as.data.frame().\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\n\nNext, cbind() is used to append the newly derived data.frame onto hunan_sf sf data.frame.\n\nhunan_gstat &lt;- cbind(hunan_sf, gwstat_df)\n\n\n\nVisualising geographically weighted summary statistic\n\ntm_shape(hunan_gstat) +\n  tm_fill(\"GDPPC_LM\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Distribution of geographically wieghted mean\",\n            main.title.position = \"center\",\n            main.title.size = 2.0,\n            legend.text.size = 1.2,\n            legend.height = 1.50, \n            legend.width = 1.50,\n            frame = TRUE)"
  },
  {
    "objectID": "In-Class_Ex04/in-class_ex04.html#geographically-weighted-summary-statistics-with-fixed",
    "href": "In-Class_Ex04/in-class_ex04.html#geographically-weighted-summary-statistics-with-fixed",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel method",
    "section": "Geographically Weighted Summary Statistics with fixed",
    "text": "Geographically Weighted Summary Statistics with fixed\n\nDetermine fixed bandwodth\n\nCross-validation\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1, \n             data = hunan_sp,\n             approach = \"CV\",\n             adaptive = FALSE, \n             kernel = \"bisquare\", \n             longlat = T)\n\nFixed bandwidth: 357.4897 CV score: 16265191728 \nFixed bandwidth: 220.985 CV score: 14954930931 \nFixed bandwidth: 136.6204 CV score: 14134185837 \nFixed bandwidth: 84.48025 CV score: 13693362460 \nFixed bandwidth: 52.25585 CV score: Inf \nFixed bandwidth: 104.396 CV score: 13891052305 \nFixed bandwidth: 72.17162 CV score: 13577893677 \nFixed bandwidth: 64.56447 CV score: 14681160609 \nFixed bandwidth: 76.8731 CV score: 13444716890 \nFixed bandwidth: 79.77877 CV score: 13503296834 \nFixed bandwidth: 75.07729 CV score: 13452450771 \nFixed bandwidth: 77.98296 CV score: 13457916138 \nFixed bandwidth: 76.18716 CV score: 13442911302 \nFixed bandwidth: 75.76323 CV score: 13444600639 \nFixed bandwidth: 76.44916 CV score: 13442994078 \nFixed bandwidth: 76.02523 CV score: 13443285248 \nFixed bandwidth: 76.28724 CV score: 13442844774 \nFixed bandwidth: 76.34909 CV score: 13442864995 \nFixed bandwidth: 76.24901 CV score: 13442855596 \nFixed bandwidth: 76.31086 CV score: 13442847019 \nFixed bandwidth: 76.27264 CV score: 13442846793 \nFixed bandwidth: 76.29626 CV score: 13442844829 \nFixed bandwidth: 76.28166 CV score: 13442845238 \nFixed bandwidth: 76.29068 CV score: 13442844678 \nFixed bandwidth: 76.29281 CV score: 13442844691 \nFixed bandwidth: 76.28937 CV score: 13442844698 \nFixed bandwidth: 76.2915 CV score: 13442844676 \nFixed bandwidth: 76.292 CV score: 13442844679 \nFixed bandwidth: 76.29119 CV score: 13442844676 \nFixed bandwidth: 76.29099 CV score: 13442844676 \nFixed bandwidth: 76.29131 CV score: 13442844676 \nFixed bandwidth: 76.29138 CV score: 13442844676 \nFixed bandwidth: 76.29126 CV score: 13442844676 \nFixed bandwidth: 76.29123 CV score: 13442844676 \n\nbw_CV \n\n[1] 76.29126\n\n\n\n\nAIC\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1, \n             data = hunan_sp,\n             approach =\"AIC\",\n             adaptive = FALSE, \n             kernel = \"bisquare\", \n             longlat = T)\n\nFixed bandwidth: 357.4897 AICc value: 1927.631 \nFixed bandwidth: 220.985 AICc value: 1921.547 \nFixed bandwidth: 136.6204 AICc value: 1919.993 \nFixed bandwidth: 84.48025 AICc value: 1940.603 \nFixed bandwidth: 168.8448 AICc value: 1919.457 \nFixed bandwidth: 188.7606 AICc value: 1920.007 \nFixed bandwidth: 156.5362 AICc value: 1919.41 \nFixed bandwidth: 148.929 AICc value: 1919.527 \nFixed bandwidth: 161.2377 AICc value: 1919.392 \nFixed bandwidth: 164.1433 AICc value: 1919.403 \nFixed bandwidth: 159.4419 AICc value: 1919.393 \nFixed bandwidth: 162.3475 AICc value: 1919.394 \nFixed bandwidth: 160.5517 AICc value: 1919.391 \n\nbw_AIC\n\n[1] 160.5517\n\n\n\n\n\nComputing adaptive bandwidth\n\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC,\n               kernel = \"bisquare\",\n               adaptive = FALSE,\n               longlat = T)\n\n\n\nPreparing the output data\nCode chunk below is used to extract SDF data table from gwss object output from gwss(). It will be converted into data.frame by using as.data.frame().\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\n\nNext, cbind() is used to append the newly derived data.frame onto hunan_sf sf data.frame.\n\nhunan_gstat &lt;- cbind(hunan_sf, gwstat_df)\n\n\n\nVisualising geographically weighted summary statistics\n\ntm_shape(hunan_gstat) +\n  tm_fill(\"GDPPC_LM\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Distribution of geographically wieghted mean\",\n            main.title.position = \"center\",\n            main.title.size = 2.0,\n            legend.text.size = 1.2,\n            legend.height = 1.50, \n            legend.width = 1.50,\n            frame = TRUE)"
  },
  {
    "objectID": "In-Class_Ex04/in-class_ex04.html#geographically-weighted-correlation-with-adaptive-bandwidth",
    "href": "In-Class_Ex04/in-class_ex04.html#geographically-weighted-correlation-with-adaptive-bandwidth",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel method",
    "section": "Geographically Weighted Correlation with Adaptive Bandwidth",
    "text": "Geographically Weighted Correlation with Adaptive Bandwidth\nBusiness question: Is there any relationship between GDP per capita and Gross Industry Output?\n\nConventional statistical solution\n\nggscatterstats(\n  data = hunan2012, \n  x = Agri, \n  y = GDPPC,\n  xlab = \"Gross Agriculture Output\", ## label for the x-axis\n  ylab = \"GDP per capita\", \n  label.var = County, \n  label.expression = Agri &gt; 10000 & GDPPC &gt; 50000, \n  point.label.args = list(alpha = 0.7, size = 4, color = \"grey50\"),\n  xfill = \"#CC79A7\", \n  yfill = \"#009E73\", \n  title = \"Relationship between GDP PC and Gross Agriculture Output\")\n\n\n\n\n\n\n\n\n\n\nGeospatial analytics solution\n\nDetermine the bandwidth\n\nbw &lt;- bw.gwr(GDPPC ~ GIO, \n             data = hunan_sp, \n             approach = \"AICc\", \n             adaptive = TRUE)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1870.235 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1870.852 \nAdaptive bandwidth (number of nearest neighbours): 72 AICc value: 1869.744 \nAdaptive bandwidth (number of nearest neighbours): 78 AICc value: 1869.713 \nAdaptive bandwidth (number of nearest neighbours): 82 AICc value: 1869.604 \nAdaptive bandwidth (number of nearest neighbours): 84 AICc value: 1869.537 \nAdaptive bandwidth (number of nearest neighbours): 86 AICc value: 1869.647 \nAdaptive bandwidth (number of nearest neighbours): 83 AICc value: 1869.567 \nAdaptive bandwidth (number of nearest neighbours): 84 AICc value: 1869.537 \n\n\n\n\nComputing gwCorrelation\n\ngwstats &lt;- gwss(hunan_sp, \n                vars = c(\"GDPPC\", \"GIO\"), \n                bw = bw,\n                kernel = \"bisquare\",\n                adaptive = TRUE, \n                longlat = T)\n\n\n\nExtracting the result\nCode chunk below is used to extract SDF data table from gwss object output from gwss(). It will be converted into data.frame by using as.data.frame().\n\ngwstat_df &lt;- as.data.frame(gwstats$SDF) %&gt;%\n  select(c(12,13)) %&gt;%\n  rename(gwCorr = Corr_GDPPC.GIO,\n         gwSpearman = Spearman_rho_GDPPC.GIO)\n\nNext, cbind() is used to append the newly derived data.frame onto hunan_sf sf data.frame.\n\nhunan_Corr &lt;- cbind(hunan_sf, gwstat_df)\n\n\n\nVisualising Local Correlation\n\ntm_shape(hunan_Corr) +\n  tm_polygons(fill = \"gwSpearman\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                title = \"local Spearman Rho\")) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Local Spearman Rho\", \n  size = 2.0) +\n  tm_layout(frame = TRUE)\n\n\n\n\n\n\n\n\nReferences\n\nBrunsdon, C. et. al. (2002) “Geographically weighted summary statistics - a framework for localised exploratory data analysis”, Computer, Environment and Urban Systems, Vol 26, pp. 501-525. Available as e-journal, SMU library.\nHarris, P. & Brunsdon, C. (2010) “Exploring spatial variation and spatial relationships in freshwater acidification critical load data set for Great Britain using geographically weighted summary statistics”, Computers & Geosciences, Vol. 36, pp. 54-70. Available as e-journal, SMU library."
  },
  {
    "objectID": "Hands-on_Ex02/Hand-on_Ex02.html",
    "href": "Hands-on_Ex02/Hand-on_Ex02.html",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "The specific questions we would like to answer are as follows:\n\nAre the childcare centres in Singapore randomly distributed throughout the country?\nIf the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?\n\n\n\n\n\n# Install 'pacman' once if you do not have it (uncomment next line and run only once)\n# install.packages(\"pacman\")\n\n# Use pacman::p_load() to install (if needed) and then load the listed packages automatically\npacman::p_load(\n  sf,            # modern vector geospatial data handling (Simple Features)\n  terra,         # modern raster + vector geospatial data handling\n  spatstat,      # meta‑package: tools for spatial point pattern analysis (SPPA)\n  tmap,          # cartographic and interactive mapping\n  rvest,         # web‑scraping helper used here to parse HTML inside KML attributes\n  tidyverse      # data wrangling helpers (dplyr, purrr, stringr, readr, etc.)\n)\n\n\n\n\nImport the Master Plan 2019 Subzone (No Sea) polygons as sf and set projection to EPSG:3414 (SVY21 / Singapore TM)\n\n# Read the subzone boundary KML into an sf object named 'mpsz_sf'\nmpsz_sf &lt;- sf::st_read(\"data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\") %&gt;%\n  sf::st_zm(drop = TRUE, what = \"ZM\") %&gt;%  # remove Z (elevation) and M (measure) dimensions to keep 2D only\n  sf::st_transform(crs = 3414)   \n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex02/Data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nWhy remove Z/M? Our analysis is purely 2D on a planar map. Extra dimensions are unnecessary and can break some operations.\nWhy EPSG:3414? This is the standard projected system for Singapore. Distances/areas become meaningful (meters) instead of degrees.\n\nExtract REGION_N, PLN_AREA_N, SUBZONE_N, SUBZONE_C from the Description field (HTML inside KML) (as in the guidance helper function)\n\n# Define a small helper function to pull one named item from the HTML table stored in the 'Description' field\nextract_kml_field &lt;- function(html_text, field_name) {\n  if (is.na(html_text) || html_text == \"\") return(NA_character_) # if Description is empty, return NA immediately\n\n  page &lt;- rvest::read_html(html_text)       # parse the HTML string\n  rows &lt;- rvest::html_elements(page, \"tr\")  # get all table rows (&lt;tr&gt;)\n\n  # Find the row whose header cell (&lt;th&gt;) equals the field_name, then take the value in its &lt;td&gt;\n  value &lt;- rows %&gt;%\n    purrr::keep(~ rvest::html_text2(rvest::html_element(.x, \"th\")) == field_name) %&gt;%\n    rvest::html_element(\"td\") %&gt;%\n    rvest::html_text2()\n\n  if (length(value) == 0) NA_character_ else value    # if not found, return NA\n}\n\n\n# Apply the function to build clean attributes from 'Description'\nmpsz_sf &lt;- mpsz_sf %&gt;%\n  dplyr::mutate(\n    REGION_N   = purrr::map_chr(Description, extract_kml_field, \"REGION_N\"),   # region name\n    PLN_AREA_N = purrr::map_chr(Description, extract_kml_field, \"PLN_AREA_N\"), # planning area name\n    SUBZONE_N  = purrr::map_chr(Description, extract_kml_field, \"SUBZONE_N\"),  # subzone name\n    SUBZONE_C  = purrr::map_chr(Description, extract_kml_field, \"SUBZONE_C\")   # subzone code\n  ) %&gt;%\n  dplyr::select(-Name, -Description) %&gt;%     # drop original noisy fields\n  dplyr::relocate(geometry, .after = dplyr::last_col())  # move geometry column to the end for readability\n\n\nCheckpoint: You now have clean polygon attributes and the proper CRS.\n\n(Optional) Filter out offshore/irrelevant areas exactly like in the slides\n\n# Create a cleaned version that excludes southern group, western islands, and north‑eastern islands (as per slides)\nmpsz_cl &lt;- mpsz_sf %&gt;%\n  dplyr::filter(\n    SUBZONE_N != \"SOUTHERN GROUP\",\n    PLN_AREA_N != \"WESTERN ISLANDS\",\n    PLN_AREA_N != \"NORTH-EASTERN ISLANDS\"\n  )\n\n# Save a small RDS for repeatability (optional)\n# readr::write_rds(mpsz_cl, \"chap04/data/mpsz_cl.rds\")\n\nImport Child Care Services points as sf, drop Z/M, and project to EPSG:3414\n\n# Read childcare locations KML into an sf object named 'childcare_sf'\nchildcare_sf &lt;- sf::st_read(\"data/geospatial/ChildCareServices.kml\") %&gt;%\n  sf::st_zm(drop = TRUE, what = \"ZM\") %&gt;%     # keep 2D only\n  sf::st_transform(crs = 3414)         \n\nReading layer `CHILDCARE' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex02/Data/geospatial/ChildCareServices.kml' \n  using driver `KML'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\n\n# Quick mapping of both layers to verify alignment (childcare points inside planning subzones)\ntmap::tmap_mode(\"plot\")  # ensure static plotting mode\n\nℹ tmap mode set to \"plot\".\n\n# Plot subzones with childcare points overlaid\ntmap::tm_shape(mpsz_cl) +\n  tmap::tm_polygons(col = \"grey85\", border.col = \"black\") +\n  tmap::tm_shape(childcare_sf) +\n  tmap::tm_dots(size = 0.2, col = \"red\")\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_polygons()`: use 'fill' for the fill color of polygons/symbols\n(instead of 'col'), and 'col' for the outlines (instead of 'border.col').\n\n\n\n\n\n\n\n\n\n\nWhat to check: All childcare centres (black dots) fall neatly inside Singapore’s subzones (grey polygons). If not, check CRS and transformations.\n\nInteractive mapping with tmap + leaflet\n\n# Switch tmap into interactive mode (internally uses the leaflet library)\ntmap::tmap_mode(\"view\")                # enable pan/zoom and feature popups\n\nℹ tmap mode set to \"view\".\n\n# Draw an interactive point map on top of a web basemap\n# - Click a point to see its attributes\n# - Use the layer control to change basemaps (e.g., ESRI.WorldGrayCanvas, OpenStreetMap)\ntmap::tm_shape(childcare_sf) +         # select the childcare sf layer\n  tmap::tm_dots()                      # render as clickable points\n\nRegistered S3 method overwritten by 'jsonify':\n  method     from    \n  print.json jsonlite\n\n\n\n\n\n# IMPORTANT: After exploring, switch back to static plotting for the rest of the workflow\n# This avoids keeping too many active web-map connections during knitting/deployment\ntmap::tmap_mode(\"plot\")               # restore static plotting mode\n\nℹ tmap mode set to \"plot\".\n\n\n\n# Switch to interactive mode for web-map style exploration\n# tmap::tmap_mode(\"view\")\n# \n# # Create an interactive map where you can zoom and click points\n# tmap::tm_shape(mpsz_cl) +\n#   tmap::tm_polygons(col = \"lightgrey\", border.col = \"white\") +\n#   tmap::tm_shape(childcare_sf) +\n#   tmap::tm_dots(col = \"blue\", size = 0.5)\n# \n# # Always switch back to static plotting when done\n# tmap::tmap_mode(\"plot\")\n\n\nNotes: In interactive mode you can zoom, pan, and click childcare points to view their attributes. Remember to switch back to plot mode before continuing with static maps.\n\n\n\n\n\n\n\n\n# Convert the sf point layer to spatstat's planar point pattern (ppp) object\nchildcare_ppp &lt;- spatstat.geom::as.ppp(childcare_sf)  # now suitable for SPPA functions\n\n\n# Verify the class\nclass(childcare_ppp)  # expect: \"ppp\"\n\n[1] \"ppp\"\n\n\n\n# Peek at summary to understand the point pattern and its window\nsummary(childcare_ppp)  # quick glance (number of points, intensity, window size)\n\nMarked planar point pattern:  1925 points\nAverage intensity 2.417323e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nMark variables: Name, Description\nSummary:\n     Name           Description       \n Length:1925        Length:1925       \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units\n\n\n\n\n\n\n# Convert the cleaned subzones into a single observation window (owin) for clipping/analysis\nsg_owin &lt;- spatstat.geom::as.owin(mpsz_cl)\n\n\n# Verify the class\nclass(sg_owin)  # expect: \"owin\"\n\n[1] \"owin\"\n\n\n\n# Visualize the boundary to confirm it looks right\nplot(sg_owin, main = \"sg_owin — Singapore Observation Window\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Clip the point pattern to the Singapore window to exclude any points outside the boundary\nchildcareSG_ppp &lt;- childcare_ppp[sg_owin]\n\n\n# Confirm the combined object (ppp with polygon window information)\nchildcareSG_ppp  # should report a polygonal window and the point count\n\nMarked planar point pattern: 1925 points\nMark variables: Name, Description \nwindow: polygonal boundary\nenclosing rectangle: [2667.54, 55941.94] x [21448.47, 50256.33] units\n\n\n\n\n\nHypotheses:\n\n\\(H_0\\): Childcare centres are randomly distributed (Complete Spatial Randomness, CSR).\n\\(H_1\\): Childcare centres are not randomly distributed (clustered or regular).\n\nThe 95% confident interval will be used.\nThe Clark–Evans test returns an index R:\n\n\\(R &lt; 1 → clustered\\).\n\\(R = 1 → random\\)\n\\(R &gt; 1 → regular\\)\n\n\n\n\n# Run Clark–Evans using observed pattern only (Z-test)\nce_noCSR &lt;- spatstat.explore::clarkevans.test(\nX = childcareSG_ppp, # ppp object of childcare centres\ncorrection = \"none\", # no edge correction (per slides)\nalternative = \"clustered\" # one-sided: test for clustering (R &lt; 1)\n)\n\n# Show results\nce_noCSR\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.53532, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\n\n\n\n\nNoteClark–Evans Test without CSR (Z-test)\n\n\n\n\nR = 0.53532 (&lt; 1) → indicates clustering.\np-value &lt; 2.2e-16 (&lt; 0.05): → reject H₀.\nStatistical conclusion: Distribution is not random; strong clustering exists.\nBusiness communication: Childcare centres are concentrated in specific neighbourhoods. This reflects demand-driven placement but may leave some areas underserved. Authorities should consider equity in future allocations.\n\n\n\n\n\n\n\n# Monte‑Carlo Clark–Evans: compare observed R to R from CSR simulations (nsim = 99)\nce_MC &lt;- spatstat.explore::clarkevans.test( # compute simulated p‑value under CSR\nX = childcareSG_ppp, # same ppp as above (metres)\ncorrection = \"none\", # keep consistent with slides\nalternative = \"clustered\", # one‑sided for clustering (R &lt; 1)\nmethod = \"MonteCarlo\", # enable Monte‑Carlo simulation mode\nnsim = 99 # number of CSR replicates as per slides\n) # end clarkevans.test call\n\nce_MC\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 99 simulations of CSR with fixed n\n\ndata:  childcareSG_ppp\nR = 0.53532, p-value = 0.01\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\n\n\n\n\nNoteClark–Evans Test with CSR (Monte Carlo, nsim=99)\n\n\n\n\nR = 0.53532 (&lt; 1): → clustering again.\np-value = 0.01 (&lt; 0.05) → reject H₀ at 95% CI.\nStatistical conclusion: Distribution is not random; clustering is statistically significant even under CSR simulations.\nBusiness communication: Confirms earlier finding with stronger robustness. Clustering is not due to chance — it is systematic. Policymakers should expand childcare access in low-density areas to reduce inequality in service availability.\n\n\n\n\n\n\n\nGoal: Turn points into a smooth surface to reveal hotspots. Bandwidth controls smoothness; kernel controls the spread shape.\n\n\n\nkde_SG_diggle &lt;- density(          # Create KDE surface and save to object 'kde_SG_diggle'\n  childcareSG_ppp,                 # Input: childcare centres dataset in 'ppp' format\n  sigma = bw.diggle,               # Bandwidth: automatic smoothing radius (Diggle’s selector)\n  edge  = TRUE,                    # Apply edge correction to fix boundary underestimation\n  kernel = \"gaussian\"              # Kernel type: Gaussian (bell-shaped smoothing function)\n)                                  # End of density() call\n\n\n# Plot the kernel density estimation surface for childcare centres\nplot(kde_SG_diggle)        \n\n\n\n\n\n\n\n\n\nsummary(kde_SG_diggle)\n\nreal-valued pixel image\n128 x 128 pixel array (ny, nx)\nenclosing rectangle: [2667.538, 55941.94] x [21448.47, 50256.33] units\ndimensions of each pixel: 416 x 225.0614 units\nImage is defined on a subset of the rectangular grid\nSubset area = 669941961.12249 square units\nSubset area fraction = 0.437\nPixel values (inside window):\n    range = [-5.824417e-21, 3.063698e-05]\n    integral = 1927.788\n    mean = 2.877545e-06\n\n\n\n# Calculate optimal bandwidth (smoothing parameter) using Diggle’s method\nbw &lt;- bw.diggle(childcareSG_ppp)             \nbw   # Display the selected bandwidth value\n\n   sigma \n295.9712 \n\n\n\n\n\n\nchildcareSG_ppp_km &lt;- rescale.ppp(  # Rescale the point pattern dataset from metres to kilometres\n  childcareSG_ppp, 1000, \"km\")      # Display the selected bandwidth value \n\n\nkde_childcareSG_km &lt;- density(  # Compute kernel density estimation on rescaled dataset\n  childcareSG_ppp_km,           # Input point pattern in kilometres\n  sigma = bw.diggle,            # Use Diggle’s optimal bandwidth (sigma)\n  edge  = TRUE,                 # Apply edge correction to fix boundary bias\n  kernel = \"gaussian\"           # Use Gaussian kernel for smoothing\n)\n\n\n# Plot KDE surface for childcare centres (units in km)\nplot(kde_childcareSG_km)\n\n\n\n\n\n\n\n\n\n\n\n\n# Compute bandwidth using Cronie & van Lieshout method\nbw.CvL(childcareSG_ppp_km)\n\n   sigma \n4.357209 \n\n\n\n# Compute bandwidth using Scott’s rule-of-thumb method\nbw.scott(childcareSG_ppp_km)\n\n sigma.x  sigma.y \n2.159749 1.396455 \n\n\n\n# Compute bandwidth using likelihood cross-validation (PPL)\nbw.ppl(childcareSG_ppp_km)\n\n   sigma \n0.378997 \n\n\n\n# Re-compute bandwidth using Diggle’s method (on km scale)\nbw.diggle(childcareSG_ppp_km)\n\n    sigma \n0.2959712 \n\n\n\nkde_childcareSG_ppl &lt;- density(   # KDE using PPL bandwidth for smoothing\n  childcareSG_ppp_km,             # Input dataset in kilometres\n  sigma = bw.ppl,                 # Use bandwidth chosen by PPL\n  edge  = TRUE,                   # Apply edge correction\n  kernel = \"gaussian\"             # Gaussian smoothing kernel\n)\n\npar(mfrow=c(1,2))                            # Set plot area into 1 row, 2 columns for comparison\nplot(kde_childcareSG_km, main = \"bw.diggle\") # Plot KDE using Diggle bandwidth\nplot(kde_childcareSG_ppl, main = \"bw.ppl\")   # Plot KDE using PPL bandwidth\n\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,2))                        # Divide plotting window into 2 rows × 2 columns\n\nplot(density(childcareSG_ppp_km,         # KDE with Gaussian kernel\n             sigma=0.2959712, edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")                    # Title for Gaussian plot\n\nplot(density(childcareSG_ppp_km,         # KDE with Epanechnikov kernel\n             sigma=0.2959712, edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")                # Title for Epanechnikov plot\n\nplot(density(childcareSG_ppp_km,         # KDE with Quartic kernel\n             sigma=0.2959712, edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")                     # Title for Quartic plot\n\nplot(density(childcareSG_ppp_km,         # KDE with Disc kernel\n             sigma=0.2959712, edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")                        # Title for Disc plot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkde_childcareSG_fb &lt;- density(   # KDE using fixed bandwidth method\n  childcareSG_ppp_km,            # Input childcare centres dataset (in km)\n  sigma = 0.6,                   # Fixed bandwidth = 0.6 km (600 metres)\n  edge  = TRUE,                  # Apply edge correction at boundaries\n  kernel = \"gaussian\"            # Gaussian smoothing kernel\n)\n\nplot(kde_childcareSG_fb)         # Plot the fixed bandwidth KDE result\n\n\n\n\n\n\n\n\n\n\n\n\nkde_childcareSG_ab &lt;- adaptive.density(    # KDE using adaptive bandwidth method\n  childcareSG_ppp_km,                      # Input childcare centres dataset (in km)\n  method=\"kernel\"                          # Kernel smoothing method\n)\n\nplot(kde_childcareSG_ab)  # Plot the adaptive bandwidth KDE result\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,2))         # Set plotting window to 1 row × 2 columns\nplot(kde_childcareSG_fb, main = \"Fixed bandwidth\")     # Show fixed bandwidth KDE\nplot(kde_childcareSG_ab, main = \"Adaptive bandwidth\")  # Show adaptive bandwidth KDE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Convert KDE (im class) into SpatRaster object\nkde_childcareSG_bw_terra &lt;- rast(kde_childcareSG_km)\n\n\n# Check the class of the raster object (should be \"SpatRaster\")\nclass(kde_childcareSG_bw_terra)\n\n[1] \"SpatRaster\"\nattr(,\"package\")\n[1] \"terra\"\n\n\n\n# Print raster properties: resolution, extent, units, etc.\nkde_childcareSG_bw_terra\n\nclass       : SpatRaster \nsize        : 128, 128, 1  (nrow, ncol, nlyr)\nresolution  : 0.4162063, 0.2250614  (x, y)\nextent      : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncoord. ref. :  \nsource(s)   : memory\nname        :         lyr.1 \nmin value   : -4.314789e-15 \nmax value   :  3.063698e+01 \nunit        :            km \n\n\n\n\n\n\n# Assign projection system SVY21 / Singapore TM (EPSG:3414)\ncrs(kde_childcareSG_bw_terra) &lt;- \"EPSG:3414\"\n\n\n# Re-check raster details, now with CRS applied\nkde_childcareSG_bw_terra\n\nclass       : SpatRaster \nsize        : 128, 128, 1  (nrow, ncol, nlyr)\nresolution  : 0.4162063, 0.2250614  (x, y)\nextent      : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncoord. ref. : SVY21 / Singapore TM (EPSG:3414) \nsource(s)   : memory\nname        :         lyr.1 \nmin value   : -4.314789e-15 \nmax value   :  3.063698e+01 \nunit        :            km \n\n\n\n\n\n\ntm_shape(kde_childcareSG_bw_terra) +      # Define raster object to be plotted\n  tm_raster(col.scale =                        # Set raster colour scheme\n              tm_scale_continuous(values=\"viridis\"), \n            col.legend = tm_legend(       # Add legend for density values\n              title = \"Density values\",   # Legend title\n              title.size = 0.7,           # Legend title text size\n              text.size = 0.7),           # Legend labels text size\n            bg.color = \"white\",           # Background colour of map\n            bg.alpha = 0.7,               # Transparency of background\n            position = tm_pos_in(\"right\",\"bottom\"), # Place legend bottom-right\n            frame = TRUE) +               # Draw frame around raster\n  tm_graticules(labels.size = 0.7) +      # Add graticule grid with label size 0.7\n  tm_compass() +                          # Add compass to map\n  tm_layout(scale = 1.0)                  # Set layout scale\n\n[tm_raster()] Arguments `bg.color`, `bg.alpha`, `position`, and `frame`\nunknown.\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npg &lt;- mpsz_cl %&gt;%                         # Create dataset 'pg' by filtering master plan polygons\n  filter(PLN_AREA_N == \"PUNGGOL\")         # Keep only polygons where planning area = Punggol\n\ntm &lt;- mpsz_cl %&gt;%                         # Create dataset 'tm'\n  filter(PLN_AREA_N == \"TAMPINES\")        # Keep only polygons where planning area = Tampines\n\nck &lt;- mpsz_cl %&gt;%                         # Create dataset 'ck'\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")   # Keep only polygons where planning area = Choa Chu Kang\n\njw &lt;- mpsz_cl %&gt;%                         # Create dataset 'jw'\n  filter(PLN_AREA_N == \"JURONG WEST\")     # Keep only polygons where planning area = Jurong West\n\n\npar(mfrow=c(2,2))                              # Arrange plotting area into 2 rows × 2 columns\n\nplot(st_geometry(pg), main=\"Punggol\")          # Plot polygon boundary of Punggol planning area\nplot(st_geometry(tm), main=\"Tampines\")         # Plot polygon boundary of Tampines planning area\nplot(st_geometry(ck), main=\"Choa Chu Kang\")    # Plot polygon boundary of Choa Chu Kang planning area\nplot(st_geometry(jw), main=\"Jurong West\")      # Plot polygon boundary of Jurong West planning area\n\n\n\n\n\n\n\n\n\n\n\n\npg_owin &lt;- as.owin(pg)     # Convert Punggol polygon(s) to an 'owin' window (study region)\ntm_owin &lt;- as.owin(tm)     # Convert Tampines polygon(s) to 'owin'\nck_owin &lt;- as.owin(ck)     # Convert Choa Chu Kang polygon(s) to 'owin'\njw_owin &lt;- as.owin(jw)     # Convert Jurong West polygon(s) to 'owin'\n\n\n\n\n\nchildcare_pg_ppp &lt;- childcare_ppp[pg_owin]  # Clip national points to Punggol window (points inside only)\nchildcare_tm_ppp &lt;- childcare_ppp[tm_owin]  # Clip points to Tampines window\nchildcare_ck_ppp &lt;- childcare_ppp[ck_owin]  # Clip points to Choa Chu Kang window\nchildcare_jw_ppp &lt;- childcare_ppp[jw_owin]  # Clip points to Jurong West window\n\n\nchildcare_pg_ppp_km &lt;- rescale.ppp(  # Rescale Punggol points from metres → kilometres\n  childcare_pg_ppp, 1000, \"km\"       # divide coords by 1000; label new unit as \"km\"\n)\nchildcare_tm_ppp_km &lt;- rescale.ppp(  # Rescale Tampines points to kilometres\n  childcare_tm_ppp, 1000, \"km\"\n)\nchildcare_ck_ppp_km &lt;- rescale.ppp(  # Rescale CCK points to kilometres\n  childcare_ck_ppp, 1000, \"km\"\n)\nchildcare_jw_ppp_km &lt;- rescale.ppp(  # Rescale Jurong West points to kilometres\n  childcare_jw_ppp, 1000, \"km\"\n)\n\n\npar(mfrow = c(2,2))               # Arrange plotting area into a 2×2 grid\n\nplot(unmark(childcare_pg_ppp_km), # Plot Punggol points (unmark = hide text marks)\n     main = \"Punggol\")            # Panel title\n\nplot(unmark(childcare_tm_ppp_km), # Plot Tampines points\n     main = \"Tampines\")\n\nplot(unmark(childcare_ck_ppp_km), # Plot Choa Chu Kang points\n     main = \"Choa Chu Kang\")\n\nplot(unmark(childcare_jw_ppp_km), # Plot Jurong West points\n     main = \"Jurong West\")\n\n\n\n\n\n\n\npar(mfrow = c(1,1))               # Reset plotting layout back to single panel\n\n\n\n\n\n\nclarkevans.test(childcare_ck_ppp, # Clark–Evans test for the Choa Chu Kang point pattern\n  correction  = \"none\",           # No edge correction (consistent with slides)\n  clipregion  = NULL,             # Use the pattern's own observation window\n  alternative = c(\"two.sided\"),   # Two-sided hypothesis (clustered or regular)\n  nsim        = 999               # 999 CSR simulations for p-value\n)                                 # End of clarkevans.test call\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.84097, p-value = 0.008866\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(childcare_tm_ppp,   # Clark–Evans test for the Tampines point pattern\n  correction  = \"none\",             # No edge correction (to match slides)\n  clipregion  = NULL,               # Do not clip by an additional region (use pattern's window)\n  alternative = c(\"two.sided\"),     # Two-sided test: allow clustering (R&lt;1) or regularity (R&gt;1)\n  nsim        = 999                 # Monte-Carlo CSR simulations (999 replicates)\n)                                   # End of clarkevans.test call\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.66817, p-value = 6.58e-12\nalternative hypothesis: two-sided\n\n\n\n\n\n\n\npar(mfrow = c(2,2))                # Arrange plotting window into 2 rows × 2 columns\n\nplot(density(childcare_pg_ppp_km,  # KDE for Punggol (data already rescaled to km)\n             sigma = bw.diggle,    # Use Diggle’s automatic bandwidth selector\n             edge  = TRUE,         # Apply edge correction (reduces boundary bias)\n             kernel = \"gaussian\"), # Gaussian kernel (smooth bell-shaped influence)\n     main = \"Punggol\")             # Panel title\n\nplot(density(childcare_tm_ppp_km,  # KDE for Tampines\n             sigma = bw.diggle,    # Same bandwidth rule for comparability\n             edge  = TRUE,         # Edge correction on\n             kernel = \"gaussian\"), # Gaussian kernel\n     main = \"Tampines\")            # Panel title\n\nplot(density(childcare_ck_ppp_km,  # KDE for Choa Chu Kang\n             sigma = bw.diggle,    # Diggle bandwidth (km)\n             edge  = TRUE,         # Edge correction on\n             kernel = \"gaussian\"), # Gaussian kernel\n     main = \"Choa Chu Kang\")       # Panel title\n\nplot(density(childcare_jw_ppp_km,  # KDE for Jurong West\n             sigma = bw.diggle,    # Diggle bandwidth (km)\n             edge  = TRUE,         # Edge correction on\n             kernel = \"gaussian\"), # Gaussian kernel\n     main = \"Jurong West\")         # Panel title"
  },
  {
    "objectID": "Hands-on_Ex02/Hand-on_Ex02.html#overview",
    "href": "Hands-on_Ex02/Hand-on_Ex02.html#overview",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "The specific questions we would like to answer are as follows:\n\nAre the childcare centres in Singapore randomly distributed throughout the country?\nIf the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex02/Hand-on_Ex02.html#installing-and-loading-the-r-packagesn",
    "href": "Hands-on_Ex02/Hand-on_Ex02.html#installing-and-loading-the-r-packagesn",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "# Install 'pacman' once if you do not have it (uncomment next line and run only once)\n# install.packages(\"pacman\")\n\n# Use pacman::p_load() to install (if needed) and then load the listed packages automatically\npacman::p_load(\n  sf,            # modern vector geospatial data handling (Simple Features)\n  terra,         # modern raster + vector geospatial data handling\n  spatstat,      # meta‑package: tools for spatial point pattern analysis (SPPA)\n  tmap,          # cartographic and interactive mapping\n  rvest,         # web‑scraping helper used here to parse HTML inside KML attributes\n  tidyverse      # data wrangling helpers (dplyr, purrr, stringr, readr, etc.)\n)"
  },
  {
    "objectID": "Hands-on_Ex02/Hand-on_Ex02.html#importing-and-wrangling-geospatial-data-sets",
    "href": "Hands-on_Ex02/Hand-on_Ex02.html#importing-and-wrangling-geospatial-data-sets",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "Import the Master Plan 2019 Subzone (No Sea) polygons as sf and set projection to EPSG:3414 (SVY21 / Singapore TM)\n\n# Read the subzone boundary KML into an sf object named 'mpsz_sf'\nmpsz_sf &lt;- sf::st_read(\"data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\") %&gt;%\n  sf::st_zm(drop = TRUE, what = \"ZM\") %&gt;%  # remove Z (elevation) and M (measure) dimensions to keep 2D only\n  sf::st_transform(crs = 3414)   \n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex02/Data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nWhy remove Z/M? Our analysis is purely 2D on a planar map. Extra dimensions are unnecessary and can break some operations.\nWhy EPSG:3414? This is the standard projected system for Singapore. Distances/areas become meaningful (meters) instead of degrees.\n\nExtract REGION_N, PLN_AREA_N, SUBZONE_N, SUBZONE_C from the Description field (HTML inside KML) (as in the guidance helper function)\n\n# Define a small helper function to pull one named item from the HTML table stored in the 'Description' field\nextract_kml_field &lt;- function(html_text, field_name) {\n  if (is.na(html_text) || html_text == \"\") return(NA_character_) # if Description is empty, return NA immediately\n\n  page &lt;- rvest::read_html(html_text)       # parse the HTML string\n  rows &lt;- rvest::html_elements(page, \"tr\")  # get all table rows (&lt;tr&gt;)\n\n  # Find the row whose header cell (&lt;th&gt;) equals the field_name, then take the value in its &lt;td&gt;\n  value &lt;- rows %&gt;%\n    purrr::keep(~ rvest::html_text2(rvest::html_element(.x, \"th\")) == field_name) %&gt;%\n    rvest::html_element(\"td\") %&gt;%\n    rvest::html_text2()\n\n  if (length(value) == 0) NA_character_ else value    # if not found, return NA\n}\n\n\n# Apply the function to build clean attributes from 'Description'\nmpsz_sf &lt;- mpsz_sf %&gt;%\n  dplyr::mutate(\n    REGION_N   = purrr::map_chr(Description, extract_kml_field, \"REGION_N\"),   # region name\n    PLN_AREA_N = purrr::map_chr(Description, extract_kml_field, \"PLN_AREA_N\"), # planning area name\n    SUBZONE_N  = purrr::map_chr(Description, extract_kml_field, \"SUBZONE_N\"),  # subzone name\n    SUBZONE_C  = purrr::map_chr(Description, extract_kml_field, \"SUBZONE_C\")   # subzone code\n  ) %&gt;%\n  dplyr::select(-Name, -Description) %&gt;%     # drop original noisy fields\n  dplyr::relocate(geometry, .after = dplyr::last_col())  # move geometry column to the end for readability\n\n\nCheckpoint: You now have clean polygon attributes and the proper CRS.\n\n(Optional) Filter out offshore/irrelevant areas exactly like in the slides\n\n# Create a cleaned version that excludes southern group, western islands, and north‑eastern islands (as per slides)\nmpsz_cl &lt;- mpsz_sf %&gt;%\n  dplyr::filter(\n    SUBZONE_N != \"SOUTHERN GROUP\",\n    PLN_AREA_N != \"WESTERN ISLANDS\",\n    PLN_AREA_N != \"NORTH-EASTERN ISLANDS\"\n  )\n\n# Save a small RDS for repeatability (optional)\n# readr::write_rds(mpsz_cl, \"chap04/data/mpsz_cl.rds\")\n\nImport Child Care Services points as sf, drop Z/M, and project to EPSG:3414\n\n# Read childcare locations KML into an sf object named 'childcare_sf'\nchildcare_sf &lt;- sf::st_read(\"data/geospatial/ChildCareServices.kml\") %&gt;%\n  sf::st_zm(drop = TRUE, what = \"ZM\") %&gt;%     # keep 2D only\n  sf::st_transform(crs = 3414)         \n\nReading layer `CHILDCARE' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex02/Data/geospatial/ChildCareServices.kml' \n  using driver `KML'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\n\n# Quick mapping of both layers to verify alignment (childcare points inside planning subzones)\ntmap::tmap_mode(\"plot\")  # ensure static plotting mode\n\nℹ tmap mode set to \"plot\".\n\n# Plot subzones with childcare points overlaid\ntmap::tm_shape(mpsz_cl) +\n  tmap::tm_polygons(col = \"grey85\", border.col = \"black\") +\n  tmap::tm_shape(childcare_sf) +\n  tmap::tm_dots(size = 0.2, col = \"red\")\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_polygons()`: use 'fill' for the fill color of polygons/symbols\n(instead of 'col'), and 'col' for the outlines (instead of 'border.col').\n\n\n\n\n\n\n\n\n\n\nWhat to check: All childcare centres (black dots) fall neatly inside Singapore’s subzones (grey polygons). If not, check CRS and transformations.\n\nInteractive mapping with tmap + leaflet\n\n# Switch tmap into interactive mode (internally uses the leaflet library)\ntmap::tmap_mode(\"view\")                # enable pan/zoom and feature popups\n\nℹ tmap mode set to \"view\".\n\n# Draw an interactive point map on top of a web basemap\n# - Click a point to see its attributes\n# - Use the layer control to change basemaps (e.g., ESRI.WorldGrayCanvas, OpenStreetMap)\ntmap::tm_shape(childcare_sf) +         # select the childcare sf layer\n  tmap::tm_dots()                      # render as clickable points\n\nRegistered S3 method overwritten by 'jsonify':\n  method     from    \n  print.json jsonlite\n\n\n\n\n\n# IMPORTANT: After exploring, switch back to static plotting for the rest of the workflow\n# This avoids keeping too many active web-map connections during knitting/deployment\ntmap::tmap_mode(\"plot\")               # restore static plotting mode\n\nℹ tmap mode set to \"plot\".\n\n\n\n# Switch to interactive mode for web-map style exploration\n# tmap::tmap_mode(\"view\")\n# \n# # Create an interactive map where you can zoom and click points\n# tmap::tm_shape(mpsz_cl) +\n#   tmap::tm_polygons(col = \"lightgrey\", border.col = \"white\") +\n#   tmap::tm_shape(childcare_sf) +\n#   tmap::tm_dots(col = \"blue\", size = 0.5)\n# \n# # Always switch back to static plotting when done\n# tmap::tmap_mode(\"plot\")\n\n\nNotes: In interactive mode you can zoom, pan, and click childcare points to view their attributes. Remember to switch back to plot mode before continuing with static maps."
  },
  {
    "objectID": "Hands-on_Ex02/Hand-on_Ex02.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex02/Hand-on_Ex02.html#geospatial-data-wrangling",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "# Convert the sf point layer to spatstat's planar point pattern (ppp) object\nchildcare_ppp &lt;- spatstat.geom::as.ppp(childcare_sf)  # now suitable for SPPA functions\n\n\n# Verify the class\nclass(childcare_ppp)  # expect: \"ppp\"\n\n[1] \"ppp\"\n\n\n\n# Peek at summary to understand the point pattern and its window\nsummary(childcare_ppp)  # quick glance (number of points, intensity, window size)\n\nMarked planar point pattern:  1925 points\nAverage intensity 2.417323e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nMark variables: Name, Description\nSummary:\n     Name           Description       \n Length:1925        Length:1925       \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units\n\n\n\n\n\n\n# Convert the cleaned subzones into a single observation window (owin) for clipping/analysis\nsg_owin &lt;- spatstat.geom::as.owin(mpsz_cl)\n\n\n# Verify the class\nclass(sg_owin)  # expect: \"owin\"\n\n[1] \"owin\"\n\n\n\n# Visualize the boundary to confirm it looks right\nplot(sg_owin, main = \"sg_owin — Singapore Observation Window\")"
  },
  {
    "objectID": "Hands-on_Ex02/Hand-on_Ex02.html#combine-the-ppp-with-the-owin-keep-only-points-inside-singapore",
    "href": "Hands-on_Ex02/Hand-on_Ex02.html#combine-the-ppp-with-the-owin-keep-only-points-inside-singapore",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "# Clip the point pattern to the Singapore window to exclude any points outside the boundary\nchildcareSG_ppp &lt;- childcare_ppp[sg_owin]\n\n\n# Confirm the combined object (ppp with polygon window information)\nchildcareSG_ppp  # should report a polygonal window and the point count\n\nMarked planar point pattern: 1925 points\nMark variables: Name, Description \nwindow: polygonal boundary\nenclosing rectangle: [2667.54, 55941.94] x [21448.47, 50256.33] units"
  },
  {
    "objectID": "Hands-on_Ex02/Hand-on_Ex02.html#clark-evan-test-for-nearest-neighbour-analysis",
    "href": "Hands-on_Ex02/Hand-on_Ex02.html#clark-evan-test-for-nearest-neighbour-analysis",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "Hypotheses:\n\n\\(H_0\\): Childcare centres are randomly distributed (Complete Spatial Randomness, CSR).\n\\(H_1\\): Childcare centres are not randomly distributed (clustered or regular).\n\nThe 95% confident interval will be used.\nThe Clark–Evans test returns an index R:\n\n\\(R &lt; 1 → clustered\\).\n\\(R = 1 → random\\)\n\\(R &gt; 1 → regular\\)\n\n\n\n\n# Run Clark–Evans using observed pattern only (Z-test)\nce_noCSR &lt;- spatstat.explore::clarkevans.test(\nX = childcareSG_ppp, # ppp object of childcare centres\ncorrection = \"none\", # no edge correction (per slides)\nalternative = \"clustered\" # one-sided: test for clustering (R &lt; 1)\n)\n\n# Show results\nce_noCSR\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.53532, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\n\n\n\n\nNoteClark–Evans Test without CSR (Z-test)\n\n\n\n\nR = 0.53532 (&lt; 1) → indicates clustering.\np-value &lt; 2.2e-16 (&lt; 0.05): → reject H₀.\nStatistical conclusion: Distribution is not random; strong clustering exists.\nBusiness communication: Childcare centres are concentrated in specific neighbourhoods. This reflects demand-driven placement but may leave some areas underserved. Authorities should consider equity in future allocations.\n\n\n\n\n\n\n\n# Monte‑Carlo Clark–Evans: compare observed R to R from CSR simulations (nsim = 99)\nce_MC &lt;- spatstat.explore::clarkevans.test( # compute simulated p‑value under CSR\nX = childcareSG_ppp, # same ppp as above (metres)\ncorrection = \"none\", # keep consistent with slides\nalternative = \"clustered\", # one‑sided for clustering (R &lt; 1)\nmethod = \"MonteCarlo\", # enable Monte‑Carlo simulation mode\nnsim = 99 # number of CSR replicates as per slides\n) # end clarkevans.test call\n\nce_MC\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 99 simulations of CSR with fixed n\n\ndata:  childcareSG_ppp\nR = 0.53532, p-value = 0.01\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\n\n\n\n\nNoteClark–Evans Test with CSR (Monte Carlo, nsim=99)\n\n\n\n\nR = 0.53532 (&lt; 1): → clustering again.\np-value = 0.01 (&lt; 0.05) → reject H₀ at 95% CI.\nStatistical conclusion: Distribution is not random; clustering is statistically significant even under CSR simulations.\nBusiness communication: Confirms earlier finding with stronger robustness. Clustering is not due to chance — it is systematic. Policymakers should expand childcare access in low-density areas to reduce inequality in service availability."
  },
  {
    "objectID": "Hands-on_Ex02/Hand-on_Ex02.html#kernel-density-estimation-kde-method",
    "href": "Hands-on_Ex02/Hand-on_Ex02.html#kernel-density-estimation-kde-method",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "Goal: Turn points into a smooth surface to reveal hotspots. Bandwidth controls smoothness; kernel controls the spread shape.\n\n\n\nkde_SG_diggle &lt;- density(          # Create KDE surface and save to object 'kde_SG_diggle'\n  childcareSG_ppp,                 # Input: childcare centres dataset in 'ppp' format\n  sigma = bw.diggle,               # Bandwidth: automatic smoothing radius (Diggle’s selector)\n  edge  = TRUE,                    # Apply edge correction to fix boundary underestimation\n  kernel = \"gaussian\"              # Kernel type: Gaussian (bell-shaped smoothing function)\n)                                  # End of density() call\n\n\n# Plot the kernel density estimation surface for childcare centres\nplot(kde_SG_diggle)        \n\n\n\n\n\n\n\n\n\nsummary(kde_SG_diggle)\n\nreal-valued pixel image\n128 x 128 pixel array (ny, nx)\nenclosing rectangle: [2667.538, 55941.94] x [21448.47, 50256.33] units\ndimensions of each pixel: 416 x 225.0614 units\nImage is defined on a subset of the rectangular grid\nSubset area = 669941961.12249 square units\nSubset area fraction = 0.437\nPixel values (inside window):\n    range = [-5.824417e-21, 3.063698e-05]\n    integral = 1927.788\n    mean = 2.877545e-06\n\n\n\n# Calculate optimal bandwidth (smoothing parameter) using Diggle’s method\nbw &lt;- bw.diggle(childcareSG_ppp)             \nbw   # Display the selected bandwidth value\n\n   sigma \n295.9712 \n\n\n\n\n\n\nchildcareSG_ppp_km &lt;- rescale.ppp(  # Rescale the point pattern dataset from metres to kilometres\n  childcareSG_ppp, 1000, \"km\")      # Display the selected bandwidth value \n\n\nkde_childcareSG_km &lt;- density(  # Compute kernel density estimation on rescaled dataset\n  childcareSG_ppp_km,           # Input point pattern in kilometres\n  sigma = bw.diggle,            # Use Diggle’s optimal bandwidth (sigma)\n  edge  = TRUE,                 # Apply edge correction to fix boundary bias\n  kernel = \"gaussian\"           # Use Gaussian kernel for smoothing\n)\n\n\n# Plot KDE surface for childcare centres (units in km)\nplot(kde_childcareSG_km)\n\n\n\n\n\n\n\n\n\n\n\n\n# Compute bandwidth using Cronie & van Lieshout method\nbw.CvL(childcareSG_ppp_km)\n\n   sigma \n4.357209 \n\n\n\n# Compute bandwidth using Scott’s rule-of-thumb method\nbw.scott(childcareSG_ppp_km)\n\n sigma.x  sigma.y \n2.159749 1.396455 \n\n\n\n# Compute bandwidth using likelihood cross-validation (PPL)\nbw.ppl(childcareSG_ppp_km)\n\n   sigma \n0.378997 \n\n\n\n# Re-compute bandwidth using Diggle’s method (on km scale)\nbw.diggle(childcareSG_ppp_km)\n\n    sigma \n0.2959712 \n\n\n\nkde_childcareSG_ppl &lt;- density(   # KDE using PPL bandwidth for smoothing\n  childcareSG_ppp_km,             # Input dataset in kilometres\n  sigma = bw.ppl,                 # Use bandwidth chosen by PPL\n  edge  = TRUE,                   # Apply edge correction\n  kernel = \"gaussian\"             # Gaussian smoothing kernel\n)\n\npar(mfrow=c(1,2))                            # Set plot area into 1 row, 2 columns for comparison\nplot(kde_childcareSG_km, main = \"bw.diggle\") # Plot KDE using Diggle bandwidth\nplot(kde_childcareSG_ppl, main = \"bw.ppl\")   # Plot KDE using PPL bandwidth\n\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,2))                        # Divide plotting window into 2 rows × 2 columns\n\nplot(density(childcareSG_ppp_km,         # KDE with Gaussian kernel\n             sigma=0.2959712, edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")                    # Title for Gaussian plot\n\nplot(density(childcareSG_ppp_km,         # KDE with Epanechnikov kernel\n             sigma=0.2959712, edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")                # Title for Epanechnikov plot\n\nplot(density(childcareSG_ppp_km,         # KDE with Quartic kernel\n             sigma=0.2959712, edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")                     # Title for Quartic plot\n\nplot(density(childcareSG_ppp_km,         # KDE with Disc kernel\n             sigma=0.2959712, edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")                        # Title for Disc plot"
  },
  {
    "objectID": "Hands-on_Ex02/Hand-on_Ex02.html#fixed-and-adaptive-kde",
    "href": "Hands-on_Ex02/Hand-on_Ex02.html#fixed-and-adaptive-kde",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "kde_childcareSG_fb &lt;- density(   # KDE using fixed bandwidth method\n  childcareSG_ppp_km,            # Input childcare centres dataset (in km)\n  sigma = 0.6,                   # Fixed bandwidth = 0.6 km (600 metres)\n  edge  = TRUE,                  # Apply edge correction at boundaries\n  kernel = \"gaussian\"            # Gaussian smoothing kernel\n)\n\nplot(kde_childcareSG_fb)         # Plot the fixed bandwidth KDE result\n\n\n\n\n\n\n\n\n\n\n\n\nkde_childcareSG_ab &lt;- adaptive.density(    # KDE using adaptive bandwidth method\n  childcareSG_ppp_km,                      # Input childcare centres dataset (in km)\n  method=\"kernel\"                          # Kernel smoothing method\n)\n\nplot(kde_childcareSG_ab)  # Plot the adaptive bandwidth KDE result\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,2))         # Set plotting window to 1 row × 2 columns\nplot(kde_childcareSG_fb, main = \"Fixed bandwidth\")     # Show fixed bandwidth KDE\nplot(kde_childcareSG_ab, main = \"Adaptive bandwidth\")  # Show adaptive bandwidth KDE"
  },
  {
    "objectID": "Hands-on_Ex02/Hand-on_Ex02.html#plotting-cartographic-quality-kde-map",
    "href": "Hands-on_Ex02/Hand-on_Ex02.html#plotting-cartographic-quality-kde-map",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "# Convert KDE (im class) into SpatRaster object\nkde_childcareSG_bw_terra &lt;- rast(kde_childcareSG_km)\n\n\n# Check the class of the raster object (should be \"SpatRaster\")\nclass(kde_childcareSG_bw_terra)\n\n[1] \"SpatRaster\"\nattr(,\"package\")\n[1] \"terra\"\n\n\n\n# Print raster properties: resolution, extent, units, etc.\nkde_childcareSG_bw_terra\n\nclass       : SpatRaster \nsize        : 128, 128, 1  (nrow, ncol, nlyr)\nresolution  : 0.4162063, 0.2250614  (x, y)\nextent      : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncoord. ref. :  \nsource(s)   : memory\nname        :         lyr.1 \nmin value   : -4.314789e-15 \nmax value   :  3.063698e+01 \nunit        :            km \n\n\n\n\n\n\n# Assign projection system SVY21 / Singapore TM (EPSG:3414)\ncrs(kde_childcareSG_bw_terra) &lt;- \"EPSG:3414\"\n\n\n# Re-check raster details, now with CRS applied\nkde_childcareSG_bw_terra\n\nclass       : SpatRaster \nsize        : 128, 128, 1  (nrow, ncol, nlyr)\nresolution  : 0.4162063, 0.2250614  (x, y)\nextent      : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncoord. ref. : SVY21 / Singapore TM (EPSG:3414) \nsource(s)   : memory\nname        :         lyr.1 \nmin value   : -4.314789e-15 \nmax value   :  3.063698e+01 \nunit        :            km \n\n\n\n\n\n\ntm_shape(kde_childcareSG_bw_terra) +      # Define raster object to be plotted\n  tm_raster(col.scale =                        # Set raster colour scheme\n              tm_scale_continuous(values=\"viridis\"), \n            col.legend = tm_legend(       # Add legend for density values\n              title = \"Density values\",   # Legend title\n              title.size = 0.7,           # Legend title text size\n              text.size = 0.7),           # Legend labels text size\n            bg.color = \"white\",           # Background colour of map\n            bg.alpha = 0.7,               # Transparency of background\n            position = tm_pos_in(\"right\",\"bottom\"), # Place legend bottom-right\n            frame = TRUE) +               # Draw frame around raster\n  tm_graticules(labels.size = 0.7) +      # Add graticule grid with label size 0.7\n  tm_compass() +                          # Add compass to map\n  tm_layout(scale = 1.0)                  # Set layout scale\n\n[tm_raster()] Arguments `bg.color`, `bg.alpha`, `position`, and `frame`\nunknown.\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling."
  },
  {
    "objectID": "Hands-on_Ex02/Hand-on_Ex02.html#first-order-sppa-at-the-planning-subzone-level",
    "href": "Hands-on_Ex02/Hand-on_Ex02.html#first-order-sppa-at-the-planning-subzone-level",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "pg &lt;- mpsz_cl %&gt;%                         # Create dataset 'pg' by filtering master plan polygons\n  filter(PLN_AREA_N == \"PUNGGOL\")         # Keep only polygons where planning area = Punggol\n\ntm &lt;- mpsz_cl %&gt;%                         # Create dataset 'tm'\n  filter(PLN_AREA_N == \"TAMPINES\")        # Keep only polygons where planning area = Tampines\n\nck &lt;- mpsz_cl %&gt;%                         # Create dataset 'ck'\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")   # Keep only polygons where planning area = Choa Chu Kang\n\njw &lt;- mpsz_cl %&gt;%                         # Create dataset 'jw'\n  filter(PLN_AREA_N == \"JURONG WEST\")     # Keep only polygons where planning area = Jurong West\n\n\npar(mfrow=c(2,2))                              # Arrange plotting area into 2 rows × 2 columns\n\nplot(st_geometry(pg), main=\"Punggol\")          # Plot polygon boundary of Punggol planning area\nplot(st_geometry(tm), main=\"Tampines\")         # Plot polygon boundary of Tampines planning area\nplot(st_geometry(ck), main=\"Choa Chu Kang\")    # Plot polygon boundary of Choa Chu Kang planning area\nplot(st_geometry(jw), main=\"Jurong West\")      # Plot polygon boundary of Jurong West planning area\n\n\n\n\n\n\n\n\n\n\n\n\npg_owin &lt;- as.owin(pg)     # Convert Punggol polygon(s) to an 'owin' window (study region)\ntm_owin &lt;- as.owin(tm)     # Convert Tampines polygon(s) to 'owin'\nck_owin &lt;- as.owin(ck)     # Convert Choa Chu Kang polygon(s) to 'owin'\njw_owin &lt;- as.owin(jw)     # Convert Jurong West polygon(s) to 'owin'\n\n\n\n\n\nchildcare_pg_ppp &lt;- childcare_ppp[pg_owin]  # Clip national points to Punggol window (points inside only)\nchildcare_tm_ppp &lt;- childcare_ppp[tm_owin]  # Clip points to Tampines window\nchildcare_ck_ppp &lt;- childcare_ppp[ck_owin]  # Clip points to Choa Chu Kang window\nchildcare_jw_ppp &lt;- childcare_ppp[jw_owin]  # Clip points to Jurong West window\n\n\nchildcare_pg_ppp_km &lt;- rescale.ppp(  # Rescale Punggol points from metres → kilometres\n  childcare_pg_ppp, 1000, \"km\"       # divide coords by 1000; label new unit as \"km\"\n)\nchildcare_tm_ppp_km &lt;- rescale.ppp(  # Rescale Tampines points to kilometres\n  childcare_tm_ppp, 1000, \"km\"\n)\nchildcare_ck_ppp_km &lt;- rescale.ppp(  # Rescale CCK points to kilometres\n  childcare_ck_ppp, 1000, \"km\"\n)\nchildcare_jw_ppp_km &lt;- rescale.ppp(  # Rescale Jurong West points to kilometres\n  childcare_jw_ppp, 1000, \"km\"\n)\n\n\npar(mfrow = c(2,2))               # Arrange plotting area into a 2×2 grid\n\nplot(unmark(childcare_pg_ppp_km), # Plot Punggol points (unmark = hide text marks)\n     main = \"Punggol\")            # Panel title\n\nplot(unmark(childcare_tm_ppp_km), # Plot Tampines points\n     main = \"Tampines\")\n\nplot(unmark(childcare_ck_ppp_km), # Plot Choa Chu Kang points\n     main = \"Choa Chu Kang\")\n\nplot(unmark(childcare_jw_ppp_km), # Plot Jurong West points\n     main = \"Jurong West\")\n\n\n\n\n\n\n\npar(mfrow = c(1,1))               # Reset plotting layout back to single panel\n\n\n\n\n\n\nclarkevans.test(childcare_ck_ppp, # Clark–Evans test for the Choa Chu Kang point pattern\n  correction  = \"none\",           # No edge correction (consistent with slides)\n  clipregion  = NULL,             # Use the pattern's own observation window\n  alternative = c(\"two.sided\"),   # Two-sided hypothesis (clustered or regular)\n  nsim        = 999               # 999 CSR simulations for p-value\n)                                 # End of clarkevans.test call\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.84097, p-value = 0.008866\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(childcare_tm_ppp,   # Clark–Evans test for the Tampines point pattern\n  correction  = \"none\",             # No edge correction (to match slides)\n  clipregion  = NULL,               # Do not clip by an additional region (use pattern's window)\n  alternative = c(\"two.sided\"),     # Two-sided test: allow clustering (R&lt;1) or regularity (R&gt;1)\n  nsim        = 999                 # Monte-Carlo CSR simulations (999 replicates)\n)                                   # End of clarkevans.test call\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.66817, p-value = 6.58e-12\nalternative hypothesis: two-sided\n\n\n\n\n\n\n\npar(mfrow = c(2,2))                # Arrange plotting window into 2 rows × 2 columns\n\nplot(density(childcare_pg_ppp_km,  # KDE for Punggol (data already rescaled to km)\n             sigma = bw.diggle,    # Use Diggle’s automatic bandwidth selector\n             edge  = TRUE,         # Apply edge correction (reduces boundary bias)\n             kernel = \"gaussian\"), # Gaussian kernel (smooth bell-shaped influence)\n     main = \"Punggol\")             # Panel title\n\nplot(density(childcare_tm_ppp_km,  # KDE for Tampines\n             sigma = bw.diggle,    # Same bandwidth rule for comparability\n             edge  = TRUE,         # Edge correction on\n             kernel = \"gaussian\"), # Gaussian kernel\n     main = \"Tampines\")            # Panel title\n\nplot(density(childcare_ck_ppp_km,  # KDE for Choa Chu Kang\n             sigma = bw.diggle,    # Diggle bandwidth (km)\n             edge  = TRUE,         # Edge correction on\n             kernel = \"gaussian\"), # Gaussian kernel\n     main = \"Choa Chu Kang\")       # Panel title\n\nplot(density(childcare_jw_ppp_km,  # KDE for Jurong West\n             sigma = bw.diggle,    # Diggle bandwidth (km)\n             edge  = TRUE,         # Edge correction on\n             kernel = \"gaussian\"), # Gaussian kernel\n     main = \"Jurong West\")         # Panel title"
  },
  {
    "objectID": "Hands-on_Ex02/Hand-on_Ex02.html#second-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex02/Hand-on_Ex02.html#second-order-spatial-point-patterns-analysis",
    "title": "Hands-on_Ex02",
    "section": "5.5 Second-order Spatial Point Patterns Analysis",
    "text": "5.5 Second-order Spatial Point Patterns Analysis\nFirst-order asks “where are points denser?”; second-order asks “how do points interact with each other across distance?”\nWe’ll use four classical functions: - G(r) — nearest-neighbour distribution (from each event to its nearest event). - F(r) — empty-space distribution (from random locations to nearest event). - K(r) — accumulates neighbours within radius r; higher than CSR suggests clustering. - L(r) = √(K(r)/π) — variance-stabilised K; plot L(r) − r to read deviations easily.\nFor each function your Prof shows estimation and a Monte Carlo CSR test with envelopes."
  },
  {
    "objectID": "Hands-on_Ex02/Hand-on_Ex02.html#analysing-spatial-point-process-using-g-function",
    "href": "Hands-on_Ex02/Hand-on_Ex02.html#analysing-spatial-point-process-using-g-function",
    "title": "Hands-on_Ex02",
    "section": "5.6 Analysing Spatial Point Process Using G-Function",
    "text": "5.6 Analysing Spatial Point Process Using G-Function\n\n5.6.1 Choa Chu Kang planning area\n\n5.6.1.1 Computing G-function estimation\n\nset.seed(1234)                                             # fix the random seed so plots are reproducible for students\nG_CK &lt;- Gest(childcare_ck_ppp, correction = \"border\")      # estimate nearest-neighbour CDF G(r) with border edge correction\nplot(G_CK, xlim = c(0, 500))                               # plot G(r) up to 500 m; dashed line shows CSR (Poisson) reference\n\n\n\n\n\n\n\n\n\n\n5.6.1.2 Performing Complete Spatial Randomness (CSR) Test — Monte Carlo\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\\(H_0\\) = The distribution of childcare services at Choa Chu Kang are randomly distributed.\n\\(H_1\\) = The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-fucntion\n\n# run 999 CSR simulations; compute simulation envelopes for G(r)\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)   \n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\n# plot observed G(r), CSR expectation, and 999-sim envelopes\nplot(G_CK.csr)    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteReading the plot:\n\n\n\nIf the black observed curve is mostly above the grey envelope → points are clustered at those distances. If it is below → regular/repulsive (inhibition). Inside the envelope → not significantly different from CSR at that scale.\n\n\n\n\n\n5.6.2 Tampines planning area\n\n5.6.2.1 Computing G-function estimation\n\nG_tm &lt;- Gest(childcare_tm_ppp, correction = \"best\")        # estimate G(r) using 'best' automatic edge correction\nplot(G_tm)                                                 # plot observed G(r) vs theoretical CSR G(r)\n\n\n\n\n\n\n\n\n\n\n5.6.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\\(H_o\\) = The distribution of childcare services at Tampines are randomly distributed.\n\\(H_1\\) = The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest,   # simulate CSR envelopes for G(r) at Tampines\n                     correction = \"all\",       # request all supported edge corrections inside envelope calc\n                     nsim = 999)               # use 999 simulations as in Prof’s slide\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_tm.csr)                                 # display observed curve, CSR, and envelopes\n\n\n\n\n\n\n\n\n\nDecision rule (as per slides): Reject \\(H_0\\): CSR if the observed curve exits the envelope and the associated p-value &lt; 0.001 (α = 0.001)."
  },
  {
    "objectID": "Hands-on_Ex02/Hand-on_Ex02.html#analysing-spatial-point-process-using-f-function",
    "href": "Hands-on_Ex02/Hand-on_Ex02.html#analysing-spatial-point-process-using-f-function",
    "title": "Hands-on_Ex02",
    "section": "5.7 Analysing Spatial Point Process Using F-Function",
    "text": "5.7 Analysing Spatial Point Process Using F-Function\n\n5.7.1 Choa Chu Kang planning area\n\n5.7.1.1 Computing F-function estimation\n\nF_CK &lt;- Fest(childcare_ck_ppp)   # estimate empty-space CDF F(r): distance from random locations to nearest facility\nplot(F_CK)                       # plot multiple estimators and the CSR reference curve F_pois(r)\n\n\n\n\n\n\n\n\n\n\n\n5.7.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\\(H_0\\) = The distribution of childcare services at Choa Chu Kang are randomly distributed.\n\\(H_1\\) = The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-fucntion\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)   # simulate 999 CSR patterns; compute F(r) envelopes\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteReading the plot:\n\n\n\n\nF(r) above CSR → space tends to be closer to facilities than CSR (suggests clustering).\nF(r) below CSR → larger gaps than expected (suggests inhibition).\n\n\n\n5.7.3 Tampines planning area\n****5.7.3.1 Computing F-function estimation****\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n\n\n\n5.7.3.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex02/Hand-on_Ex02.html#analysing-spatial-point-process-using-k-function",
    "href": "Hands-on_Ex02/Hand-on_Ex02.html#analysing-spatial-point-process-using-k-function",
    "title": "Hands-on_Ex02",
    "section": "5.8 Analysing Spatial Point Process Using K-Function",
    "text": "5.8 Analysing Spatial Point Process Using K-Function\n\n5.8.1 Choa Chu Kang planning area\n\n5.8.1.1 Computing K-fucntion estimate\n\n# estimate K(r) using Ripley (isotropic) edge correction\nK_ck &lt;- Kest(childcare_ck_ppp, correction = \"Ripley\")      \n\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n5.8.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest,   # build CSR envelopes for K(r) in Tampines\n                     nsim = 99,                # 99 simulations exactly as shown\n                     rank = 1,                 # use rank-1 global envelope\n                     glocal = TRUE)            # enable global+local envelope calculation\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(K_tm.csr, . - r ~ r,                      # plot (K_hat - r) vs r using the formula used by Prof\n     xlab = \"d\", ylab = \"K(d)-r\",              # match labels from the screenshot\n     xlim = c(0, 500))                         # limit the x-axis to 0–500 m as in the slide\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteReading the plot:\n\n\n\n\nUnder CSR, K(r) = πr² and L(r) − r = 0.\nCurve above CSR → clustering; below → inhibition; inside envelopes → not significantly different from CSR.\n\n\n\n\n\n\n5.8.2 Tampines planning area\n\n5.8.2.1 Computing K-fucntion estimation\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n5.8.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\\(H_0\\) = The distribution of childcare services at Tampines are randomly distributed.\n\\(H_1\\) = The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex02/Hand-on_Ex02.html#analysing-spatial-point-process-using-l-function",
    "href": "Hands-on_Ex02/Hand-on_Ex02.html#analysing-spatial-point-process-using-l-function",
    "title": "Hands-on_Ex02",
    "section": "5.9 Analysing Spatial Point Process Using L-Function",
    "text": "5.9 Analysing Spatial Point Process Using L-Function\n\n5.9.1 Choa Chu Kang planning area\n\n5.9.1.1 Computing L Fucntion estimation\n\nL_ck &lt;- Lest(childcare_ck_ppp, correction = \"Ripley\")      # estimate L(r) using Ripley edge correction\nplot(L_ck, . - r ~ r,                                      # plot (L_hat - r) vs r to centre CSR at zero\n     ylab = \"L(d)-r\", xlab = \"d(m)\")                       # match axis labels exactly as shown\n\n\n\n\n\n\n\n\n\n\n5.9.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\\(H_0\\) = The distribution of childcare services at Choa Chu Kang are randomly distributed.\n\\(H_1\\) = The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest,  # generate L-function CSR envelopes for CK\n                     nsim = 99,               # 99 simulations (as per screenshot)\n                     rank = 1,                # rank-1 global envelope\n                     glocal = TRUE)           # global+local envelope option\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(L_ck.csr, . - r ~ r,                     # plot (L_hat - r) vs r using Prof’s plotting formula\n     xlab = \"d\", ylab = \"L(d)-r\")             # axis labels exactly as in the slide\n\n\n\n\n\n\n\n\n\n\n\n5.9.2 Tampines planning area\n\n5.9.2.1 Computing L-function estimation\n\nL_tm &lt;- Lest(childcare_tm_ppp, correction = \"Ripley\")  # estimate L(r) for Tampines\nplot(L_tm, . - r ~ r,                                  # plot (L_hat - r) vs r as in Prof’s figure\n     ylab = \"L(d)-r\", xlab = \"d(m)\",                   # axis labels to match the slide\n     xlim = c(0, 1000))                                # distance window 0–1000 m as shown\n\n\n\n\n\n\n\n\n\n\n5.9.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\\(H_0\\) = The distribution of childcare services at Tampines are randomly distributed.\n\\(H_1\\) = The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below will be used to perform the hypothesis testing.\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest,  # CSR envelopes for L(r) in Tampines\n                     nsim = 99,               # 99 simulations\n                     rank = 1,                # rank-1 global envelope\n                     glocal = TRUE)           # global+local envelope handling\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(L_tm.csr, . - r ~ r,                     # plot (L_hat - r) vs r per Prof’s code\n     xlab = \"d\", ylab = \"L(d)-r\",             # keep labels consistent with the slide\n     xlim = c(0, 500))                        # show 0–500 m window exactly as given"
  },
  {
    "objectID": "In-Class_Ex03b/in-class_ex03b.html",
    "href": "In-Class_Ex03b/in-class_ex03b.html",
    "title": "In-class Exercise 3b: Working with Open Government Data",
    "section": "",
    "text": "1 Learning Outcome\nBy the end of this hands-on exercise, you will be able to: - Preparing ACRA (Accounting and Corporate Regulatory Authority) Information on Corporate Entities datasets downloaded from data.gov.sg portal for geocoding, - Geocoding the tidydata by using SLA OneMap API, - Converting the geocoded transaction data into sf point feature data.frame, and - Wrangling the sf point features to avoid overlapping point features.\n\n\n2 Loading the R package\n\npacman::p_load(tidyverse, sf, tmap, httr)\n\n\n\n3 Importing ACRA data\n\nfolder_path &lt;- \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Take-home_Ex01/data/aspatial\"\nfile_list &lt;- list.files(path = folder_path, \n                        pattern = \"^ACRA*.*\\\\.csv$\", \n                        full.names = TRUE)\n\nacra_data &lt;- file_list %&gt;%\n  map_dfr(read_csv)\n\n\n\n4 Saving ACRA data\n\nwrite_rds(acra_data,\n          \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Take-home_Ex01/data/rds/acra_data.rds\")\n\n\n\n5 Tidying ACRA data\n\nbiz_56111 &lt;- acra_data %&gt;%\n  select(1:24) %&gt;%\n  filter(primary_ssic_code == 56111) %&gt;%\n  rename(date = registration_incorporation_date) %&gt;%\n  mutate(date = as.Date(date),\n         YEAR = year(date),\n         MONTH_NUM = month(date),\n         MONTH_ABBR = month(date, \n                            label = TRUE, \n                            abbr = TRUE)) %&gt;% \n  mutate(\n    postal_code = str_pad(postal_code, \n    width = 6, side = \"left\", pad = \"0\")) %&gt;%\n           filter(YEAR == 2025)    \n\n\n\n6 Geocoding (It took 32 seconds to process the chunk of codes)\n\npostcodes &lt;- unique(biz_56111$postal_code)\n\nurl &lt;- \"https://onemap.gov.sg/api/common/elastic/search\"\n\nfound &lt;- data.frame()\nnot_found &lt;- data.frame(postcode = character())\n\nfor (pc in postcodes) {\n  query &lt;- list(\n    searchVal = pc,\n    returnGeom = \"Y\",\n    getAddrDetails = \"Y\",\n    pageNum = \"1\"\n  )\n  \n  res &lt;- GET(url, query = query)\n  json &lt;- content(res)\n  \n  if (json$found != 0) {\n    df &lt;- as.data.frame(json$results, stringsAsFactors = FALSE)\n    df$input_postcode &lt;- pc\n    found &lt;- bind_rows(found, df)\n  } else {\n    not_found &lt;- bind_rows(not_found, data.frame(postcode = pc))\n  }\n}\n\n\n\n7 Tidying the geocoded data\n\nfound &lt;- found %&gt;%\n  select(1:10)\n\n\n\n8 Appending the location information\n\nbiz_56111 = biz_56111 %&gt;%\n  left_join(found, \n            by = c('postal_code' = 'POSTAL'))\n\n\n\n9 Saving the data\n\nwrite_rds(biz_56111, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Take-home_Ex01/data/rds/biz_56111.rds\")\n\n\n\n10 Converting into SF data frame\n\nbiz_56111_sf &lt;- st_as_sf(biz_56111, \n                         coords = c(\"X\",\"Y\"),\n                         crs=3414) \n\n\n\n11 Visualising the distribution\n\nggplot(data = biz_56111,\n       aes(x = MONTH_ABBR)) +\n  geom_bar()"
  },
  {
    "objectID": "In-Class_Ex01/in-class_ex01.html",
    "href": "In-Class_Ex01/in-class_ex01.html",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "",
    "text": "For the purpose of this in-class exercise, the following R packages will be used: - tidyverse - sf - tmap - ggstatsplot\nWrite a code chunk to check if these two packages have been installed in R. If yes, load them in R environment.\n\npacman::p_load(tidyverse, sf, tmap, ggstatsplot)"
  },
  {
    "objectID": "In-Class_Ex01/in-class_ex01.html#the-task",
    "href": "In-Class_Ex01/in-class_ex01.html#the-task",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "",
    "text": "For the purpose of this in-class exercise, the following R packages will be used: - tidyverse - sf - tmap - ggstatsplot\nWrite a code chunk to check if these two packages have been installed in R. If yes, load them in R environment.\n\npacman::p_load(tidyverse, sf, tmap, ggstatsplot)"
  },
  {
    "objectID": "In-Class_Ex01/in-class_ex01.html#the-task-1",
    "href": "In-Class_Ex01/in-class_ex01.html#the-task-1",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "2.1 The task",
    "text": "2.1 The task\n\nCreate a sub-folder called data in In-class_Ex01 folder.\nIf necessary visit data.gov.sg and download Master Plan 2014 Subzone Boundary (Web) from the portal. You are required to download both the ESRI shapefile and kml file.\nWrite a code chunk to import Master Plan 2014 Subzone Boundary (Web) in shapefile and kml save them in sf simple features data frame.\nWrite a code chunk to export mpsz14_shp sf data.frame into kml file save the output in data sub-folder. Name the output file MP14_SUBZONE_WEB_PL.\n\n\n# This code chunk imports shapefile\nmpsz14_shp &lt;- st_read(dsn = \"data/MasterPlan2014SubzoneBoundaryWebSHP\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/In-Class_Ex01/data/MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n# This code chunk imports kml file\n# mpsz14_kml &lt;- st_read(\"data/MasterPlan2014SubzoneBoundaryKML.kml\")\n\n\n# To export mpsz14_shp sf data.frame into kml file save the output in data sub-folder\nst_write(mpsz14_shp, \n         \"data/MP14_SUBZONE_WEB_PL.kml\",\n         delete_dsn = TRUE)\n\nDeleting source `data/MP14_SUBZONE_WEB_PL.kml' using driver `KML'\nWriting layer `MP14_SUBZONE_WEB_PL' to data source \n  `data/MP14_SUBZONE_WEB_PL.kml' using driver `KML'\nWriting 323 features with 15 fields and geometry type Multi Polygon."
  },
  {
    "objectID": "In-Class_Ex01/in-class_ex01.html#the-task-2",
    "href": "In-Class_Ex01/in-class_ex01.html#the-task-2",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "3.1 The task",
    "text": "3.1 The task\n\nIf necessary visit data.gov.sg and download Pre-Schools Location from the portal. You are required to download both the kml and geojson files.\nWrite a code chunk to import Pre-Schools Location in kml geojson save them in sf simple features data frame.\n\n\n## This code chunk imports kml file.\npreschool_kml &lt;- st_read(\"data/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/In-Class_Ex01/data/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n# This code chunk imports geojson file\npreschool_geojson &lt;- st_read(\"data/PreSchoolsLocation.geojson\") \n\nReading layer `PreSchoolsLocation' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/In-Class_Ex01/data/PreSchoolsLocation.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-Class_Ex01/in-class_ex01.html#the-task-3",
    "href": "In-Class_Ex01/in-class_ex01.html#the-task-3",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "4.1 The task",
    "text": "4.1 The task\n\nVisit data.gov.sg and download Master Plan 2019 Subzone Boundary (No Sea) from the portal. You are required to download both the kml file.\nMove MPSZ-2019 shapefile provided for In-class Exercise 1 folder on elearn to data sub-folder of In-class_Ex02.\nWrite a code chunk to import Master Plan 2019 Subzone Boundary (No SEA) kml and MPSZ-2019 into sf simple feature data.frame.\n\n\n# To import shapefile\n# mpsz19_shp &lt;- st_read(dsn = \"data/\",\n#                 layer = \"MPSZ-2019\")\n\n\n# To import kml file\nmpsz19_kml &lt;- st_read(\"data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/In-Class_Ex01/data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-Class_Ex01/in-class_ex01.html#the-task-4",
    "href": "In-Class_Ex01/in-class_ex01.html#the-task-4",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "5.1 The task",
    "text": "5.1 The task\nWrite a code chunk to check the project of the imported sf objects\n\n# st_crs(mpsz19_shp)"
  },
  {
    "objectID": "In-Class_Ex01/in-class_ex01.html#the-task-5",
    "href": "In-Class_Ex01/in-class_ex01.html#the-task-5",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "6.1 The task",
    "text": "6.1 The task\nRe-write the code chunk to import the Master Plan Sub-zone 2019 and Pre-schools Location with proper transformation\n\n# To import MPSZ-2019\n# mpsz19_shp &lt;- st_read(dsn = \"data/\",\n#                 layer = \"MPSZ-2019\") %&gt;%\n#   st_transform(crs = 3414)\n\n\n# To import PreSchoolsLocation.kml\npreschool &lt;- st_read(\"data/PreSchoolsLocation.kml\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/In-Class_Ex01/data/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-Class_Ex01/in-class_ex01.html#the-task-6",
    "href": "In-Class_Ex01/in-class_ex01.html#the-task-6",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "7.1 The task",
    "text": "7.1 The task\nWrite a code chunk to count the number of pre-schools in each planning sub-zone.\n\n# mpsz19_shp &lt;- mpsz19_shp %&gt;%\n#   mutate(`PreSch Count` = lengths(\n#     st_intersects(mpsz19_shp, preschool)))"
  },
  {
    "objectID": "In-Class_Ex01/in-class_ex01.html#the-task-7",
    "href": "In-Class_Ex01/in-class_ex01.html#the-task-7",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "9.1 The task",
    "text": "9.1 The task\nUsing appropriate Exploratory Data Analysis (EDA) and Confirmatory Data Analysis (CDA) methods to explore and confirm the statistical relationship between Pre-school Density and Pre-school count.\n\n\n\n\n\n\nTip\n\n\n\nRefer to ggscatterstats() of ggstatsplot package.\n\n\n\n# mpsz$`PreSch Density` &lt;- as.numeric(as.character(mpsz19_shp$`PreSch Density`))\n# mpsz$`PreSch Count` &lt;- as.numeric(as.character(mpsz19_shp$`PreSch Count`)) \n# mpsz19_shp &lt;- as.data.frame(mpsz19_shp)\n# \n# ggscatterstats(data = mpsz19_shp,\n#                x = `PreSch Density`,\n#                y = `PreSch Count`,\n#                type = \"parametric\")"
  },
  {
    "objectID": "In-Class_Ex01/in-class_ex01.html#the-task-8",
    "href": "In-Class_Ex01/in-class_ex01.html#the-task-8",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "10.1 The task",
    "text": "10.1 The task\nVisit and extract the latest Singapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling from Singstat homepage.\n\npopdata &lt;- read_csv(\"data/respopagesextod2024.csv\")"
  },
  {
    "objectID": "In-Class_Ex01/in-class_ex01.html#the-task-9",
    "href": "In-Class_Ex01/in-class_ex01.html#the-task-9",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "11.1 The task",
    "text": "11.1 The task\nWrite a code chunk to prepare a data.frame showing population by Planning Area and Planning subzone\n\npopdata2023 &lt;- popdata %&gt;% \n  group_by(PA, SZ, AG) %&gt;% \n  summarise(`POP`=sum(`Pop`)) %&gt;%  \n  ungroup() %&gt;% \n  pivot_wider(names_from=AG,\n              values_from = POP)\n\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_over\""
  },
  {
    "objectID": "In-Class_Ex01/in-class_ex01.html#the-task-10",
    "href": "In-Class_Ex01/in-class_ex01.html#the-task-10",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "12.1 The task",
    "text": "12.1 The task\nWrite a code chunk to derive a tibble data.framewith the following fields PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY where by:\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group.\n\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate(YOUNG=rowSums(.[3:6]) # Aged 0 - 24, 10 - 24\n         +rowSums(.[14])) %&gt;% # Aged 5 - 9\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+ # Aged 25 - 59\n  rowSums(.[15])) %&gt;%  # Aged 60 -64\n  mutate(`AGED`=rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY`=(`YOUNG` + `AGED`)\n  / `ECONOMY ACTIVE`) %&gt;% \n  select(`PA`, `SZ`, `YOUNG`, \n         `ECONOMY ACTIVE`, `AGED`,\n         `TOTAL`, `DEPENDENCY`)"
  },
  {
    "objectID": "Take-home_Ex02/take-home_ex02.html#data-pre-processing-and-wrangling",
    "href": "Take-home_Ex02/take-home_ex02.html#data-pre-processing-and-wrangling",
    "title": "Take-home Ex02: Analyzing Neighborhood Bus Mobility and Emerging Urban Trends",
    "section": "5 Data Pre-processing and Wrangling",
    "text": "5 Data Pre-processing and Wrangling\nThis section details the rigorous preparation of both spatial and aspatial datasets to establish a unified analytical foundation for the subsequent spatial and spatio-temporal analyses of Singapore’s bus-mobility patterns. The procedures convert raw geospatial layers and passenger-volume tables into metrically consistent, quality-assured analytical units capable of supporting Local Moran I, Local Indicator of Spatial Association (LISA), and EHSA. All geometries are projected into the Singapore Transverse Mercator coordinate system (EPSG 3414) to maintain measurements in meters. The workflow proceeds through seven major stages: importing and projecting geospatial layers, constructing a regular hexagonal grid, validating geometric integrity, filtering relevant spatial units, integrating the aspatial passenger data, and building a balanced space–time panel for subsequent statistical modelling.\n\n5.1 Import and projection of spatial layers\nAccurate spatial statistics require that all geometries share a common projected coordinate system with metre units. This subsection imports the bus stop points and the national planning boundary, removes any third dimension or measure attributes, and projects both layers into SVY21. Using a single projection prevents unit inconsistency and ensures that all subsequent operations such as intersections, buffering, grid construction, and area or distance calculations are correct. The outcome is a pair of clean spatial layers that form the base for mainland filtering and grid creation.\n\n# Read bus stop point features from the geospatial folder\nBusStop &lt;- st_read(\"data/geospatial/BusStop.shp\") %&gt;%  # load the point layer\n  st_zm(drop = TRUE, what = \"ZM\") %&gt;%                  # drop Z and M attributes if present\n  st_transform(crs = 3414)                             # project to SVY21 in meters\n\nReading layer `BusStop' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Take-home_Ex02/data/geospatial/BusStop.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5172 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48285.52 ymax: 52983.82\nProjected CRS: SVY21\n\n# Read the planning boundary and set projection to SVY21\nmpsz &lt;- st_read(\"data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\") %&gt;%\n  st_zm(drop = TRUE, what = \"ZM\") %&gt;%    # drop Z and M for clean polygons\n  st_transform(crs = 3414)               # project to SVY21 in meters\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Take-home_Ex02/data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n## Quick structural checks\n# st_crs(BusStop)           # should report EPSG 3414\n# st_crs(mpsz)              # should report EPSG 3414\n# st_geometry_type(BusStop) # should be POINT\n# st_geometry_type(mpsz)    # should be MULTIPOLYGON\n\n\n\n5.2 Mainland mask and mainland only bus stops\nAll analysis must reflect activity on the main island. The national boundary is therefore dissolved into a single geometry and decomposed into individual polygons. The polygon with the largest area is taken as the mainland. The bus stop layer is then filtered so that only points inside the mainland polygon are retained. This prevents inclusion of stops that lie on offshore islands or in reclaimed areas outside the main island footprint. The step concludes with a map and a count audit to demonstrate that the retained points agree with the mainland extent.\n\n# --- 5.2 Mainland mask and mainland only bus stops --------------------------\n\nsg_union &lt;- st_union(mpsz) %&gt;%   # dissolve all subzones into one geometry\n  st_make_valid()                # ensure the unioned geometry is valid\n\npolys_sf &lt;- sg_union %&gt;%         # take the unioned geometry\n  st_cast(\"POLYGON\") %&gt;%         # split into single polygon parts\n  st_as_sf()                     # convert to an sf data frame for table ops\n\nsg_main &lt;- polys_sf[             # select the polygon\n  which.max(st_area(polys_sf)),  # with the largest area which is the mainland\n  ,\n  drop = FALSE\n]\n\ninside_mainland &lt;- st_within(    # compute point within polygon as a logical matrix\n  BusStop, sg_main, sparse = FALSE\n)\n\nBusStop_in_SG &lt;- BusStop[        # keep only points inside mainland\n  inside_mainland[, 1],\n]\n\n# Audit counts of retained versus removed stops\nc(total = nrow(BusStop),\n  mainland = nrow(BusStop_in_SG),\n  removed = nrow(BusStop) - nrow(BusStop_in_SG))\n\n   total mainland  removed \n    5172     5167        5 \n\n# Optional visual check of the mainland filter\ntmap_mode(\"view\")\ntm_shape(sg_main) + tm_polygons(col = \"white\", border.col = \"grey50\") +\ntm_shape(BusStop_in_SG) + tm_dots(col = \"red\", size = 0.2, alpha = 0.7) +\ntm_layout(\n  title = \"Bus stops retained on the Singapore mainland\",\n  title.position = c(\"center\", \"top\"),\n  title.size = 1.5,\n  title.fontface = \"bold\",  \n  inner.margins = c(0.05, 0.08, 0.20, 0.05),  # adjust bottom margin pushes title below frame\n  outer.margins = c(0.05, 0.08, 0.08, 0.05),  # keeps white space around map\n  frame = TRUE,\n  legend.show = FALSE\n)\n\n\n\n\n\n\nThe output confirms that the mainland filtering process was successfully executed, with 5,172 bus stop records initially detected and 5,167 retained within the Singapore mainland boundary after applying spatial masking, indicating that only five points (about 0.1%) were excluded as they fell outside the valid mainland polygon, likely on offshore islands or along the coastline. The workflow using st_union(), st_make_valid(), and st_cast(“POLYGON”) effectively consolidated all polygons and retained the largest one representing the mainland, ensuring spatial integrity before point-in-polygon filtering. The use of st_within() provides a strict geometric constraint that omits points lying exactly on the boundary, which explains the minor data loss; this can be refined by substituting with st_intersects() or buffering the polygon slightly if inclusion of boundary points is desired. The generated Quality Assurance (QA) map visually validates the correctness of the masking process, showing bus stops confined within the white mainland region bordered in grey and no spurious points beyond the coastal limits. Overall, the output verifies that the data cleaning and spatial masking steps were precise and successful, leaving only legitimate mainland bus stops for further geospatial analysis.\n\n\n5.3 Hexagon grid creation over the mainland\nA regular hexagon tessellation is generated to define neutral analytical units across the mainland. Hexagons reduce directional bias and provide a compact neighbourhood structure. The cell size is set to seven hundred meters which corresponds to a three hundred seventy five metre apothem. The grid is created only over the mainland polygon to avoid generating cells over the sea. An outline polygon is also prepared for cartographic composition in subsequent checks and figures. The section ends with a map that shows complete coverage of the mainland by the grid.\n\n# --- 5.3 Hexagon grid creation over the mainland ----------------------------\n\nhexagon &lt;- st_make_grid(\n  sg_main,            # use mainland extent\n  cellsize = 750,     # meters which approximates two times the apothem\n  what = \"polygons\",  # request polygon output\n  square = FALSE      # request hexagons rather than squares\n) %&gt;%\n  st_sf()             # convert the grid to an sf object\n\nsg_outline &lt;- sg_main # keep mainland outline for mapping\n\n# Quick checks and a coverage map\nst_is_longlat(hexagon) # should be FALSE which means metre units\n\n[1] FALSE\n\nst_crs(hexagon)        # should be EPSG 3414\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\nlength(hexagon)        # number of cells created\n\n[1] 1\n\ntmap_mode(\"plot\")\ntm_shape(sg_outline) + tm_polygons(col = \"palegreen3\", border.col = NA) +\ntm_shape(hexagon) + tm_borders(col = \"grey60\", lwd = 0.25) +\ntm_layout(\n  title = \"Hexagon grid covering the Singapore mainland\",\n  title.position = c(\"center\", \"top\"),\n  title.size = 1.5,\n  title.fontface = \"bold\",  \n  inner.margins = c(0.05, 0.08, 0.20, 0.05),  # adjust bottom margin pushes title below frame\n  outer.margins = c(0.05, 0.08, 0.08, 0.05),  # keeps white space around map\n  frame = TRUE,\n  legend.show = FALSE\n)\n\n\n\n\n\n\n\n\nThe output confirms that the hexagonal grid was successfully generated and projected in the correct coordinate reference system (EPSG:3414, SVY21 meters). The check st_is_longlat(hexagon) returned FALSE, verifying that the units are in meters rather than degrees, which is essential for accurate spatial analysis in Singapore’s projected coordinate system. The visual map shows a continuous tessellation of hexagonal cells fully covering the Singapore mainland polygon in light grey, overlaid by a green mainland outline for reference. This regular hexagonal structure offers a geometrically neutral and compact spatial framework, minimising directional bias compared to square grids. The map confirms that the grid uniformly covers the mainland extent without spilling into offshore waters, establishing a valid foundation for subsequent spatial aggregation and analysis (e.g., counting bus stops per cell or computing spatial statistics). Overall, the output verifies correct CRS, cell geometry, and mainland coverage, ensuring the tessellation is both spatially accurate and analytically reliable for the next stages of this study.\n\n\n5.4 Geometric verification of hexagon size\nThe grid must match the intended resolution. For a regular hexagon with apothem (\\(a\\)) a equal to three 75 meters, the theoretical flat to flat width is two times a which equals 750 meters, and the theoretical area equals \\(A = 2 \\sqrt3\\cdot a^2\\). Observed values from a sample cell are computed using the cell bounding box and the exact area. Close agreement between observed and theoretical values confirms that the grid represents the desired spatial scale.\n\n# --- 5.4 Geometric verification of hexagon size -----------------------------\n\none_hex   &lt;- hexagon[1, ]                       # select a sample hexagon\nbb        &lt;- st_bbox(one_hex)                   # get its bounding box\nwidth_obs &lt;- as.numeric(bb[\"xmax\"] - bb[\"xmin\"])# compute flat to flat width\narea_obs  &lt;- as.numeric(st_area(one_hex))       # compute area\n\na         &lt;- 375                                # apothem in meters\nwidth_exp &lt;- 2 * a                              # theoretical width\narea_exp  &lt;- 2 * sqrt(3) * a^2                  # theoretical area\n\nc(width_obs = width_obs, width_exp = width_exp,  # print both widths\n  area_obs = area_obs, area_exp = area_exp,      # and both areas\n  ratio_area = area_obs / area_exp)              # ratio should be close to one\n\n width_obs  width_exp   area_obs   area_exp ratio_area \n     750.0      750.0   487139.3   487139.3        1.0 \n\n\n\n\n5.5 Keep only the active hexagons that contain bus stops\nOnly cells that contain at least one mainland bus stop can originate trips. Cells without bus stops do not contribute information and would degrade the quality of spatial statistics by adding empty units. The number of bus stops within each cell is calculated using topological intersection, and only those with a positive count are retained. The result is a subset that represents the serviced mainland and forms the base for spatial aggregation and later second order analysis.\n\n# --- 5.5 Retain only cells that contain bus stops ---------------------------\n\nhexagon$busstop_count &lt;- lengths(        # count bus stops per hexagon\n  st_intersects(hexagon, BusStop_in_SG)\n)\n\nhexagon_active &lt;- dplyr::filter(         # keep cells with at least one stop\n  hexagon, busstop_count &gt; 0\n)\n\n# Distribution and a simple map for quality assurance\nsummary(hexagon$busstop_count)           # counts before filtering\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.000   0.000   1.702   2.000  20.000 \n\nmin(hexagon_active$busstop_count)        # should be at least one\n\n[1] 1\n\nnrow(hexagon_active)                     # number of active cells\n\n[1] 826\n\ntmap_mode(\"plot\")\ntm_shape(sg_outline) +\n  tm_polygons(col = \"palegreen3\", border.col = NA) +\ntm_shape(hexagon_active) + \n  tm_borders(col = \"white\", alpha = 1, border.col = \"grey40\", lwd = 0.25) +\n  tm_compass(type = \"8star\", size = 2, position = c(\"right\",\"bottom\")) +\ntm_scalebar(position = c(\"right\",\"bottom\")) +\ntm_layout(\n  title = \"Active mainland hexagons containing bus stops\",\n  title.position = c(\"center\", \"top\"),\n  title.size = 1.5,\n  title.fontface = \"bold\",  \n  inner.margins = c(0.05, 0.08, 0.20, 0.05),  # adjust bottom margin (0.10) pushes title below frame\n  outer.margins = c(0.05, 0.08, 0.08, 0.05),  # keeps white space around map\n  frame = TRUE,\n  legend.show = FALSE\n)\n\n\n\n\n\n\n\n\nThe output confirms that the filtering process accurately retained only the mainland hexagons that contain at least one bus stop, producing 826 active cells for subsequent spatial analysis. The statistical summary shows that the number of bus stops per hexagon ranges from zero to twenty, with an average of about 1.7, meaning most hexagons include one or two stops while a small number contain more. The QA map visually verifies this result as the green polygon represents the Singapore mainland boundary and the grey outlined hexagons indicate active cells that intersect with at least one bus stop. These active hexagons are distributed across the developed and populated parts of the island including the central, eastern, and northern regions, whereas large interior and peripheral zones such as the Central Water Catchment, Bukit Timah Nature Reserve, Lim Chu Kang, and Jurong Industrial Area show no active cells, reflecting the absence of public transport facilities in those regions. This confirms that the spatial filter worked correctly by excluding non urban and restricted areas, leaving a valid and realistic representation of Singapore’s operational bus stop network for further geospatial analysis.\n\n\n5.6 Assign stable identifiers to active cells\nA stable key is required to link spatial cells with aspatial tables and to keep results traceable. Sequential identifiers with leading zeros are created and attached to every active cell. These identifiers are used in all subsequent joins and aggregations. A quick check confirms that there are no duplicate keys and that all values are present.\n\n# --- 5.6 Assign stable identifiers ------------------------------------------\n\nhexagon_active &lt;- hexagon_active %&gt;%\n  mutate(HEX_ID = sprintf(\"H%04d\", row_number()))  # create codes H0001 and so on\n\nhead(hexagon_active$HEX_ID)              # preview the first few codes\n\n[1] \"H0001\" \"H0002\" \"H0003\" \"H0004\" \"H0005\" \"H0006\"\n\nany(duplicated(hexagon_active$HEX_ID))   # should be FALSE\n\n[1] FALSE\n\n\nThe output confirms that each active hexagonal cell was successfully assigned a unique identifier for reliable linking between spatial and aspatial data. Sequential codes such as H0001, H0002, and H0003 were generated using the sprintf() function, ensuring consistent formatting with leading zeros. The preview of the first six IDs confirms correct sequencing, while the validation check returned FALSE for duplicates, proving that all identifiers are unique. This step secures data integrity and traceability, allowing each cell to be distinctly referenced in subsequent spatial joins, aggregations, and visual analyses throughout our study.\n\n\n5.7 Integrate the passenger table with mainland cells\nPassenger volume data report boardings by origin stop code hour and day type. To analyse these counts spatially, each stop must inherit the identifier of the cell that contains it. A lookup from bus stop code to cell identifier is built with a point in polygon intersection restricted to the mainland. The passenger table is then harmonised by renaming and standardising keys and is joined to the lookup. Trip counts are aggregated by cell by day type and by hour to produce an hourly spatial table of passenger intensity across the mainland.\n\n# --- 5.7 Integrate passenger table with mainland cells ----------------------\n\nbs_hex &lt;- st_intersection(          # intersect stops with active cells\n  BusStop_in_SG, hexagon_active\n) %&gt;%\n  st_drop_geometry() %&gt;%            # drop geometry to keep a lean table\n  select(BUS_STOP_N, HEX_ID)        # retain stop code and cell id\n\nodbus &lt;- readr::read_csv(           # read passenger origin destination table\n  \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/take-home_ex02/data/aspatial/origin_destination_bus_202508.csv\"\n)\n\ntrips &lt;- odbus %&gt;%\n  select(ORIGIN_PT_CODE, DAY_TYPE, TIME_PER_HOUR, TOTAL_TRIPS) %&gt;% # keep needed fields\n  rename(BUS_STOP_N = ORIGIN_PT_CODE,             # standardise field names\n         HOUR_OF_DAY = TIME_PER_HOUR,\n         TRIPS = TOTAL_TRIPS) %&gt;%\n  mutate(BUS_STOP_N = str_pad(as.character(BUS_STOP_N), 5, pad = \"0\")) %&gt;% # code format\n  inner_join(bs_hex, by = \"BUS_STOP_N\") %&gt;%       # attach HEX_ID\n  group_by(HEX_ID, DAY_TYPE, HOUR_OF_DAY) %&gt;%     # group for aggregation\n  summarise(TRIPS = sum(TRIPS), .groups = \"drop\") # sum trips\n\nkable(head(trips))                                # inspect the structure\n\n\n\n\nHEX_ID\nDAY_TYPE\nHOUR_OF_DAY\nTRIPS\n\n\n\n\nH0001\nWEEKDAY\n6\n120\n\n\nH0001\nWEEKDAY\n7\n111\n\n\nH0001\nWEEKDAY\n8\n77\n\n\nH0001\nWEEKDAY\n9\n66\n\n\nH0001\nWEEKDAY\n10\n32\n\n\nH0001\nWEEKDAY\n11\n66\n\n\n\n\nsort(unique(trips$DAY_TYPE))                      # list day types\n\n[1] \"WEEKDAY\"          \"WEEKENDS/HOLIDAY\"\n\nrange(trips$HOUR_OF_DAY, na.rm = TRUE)            # check hour range\n\n[1]  0 23\n\n\nThe output confirms that the passenger trip data containing more than 5.8 million records has been successfully linked to the mainland hexagonal grid through a spatial join, assigning each bus stop and its passenger counts to a corresponding hexagonal cell. Each record now carries both spatial and temporal attributes represented by the hexagon identifier, day type, and hour of day, allowing aggregation of trip volumes by space and time. The sample output for cell H0001 shows weekday trips ranging from 32 to 120 between 6 am and 11 am, clearly reflecting hourly variations that form the foundation for spatio-temporal analysis. Although this integration provides a crucial spatial-temporal linkage, it is not yet sufficient to construct a time-space cube, as the current table remains in a flat structure without explicit three-dimensional temporal stacking or spatial indexing. The next section will therefore build upon this output to prepare the data for time-space cube generation by restructuring it into a multidimensional format suitable for analysing dynamic passenger intensity across both space and time.\n\n\n5.8 Build a balanced space time panel with geometry\nA complete space time dataset requires the full set of cells across the full set of hours for each day type. The keys are created from all active cells the two canonical day types and the twenty four hours. The aggregated trips are left joined to this key and missing combinations are zero filled. Geometry from the active cells is attached to every row and a chronological index is created to allow ordering and trend analysis. Strict assertions confirm that the panel is complete and that each cell day combination contributes exactly twenty four hourly rows.\n\n# --- 5.8 Balanced space time panel with geometry ----------------------------\n\nkey_hex   &lt;- hexagon_active$HEX_ID              # full universe of active cells\nkey_days  &lt;- c(\"WEEKDAY\", \"WEEKENDS/HOLIDAY\")   # canonical day types\nkey_hours &lt;- 0:23                               # full set of hours\n\nkey_full &lt;- expand_grid(                        # full Cartesian product\n  HEX_ID = key_hex,\n  DAY_TYPE = key_days,\n  HOUR_OF_DAY = key_hours\n)\n\ntrips_full &lt;- key_full %&gt;%              # attach trip counts to the key\n  left_join(trips, by = c(\"HEX_ID\", \"DAY_TYPE\", \"HOUR_OF_DAY\")) %&gt;%\n  mutate(TRIPS = coalesce(TRIPS, 0L))   # zero fill missing combinations\n\ntrips_panel_sf &lt;- hexagon_active %&gt;%    # attach geometry to each row\n  select(HEX_ID, geometry) %&gt;%\n  right_join(trips_full, by = \"HEX_ID\") %&gt;%\n  mutate(datetime = as.POSIXct(sprintf(\"2024-05-01 %02d:00:00\", HOUR_OF_DAY),\n                               tz = \"UTC\")) %&gt;%\n  st_as_sf()                            # convert to sf object with geometry\n\nThe chunk code below will be executed to validate the completeness of balanced space-time cube.\n\n# # --- Validation: Balanced space–time panel completeness ---------------------\n# \n# expected_n &lt;- length(key_hex) * length(key_days) * length(key_hours)\n# \n# # Actual number of rows in the panel\n# actual_n &lt;- nrow(trips_panel_sf)\n# \n# cat(\"\\nValidation Summary for trips_panel_sf\\n\")\n# cat(\"---------------------------------------\\n\")\n# cat(\"Expected number of rows : \", expected_n, \"\\n\")\n# cat(\"Actual number of rows   : \", actual_n, \"\\n\")\n# \n# # Check that each HEX_ID × DAY_TYPE combination has exactly 24 rows\n# chk &lt;- trips_panel_sf %&gt;%\n#   count(HEX_ID, DAY_TYPE, name = \"n_rows\")\n# \n# rows_ok   &lt;- all(chk$n_rows == 24)\n# rows_fail &lt;- chk %&gt;% filter(n_rows != 24)\n# \n# cat(\"\\nPer-cell/day completeness check:\\n\")\n# cat(\"  All HEX_ID × DAY_TYPE combinations have 24 rows?  \",\n#     ifelse(rows_ok, \"✅ YES\", \"❌ NO\"), \"\\n\")\n# if (!rows_ok) {\n#   cat(\"  HEX_IDs failing completeness:\\n\")\n#   print(rows_fail)\n# }\n# \n# # Ensure uniqueness per HEX_ID × DAY_TYPE × HOUR_OF_DAY\n# dup &lt;- trips_panel_sf %&gt;%\n#   count(HEX_ID, DAY_TYPE, HOUR_OF_DAY, name = \"n\") %&gt;%\n#   filter(n != 1)\n# \n# dup_ok &lt;- nrow(dup) == 0\n# cat(\"\\nUniqueness check for HEX_ID × DAY_TYPE × HOUR_OF_DAY:\\n\")\n# cat(\"  Duplicates present? \", ifelse(dup_ok, \"✅ NO\", \"❌ YES\"), \"\\n\")\n# if (!dup_ok) {\n#   cat(\"  Duplicated keys:\\n\")\n#   print(dup)\n# }\n# \n# # Check for missing keys or invalid geometry\n# na_hex   &lt;- sum(is.na(trips_panel_sf$HEX_ID))\n# na_day   &lt;- sum(is.na(trips_panel_sf$DAY_TYPE))\n# na_hour  &lt;- sum(is.na(trips_panel_sf$HOUR_OF_DAY))\n# geom_val &lt;- all(st_is_valid(trips_panel_sf))\n# \n# cat(\"\\nKey and geometry diagnostics:\\n\")\n# cat(\"  Missing HEX_ID values  : \", na_hex, \"\\n\")\n# cat(\"  Missing DAY_TYPE values: \", na_day, \"\\n\")\n# cat(\"  Missing HOUR_OF_DAY    : \", na_hour, \"\\n\")\n# cat(\"  Geometry validity OK?  : \", ifelse(geom_val, \"✅ YES\", \"❌ NO\"), \"\\n\")\n# \n# # Simple assertion guards (keep them for safety)\n# stopifnot(actual_n == expected_n)\n# stopifnot(rows_ok)\n# stopifnot(dup_ok)\n# stopifnot(na_hex == 0, na_day == 0, na_hour == 0)\n# stopifnot(geom_val)\n# \n# cat(\"\\n✅  Validation completed successfully — trips_panel_sf is fully balanced, unique, and geometrically valid.\\n\")\n\nThe validation output confirms that the balanced space–time panel was successfully constructed and meets all completeness and integrity checks required for time–space cube preparation. The expected and actual row counts match at 39,648, proving that every active hexagon has records for both day types and all 24 hourly periods. Each cell–day combination contains exactly 24 rows, ensuring full temporal coverage, while no duplicate entries were detected across the HEX_ID, DAY_TYPE, and HOUR_OF_DAY dimensions. Additionally, there are no missing identifiers or invalid geometries, and all spatial features are confirmed valid. This guarantees that the dataset is fully balanced, unique, and spatially sound. With this validated panel, the data is now structurally sufficient for constructing a time–space cube, enabling spatio–temporal visualisation and analysis of passenger trip intensity across Singapore’s mainland bus network.\nNext, we will include a concise tabular preview and completeness summary of the trips_full dataset, inspecting and confirming that all spatial cells, day types, and hourly intervals are represented before geometry is attached. It provides transparent evidence of balanced coverage across time and space for subsequent spatio-temporal analyses.\n\n# --- 5.8a Informational tables for trips_full --------------------------------\n# Show a tidy preview of trips_full so the panel content is transparent\n\n# Order rows for human reading then take the first ten per day type\npreview_trips_full &lt;- trips_full %&gt;%\n  dplyr::arrange(HEX_ID, DAY_TYPE, HOUR_OF_DAY) %&gt;%\n  dplyr::group_by(DAY_TYPE) %&gt;%\n  dplyr::slice_head(n = 10) %&gt;%\n  dplyr::ungroup()\n\nknitr::kable(\n  preview_trips_full,\n  caption = \"Preview of trips_full ordered by cell day and hour\"\n)\n\n\nPreview of trips_full ordered by cell day and hour\n\n\nHEX_ID\nDAY_TYPE\nHOUR_OF_DAY\nTRIPS\n\n\n\n\nH0001\nWEEKDAY\n0\n0\n\n\nH0001\nWEEKDAY\n1\n0\n\n\nH0001\nWEEKDAY\n2\n0\n\n\nH0001\nWEEKDAY\n3\n0\n\n\nH0001\nWEEKDAY\n4\n0\n\n\nH0001\nWEEKDAY\n5\n0\n\n\nH0001\nWEEKDAY\n6\n120\n\n\nH0001\nWEEKDAY\n7\n111\n\n\nH0001\nWEEKDAY\n8\n77\n\n\nH0001\nWEEKDAY\n9\n66\n\n\nH0001\nWEEKENDS/HOLIDAY\n0\n0\n\n\nH0001\nWEEKENDS/HOLIDAY\n1\n0\n\n\nH0001\nWEEKENDS/HOLIDAY\n2\n0\n\n\nH0001\nWEEKENDS/HOLIDAY\n3\n0\n\n\nH0001\nWEEKENDS/HOLIDAY\n4\n0\n\n\nH0001\nWEEKENDS/HOLIDAY\n5\n0\n\n\nH0001\nWEEKENDS/HOLIDAY\n6\n114\n\n\nH0001\nWEEKENDS/HOLIDAY\n7\n81\n\n\nH0001\nWEEKENDS/HOLIDAY\n8\n126\n\n\nH0001\nWEEKENDS/HOLIDAY\n9\n132\n\n\n\n\n# Compact completeness summary to accompany the preview\nsummary_trips_full &lt;- dplyr::summarise(\n  trips_full,\n  n_rows       = dplyr::n(),\n  n_hex        = dplyr::n_distinct(HEX_ID),\n  n_day_types  = dplyr::n_distinct(DAY_TYPE),\n  n_hours      = dplyr::n_distinct(HOUR_OF_DAY),\n  min_hour     = min(HOUR_OF_DAY, na.rm = TRUE),\n  max_hour     = max(HOUR_OF_DAY, na.rm = TRUE),\n  zeros_in_TRIPS = sum(TRIPS == 0, na.rm = TRUE)\n)\n\nknitr::kable(\n  summary_trips_full,\n  caption = \"Completeness summary of trips_full\"\n)\n\n\nCompleteness summary of trips_full\n\n\n\n\n\n\n\n\n\n\n\nn_rows\nn_hex\nn_day_types\nn_hours\nmin_hour\nmax_hour\nzeros_in_TRIPS\n\n\n\n\n39648\n826\n2\n24\n0\n23\n7502\n\n\n\n\n# Optional distribution by hour and day to verify balanced coverage\nby_hour_day &lt;- trips_full %&gt;%\n  dplyr::count(DAY_TYPE, HOUR_OF_DAY, name = \"n_records\") %&gt;%\n  dplyr::arrange(DAY_TYPE, HOUR_OF_DAY)\n\nknitr::kable(\n  by_hour_day,\n  caption = \"Record count in trips_full by day type and hour\"\n)\n\n\nRecord count in trips_full by day type and hour\n\n\nDAY_TYPE\nHOUR_OF_DAY\nn_records\n\n\n\n\nWEEKDAY\n0\n826\n\n\nWEEKDAY\n1\n826\n\n\nWEEKDAY\n2\n826\n\n\nWEEKDAY\n3\n826\n\n\nWEEKDAY\n4\n826\n\n\nWEEKDAY\n5\n826\n\n\nWEEKDAY\n6\n826\n\n\nWEEKDAY\n7\n826\n\n\nWEEKDAY\n8\n826\n\n\nWEEKDAY\n9\n826\n\n\nWEEKDAY\n10\n826\n\n\nWEEKDAY\n11\n826\n\n\nWEEKDAY\n12\n826\n\n\nWEEKDAY\n13\n826\n\n\nWEEKDAY\n14\n826\n\n\nWEEKDAY\n15\n826\n\n\nWEEKDAY\n16\n826\n\n\nWEEKDAY\n17\n826\n\n\nWEEKDAY\n18\n826\n\n\nWEEKDAY\n19\n826\n\n\nWEEKDAY\n20\n826\n\n\nWEEKDAY\n21\n826\n\n\nWEEKDAY\n22\n826\n\n\nWEEKDAY\n23\n826\n\n\nWEEKENDS/HOLIDAY\n0\n826\n\n\nWEEKENDS/HOLIDAY\n1\n826\n\n\nWEEKENDS/HOLIDAY\n2\n826\n\n\nWEEKENDS/HOLIDAY\n3\n826\n\n\nWEEKENDS/HOLIDAY\n4\n826\n\n\nWEEKENDS/HOLIDAY\n5\n826\n\n\nWEEKENDS/HOLIDAY\n6\n826\n\n\nWEEKENDS/HOLIDAY\n7\n826\n\n\nWEEKENDS/HOLIDAY\n8\n826\n\n\nWEEKENDS/HOLIDAY\n9\n826\n\n\nWEEKENDS/HOLIDAY\n10\n826\n\n\nWEEKENDS/HOLIDAY\n11\n826\n\n\nWEEKENDS/HOLIDAY\n12\n826\n\n\nWEEKENDS/HOLIDAY\n13\n826\n\n\nWEEKENDS/HOLIDAY\n14\n826\n\n\nWEEKENDS/HOLIDAY\n15\n826\n\n\nWEEKENDS/HOLIDAY\n16\n826\n\n\nWEEKENDS/HOLIDAY\n17\n826\n\n\nWEEKENDS/HOLIDAY\n18\n826\n\n\nWEEKENDS/HOLIDAY\n19\n826\n\n\nWEEKENDS/HOLIDAY\n20\n826\n\n\nWEEKENDS/HOLIDAY\n21\n826\n\n\nWEEKENDS/HOLIDAY\n22\n826\n\n\nWEEKENDS/HOLIDAY\n23\n826\n\n\n\n\n\nThe tables verify that trips_full is a complete and well ordered space time panel ready for cube construction. The preview shows rows sorted by cell, day type, and hour, with cell H0001 illustrating zero values at early hours and rising counts from 6 to 11, which matches expected morning activity. The completeness summary reports 39,648 rows across 826 hexagons, two day types, and twenty four hourly slots from zero to twenty three, with 7,502 zero trip entries correctly retained as structural zeros rather than missing data. The final check lists exactly 826 records for every hour within each day type, confirming that every cell day combination contributes twenty four rows. Together these results demonstrate full temporal coverage, consistent spatial indexing, and integrity of counts, which is sufficient for building the time space cube in the next step."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Geospatial Analytics and Applications Coursework",
    "section": "",
    "text": "Welcome to Geospatial Analytics and Application (ISSS626). This website collects my submission of coursework. Use the top navigation bar to open each page."
  },
  {
    "objectID": "index.html#quick-links-recent-submissions",
    "href": "index.html#quick-links-recent-submissions",
    "title": "Geospatial Analytics and Applications Coursework",
    "section": "Quick Links – Recent Submissions",
    "text": "Quick Links – Recent Submissions\n(Refer to the drop-down menus above for complete list of assignment submissions)\n\n👉 In-class Exercise 8: Open the assignment\n👉 Hands-on Exercise 8: Open the assignment\n👉 Take-home Exercise 2: Open the assignment\n👉 In-class Exercise 7: Open the assignment\n👉 Hands-on Exercise 7: Open the assignment"
  },
  {
    "objectID": "index.html#objectives",
    "href": "index.html#objectives",
    "title": "Geospatial Analytics and Applications Coursework",
    "section": "Objectives:",
    "text": "Objectives:\n\nDemonstrate step-by-step workflows for geospatial tasks that a beginner can follow.\nUse clear, descriptive names and relative file paths so the website renders correctly on Netlify.\nProvide reproducible results with the same structure for every assignment."
  },
  {
    "objectID": "In-Class_Ex07/in-class_ex07.html",
    "href": "In-Class_Ex07/in-class_ex07.html",
    "title": "In-class_Ex07: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "Geographically Weighted Regression (GWR) allows relationships between predictors (independent variables) and an outcome (dependent variable) to vary by location. In hedonic pricing, we model the resale prices of condominium units using structural factors (e.g., floor area, age) and locational accessibility (e.g., proximity to transport, parks, schools)."
  },
  {
    "objectID": "In-Class_Ex07/in-class_ex07.html#getting-started",
    "href": "In-Class_Ex07/in-class_ex07.html#getting-started",
    "title": "In-class_Ex07: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "3 Getting Started",
    "text": "3 Getting Started\nBefore we get started, it is important for us to install the necessary R packages into R and launch these R packages into R environment.\n\n# Install and load all required packages in one call --------------------------------\n# pacman::p_load() will install any missing packages and then load them into memory\npacman::p_load(olsrr, corrplot, ggpubr,\n               sf, sfdep, GWmodel, tmap,\n               tidyverse, gtsummary,\n               performance, RColorBrewer, see)\n\nThe R packages needed for this exercise are as follows:\n\nsf: spatial vector data handling; projections.\nsfdep: spatial weights and Moran’s I with tidy‑sf interface.\nGWmodel: GWR bandwidth search and model fitting.\ntmap: static/interactive maps.\ntidyverse: wrangling (dplyr, readr, ggplot2).\nolsrr, performance: OLS diagnostics, VIF, assumption checks.\ncorrplot: correlation matrix visual.\ngtsummary: publication‑quality regression tables.\nRColorBrewer: color palettes for maps."
  },
  {
    "objectID": "In-Class_Ex07/in-class_ex07.html#overview",
    "href": "In-Class_Ex07/in-class_ex07.html#overview",
    "title": "In-class_Ex07: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "Geographically Weighted Regression (GWR) allows relationships between predictors (independent variables) and an outcome (dependent variable) to vary by location. In hedonic pricing, we model the resale prices of condominium units using structural factors (e.g., floor area, age) and locational accessibility (e.g., proximity to transport, parks, schools)."
  },
  {
    "objectID": "In-Class_Ex07/in-class_ex07.html#the-data",
    "href": "In-Class_Ex07/in-class_ex07.html#the-data",
    "title": "In-class_Ex07: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "2 The Data",
    "text": "2 The Data\n\nGeospatial: MP14_SUBZONE_WEB_PL (subzone polygons; SVY21 projection).\nAspatial: Condo_resale_2015.csv with columns such as SELLING_PRICE, AREA_SQM, AGE, and multiple proximity variables (in kilometers) to amenities (MRT, parks, schools, etc.)."
  },
  {
    "objectID": "In-Class_Ex07/in-class_ex07.html#geospatial-data-wrangling",
    "href": "In-Class_Ex07/in-class_ex07.html#geospatial-data-wrangling",
    "title": "In-class_Ex07: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "4 Geospatial Data Wrangling",
    "text": "4 Geospatial Data Wrangling\n\n4.1 Importing geospatial data\n\n# Read the URA Master Plan 2014 subzone shapefile\n# dsn: directory; layer: shapefile base name without extension\nmpsz = st_read(dsn = \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex07/data/geospatial\",\n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex07/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n4.2 Updating CRS information to EPSG:3414 (SVY21 meters)\n\n# Transform the coordinate reference system to SVY21 / EPSG:3414\n# This ensures all distance‑based operations use meters (required by GWR bandwidth)\nmpsz_svy21 &lt;- st_transform(mpsz, 3414)\n\n\n# Verify the target CRS\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNext, inspect layer extent (bounding box)\n\nst_bbox(mpsz_svy21)\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334 \n\n\nThe print above reports the extent of mpsz_svy21 layer by its lower and upper limits."
  },
  {
    "objectID": "In-Class_Ex07/in-class_ex07.html#aspatial-data-wrangling",
    "href": "In-Class_Ex07/in-class_ex07.html#aspatial-data-wrangling",
    "title": "In-class_Ex07: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "5 Aspatial Data Wrangling",
    "text": "5 Aspatial Data Wrangling\n\n5.1 Importing the aspatial data and inspect\n\n# Read the 2015 condo resale dataset as a tibble\ncondo_resale = read_csv(\n  \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex07/data/aspatial/Condo_resale_2015.csv\")\n\nRows: 1436 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (23): LATITUDE, LONGITUDE, POSTCODE, SELLING_PRICE, AREA_SQM, AGE, PROX_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n# Peek at structure: variable names, types, first few rows\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             &lt;dbl&gt; 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            &lt;dbl&gt; 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\nhead(condo_resale$LONGITUDE)\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\n\n\nhead(condo_resale$LATITUDE)\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\nThe print above reveals that the values of LONGITITUDE and LATITUDE fields are in decimal degree. Most probably wgs84 geographic coordinate system is used.\n\n# Quick descriptive statistics for all columns\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\n\n5.2 Converting aspatial data frame into a sf object\n\n# Convert LONGITUDE/LATITUDE (WGS84) to POINT geometry and reproject to SVY21\n# 1) st_as_sf(): declare coordinates (lon, lat) with crs=4326 (WGS84 degrees)\n# 2) st_transform(): project to EPSG:3414 so distances are in meters\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that st_transform() of sf package is used to convert the coordinates from wgs84 (i.e. crs:4326) to svy21 (i.e. crs=3414).\n\n\n\n# Confirm the first few records including geometry\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n     &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1   118635       3000000      309    30     7.94          0.166            2.52 \n2   288420       3880000      290    32     6.61          0.280            1.93 \n3   267833       3325000      248    33     6.90          0.429            0.502\n4   258380       4250000      127     7     4.04          0.395            1.99 \n5   467169       1400000      145    28    11.8           0.119            1.12 \n6   466472       1320000      139    22    10.3           0.125            0.789\n# ℹ 15 more variables: PROX_URA_GROWTH_AREA &lt;dbl&gt;, PROX_HAWKER_MARKET &lt;dbl&gt;,\n#   PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;, PROX_PARK &lt;dbl&gt;,\n#   PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\n\nNotice that the output is in point feature data frame."
  },
  {
    "objectID": "In-Class_Ex07/in-class_ex07.html#exploratory-data-analysis-eda",
    "href": "In-Class_Ex07/in-class_ex07.html#exploratory-data-analysis-eda",
    "title": "In-class_Ex07: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "6 Exploratory Data Analysis (EDA)",
    "text": "6 Exploratory Data Analysis (EDA)\n\n6.1 EDA using statistical graphics\nWe can plot the distribution of SELLING_PRICE by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\n\n# Plot raw SELLING_PRICE distribution\n# aes(x=SELLING_PRICE) maps the price variable to the x‑axis for a histogram\nggplot(data = condo_resale.sf,\n       aes(x = `SELLING_PRICE`)) +\n  geom_histogram(bins = 20,           # 20 equal‑width bins\n                 color = \"black\",     # black outline for readability\n                 fill = \"light blue\") # soft fill color for clarity\n\n\n\n\n\n\n\n\nThe figure above reveals a right skewed distribution. This means that more condominium units were transacted at relative lower prices.\nStatistically, the skewed dsitribution can be normalised by using log transformation. The code chunk below is used to derive a new variable called LOG_SELLING_PRICE by using a log transformation on the variable SELLING_PRICE. It is performed using mutate() of dplyr package.\n\n# Create a log‑price to reduce skewness\n# mutate() adds a new variable LOG_SELLING_PRICE = log(SELLING_PRICE)\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nNow, we can plot the LOG_SELLING_PRICE using the code chunk below.\n\n# Plot the log‑transformed price distribution -----------------------------------\nggplot(data = condo_resale.sf,\n       aes(x = `LOG_SELLING_PRICE`)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\")\n\n\n\n\n\n\n\n\nNotice that the distribution is relatively less skewed after the transformation.\n\n\n6.2 Multiple Histogram Plots distribution of variables\nn this section, we will learn how to draw a small multiple histograms (also known as trellis plot) by using ggarrange() of ggpubr package.\nThe code chunk below is used to create 12 histograms. Then, ggarrange() is used to organised these histogram into a 3 columns by 4 rows small multiple plot.\n\n# Build individual histograms for key predictors ---------------------------------\nAREA_SQM &lt;- ggplot(data = condo_resale.sf, aes(x = `AREA_SQM`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nAGE &lt;- ggplot(data = condo_resale.sf, aes(x = `AGE`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_CBD &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_CBD`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_CHILDCARE &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_CHILDCARE`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_ELDERLYCARE &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_URA_GROWTH_AREA &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_HAWKER_MARKET &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_KINDERGARTEN &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_MRT &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_MRT`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_PARK &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_PARK`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_PRIMARY_SCH &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\nPROX_TOP_PRIMARY_SCH &lt;- ggplot(data = condo_resale.sf, aes(x = `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\")\n\n# Arrange the 12 histograms into a 3x4 panel ------------------------------------\n# ggarrange() helps create small‑multiples (trellis) display\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE,\n          PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA,\n          PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)"
  },
  {
    "objectID": "In-Class_Ex07/in-class_ex07.html#hedonic-pricing-modelling-in-r",
    "href": "In-Class_Ex07/in-class_ex07.html#hedonic-pricing-modelling-in-r",
    "title": "In-class_Ex07: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "7 Hedonic Pricing Modelling in R",
    "text": "7 Hedonic Pricing Modelling in R\nIn this section, we will learn how to building hedonic pricing models for condominium resale units using lm() of R base.\n\n7.1 Simple Linear Regression (SLR): SELLING_PRICE ~ AREA_SQM\n\n# Fit a simple linear regression with floor area as the only predictor ------------\ncondo.slr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM,\n                data = condo_resale.sf)\n\n\n# Print model summary: coefficients, R², p‑values, residual spread ----------------\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: &lt; 2.2e-16\n\n\nThe output report reveals that the SELLING_PRICE can be explained by using the formula:\n\\[\\text{Selling_Price} = -258121.1 + 14719\\cdot\\text{Area_SQM}\\]\nThe R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince p-value is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of SELLING_PRICE.\nThe Coefficients: section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.\nTo visualise the best fit curve on a scatterplot, we can incorporate lm() as a method function in ggplot’s geometry as shown in the code chunk below.\n\n# Visualize scatter with best‑fit line from lm() ---------------------------------\n# geom_smooth(method = lm) overlays the OLS regression line with CI ribbon\nggplot(data = condo_resale.sf,  \n       aes(x = `AREA_SQM`, y = `SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nFigure above reveals that there are a few statistical outliers with relatively high selling prices.\n\n\n7.2 Multiple Linear Regression Method\n\n7.2.1 Visualising the relationships of the independent variables\nBefore building a multiple regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other. If these highly correlated independent variables are used in building a regression model by mistake, the quality of the model will be compromised. This phenomenon is known as multicollinearity in statistics.\nCorrelation matrix is commonly used to visualise the relationships between the independent variables. Beside the pairs() of R, there are many packages support the display of a correlation matrix. In this section, the corrplot package will be used.\nThe code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in condo_resale data.frame.\n\n# Visualize pairwise correlations among predictors (cols 5:23 from the CSV) ------\ncorrplot(cor(condo_resale[, 5:23]),\n         diag = FALSE,\n         order = \"AOE\",      # Angular Order of Eigenvectors (stable ordering)\n         tl.pos = \"td\",      # text labels on top diagonal\n         tl.cex = 0.5,        # smaller text\n         method = \"number\",  # print numeric correlations\n         type = \"upper\")     # upper triangle only\n\n\n\n\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, LEASE_99YEAR is excluded in the subsequent model building.\n\n\n\n7.3 Building a hedonic pricing model using multiple linear regression method\nThe code chunk below using lm() to calibrate the multiple linear regression model.\n\n# Build the full hedonic model (drop LEASEHOLD_99YR to avoid high correlation) ---\ncondo.mlr &lt;- lm(\n  formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n    PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n    PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET   +\n    PROX_KINDERGARTEN   + PROX_MRT  + PROX_PARK +\n    PROX_PRIMARY_SCH + PROX_TOP_PRIMARY_SCH +\n    PROX_SHOPPING_MALL  + PROX_SUPERMARKET + \n    PROX_BUS_STOP   + NO_Of_UNITS + \n    FAMILY_FRIENDLY + FREEHOLD, \n  data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  &lt; 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  &lt; 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  &lt; 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk above consists of two parts:\n- lm() of Base R is used to calibrate a multiple linear regression model. The model output is stored in an lm object called condo.mlr.\n- summary() is used to print the model output.\n\n\n\n\n7.4 Revising the model by removing non-significant predictors\nWith reference to the report above, it is clear that not all the independent variables are statistically significant. We will revised the model by removing those variables which are not statistically significant.\nNow, we are ready to calibrate the revised model by using the code chunk below.\n\n# Remove variables with weak significance to improve parsimony -------------------\ncondo.mlr1 &lt;- lm(\n  formula = SELLING_PRICE ~ AREA_SQM + AGE + \n    PROX_CBD + PROX_CHILDCARE + PROX_MRT +\n    PROX_ELDERLYCARE    + PROX_URA_GROWTH_AREA +\n    PROX_PARK   + PROX_PRIMARY_SCH + \n    PROX_SHOPPING_MALL  + PROX_BUS_STOP + \n    NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n  data = condo_resale.sf)\n\n\n# Verify all retained predictors are significant at 5% (or better) ---------------\nsummary(condo.mlr1)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_MRT + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_PARK + \n    PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n    FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\nAREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\nAGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\nPROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\nPROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \nPROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\nPROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\nPROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\nPROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \nPROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\nPROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\nNO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \nFAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \nFREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 756000 on 1421 degrees of freedom\nMultiple R-squared:  0.6507,    Adjusted R-squared:  0.6472 \nF-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16\n\n\nThe output above reveals that all explanatory variables are statistically significant at 95% confident level.\n\n\n7.5 Preparing Publication Quality Table: gtsummary method\nThe gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R.\nIn the code chunk below, tbl_regression() is used to create a well formatted regression report.\n\n# Create a clean table of coefficients, CIs, and p‑values\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI\np-value\n\n\n\n\n(Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n\n\nAREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n\n\nAGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n\n\nPROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n\n\nPROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n\n\nPROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n\n\nPROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n\n\nPROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n\n\nPROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n\n\nPROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n\n\nPROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n\n\nPROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n\n\nNO_Of_UNITS\n-245\n-418, -73\n0.005\n\n\nFAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n\n\nFREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n\n\n\nAbbreviation: CI = Confidence Interval\n\n\n\n\n\n\n\n\nWith gtsummary package, model statistics can be included in the report by either appending them to the report table by using add_glance_table() or adding as a table source note by using add_glance_source_note() as shown in the code chunk below.\n\n# Append model‑level statistics as a footnote (AIC, R², sigma, etc.) -------------\ntbl_regression(condo.mlr1,\nintercept = TRUE) %&gt;%\nadd_glance_source_note(\nlabel = list(sigma ~ \"σ\"), # Greek sigma symbol\ninclude = c(r.squared, adj.r.squared,\nAIC, statistic,\np.value, sigma))\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI\np-value\n\n\n\n\n(Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n\n\nAREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n\n\nAGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n\n\nPROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n\n\nPROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n\n\nPROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n\n\nPROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n\n\nPROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n\n\nPROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n\n\nPROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n\n\nPROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n\n\nPROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n\n\nNO_Of_UNITS\n-245\n-418, -73\n0.005\n\n\nFAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n\n\nFREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n\n\n\nAbbreviation: CI = Confidence Interval\n\n\nR² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = &lt;0.001; σ = 755,957\n\n\n\n\n\n\n\n\nFor more customization options, refer to Tutorial: tbl_regression.\n\n\n7.6 Regression Diagnostics\nRegression diagnostics are a set of procedures used to check if a regression model’s assumptions are met and how well the model fits the data. These diagnostics involve checking for issues like non-linear relationships, non-normal errors, non-constant variance, and influential observations to ensure the model’s conclusions are valid and reliable. Common methods include graphical analysis, like residual plots and QQ-plots, and quantitative tests\nIn this section, we would like to introduce a fantastic R package specially programmed for performing OLS regression diagnostics. It is called olsrr. It provides a collection of very useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\n\nresidual diagnostics\n\nmeasures of influence\n\nheteroskedasticity tests\n\ncollinearity diagnostics\n\nmodel fit assessment\n\nvariable contribution assessment\n\nvariable selection procedures\n\n\n7.6.1 Multicollinearity test\nMulticollinearity occurs when independent variables are not truly independent, meaning a change in one is associated with a change in another. This makes it hard for the model to isolate each variable’s influence on the outcome.\nPerforming a multicollinearity test is crucial in multiple linear regression because it ensures the reliability and interpretability of the model’s results. High multicollinearity, where independent variables are highly correlated, inflates the variance of the estimated coefficients, making them unstable, unreliable, and difficult to interpret. This instability can lead to misleading statistical conclusions, such as a variable appearing statistically insignificant when it is not.\nIn the code chunk below, the check_collinearity() of performance package is used to test if there are sign of multicollinearity.\n\n# Check Variance Inflation Factors (VIF) to confirm low multicollinearity --------\nmlr.vif &lt;- check_collinearity(condo.mlr1) # compute VIFs\nmlr.vif # print the table\n\n# Check for Multicollinearity\n\nLow Correlation\n\n                 Term  VIF   VIF 95% CI adj. VIF Tolerance Tolerance 95% CI\n             AREA_SQM 1.15 [1.09, 1.23]     1.07      0.87     [0.81, 0.92]\n                  AGE 1.41 [1.33, 1.52]     1.19      0.71     [0.66, 0.75]\n             PROX_CBD 1.57 [1.47, 1.69]     1.25      0.64     [0.59, 0.68]\n       PROX_CHILDCARE 3.26 [3.00, 3.56]     1.81      0.31     [0.28, 0.33]\n             PROX_MRT 1.91 [1.78, 2.07]     1.38      0.52     [0.48, 0.56]\n     PROX_ELDERLYCARE 1.52 [1.42, 1.63]     1.23      0.66     [0.61, 0.70]\n PROX_URA_GROWTH_AREA 1.33 [1.26, 1.43]     1.15      0.75     [0.70, 0.80]\n            PROX_PARK 1.21 [1.15, 1.29]     1.10      0.83     [0.77, 0.87]\n     PROX_PRIMARY_SCH 2.21 [2.05, 2.40]     1.49      0.45     [0.42, 0.49]\n   PROX_SHOPPING_MALL 1.48 [1.39, 1.60]     1.22      0.67     [0.63, 0.72]\n        PROX_BUS_STOP 2.85 [2.62, 3.10]     1.69      0.35     [0.32, 0.38]\n          NO_Of_UNITS 1.45 [1.36, 1.56]     1.20      0.69     [0.64, 0.73]\n      FAMILY_FRIENDLY 1.38 [1.30, 1.48]     1.17      0.72     [0.67, 0.77]\n             FREEHOLD 1.44 [1.36, 1.55]     1.20      0.69     [0.65, 0.74]\n\nplot(mlr.vif) # quick visual of VIF levels\n\n\n\n\n\n\n\n\nSince the VIF of the independent variables are less than 10. We can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n\n7.6.2 Test for Non-Linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\n#check_model(condo.mlr1, check = \"linearity\")\n\n# Visual check that residuals vs fitted show no strong non‑linearity -------------\nggplot(data = data.frame(Fitted = fitted(condo.mlr1), Residuals = resid(condo.mlr1)),\naes(x = Fitted, y = Residuals)) +\ngeom_point(color = 'blue', alpha = 0.6) +\ngeom_smooth(method = 'loess', se = TRUE, color = 'green', fill = 'grey70') +\ngeom_hline(yintercept = 0, color = 'black', linetype = 'dashed') +\nlabs(title = 'Linearity', subtitle = 'Reference line should be flat and horizontal',\nx = 'Fitted values', y = 'Residuals') +\ntheme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe figure above reveals that most of the data poitns are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n7.6.3 Test for Normality Assumption\nThe normality assumption test for multiple linear regression checks if the model’s residuals (the differences between observed and predicted values) are normally distributed. This is crucial for accurate hypothesis testing and confidence intervals. To test this, we can use visual methods like histograms and Q-Q plots of the residuals, or conduct statistical tests like Shapiro-Wilk test and Kolmogorov-Smirnov test.\nIn the code chunk below, check_normality() of performance package is used to perform normality assumption test on condo.mlr1 model.\n\n# Formal test (often significant with large n); complement with Q‑Q plot ---------\ncheck_normality(condo.mlr1)\n\nWarning: Non-normality of residuals detected (p &lt; .001).\n\n\nThe print above reveals that the p-value of the normality assumption test is less than alpha value of 0.05. Hence we reject the normality assumption at 95% confident level.\n\n\n\n\n\n\nNote\n\n\n\n\ncheck_normality() calls stats::shapiro.test and checks the standardized residuals (or studentized residuals for mixed models) for normal distribution.\n\nNote that this formal test almost always yields significant results for the distribution of residuals and visual inspection (e.g. Q-Q plots) are preferable.\n\n\n\nInstead of showing the test statistic, plot() of see package can be used to plot a the output of check_normality() for visual inspection as shown below.\n\n# Q‑Q plot of standardized residuals from the check_normality() output -----------\nplot(check_normality(condo.mlr1), type = \"qq\")\n\nFor confidence bands, please install `qqplotr`.\n\n\n\n\n\n\n\n\n\nQ-Q plot above below shows that majority of the data points are felt along the zero line.\nAnother way to check for normality assumption visual is by using check_model() of performance package as shown in the code chunk below.\n\n# Alternative normality panel via performance::check_model -----------------------\ncheck_model(condo.mlr1, check = \"normality\")\n\n\n\n\n\n\n\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\n\n\n7.6.4 Testing for Spatial Autocorrelation\nThe hedonic model we try to build are using geographically referenced data. Hence, it is crucial to check for spatial autocorrelation because its presence can produce unreliable and misleading results. Traditional regression models, such as ordinary least squares (OLS), assume that observations are independent of one another. However, spatial data often violates this assumption.\nSpatial autocorrelation is the correlation of a variable with itself across different spatial locations. Positive spatial autocorrelation means nearby features tend to be more similar, while negative autocorrelation means they tend to be more dissimilar. This phenomenon is based on the first law of geography: “Everything is related to everything else, but nearby things are more related than distant things”.\nIgnoring spatial autocorrelation in a regression model can lead to serious statistical issues:\n\nBiased and inefficient coefficient estimates: If autocorrelation is present, standard errors of the model coefficients can be wrong, leading to unreliable hypothesis tests (p-values). The model might appear more significant than it is.\nMisleading significance tests: Standard regression models cannot distinguish between true explanatory power and the influence of spatial patterns, resulting in inaccurate p-values.\nModel misspecification: Significant spatial autocorrelation in the regression residuals often signals that important explanatory variables are missing from the model. The spatial patterning of the residuals (over- and under-predictions) can provide clues about what these missing variables might be.\nInflated Type I error rates: Researchers might incorrectly reject a true null.\n\nTo test for spatial autocorrelation, We can run a Moran’s I test on the model’s residuals. Significant spatial autocorrelation in the residuals means the model is not capturing the full spatial story.\nIn order to perform spatial autocorrelation test, we need to export the residual of the hedonic pricing model and save it as a data frame first.\n\nmlr.output &lt;- as.data.frame(condo.mlr1$residuals)\n\nNext, we will join the newly created data frame with condo_resale.sf object.\n\n# Extract residuals into the sf layer so we can map and test them -------------\ncondo_resale.sf &lt;- cbind(condo_resale.sf,\ncondo.mlr1$residuals) %&gt;%\nrename(`MLR_RES` = `condo.mlr1.residuals`) # rename residual column\n\nNext, we will use tmap package to display the distribution of the residuals on a static map.\nThe code chunks below is used to create a static point symbol map.\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\ntm_shape(mpsz_svy21) +\ntm_polygons(fill_alpha = 0.4) + # semi‑transparent base\ntm_shape(condo_resale.sf) +\ntm_dots(\nfill = \"MLR_RES\", # color by residual value\nsize = 0.7, # point size\ncol = \"black\", # thin border\nfill.scale = tm_scale( # custom diverging palette\nn = 10,\nvalues = rev(brewer.pal(11, \"RdBu\")), # red‑blue diverging\nstyle = \"quantile\",\nmidpoint = NA),\nfill.legend = tm_legend(title = \"Residuals\")\n) +\ntm_title(\"LM Residuals (Quantile Classification)\") +\ntm_layout(legend.outside = TRUE) +\ntm_view(set_zoom_limits = c(11,14))\n\n\n\n\n\n\n\n\nThe figure above reveal that there is sign of spatial autocorrelation.\nTo proof that our observation is indeed true, Global Moran’s I test will be performed\nFirst, we will compute the distance-based weight matrix by using st_dist_band() function of sfdep.\n\n# Build distance‑band neighbors and row‑standardized weights ------------------\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(\n    nb = st_dist_band(st_geometry(geometry), upper = 1500), # neighbors &lt;= 1.5 km\n    wt = st_weights(nb, style = \"W\"), # row‑standardized W\n    .before = 1)\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `nb = st_dist_band(st_geometry(geometry), upper = 1500)`.\nCaused by warning in `spdep::dnearneigh()`:\n! neighbour object has 10 sub-graphs\n\n\nNext, global_moran_perm() of sfdep package will be used to perform Moran’s I test for residual spatial autocorrelation\n\n# Permutation Moran’s I test on residuals -------------------------------------\nset.seed(1234) # for reproducibility of the permutation p‑value\nglobal_moran_perm(\n  condo_resale.sf$MLR_RES,\n  nb = condo_resale.sf$nb,\n  wt = condo_resale.sf$wt,\n  alternative = \"two.sided\",\n  nsim = 499)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 500 \n\nstatistic = 0.14389, observed rank = 500, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.14389 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "In-Class_Ex07/in-class_ex07.html#building-hedonic-pricing-models-using-gwmodel",
    "href": "In-Class_Ex07/in-class_ex07.html#building-hedonic-pricing-models-using-gwmodel",
    "title": "In-class_Ex07: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8 Building Hedonic Pricing Models using GWmodel",
    "text": "8 Building Hedonic Pricing Models using GWmodel\nIn this section, we are going to learn how to modelling hedonic pricing using both the fixed and adaptive bandwidth schemes\n\n8.1 Building Fixed Bandwidth GWR Model\n\n8.1.1 Computing fixed bandwith using CV and AIC approach\nIn the code chunk below bw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model. Notice that the argument **adaptive is set to FALSE indicates that we are interested to compute the fixed bandwidth.\nThere are two possible approaches can be uused to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using approach agreement.\n\n8.1.1.1 Fixed bandwidth computation via CV\n\n# Search for the optimal fixed bandwidth (in meters) using CV\nbw.fixed_CV &lt;- bw.gwr(\nformula = SELLING_PRICE ~ AREA_SQM + AGE +\nPROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\nPROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK +\nPROX_PRIMARY_SCH + PROX_SHOPPING_MALL +\nPROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY +\nFREEHOLD,\ndata = condo_resale.sf,\napproach = \"CV\", # cross‑validation criterion\nkernel = \"gaussian\", # Gaussian kernel\nadaptive = FALSE, # fixed (distance) bandwidth\nlonglat = FALSE) # coordinates are projected (meters)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.379526e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3396 CV score: 4.721292e+14 \nFixed bandwidth: 971.3402 CV score: 4.721292e+14 \nFixed bandwidth: 971.3398 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3399 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \n\n\n\n\n8.1.1.2 Fixed bandwidth computation via AIC\n\n# Search for the optimal fixed bandwidth (in meters) using AIC\nbw.fixed_AIC &lt;- bw.gwr(\nformula = SELLING_PRICE ~ AREA_SQM + AGE +\nPROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\nPROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK +\nPROX_PRIMARY_SCH + PROX_SHOPPING_MALL +\nPROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY +\nFREEHOLD,\ndata = condo_resale.sf,\napproach = \"AIC\", # AIC criterion\nkernel = \"gaussian\", # Gaussian kernel\nadaptive = FALSE, # fixed (distance) bandwidth\nlonglat = FALSE) # coordinates are projected (meters)\n\nFixed bandwidth: 17660.96 AICc value: 42937.77 \nFixed bandwidth: 10917.26 AICc value: 42886.26 \nFixed bandwidth: 6749.419 AICc value: 42757.54 \nFixed bandwidth: 4173.553 AICc value: 42565.01 \nFixed bandwidth: 2581.58 AICc value: 42368.05 \nFixed bandwidth: 1597.687 AICc value: 42256.42 \nFixed bandwidth: 989.6077 AICc value: 42262.3 \nFixed bandwidth: 1973.501 AICc value: 42279.95 \nFixed bandwidth: 1365.421 AICc value: 42254.72 \nFixed bandwidth: 1221.873 AICc value: 42255.41 \nFixed bandwidth: 1454.139 AICc value: 42254.82 \nFixed bandwidth: 1310.591 AICc value: 42254.84 \nFixed bandwidth: 1399.309 AICc value: 42254.71 \nFixed bandwidth: 1420.252 AICc value: 42254.73 \nFixed bandwidth: 1386.365 AICc value: 42254.7 \nFixed bandwidth: 1378.365 AICc value: 42254.71 \nFixed bandwidth: 1391.309 AICc value: 42254.7 \n\n\n\n\n\n8.1.2 GWModel method - fixed-bandwith (CV and AIC; K nearest neighbors)\nNow we can use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.\n\n8.1.2.1 Calibrate fixed-bandwidth using CV\n\n# Calibrate the fixed‑bandwidth GWR model ---------------------------------------\ngwr.fixed_CV &lt;- gwr.basic(\nformula = SELLING_PRICE ~ AREA_SQM + AGE +\nPROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\nPROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK +\nPROX_PRIMARY_SCH + PROX_SHOPPING_MALL +\nPROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY +\nFREEHOLD,\ndata = condo_resale.sf,\nbw = bw.fixed_CV,\nkernel = 'gaussian',\nlonglat = FALSE)\n\n\n# Inspect the fixed GWR diagnostics (AICc, R², parameter summaries) --------------\ngwr.fixed_CV\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2025-10-18 22:50:14.593355 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf, bw = bw.fixed_CV, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.34 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3599e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7426e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5001e+06 -1.5970e+05  3.1970e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8074e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112794435\n   AREA_SQM                 21575\n   AGE                     434203\n   PROX_CBD               2704604\n   PROX_CHILDCARE         1654086\n   PROX_ELDERLYCARE      38867861\n   PROX_URA_GROWTH_AREA  78515805\n   PROX_MRT               3124325\n   PROX_PARK             18122439\n   PROX_PRIMARY_SCH       4637517\n   PROX_SHOPPING_MALL     1529953\n   PROX_BUS_STOP         11342209\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720745\n   FREEHOLD               6073642\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3807 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6193 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.534069e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430418 \n\n   ***********************************************************************\n   Program stops at: 2025-10-18 22:50:15.74219 \n\n\n\n\n8.1.2.2 Calibrate fixed-bandwidth using AIC\n\n# Calibrate the fixed‑bandwidth GWR model ---------------------------------------\ngwr.fixed_AIC &lt;- gwr.basic(\nformula = SELLING_PRICE ~ AREA_SQM + AGE +\nPROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\nPROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK +\nPROX_PRIMARY_SCH + PROX_SHOPPING_MALL +\nPROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY +\nFREEHOLD,\ndata = condo_resale.sf,\nbw = bw.fixed_AIC,\nkernel = 'gaussian',\nlonglat = FALSE)\n\n\n# Inspect the fixed GWR diagnostics (AICc, R², parameter summaries) --------------\ngwr.fixed_AIC\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2025-10-18 22:50:15.756869 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf, bw = bw.fixed_AIC, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 1386.365 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -5.0947e+06  7.5228e+04  9.6933e+05  1.6560e+06\n   AREA_SQM              2.5558e+03  5.4041e+03  7.6995e+03  1.2569e+04\n   AGE                  -8.4563e+04 -2.1045e+04 -1.1083e+04 -5.3192e+03\n   PROX_CBD             -3.0121e+06 -2.2299e+05 -1.0207e+05 -5.3900e+04\n   PROX_CHILDCARE       -3.6679e+06 -1.7018e+05 -1.6108e+04  2.4420e+05\n   PROX_ELDERLYCARE     -4.9526e+05 -4.0047e+04  7.6715e+04  1.9650e+05\n   PROX_URA_GROWTH_AREA -3.0350e+05 -3.0201e+04  5.1598e+04  1.5573e+05\n   PROX_MRT             -2.6892e+06 -3.9441e+05 -2.3485e+05 -1.3171e+05\n   PROX_PARK            -9.1626e+05 -1.2375e+05  4.7999e+04  4.0312e+05\n   PROX_PRIMARY_SCH     -4.7607e+05 -1.2189e+05  2.9963e+04  3.0890e+05\n   PROX_SHOPPING_MALL   -9.7562e+05 -1.2594e+05 -1.2552e+04  1.0019e+05\n   PROX_BUS_STOP        -8.4504e+05  8.8484e+04  3.7699e+05  1.4980e+06\n   NO_Of_UNITS          -1.2111e+03 -3.4940e+02 -5.8441e+01  1.0022e+02\n   FAMILY_FRIENDLY      -1.3608e+06 -5.1541e+04  1.0951e+04  1.5911e+05\n   FREEHOLD             -1.1559e+05  9.5013e+04  2.0430e+05  3.5295e+05\n                             Max.\n   Intercept            4639265.4\n   AREA_SQM               19642.4\n   AGE                    41275.9\n   PROX_CBD              272116.0\n   PROX_CHILDCARE       1776212.0\n   PROX_ELDERLYCARE     2742988.5\n   PROX_URA_GROWTH_AREA 3038754.5\n   PROX_MRT             1349867.9\n   PROX_PARK            1102849.3\n   PROX_PRIMARY_SCH     2148894.9\n   PROX_SHOPPING_MALL    668261.7\n   PROX_BUS_STOP        4267600.2\n   NO_Of_UNITS             2174.3\n   FAMILY_FRIENDLY      1289044.9\n   FREEHOLD             1001304.5\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 302.5667 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1133.433 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42254.7 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41902.94 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42011.36 \n   Residual sum of squares: 3.334499e+14 \n   R-square value:  0.8565589 \n   Adjusted R-square value:  0.8182339 \n\n   ***********************************************************************\n   Program stops at: 2025-10-18 22:50:16.656112 \n\n\n\n\n\n8.1.3 Insights into fixed bandwidth performance under CV and AIC approaches\nThe two fixed-bandwidth GWR runs differ in a meaningful way this time. The cross-validated model, gwr.fixed_CV, selects a fixed kernel width of about 971 m and yields AICc ≈ 42,263.6, R² ≈ 0.8099 (adjusted ≈ 0.8430), an effective parameter count of about 438.4, and residual sum of squares around 2.534×10¹⁴. The AICc-tuned model, gwr.fixed_AIC, chooses a larger fixed bandwidth of about 1,386 m, with AICc ≈ 42,254.7, R² ≈ 0.8566 (adjusted ≈ 0.8182), an effective parameter count of about 302.6, and residual sum of squares reported near 3.335×10¹⁴. In practical terms, AICc prefers a smoother spatial surface: a wider bandwidth pools information from more neighbours, which reduces local variance and shrinks the effective complexity by roughly one-third (≈303 vs ≈438 parameters). That parsimony is exactly what AICc rewards, and it explains why the AICc model attains the lower information criterion despite being less “wiggly.” The higher R² from the AICc fit indicates that, at this broader spatial scale, the model explains more variation in prices overall; the CV model’s smaller bandwidth is better at capturing very local idiosyncrasies but at the cost of higher model complexity and potentially noisier local coefficients.\nSubstantively, the AICc model is preferable if our goal is a defensible, generalizable explanation of price drivers with restrained local volatility and reduced risk of overfitting or local multicollinearity. The CV model is preferable if our priority is detecting fine-grained neighbourhood effects and sharp spatial gradients, accepting a more complex surface. Before deciding, inspect side-by-side maps of local coefficients and t-values, compare the stability of signs across space, and check residual spatial autocorrelation. If small-area policy targeting or micro-market storytelling is central, keep the CV bandwidth; if we need a succinct, reliable narrative for the whole city, the AICc bandwidth is the stronger choice.\n\n\n\n8.2 Building Adaptive Bandwidth GWR Model\nIn this section, we will calibrate the gwr-based hedonic pricing model by using adaptive bandwidth approach.\n\n8.2.1 Computing the adaptive bandwidth\nSimilar to the earlier section, we will first use bw.gwr() to determine the recommended data point to use.\n\n8.2.1.1 Adaptive bandwidth computation via CV\nThe code chunk used look very similar to the one used to compute the fixed bandwidth except the adaptive argument has changed to TRUE.\n\n# Search for the optimal adaptive bandwidth (K neighbors) using CV\nbw.adaptive_CV &lt;- bw.gwr(\nformula = SELLING_PRICE ~ AREA_SQM + AGE +\nPROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\nPROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK +\nPROX_PRIMARY_SCH + PROX_SHOPPING_MALL +\nPROX_BUS_STOP + NO_Of_UNITS +\nFAMILY_FRIENDLY + FREEHOLD,\ndata = condo_resale.sf,\napproach = \"CV\", \nkernel = \"gaussian\",\nadaptive = TRUE, # K‑NN style bandwidth\nlonglat = FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\n\n\n8.2.1.2 Adaptive bandwidth computation via AIC\n\n# Search for the optimal adaptive bandwidth (K neighbors) using AIC\nbw.adaptive_AIC &lt;- bw.gwr(\nformula = SELLING_PRICE ~ AREA_SQM + AGE +\nPROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\nPROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK +\nPROX_PRIMARY_SCH + PROX_SHOPPING_MALL +\nPROX_BUS_STOP + NO_Of_UNITS +\nFAMILY_FRIENDLY + FREEHOLD,\ndata = condo_resale.sf,\napproach = \"AIC\", \nkernel = \"gaussian\",\nadaptive = TRUE, # K‑NN style bandwidth\nlonglat = FALSE)\n\nAdaptive bandwidth (number of nearest neighbours): 895 AICc value: 42879.45 \nAdaptive bandwidth (number of nearest neighbours): 561 AICc value: 42823.52 \nAdaptive bandwidth (number of nearest neighbours): 354 AICc value: 42677.14 \nAdaptive bandwidth (number of nearest neighbours): 226 AICc value: 42484.37 \nAdaptive bandwidth (number of nearest neighbours): 147 AICc value: 42353.27 \nAdaptive bandwidth (number of nearest neighbours): 98 AICc value: 42280.68 \nAdaptive bandwidth (number of nearest neighbours): 68 AICc value: 42201.18 \nAdaptive bandwidth (number of nearest neighbours): 49 AICc value: 42100.66 \nAdaptive bandwidth (number of nearest neighbours): 37 AICc value: 42055.68 \nAdaptive bandwidth (number of nearest neighbours): 30 AICc value: 41982.22 \nAdaptive bandwidth (number of nearest neighbours): 25 AICc value: 42003.33 \nAdaptive bandwidth (number of nearest neighbours): 32 AICc value: 42035.41 \nAdaptive bandwidth (number of nearest neighbours): 27 AICc value: 41978.63 \nAdaptive bandwidth (number of nearest neighbours): 27 AICc value: 41978.63 \n\n\n\n\n\n8.2.2 Constructing the adaptive bandwidth gwr model\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\n\n8.2.2.1 Calibrate adaptive bandwidth using CV\n\n# Calibrate the adaptive‑bandwidth GWR model ------------------------------------\ngwr.adaptive_CV &lt;- gwr.basic(\n  formula = SELLING_PRICE ~ AREA_SQM + AGE +\n    PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n    PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK +\n    PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\n    NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n  data = condo_resale.sf,\n  bw = bw.adaptive_CV,\n  kernel = 'gaussian',\n  adaptive = TRUE, # activate adaptive bandwidth in the fit\n  longlat = FALSE)\n\n# Inspect the adaptive GWR diagnostics (AICc, R²) --------------------------------\ngwr.adaptive_CV\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2025-10-18 22:50:36.424464 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf, bw = bw.adaptive_CV, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2025-10-18 22:50:37.649116 \n\n\n\n\n8.2.2.2 Calibrate adaptive bandwidth using AIC\n\n# Calibrate the adaptive‑bandwidth GWR model ------------------------------------\ngwr.adaptive_AIC &lt;- gwr.basic(\n  formula = SELLING_PRICE ~ AREA_SQM + AGE +\n    PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n    PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK +\n    PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\n    NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n  data = condo_resale.sf,\n  bw = bw.adaptive_AIC,\n  kernel = 'gaussian',\n  adaptive = TRUE, # activate adaptive bandwidth in the fit\n  longlat = FALSE)\n\n# Inspect the adaptive GWR diagnostics (AICc, R²) --------------------------------\ngwr.adaptive_AIC\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2025-10-18 22:50:37.661237 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf, bw = bw.adaptive_AIC, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 27 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.4055e+08 -4.9698e+05  7.6667e+05  1.6291e+06\n   AREA_SQM              3.2900e+03  5.5381e+03  7.6847e+03  1.2674e+04\n   AGE                  -1.0016e+05 -2.7556e+04 -1.3592e+04 -4.6598e+03\n   PROX_CBD             -4.0881e+06 -1.9515e+05 -7.3518e+04  2.9526e+04\n   PROX_CHILDCARE       -1.7059e+06 -2.6967e+05 -1.2514e+04  3.4777e+05\n   PROX_ELDERLYCARE     -2.2412e+06 -9.4985e+04  7.9372e+04  3.2765e+05\n   PROX_URA_GROWTH_AREA -1.8375e+07 -2.3765e+04  5.7504e+04  2.9631e+05\n   PROX_MRT             -4.5351e+07 -6.2318e+05 -2.0888e+05 -3.8964e+04\n   PROX_PARK            -1.0166e+08 -2.0084e+05  1.1152e+05  4.4450e+05\n   PROX_PRIMARY_SCH     -4.6505e+06 -1.9579e+05 -9.1754e+03  4.3824e+05\n   PROX_SHOPPING_MALL   -2.4269e+06 -1.4053e+05 -1.3684e+04  1.5823e+05\n   PROX_BUS_STOP        -2.1436e+06 -8.7705e+04  4.1820e+05  1.2784e+06\n   NO_Of_UNITS          -3.2993e+03 -2.2606e+02 -2.1790e+01  1.4231e+02\n   FAMILY_FRIENDLY      -4.0477e+06 -6.5054e+04  2.2989e+04  1.9452e+05\n   FREEHOLD             -1.0164e+08  2.4578e+04  1.8212e+05  3.8182e+05\n                              Max.\n   Intercept            55107367.7\n   AREA_SQM                23242.4\n   AGE                    265480.4\n   PROX_CBD             26220365.3\n   PROX_CHILDCARE        3565627.3\n   PROX_ELDERLYCARE     93434430.7\n   PROX_URA_GROWTH_AREA 25096283.7\n   PROX_MRT              9223676.8\n   PROX_PARK             2754387.0\n   PROX_PRIMARY_SCH      4618809.5\n   PROX_SHOPPING_MALL   39514834.8\n   PROX_BUS_STOP        13319341.1\n   NO_Of_UNITS              9878.1\n   FAMILY_FRIENDLY       2315112.2\n   FREEHOLD              1876281.2\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 393.0807 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1042.919 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41978.63 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41453.88 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42070.13 \n   Residual sum of squares: 2.305296e+14 \n   R-square value:  0.9008324 \n   Adjusted R-square value:  0.8634199 \n\n   ***********************************************************************\n   Program stops at: 2025-10-18 22:50:38.659062 \n\n\n\n\n\n8.2.3 Insights into adaptive bandwidth performance under CV and AIC approaches\nOur two adaptive GWR calibrations use the same data, kernel and metric but settle on different neighbour counts. gwr.adaptive_CV chooses 30 neighbours (CV = prediction-error minimization), whereas gwr.adaptive_AIC prefers a narrower window of 27 neighbours (AICc = fit–parsimony trade-off). The smaller window lets coefficients vary more sharply across space.\nThat choice shows up in the diagnostics. The AICc model is more flexible (effective parameters ≈ 393.1 vs 350.3; effective d.f. 1042.9 vs 1085.7, which is lower because the model is more complex). With that extra flexibility it achieves lower residual SS (2.305×10¹⁴ vs 2.528×10¹⁴), higher R² (0.9008 vs 0.8912, adjusted 0.8634 vs 0.8561), and a slightly better AICc (41,979 vs 41,982). In short: AICc is telling us the data support a somewhat finer spatial scale of non-stationarity than CV was willing to choose.\nHow to read this substantively: the AICc model will draw sharper local contrasts in the effects of the predictors (e.g., accessibility and amenities), which can be useful for micro-market interpretation and targeting. The CV model is slightly smoother, prioritizing out-of-sample error control; its surfaces will be a bit less volatile and may generalize more conservatively.\nWhich should we use? If our goal is inference with crisp local detail and we are comfortable managing higher complexity, the adaptive_AIC (27-NN) fit is preferable given its lower AICc and higher R². If our priority is predictive robustness, keep adaptive_CV (30-NN) unless a held-out test confirms that the 27-NN model does at least as well on unseen data."
  },
  {
    "objectID": "In-Class_Ex07/in-class_ex07.html#converting-sdf-into-sf-data.frame",
    "href": "In-Class_Ex07/in-class_ex07.html#converting-sdf-into-sf-data.frame",
    "title": "In-class_Ex07: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9 Converting SDF into sf data.frame",
    "text": "9 Converting SDF into sf data.frame\nTo visualise the fields in SDF, we need to first covert it into sf data.frame by using the code chunk below.\n\n# Convert the GWR output SDF (Spatial*DataFrame) to sf for mapping ---------------\ncondo_resale.sf.adaptive &lt;-\nst_as_sf(gwr.adaptive_AIC$SDF) %&gt;%\nst_transform(crs = 3414) # ensure consistent projection for mapping\n\nNext, glimpse() is used to display the content of condo_resale.sf.adaptive sf data frame.\n\n# Inspect the fields (coefficients, SE, t‑values, Local_R2, fitted yhat, etc.) ---\nglimpse(condo_resale.sf.adaptive)\n\nRows: 1,436\nColumns: 52\n$ Intercept               &lt;dbl&gt; 2044700.26, 1773153.15, 3520072.36, 1539855.35…\n$ AREA_SQM                &lt;dbl&gt; 9559.598, 15390.155, 13016.013, 21340.305, 678…\n$ AGE                     &lt;dbl&gt; -9500.111, -48975.055, -25897.022, -97109.448,…\n$ PROX_CBD                &lt;dbl&gt; -120265.31, -173034.60, -266084.74, 4535464.61…\n$ PROX_CHILDCARE          &lt;dbl&gt; 318045.039, 348815.035, -194366.004, 286266.93…\n$ PROX_ELDERLYCARE        &lt;dbl&gt; -394643.95, 238275.45, 558021.92, 402763.72, -…\n$ PROX_URA_GROWTH_AREA    &lt;dbl&gt; -159575.59, -31187.00, -253591.14, -4781655.68…\n$ PROX_MRT                &lt;dbl&gt; -299592.54, -2557296.15, -942766.83, -2495885.…\n$ PROX_PARK               &lt;dbl&gt; -172380.89, 442318.02, 246972.65, -937538.48, …\n$ PROX_PRIMARY_SCH        &lt;dbl&gt; 242732.037, 919399.390, 558785.123, 3340638.60…\n$ PROX_SHOPPING_MALL      &lt;dbl&gt; 302051.162, -215149.309, -142022.712, 134573.9…\n$ PROX_BUS_STOP           &lt;dbl&gt; 1209536.14, 1919405.53, 1450141.54, 8743551.68…\n$ NO_Of_UNITS             &lt;dbl&gt; 106.372669, -211.071177, 19.339246, -150.59531…\n$ FAMILY_FRIENDLY         &lt;dbl&gt; -9098.124, 152642.975, -29284.824, 1723147.674…\n$ FREEHOLD                &lt;dbl&gt; 303927.63, 400568.89, 162972.29, 1318502.10, 3…\n$ y                       &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    &lt;dbl&gt; 2885980.3, 3464956.3, 3621402.8, 5528248.5, 13…\n$ residual                &lt;dbl&gt; 114019.686, 415043.736, -296402.814, -1278248.…\n$ CV_Score                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           &lt;dbl&gt; 0.39812858, 1.12993822, -0.89467945, -3.237264…\n$ Intercept_SE            &lt;dbl&gt; 505352.2, 959583.4, 1088656.5, 644451.8, 21882…\n$ AREA_SQM_SE             &lt;dbl&gt; 803.9810, 1041.2806, 1005.1322, 647.0447, 1408…\n$ AGE_SE                  &lt;dbl&gt; 5754.545, 7873.214, 6772.090, 6339.353, 8401.1…\n$ PROX_CBD_SE             &lt;dbl&gt; 36644.67, 46892.76, 64224.98, 723130.45, 42870…\n$ PROX_CHILDCARE_SE       &lt;dbl&gt; 311604.5, 383548.3, 356362.3, 318029.0, 726053…\n$ PROX_ELDERLYCARE_SE     &lt;dbl&gt; 117822.10, 121329.51, 145658.37, 153818.83, 36…\n$ PROX_URA_GROWTH_AREA_SE &lt;dbl&gt; 54991.59, 138590.35, 104509.67, 714454.45, 501…\n$ PROX_MRT_SE             &lt;dbl&gt; 181049.7, 426727.9, 290345.8, 310229.2, 399736…\n$ PROX_PARK_SE            &lt;dbl&gt; 200556.4, 337273.4, 328846.1, 250084.3, 406910…\n$ PROX_PRIMARY_SCH_SE     &lt;dbl&gt; 149035.4, 213215.4, 206844.1, 276593.8, 253671…\n$ PROX_SHOPPING_MALL_SE   &lt;dbl&gt; 106789.05, 168563.26, 124684.33, 237237.76, 33…\n$ PROX_BUS_STOP_SE        &lt;dbl&gt; 587417.1, 527904.1, 468907.1, 625949.7, 748596…\n$ NO_Of_UNITS_SE          &lt;dbl&gt; 213.2704, 232.9495, 211.9892, 452.1575, 315.82…\n$ FAMILY_FRIENDLY_SE      &lt;dbl&gt; 128381.97, 139756.71, 152249.80, 115274.06, 16…\n$ FREEHOLD_SE             &lt;dbl&gt; 113234.6, 170426.6, 146100.1, 149874.1, 215886…\n$ Intercept_TV            &lt;dbl&gt; 4.04608981, 1.84783643, 3.23340951, 2.38940359…\n$ AREA_SQM_TV             &lt;dbl&gt; 11.890328, 14.780026, 12.949553, 32.981191, 4.…\n$ AGE_TV                  &lt;dbl&gt; -1.6508882, -6.2204656, -3.8240810, -15.318510…\n$ PROX_CBD_TV             &lt;dbl&gt; -3.28193222, -3.69000648, -4.14301022, 6.27198…\n$ PROX_CHILDCARE_TV       &lt;dbl&gt; 1.020669014, 0.909442298, -0.545416851, 0.9001…\n$ PROX_ELDERLYCARE_TV     &lt;dbl&gt; -3.34948996, 1.96387060, 3.83103226, 2.6184291…\n$ PROX_URA_GROWTH_AREA_TV &lt;dbl&gt; -2.90181817, -0.22503007, -2.42648497, -6.6927…\n$ PROX_MRT_TV             &lt;dbl&gt; -1.65475280, -5.99280279, -3.24704810, -8.0452…\n$ PROX_PARK_TV            &lt;dbl&gt; -0.8595132, 1.3114524, 0.7510281, -3.7488897, …\n$ PROX_PRIMARY_SCH_TV     &lt;dbl&gt; 1.62868734, 4.31206879, 2.70147945, 12.0777779…\n$ PROX_SHOPPING_MALL_TV   &lt;dbl&gt; 2.82848439, -1.27637129, -1.13905821, 0.567253…\n$ PROX_BUS_STOP_TV        &lt;dbl&gt; 2.0590756, 3.6358978, 3.0925989, 13.9684567, 0…\n$ NO_Of_UNITS_TV          &lt;dbl&gt; 0.49876913, -0.90608143, 0.09122749, -0.333059…\n$ FAMILY_FRIENDLY_TV      &lt;dbl&gt; -0.07086762, 1.09220500, -0.19234721, 14.94826…\n$ FREEHOLD_TV             &lt;dbl&gt; 2.68405282, 2.35038940, 1.11548393, 8.79739845…\n$ Local_R2                &lt;dbl&gt; 0.9172836, 0.9154542, 0.9132622, 0.9192190, 0.…\n$ geometry                &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n\n\n\n# Quick summary of fitted values (yhat) ------------------------------------------\nsummary(gwr.adaptive_AIC$SDF$yhat)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  392814  1098774  1383270  1751256  1985895 13892256"
  },
  {
    "objectID": "In-Class_Ex07/in-class_ex07.html#selecting-tampines-planning-areas",
    "href": "In-Class_Ex07/in-class_ex07.html#selecting-tampines-planning-areas",
    "title": "In-class_Ex07: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "10 Selecting Tampines planning areas",
    "text": "10 Selecting Tampines planning areas\n\n# --- 1) Select the Tampines planning area polygon ------------------------------\n# (Common MP14 fields are PLN_AREA_N (planning area) and SUBZONE_N (subzone).)\ntampines_pa &lt;- mpsz_svy21 %&gt;% \n  filter(PLN_AREA_N == \"TAMPINES\")\n\n# --- 2) Keep only condo points that fall inside Tampines -----------------------\n# Our GWR results were attached to `condo_resale.sf.adaptive` and include `Local_R2`.\ntampines_pts &lt;- condo_resale.sf.adaptive[tampines_pa, , op = st_within]\n\n# --- 3) Visualise: Tampines boundary + points coloured by Local R² -------------\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\ntm_shape(tampines_pa) +\n  tm_polygons(fill_alpha = 0.1) +\ntm_shape(tampines_pts) +\n  tm_dots(\n    fill = \"Local_R2\",           # tmap v4: 'fill' controls symbol fill colour\n    col = \"grey30\",              # thin outline\n    size = 0.6,\n    fill.scale = tm_scale(\n      n = 7,\n      style = \"quantile\"         # consistent with the tutorial’s quantile breaks\n    ),\n    fill.legend = tm_legend(title = \"Local R²\")\n  ) +\n  tm_view(set_zoom_limits = c(11, 14))\n\n\n\n\n\n\n\n# --- 4) Summarise Local R² for Tampines ----------------------------------------\ntampines_r2_summary &lt;- tampines_pts %&gt;%\n  st_drop_geometry() %&gt;%\n  summarise(\n    n      = dplyr::n(),\n    r2_min = min(Local_R2, na.rm = TRUE),\n    r2_q1  = quantile(Local_R2, 0.25, na.rm = TRUE),\n    r2_med = median(Local_R2, na.rm = TRUE),\n    r2_mean= mean(Local_R2, na.rm = TRUE),\n    r2_q3  = quantile(Local_R2, 0.75, na.rm = TRUE),\n    r2_max = max(Local_R2, na.rm = TRUE)\n  )\n\ntampines_r2_summary\n\n   n    r2_min     r2_q1    r2_med   r2_mean     r2_q3    r2_max\n1 76 0.8944806 0.9550013 0.9652041 0.9546181 0.9710822 0.9724414\n\n\n\n10.1 Insights and intepretation:\nThe adaptive GWR results for Tampines show an exceptionally strong and spatially consistent model fit across condominium resale points. With n = 76, the Local R² ranges from 0.894 to 0.972, a median of 0.965, and a mean of 0.955, indicating that the model explains over 95% of local price variation for most locations. Such high and tightly clustered R² values suggest the explanatory variables—floor area, age, proximity to amenities, accessibility, and tenure—collectively provide a robust representation of spatial price dynamics in Tampines.\nSpatially, the map reveals that the dark blue clusters with higher Local R² values are concentrated around Tampines Central, where key amenities such as the MRT interchange, bus interchange, and shopping malls are located. These areas exhibit highly predictable housing prices because accessibility and urban conveniences strongly align with price determinants. Hence, the model performs best in these well-connected and amenity-rich subzones.\nIn contrast, lighter blue areas along the western and peripheral edges display slightly lower R² values (around 0.89–0.95). This suggests that local housing prices there are influenced by factors not fully captured by the model, such as road noise, micro-neighbourhood effects, or smaller sample density. Nevertheless, these lower values still represent a high level of explanatory power.\nOverall, the GWR model is highly reliable for Tampines, with particularly strong performance near the town centre. Future refinement could include adding micro-accessibility or environmental variables to further improve local accuracy in edge areas."
  },
  {
    "objectID": "In-Class_Ex07/in-class_ex07.html#subset-the-dataset-to-features-within-the-tampines-planning-are",
    "href": "In-Class_Ex07/in-class_ex07.html#subset-the-dataset-to-features-within-the-tampines-planning-are",
    "title": "In-class_Ex07: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "10 Subset the dataset to features within the Tampines Planning Are",
    "text": "10 Subset the dataset to features within the Tampines Planning Are\n\n# --- 1) Select the Tampines planning area polygon ------------------------------\n# (Common MP14 fields are PLN_AREA_N (planning area) and SUBZONE_N (subzone).)\ntampines_pa &lt;- mpsz_svy21 %&gt;% \n  filter(PLN_AREA_N == \"TAMPINES\")\n\n# --- 2) Keep only condo points that fall inside Tampines -----------------------\n# Our GWR results were attached to `condo_resale.sf.adaptive` and include `Local_R2`.\ntampines_pts &lt;- condo_resale.sf.adaptive[tampines_pa, , op = st_within]\n\n# --- 3) Visualise: Tampines boundary + points coloured by Local R² -------------\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\ntm_shape(tampines_pa) +\n  tm_polygons(fill_alpha = 0.1) +\ntm_shape(tampines_pts) +\n  tm_dots(\n    fill = \"Local_R2\",           # tmap v4: 'fill' controls symbol fill colour\n    col = \"grey30\",              # thin outline\n    size = 0.6,\n    fill.scale = tm_scale(\n      n = 7,\n      style = \"quantile\"         # consistent with the tutorial’s quantile breaks\n    ),\n    fill.legend = tm_legend(title = \"Local R²\")\n  ) +\n  tm_view(set_zoom_limits = c(11, 14))\n\n\n\n\n\n\n\n# --- 4) Summarise Local R² for Tampines ----------------------------------------\ntampines_r2_summary &lt;- tampines_pts %&gt;%\n  st_drop_geometry() %&gt;%\n  summarise(\n    n      = dplyr::n(),\n    r2_min = min(Local_R2, na.rm = TRUE),\n    r2_q1  = quantile(Local_R2, 0.25, na.rm = TRUE),\n    r2_med = median(Local_R2, na.rm = TRUE),\n    r2_mean= mean(Local_R2, na.rm = TRUE),\n    r2_q3  = quantile(Local_R2, 0.75, na.rm = TRUE),\n    r2_max = max(Local_R2, na.rm = TRUE)\n  )\n\ntampines_r2_summary\n\n   n    r2_min     r2_q1    r2_med   r2_mean     r2_q3    r2_max\n1 76 0.8944806 0.9550013 0.9652041 0.9546181 0.9710822 0.9724414\n\n\n\n10.1 Insights into Tampines planning area\nThe adaptive GWR results for Tampines show an exceptionally strong and spatially consistent model fit across condominium resale points. With n = 76, the Local R² ranges from 0.894 to 0.972, a median of 0.965, and a mean of 0.955, indicating that the model explains over 95% of local price variation for most locations. Such high and tightly clustered R² values suggest the explanatory variables—floor area, age, proximity to amenities, accessibility, and tenure—collectively provide a robust representation of spatial price dynamics in Tampines.\nSpatially, the map reveals that the dark blue clusters with higher Local R² values are concentrated around Tampines Central, where key amenities such as the MRT interchange, bus interchange, and shopping malls are located. These areas exhibit highly predictable housing prices because accessibility and urban conveniences strongly align with price determinants. Hence, the model performs best in these well-connected and amenity-rich subzones.\nIn contrast, lighter blue areas along the western and peripheral edges display slightly lower R² values (around 0.89–0.95). This suggests that local housing prices there are influenced by factors not fully captured by the model, such as road noise, micro-neighbourhood effects, or smaller sample density. Nevertheless, these lower values still represent a high level of explanatory power.\nOverall, the GWR model is highly reliable for Tampines, with particularly strong performance near the town centre. Future refinement could include adding micro-accessibility or environmental variables to further improve local accuracy in edge areas."
  },
  {
    "objectID": "Take-home_Ex01/take-home_ex01.html#introduction",
    "href": "Take-home_Ex01/take-home_ex01.html#introduction",
    "title": "Take-home Ex01: Geospatial Analytics for Public Good",
    "section": "1 Introduction",
    "text": "1 Introduction\nRestaurants are a sensitive barometer of urban vitality: they emerge where pedestrian flows, accessibility, and complementary land uses intersect, and they amplify activity through agglomeration effects. This study examines the first-order (intensity) and second-order (interaction) properties of new restaurant registrations in Singapore between 1 January 2025 and 30 June 2025. The workflow comprises five steps: (i) tidying ACRA registration records, (ii) geocoding 6-digit postcodes via OneMap, (iii) projecting to SVY21 (EPSG:3414) to preserve distance accuracy, (iv) estimating kernel densities using fixed and adaptive bandwidths to reveal spatial concentrations over time, and (v) applying Ripley’s \\(L/K\\) functions with Complete Spatial Randomness (CSR) envelopes to identify statistically significant clustering scales. The results are interpreted through the lens of planning and urban management, with implications for town-centre provisioning, licensing cadence, last-mile logistics, and transit-oriented development."
  },
  {
    "objectID": "Take-home_Ex01/take-home_ex01.html#the-data",
    "href": "Take-home_Ex01/take-home_ex01.html#the-data",
    "title": "Take-home Ex01: Geospatial Analytics for Public Good",
    "section": "2 The Data",
    "text": "2 The Data\nTo analyse the Food & Beverage (F&B) industry in Singapore, this exercise integrates four key data sources. The Singapore Standard Industrial Classification (SSIC) provides the authoritative framework to define and filter economic activities (e.g., Restaurants and Cafés). ACRA business registry extracts supply establishment-level records with SSIC codes and addresses. URA Master Plan boundaries offer official geospatial polygons (planning areas and subzones) to aggregate and visualise spatial distributions. Finally, OneMap APIs provide authoritative coordinates and geocoding services to standardise addresses and link firms to spatial units. Together, these datasets allow us to identify, locate, and analyse F&B businesses consistently across Singapore’s geography, ensuring both statistical reliability and spatial accuracy.\n\n\n\nTable 1: Data Sources for F&B Industry Analysis in Singapore\n\n\nDataset_Name\nDescription\nFormat\nSource\n\n\n\n\nSSIC 2020 – Report & Detailed Definitions\nPrior edition still widely used; contains 5-digit codes (e.g., 56111 Restaurants, 56112 Cafés).\nExcel / PDF\nSingStat (DOS)\n\n\nACRA Information on Corporate Entities\nOpen data extract of registered entities, including SSIC codes and addresses for firm-level analysis.\nCSV\ndata.gov.sg (ACRA)\n\n\nURA Master Plan 2019 – Subzone Boundary (No Sea)\nOfficial subzone polygons for aggregation and spatial analysis (choropleths).\nGeoJSON / KML\ndata.gov.sg (URA)\n\n\nOneMap (SLA) – Search & Reverse Geocode / Thematic Layers\nAuthoritative API to geocode/standardise addresses, fetch POIs, and retrieve thematic layers.\nREST / JSON API\nOneMap (SLA)"
  },
  {
    "objectID": "Take-home_Ex01/take-home_ex01.html#research-quetions",
    "href": "Take-home_Ex01/take-home_ex01.html#research-quetions",
    "title": "Take-home Ex01: Geospatial Analytics for Public Good",
    "section": "3 Research Quetions",
    "text": "3 Research Quetions\nAligned with the stated exercise objectives (“identify where and when new firms appear; detect clustering; discuss implications”), our research questions translate the statistical toolkit into targeted, decision-relevant tests for restaurant activity. We deliberately distinguish between first-order analysis (examining where intensity is high) and second-order analysis (evaluating how points interact relative to CSR), while also incorporating a minimal spatio-temporal perspective through monthly facets to capture temporal variation in establishment patterns.\nRQ1 — Where/When: Where do new restaurants (SSIC 56111) concentrate spatially within January 2025 – Jun 2025, and how do these concentrations evolve month-to-month?\nRQ2 — First-order intensity (Core): What is the intensity structure of new restaurants and which locales exhibit persistent high density after smoothing?\nRQ3 — Second-order clustering scales: At which distance bands (e.g., 0–1000 m) do restaurants exhibit significant clustering or dispersion relative to CSR?\nRQ4 — Planning/Management Implications: How should statistically validated hotspots and clustering scales inform town-centre planning, licensing cadence, amenity siting, and last-mile/logistics near identified corridors and nodes?"
  },
  {
    "objectID": "Take-home_Ex01/take-home_ex01.html#setup-the-environment",
    "href": "Take-home_Ex01/take-home_ex01.html#setup-the-environment",
    "title": "Take-home Ex01: Geospatial Analytics for Public Good",
    "section": "4 Setup the environment",
    "text": "4 Setup the environment\nDefines the initial environment settings to ensure consistent execution of the R script.\n\n4.1 Load/install packages\nChecks and installs required R packages (via pacman), then loads libraries for data wrangling, mapping, geospatial analysis, and reproducibility.\n\nif (!require(pacman)) install.packages(\"pacman\")  # install pacman once if missing\n\npacman::p_load(                                   # load (and auto-install if needed)\n  tidyverse,      # data wrangling + plotting (dplyr, tidyr, ggplot2, readr)\n  stringr,        # string helpers (e.g., str_pad, str_detect)\n  lubridate,      # date helpers (e.g., year, month, floor_date)\n  sf,             # vector geospatial (points/polygons, CRS transforms)\n  tmap,           # cartographic maps (static/interactive)\n  terra,          # raster/SpatRaster conversion for KDE images\n  sparr,          # Spatial and spatio-temporal relative risk functions.\n  spatstat.geom,  # required for the spatstat family of analysis functions.\n  stpp,           # spatio-temporal point process package.\n  rvest,          # Web scraping and HTML parsing package.\n  httr,      # HTTP client for OneMap geocoding calls\n  spatstat,  # point pattern analysis meta-package (ppp, Kest, Lest, envelope, density)\n  ggplot2,   # grammar-of-graphics plotting system (part of tidyverse).\n  plotly,    # adds interactivity to ggplot2 plots.\n  ggthemes  # provides professional ggplot2 themes (e.g., tufte, economist).\n)\n\n\n\n4.2 Reproducibility for CSR envelopes\nSets a random seed to guarantee reproducible results when generating CSR envelopes.\n\nset.seed(626)  # reproducibility for CSR envelopes"
  },
  {
    "objectID": "Take-home_Ex01/take-home_ex01.html#raw-data-preprocessing-restaurants-only",
    "href": "Take-home_Ex01/take-home_ex01.html#raw-data-preprocessing-restaurants-only",
    "title": "Take-home Ex01: Geospatial Analytics for Public Good",
    "section": "5 Raw data preprocessing (Restaurants only)",
    "text": "5 Raw data preprocessing (Restaurants only)\nIn this section, we import the Accounting and Corporate Regulatory Authority (ACRA) corporate entities data, which is organised into multiple CSV files. The objective is to compile, clean, and filter these records to isolate restaurants and cafés coded under SSIC 56111. This step is fundamental because it converts raw administrative files into a consistent and analysis-ready dataset, with standardised variable names, parsed dates, and validated postal codes. The outcome is a tidy dataset that preserves the essential business attributes required for downstream geocoding, spatial conversion, and statistical analysis.\n\n5.1 Importing ACRA data\nFirst, we need to import raw ACRA business registration data from CSV files. The code specifies the folder path, lists all files with names starting with “ACRA” and ending in .csv, and then reads them into R using map_dfr(read_csv), which stacks them into a single tibble (row binding).\n\n# folder_path points to the directory containing the ACRA CSV files.\nfolder_path &lt;- \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Take-home_Ex01/data/aspatial\"\n\n# list.files() collects all ACRA files that match the naming pattern and returns their full paths.\nfile_list &lt;- list.files(path = folder_path, \n                        pattern = \"^ACRA*.*\\\\.csv$\", \n                        full.names = TRUE)\n\n# map_dfr() reads each CSV file and stacks them into one tibble (row binding).\nacra_data &lt;- file_list %&gt;%\n  map_dfr(read_csv)\n\n\n\n5.2 Saving ACRA data for reproducibility\nHere, the imported raw data is saved as an RDS file using write_rds(). This ensures reproducibility and efficiency, since future analysis can load the cleaned RDS file directly without re-importing all CSVs.\n\n# Save the raw imported data as an RDS file to avoid repeated imports in future runs.\nwrite_rds(acra_data,\n          \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Take-home_Ex01/data/rds/acra_data.rds\")\n\n\n\n5.3 Tidying ACRA data (restaurants only, SSIC 56111)\nNext, we will filters and transforms the raw dataset to focus exclusively on restaurants, defined by SSIC code 56111. The dataset is trimmed to the first 24 columns, the registration date is standardised to Date class, and additional temporal fields such as year, month number, and month abbreviation are created. Postal codes are normalised into six-digit format, and the dataset is restricted to businesses incorporated in 2025.\n\nbiz_56111 &lt;- acra_data %&gt;%\n  select(1:24) %&gt;%                                    # Select only the first 24 columns (ignore extra metadata columns).\n  filter(primary_ssic_code == 56111) %&gt;%              # Keep only businesses coded as restaurants and cafés (SSIC 56111).\n  rename(date = registration_incorporation_date) %&gt;%  # Rename registration date field to a shorter label 'date'.\n  \n  # Convert registration date to Date class, extract Year and Month (numeric and abbreviated).\n  mutate(date = as.Date(date),\n         YEAR = year(date),\n         MONTH_NUM = month(date),\n         MONTH_ABBR = month(date, \n                            label = TRUE, \n                            abbr = TRUE)) %&gt;% \n  \n  # Standardise postal code to six digits with leading zeros.\n  mutate(\n    postal_code = str_pad(postal_code, \n    width = 6, side = \"left\", pad = \"0\")) %&gt;%\n           filter(YEAR == 2025)    \n\n\n\n5.4 Saving tidy restaurant data\nFinally, the dataset is filtered to focus exclusively on restaurant businesses, defined by SSIC code 56111. Only the relevant columns are retained, and the data is restricted to businesses incorporated in 2025.\n\n# Save the tidy restaurant dataset for subsequent steps such as geocoding and EDA.\nwrite_rds(biz_56111, \n          \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Take-home_Ex01/data/rds/restaurants_56111_tidy.rds\")"
  },
  {
    "objectID": "Take-home_Ex01/take-home_ex01.html#exploratory-data-analysis-eda-of-restaurants",
    "href": "Take-home_Ex01/take-home_ex01.html#exploratory-data-analysis-eda-of-restaurants",
    "title": "Take-home Ex01: Geospatial Analytics for Public Good",
    "section": "6 Exploratory Data Analysis (EDA) of Restaurants",
    "text": "6 Exploratory Data Analysis (EDA) of Restaurants\nBefore any spatial conversion or modelling, it is essential to perform EDA to understand the characteristics of the cleaned dataset. EDA helps confirm that the data aligns with the research window (January 2025 – Jun 2025) and that restaurants are being correctly filtered. It also allows us to observe temporal dynamics such as monthly registration counts and possible seasonal patterns. Through simple summaries, tables, and visualisations, we can validate the dataset’s integrity and gain initial insights into how new restaurants are distributed over time. This diagnostic step ensures confidence in the subsequent geocoding and spatial analyses.\n\n6.1 Inspect data structure\nThis section uses the glimpse() function to display the structure of the tidied restaurant dataset (biz_56111). The function provides an overview of column names, data types, and a preview of the values within each column.\n\n# glimpse() provides an overview of column names, data types, and a sample of values.\nglimpse(biz_56111)\n\nRows: 677\nColumns: 27\n$ uen                               &lt;chr&gt; \"202501136C\", \"202501329K\", \"2025029…\n$ issuance_agency_id                &lt;chr&gt; \"ACRA\", \"ACRA\", \"ACRA\", \"ACRA\", \"ACR…\n$ entity_name                       &lt;chr&gt; \"AL ASHIK PTE. LTD.\", \"ARASH LEGACY …\n$ entity_type_description           &lt;chr&gt; \"Local Company\", \"Local Company\", \"L…\n$ business_constitution_description &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ company_type_description          &lt;chr&gt; \"Exempt Private Company Limited by S…\n$ paf_constitution_description      &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ entity_status_description         &lt;chr&gt; \"Live Company\", \"Live Company\", \"Liv…\n$ date                              &lt;date&gt; 2025-01-08, 2025-01-09, 2025-01-19,…\n$ uen_issue_date                    &lt;date&gt; 2025-01-08, 2025-01-09, 2025-01-19,…\n$ address_type                      &lt;chr&gt; \"LOCAL\", \"LOCAL\", \"LOCAL\", \"LOCAL\", …\n$ block                             &lt;chr&gt; \"305D\", \"21\", \"324\", \"502\", \"15\", \"2…\n$ street_name                       &lt;chr&gt; \"ANCHORVALE LINK\", \"TAN QUEE LAN STR…\n$ level_no                          &lt;chr&gt; \"11\", \"02\", \"na\", \"02\", \"10\", \"na\", …\n$ unit_no                           &lt;chr&gt; \"23\", \"04\", \"na\", \"02\", \"32\", \"na\", …\n$ building_name                     &lt;chr&gt; \"ANCHORVALE PLACE\", \"HERITAGE PLACE\"…\n$ postal_code                       &lt;chr&gt; \"544305\", \"188108\", \"338822\", \"46902…\n$ other_address_line1               &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ other_address_line2               &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ account_due_date                  &lt;chr&gt; \"2026-08-31\", \"2026-07-31\", \"2026-07…\n$ annual_return_date                &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ primary_ssic_code                 &lt;dbl&gt; 56111, 56111, 56111, 56111, 56111, 5…\n$ primary_ssic_description          &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ primary_user_described_activity   &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ YEAR                              &lt;dbl&gt; 2025, 2025, 2025, 2025, 2025, 2025, …\n$ MONTH_NUM                         &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, …\n$ MONTH_ABBR                        &lt;ord&gt; Jan, Jan, Jan, Jan, Jan, Jan, Feb, F…\n\n\nThe output indicates that the dataset contains 677 rows and 27 columns, with fields such as unique entity number (uen), issuance agency, entity name, entity type, business constitution, company type, entity status, registration date, postal code, and location descriptors (block, street, building).\n\n\n6.2 Count restaurants by year\nThis section uses the count() function to summarise the number of restaurants incorporated by year from the tidied dataset. Since the data has already been filtered to include only 2025 records, the result shows a single row with the year 2025 and a corresponding total of 677 newly registered restaurants.\n\n# Summarise how many restaurants were registered in each year within the study period.\nbiz_56111 %&gt;% \n  count(YEAR, name = \"n_restaurants\")\n\n# A tibble: 1 × 2\n   YEAR n_restaurants\n  &lt;dbl&gt;         &lt;int&gt;\n1  2025           677\n\n\nThe dataset shows that in 2025 alone, there were 677 new restaurant registrations recorded within the study period (Jan – Jun 2025).\n\n\n6.3 Monthly registration counts (bar chart)\nRestaurant incorporations in 2025 are aggregated at the monthly level and visualised to reveal short-term temporal dynamics in business activity. The counts are structured chronologically to avoid distortions in seasonal interpretation, and the resulting bar chart provides both absolute values through labelled bars and directional movement through a superimposed trend line. By combining these elements, the plot not only conveys the magnitude of new entries each month but also highlights emerging trajectories within the first half of 2025, setting the stage for discussions on whether incorporations are accelerating, stabilising, or declining as the year progresses.\n\n# 1) Aggregate once: counts per month (make sure months are ordered nicely)\nmonth_levels &lt;- c(\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\")\ndf_month &lt;- biz_56111 %&gt;%\n  count(MONTH_ABBR, name = \"registrations\") %&gt;%\n  mutate(MONTH_ABBR = factor(MONTH_ABBR, levels = month_levels)) %&gt;%\n  arrange(MONTH_ABBR)\n\ny_max &lt;- max(df_month$registrations) * 1.10  # headroom for labels\n\n# 2) Plot: bars + count labels + centre title + trend line\np_month_bar &lt;- ggplot(df_month, aes(x = MONTH_ABBR, y = registrations, group = 1)) +\n  geom_col(fill = \"steelblue\") +\n  geom_text(aes(label = registrations), vjust = -0.5, size = 3.5) +  # labels on bars\n  geom_line(color = \"red\", linewidth = 1) +                          # trend line\n  geom_point(color = \"red\") +                                        # trend points (optional)\n  labs(\n    title = \"New Restaurants by Month (Jan 2025 – Jun 2025)\",\n    x = \"Month\", y = \"Registrations\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5)) +                    # centres title\n  expand_limits(y = y_max)                                           # keep labels above bars\n\np_month_bar\n\n\n\n\n\n\n\n\nBetween Jan 2021 and Jul 2025, new restaurant registrations ranged from a high of 110 in March 2024 to a low of 79 in July 2025, with most months maintaining 90–105 openings, reflecting both seasonal dynamics and the resilience of the F&B sector. From a geospatial perspective, however, this chart is limited as it only shows overall counts by month without accounting for where the restaurants are located, how they cluster across planning areas or subzones, or whether growth is concentrated in certain regions. Without spatial context, we cannot assess neighborhood-level competition, urban planning implications, or the uneven distribution of opportunities across Singapore."
  },
  {
    "objectID": "Take-home_Ex01/take-home_ex01.html#geospatial-data-wrangling",
    "href": "Take-home_Ex01/take-home_ex01.html#geospatial-data-wrangling",
    "title": "Take-home Ex01: Geospatial Analytics for Public Good",
    "section": "7 Geospatial data wrangling",
    "text": "7 Geospatial data wrangling\nThis section converts six-digit postal codes from the cleaned ACRA table into planar coordinates suitable for spatial analysis. We query the OneMap endpoint for each unique postcode, store results, and left-join them back to the restaurant records by matching postal_code to OneMap’s POSTAL. We deliberately retain OneMap’s original column names (e.g., POSTAL, X, Y, LONGITUDE, LATITUDE). After joining, we save an RDS copy for reproducibility and create an sf object directly in SVY21 (EPSG:3414) using coords = c(“X”,“Y”), which is required for distance-true kernel density estimation and Ripley’s K/L.\n\n7.1 Geocoding loop (query OneMap and collect results)\nWe prepare a vector of unique postcodes to minimise API calls, then iterate through them sequentially. For each postcode, the relevant parameters (searchVal, returnGeom, getAddrDetails, pageNum) are submitted to the OneMap endpoint. Successful responses are converted into a data frame and appended to the found table, while unmatched postcodes are stored separately in not_found. This process ensures efficient use of the API, reduces redundancy, and creates a clear separation between valid and invalid geocoded results for subsequent analysis.\n\n# --- Geocoding (It took XX seconds to process this chunk) ---------------------------\n\n# Create a unique vector of six-digit postcodes to avoid redundant API requests.\npostcodes &lt;- unique(biz_56111$postal_code)\n\n# OneMap elastic search endpoint \nurl &lt;- \"https://onemap.gov.sg/api/common/elastic/search\"\n\n# Initialise an empty data.frame to accumulate matched results from OneMap.\nfound &lt;- data.frame()\n\n# Initialise an empty data.frame to record postcodes with no matches.\nnot_found &lt;- data.frame(postcode = character())\n\n# Iterate over each unique postcode.\nfor (pc in postcodes) {\n  query &lt;- list(\n    searchVal    = pc,   # The postcode we are querying for.\n    returnGeom   = \"Y\",  # Request coordinates in the response.\n    getAddrDetails = \"Y\",# Request address details in the response.\n    pageNum      = \"1\"   # First page of results (sufficient for exact postcodes).\n  )\n\n  # Submit an HTTP GET request to OneMap with the query parameters.\n  res  &lt;- httr::GET(url, query = query)\n  \n  # Parse the HTTP response content as a list (OneMap returns JSON).\n  json &lt;- httr::content(res)\n  \n  # If OneMap reports at least one match for this postcode...\n  if (json$found != 0) {\n    \n    # Convert the 'results' array to a data.frame, preserving original OneMap field names.\n    df &lt;- as.data.frame(json$results, stringsAsFactors = FALSE)\n    \n    # Keep the input postcode as a traceability column (useful for QA).\n    df$input_postcode &lt;- pc\n\n    # Append the current result to the cumulative 'found' table.\n    found &lt;- dplyr::bind_rows(found, df)\n\n    # If there is no match for this postcode...\n  } else {\n    \n    # Record the postcode in 'not_found' for later inspection.\n    not_found &lt;- dplyr::bind_rows(not_found, data.frame(postcode = pc))\n\n  }\n}\n\n\n\n7.2 Tidy the geocoded table\nTo prepare the geocoded dataset for integration with the business records, we retain only the essential columns returned by OneMap. Specifically, the first ten fields are preserved, covering postal codes, spatial coordinates (X, Y, longitude, latitude), and key address attributes. This step removes extraneous metadata while maintaining all information required for spatial joins and mapping. By standardising the table structure, subsequent operations such as left_join() become more efficient and less error-prone, ensuring that the geocoded records align seamlessly with the cleaned business dataset. The result is a compact, analysis ready table that is useful for downstream spatial analysis and visualisation.\n\n# Keep the first ten columns from OneMap.\n# (These include POSTAL, X, Y, LONGITUDE, LATITUDE, etc.)\n\nfound &lt;- found %&gt;%\n  dplyr::select(1:10)\n\n\n\n7.3 Append coordinates to restaurants (join by postal code)\nWe attach the geocoded coordinates to the restaurant records using a left join from biz_56111 to found, matching postal_code (our cleaned field) with OneMap’s POSTAL. This preserves all restaurant rows and adds coordinate columns where available.\n\n# Left-join OneMap coordinates back to the restaurant table.\n# The join is on 'postal_code' (ours) = 'POSTAL' (OneMap).\nbiz_56111 &lt;- biz_56111 %&gt;%\n  dplyr::left_join(found, by = c('postal_code' = 'POSTAL'))\n\n\n# Convert geocoded restaurants into sf object\nbiz_56111_sf &lt;- sf::st_as_sf(\n  biz_56111,\n  coords = c(\"X\", \"Y\"),    # the coordinate columns from OneMap geocoding\n  crs    = 3414            # Singapore SVY21 / EPSG:3414\n)\n\n# Quick check: print an overview of column names, data types, and a sample of values.\nglimpse(biz_56111_sf)\n\nRows: 677\nColumns: 35\n$ uen                               &lt;chr&gt; \"202501136C\", \"202501329K\", \"2025029…\n$ issuance_agency_id                &lt;chr&gt; \"ACRA\", \"ACRA\", \"ACRA\", \"ACRA\", \"ACR…\n$ entity_name                       &lt;chr&gt; \"AL ASHIK PTE. LTD.\", \"ARASH LEGACY …\n$ entity_type_description           &lt;chr&gt; \"Local Company\", \"Local Company\", \"L…\n$ business_constitution_description &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ company_type_description          &lt;chr&gt; \"Exempt Private Company Limited by S…\n$ paf_constitution_description      &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ entity_status_description         &lt;chr&gt; \"Live Company\", \"Live Company\", \"Liv…\n$ date                              &lt;date&gt; 2025-01-08, 2025-01-09, 2025-01-19,…\n$ uen_issue_date                    &lt;date&gt; 2025-01-08, 2025-01-09, 2025-01-19,…\n$ address_type                      &lt;chr&gt; \"LOCAL\", \"LOCAL\", \"LOCAL\", \"LOCAL\", …\n$ block                             &lt;chr&gt; \"305D\", \"21\", \"324\", \"502\", \"15\", \"2…\n$ street_name                       &lt;chr&gt; \"ANCHORVALE LINK\", \"TAN QUEE LAN STR…\n$ level_no                          &lt;chr&gt; \"11\", \"02\", \"na\", \"02\", \"10\", \"na\", …\n$ unit_no                           &lt;chr&gt; \"23\", \"04\", \"na\", \"02\", \"32\", \"na\", …\n$ building_name                     &lt;chr&gt; \"ANCHORVALE PLACE\", \"HERITAGE PLACE\"…\n$ postal_code                       &lt;chr&gt; \"544305\", \"188108\", \"338822\", \"46902…\n$ other_address_line1               &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ other_address_line2               &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ account_due_date                  &lt;chr&gt; \"2026-08-31\", \"2026-07-31\", \"2026-07…\n$ annual_return_date                &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ primary_ssic_code                 &lt;dbl&gt; 56111, 56111, 56111, 56111, 56111, 5…\n$ primary_ssic_description          &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ primary_user_described_activity   &lt;chr&gt; \"na\", \"na\", \"na\", \"na\", \"na\", \"na\", …\n$ YEAR                              &lt;dbl&gt; 2025, 2025, 2025, 2025, 2025, 2025, …\n$ MONTH_NUM                         &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, …\n$ MONTH_ABBR                        &lt;ord&gt; Jan, Jan, Jan, Jan, Jan, Jan, Feb, F…\n$ SEARCHVAL                         &lt;chr&gt; \"ANCHORVALE PLACE\", \"HERITAGE PLACE\"…\n$ BLK_NO                            &lt;chr&gt; \"305D\", \"21\", \"324\", \"502\", \"15\", \"2…\n$ ROAD_NAME                         &lt;chr&gt; \"ANCHORVALE LINK\", \"TAN QUEE LAN STR…\n$ BUILDING                          &lt;chr&gt; \"ANCHORVALE PLACE\", \"HERITAGE PLACE\"…\n$ ADDRESS                           &lt;chr&gt; \"305D ANCHORVALE LINK ANCHORVALE PLA…\n$ LATITUDE                          &lt;chr&gt; \"1.38903342950987\", \"1.2985892658367…\n$ LONGITUDE                         &lt;chr&gt; \"103.887299862674\", \"103.85640505809…\n$ geometry                          &lt;POINT [m]&gt; POINT (34007.42 41217.84), POI…\n\n\nThe dataset now contains 677 records and 35 variables, representing restaurants incorporated in 2025 under SSIC 56111. Each row corresponds to a unique registered entity, identifiable by its UEN (Unique Entity Number), with accompanying details on company type, incorporation date, address, and geospatial coordinates. The presence of date and uen_issue_date in date format confirms proper temporal standardisation, allowing the dataset to be analysed along monthly or yearly dimensions.\nAddress-related variables such as block, street_name, building_name, postal_code, and their derived forms (BLK_NO, ROAD_NAME, ADDRESS) demonstrate that the cleaning and enrichment steps successfully prepared the dataset for spatial matching. Crucially, the dataset now includes geocoded coordinates (LATITUDE, LONGITUDE) and a geometry field, which transforms each restaurant record into a spatial point object. This enables integration with planning boundaries, kernel density estimation, or other forms of spatial point pattern analysis.\nOverall, the output confirms that the dataset is no longer just an administrative registry but a geospatially enabled dataset. It can now support advanced analysis such as mapping restaurant hotspots, measuring clustering within planning subzones, or comparing incorporation intensity across different regions of Singapore. The presence of 677 records highlights the scale of new restaurant entrants in 2025, and the completeness of attributes ensures both temporal and spatial dimensions can be meaningfully explored.\n\n\n7.4 Save a reproducible copy (RDS) for downstream steps\nSaving after the join ensures the same input is used for EDA and spatial analyses without re-calling the API. If we want to maintain a different project root, adjust the path accordingly.\n\nreadr::write_rds(\n  biz_56111,\n  \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Take-home_Ex01/data/rds/biz_56111_geocoded.rds\"\n)"
  },
  {
    "objectID": "Take-home_Ex01/take-home_ex01.html#boundary-preparation-parse-mp19-kml-description-quality-assurance-qa-map",
    "href": "Take-home_Ex01/take-home_ex01.html#boundary-preparation-parse-mp19-kml-description-quality-assurance-qa-map",
    "title": "Take-home Ex01: Geospatial Analytics for Public Good",
    "section": "8 Boundary preparation (parse MP19 KML Description) + Quality Assurance (QA) Map",
    "text": "8 Boundary preparation (parse MP19 KML Description) + Quality Assurance (QA) Map\nMany URA MP19 KML files appear to contain only two visible fields (Name, Description). However, the actual attributes—such as SUBZONE_N and PLN_AREA_N—are embedded within an HTML table inside the Description column. To handle this, we define a helper function that parses the HTML and extracts specific fields by label (e.g., SUBZONE_N). Using this function, we generate clean columns for each feature, remove offshore polygons (e.g., SOUTHERN GROUP, WESTERN ISLANDS), and create a QA map to verify that restaurant points fall correctly within the refined subzone boundaries. This ensures that subsequent spatial analyses (KDE and L/K functions) are accurate and reliable.\n\n8.1 Read MP19 KML and project to SVY21\nWe read the “MasterPlan2019SubzoneBoundaryNoSeaKML.kml”, drop Z/M, and project to SVY21 (EPSG:3414). At this point the table likely has only Name and Description; we do not filter yet because those fields are still inside the HTML.\n\n# read the KML layer (likely Name + Description fields)\nmpsz_raw &lt;- sf::st_read(\"data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\", quiet = TRUE) %&gt;%   \n  sf::st_zm(drop = TRUE, what = \"ZM\") %&gt;%   # drop Z/M to keep 2D geometry only\n  sf::st_transform(crs = 3414)              # project to SVY21 meters so distance/area are metric\n\n\n\n8.2 Helper to extract one field from the KML Description HTML\nWe will parse the HTML table inside Description and return the value from the table row where the &lt;th&gt; (header) equals a requested field label (e.g., “SUBZONE_N”). We wrap this into a function extract_kml_field(html_text, field_name) and make sure it fails safely (returns NA_character_ if the label cannot be found).\n\nextract_kml_field &lt;- function(html_text, field_name) {\n  # If the cell is empty or NA, return NA to avoid errors later\n  if (is.na(html_text) || html_text == \"\") return(NA_character_)\n  \n  # Parse the HTML string into a document\n  page &lt;- rvest::read_html(html_text)\n  \n  # Grab all table rows &lt;tr&gt; (the KML Description usually contains one table)\n  rows &lt;- rvest::html_elements(page, \"tr\")\n  \n  # Keep the row whose header cell &lt;th&gt; equals the requested field label,\n  # then take the text of the &lt;td&gt; cell in that same row\n  value &lt;- rows %&gt;%\n    purrr::keep(~ rvest::html_text2(rvest::html_element(.x, \"th\")) == field_name) %&gt;%\n    rvest::html_element(\"td\") %&gt;%\n    rvest::html_text2()\n  \n  # If nothing matched, return NA; otherwise return the extracted value\n  if (length(value) == 0) NA_character_ else value\n}\n\n\n\n8.3 Materialise attributes from Description, tidy columns, and filter\nWe now map the helper over each feature’s Description to create real columns: REGION_N, PLN_AREA_N, SUBZONE_N, SUBZONE_C. Then we drop the original Name / Description, put geometry last (nice console print), and filter out Southern Group and Western Islands by the newly-created columns—exactly the step that previously failed because those columns didn’t exist.\n\n# --- Parse Description to real columns, then tidy and filter -----------------------\n\nmpsz &lt;- mpsz_raw %&gt;%\n  dplyr::mutate(\n    REGION_N   = purrr::map_chr(Description, extract_kml_field, \"REGION_N\"),   # parse region name\n    PLN_AREA_N = purrr::map_chr(Description, extract_kml_field, \"PLN_AREA_N\"), # parse planning area name\n    SUBZONE_N  = purrr::map_chr(Description, extract_kml_field, \"SUBZONE_N\"),  # parse subzone name\n    SUBZONE_C  = purrr::map_chr(Description, extract_kml_field, \"SUBZONE_C\")   # parse subzone code\n  ) %&gt;%\n  dplyr::select(-Name, -Description) %&gt;%     # remove raw Name/Description\n  dplyr::relocate(geometry, .after = dplyr::last_col())   # move geometry to the last column\n\n# Print a few rows so we can see the new columns are present\nmpsz %&gt;% dplyr::slice_head(n = 3)\n\nSimple feature collection with 3 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 24431.8 ymin: 28515.07 xmax: 29766.12 ymax: 29741.75\nProjected CRS: SVY21 / Singapore TM\n        REGION_N  PLN_AREA_N   SUBZONE_N SUBZONE_C\n1 CENTRAL REGION BUKIT MERAH  DEPOT ROAD    BMSZ12\n2 CENTRAL REGION BUKIT MERAH BUKIT MERAH    BMSZ02\n3 CENTRAL REGION      OUTRAM   CHINATOWN    OTSZ03\n                        geometry\n1 MULTIPOLYGON (((25910.34 29...\n2 MULTIPOLYGON (((26750.09 29...\n3 MULTIPOLYGON (((29161.2 297...\n\n# Filter out offshore groups using the newly created columns\nmpsz_clean &lt;- mpsz %&gt;%\n  dplyr::filter(SUBZONE_N != \"SOUTHERN GROUP\",\n                PLN_AREA_N != \"WESTERN ISLANDS\",\n                SUBZONE_N != \"NORTH-EASTERN ISLANDS\"\n                )\n\n\n\n8.4 QA Map (tmap v4): Restaurants over cleaned MP19 subzones\nWe will build a QA map to confirm geocoded restaurants lie within the cleaned subzones. The code builds a static quality-assurance map to verify that geocoded restaurant points fall correctly within Singapore’s Master Plan 2019 planning areas. It first aligns coordinate reference systems (reprojecting the restaurant points if needed to match the MP19 layer, SVY21), then dissolves subzone polygons into single planning-area geometries via group_by (PLN_AREA_N) |&gt; summarise() and repairs any invalid shapes with st_make_valid(). With tmap in plot mode, it renders the planning-area polygons in neutral greys and places readable area labels (tm_text with shadow and auto-placement). Finally, it overlays the restaurant locations from biz_56111_sf as semi-transparent red dots and adds a clear title, producing a publication-ready QA visual that confirms spatial alignment before downstream analyses.\n\n# --- QA Map (tmap v4): restaurants over MP19 planning areas with labels -----\n\n# 0) Ensure both layers share the same CRS (SVY21)\nif (sf::st_crs(biz_56111_sf) != sf::st_crs(mpsz_clean)) {\n  biz_56111_sf &lt;- sf::st_transform(biz_56111_sf, sf::st_crs(mpsz_clean))  # align CRS if needed\n}\n\n# 1) Dissolve subzones -&gt; Planning Areas (by PLN_AREA_N)\n#    (keeps one polygon per planning area; fixes invalids just in case)\nmp19_pa &lt;-\n  mpsz_clean |&gt;\n  dplyr::group_by(PLN_AREA_N) |&gt;\n  dplyr::summarise(.groups = \"drop\") |&gt;\n  sf::st_make_valid()\n\n# 2) Draw the QA map with labels\ntmap::tmap_mode(\"plot\")  # static mode (consistent in reports)\n\nqa_map_pa &lt;-\n  tmap::tm_shape(mp19_pa) +\n    tmap::tm_polygons(\n      fill = \"grey95\",     # polygon fill (v4)\n      col  = \"grey50\",     # polygon outline color (v4)\n      lwd  = 0.6\n    ) +\n    tmap::tm_text(\n      \"PLN_AREA_N\",\n      size = 0.5,          # label size\n      col  = \"grey20\",\n      shadow = TRUE,\n      auto.placement = TRUE\n    ) +\n  tmap::tm_shape(biz_56111_sf) +\n    tmap::tm_dots(\n      size      = 0.15,    # dot size\n      fill      = \"red\",   # dot color\n      fill_alpha= 0.7      # dot transparency (v4)\n    ) +\n  tmap::tm_title(\"QA Map: Geocoded Restaurants over MP19 Planning Areas (SVY21)\")\n\nqa_map_pa   # IMPORTANT: print the map so Quarto renders it\n\n\n\n\n\n\n\n\nThe QA map overlays geocoded restaurant registrations (red dots) from the ACRA dataset onto Singapore’s Master Plan 2019 planning areas (grey polygons). The spatial alignment confirms that the restaurant points fall within their corresponding planning area boundaries, indicating that the geocoding and CRS transformation were successfully executed.\nFrom the spatial distribution, several insights emerge. The densest concentration of new restaurants in 2025 is clustered in the Central Region, particularly within planning areas such as Orchard, River Valley, Downtown Core, Outram, and Bukit Merah. This reflects the commercial dominance of the central business district and adjacent entertainment hubs, where demand for food and beverage outlets is consistently high. Moderate densities appear across Toa Payoh, Geylang, Marine Parade, and Tampines, showing strong activity in mature residential towns and regional centres. In contrast, western and northern regions such as Lim Chu Kang, Sungei Kadut, and Western Water Catchment display sparse distributions, suggesting minimal restaurant incorporations due to their industrial or non-residential land uses.\nOverall, the output validates the geospatial preprocessing workflow while simultaneously revealing the spatial asymmetry of restaurant incorporations in Singapore. Concentrations in central and eastern urban corridors highlight areas of vibrant market demand, while sparse coverage in peripheral planning areas reflects structural land-use constraints and lower commercial viability. This spatial insight sets the foundation for deeper first- and second-order spatial point pattern analyses, such as Kernel Density Estimation (KDE) or clustering tests, to quantify and statistically assess these observed patterns.\n\n8.4.1 Enhancing spatial validation with interactive QA maps\nThis interactive version of the QA map is important because it allows users to zoom, pan, and explore individual planning areas in greater detail. While the static map is suitable for reporting, an interactive map provides flexibility to validate whether each restaurant point is correctly placed within its boundary, especially in dense central regions where overlaps occur. It enhances data verification, spatial accuracy checks, and stakeholder communication, making it easier to spot potential geocoding or boundary alignment errors that might not be visible in a static output.\n\ntmap::tmap_mode(\"view\")\n\nqa_map_pa_int &lt;-\n  tm_basemap(\"CartoDB.Positron\") +\n  tm_shape(mp19_pa, name = \"Planning Areas\") +\n    tm_polygons(fill = \"grey80\", col = \"grey50\", lwd = 0.6, alpha = 0.3) +\n  tm_shape(mp19_pa, name = \"PA Labels\") +\n    tm_text(\"PLN_AREA_N\", size = 1, col = \"black\",\n            bg.color = \"white\", bg.alpha = 0.6, auto.placement = TRUE) +\n  tm_shape(biz_56111_sf, name = \"Restaurants\") +\n    tm_dots(\n            size      = 0.4,    # dot size\n            fill      = \"red\",   # dot color\n            fill_alpha= 0.7      # dot transparency (v4)\n    )\n\nqa_map_pa_int"
  },
  {
    "objectID": "Take-home_Ex01/take-home_ex01.html#first-order-analysis-kernel-density-estimation-kde",
    "href": "Take-home_Ex01/take-home_ex01.html#first-order-analysis-kernel-density-estimation-kde",
    "title": "Take-home Ex01: Geospatial Analytics for Public Good",
    "section": "9 First-order analysis: Kernel Density Estimation (KDE)",
    "text": "9 First-order analysis: Kernel Density Estimation (KDE)\nThis section investigates the first-order intensity of new restaurant registrations using KDE. We first estimate intensity surfaces for all Singapore (national level). Next, we drill down to the planning subzone level to highlight local variations. Finally, we extend to spatio-temporal KDE (STKDE) to capture dynamics across both space and time (Jan–Jun 2025).\n\n9.1 Prepare spatstat objects\nWe already have clean data: restaurants_sf (points in EPSG:3414) and mpsz_cl (planning subzones in EPSG:3414). Here, we convert them into formats required for point pattern analysis: an observation window (owin) and a point pattern (ppp). We also create a kilometer-scaled version for sensitivity analysis.\n\n# 0) Defensive checks: both layers must be in SVY21 (EPSG:3414; units = meters)\nstopifnot(sf::st_crs(mpsz_clean)$epsg == 3414)      # confirm polygons (study area) are in 3414\nstopifnot(sf::st_crs(biz_56111_sf)$epsg == 3414)    # confirm restaurant points are in 3414\n\n# 1) Create the observation window (owin) from subzones (still in meters here)\nsg_owin &lt;- spatstat.geom::as.owin(mpsz_clean)       # convert sf polygons -&gt; spatstat 'owin' window\n\n# 2) Create the point pattern (ppp) from restaurants (still in meters here)\nrest_ppp &lt;- spatstat.geom::as.ppp(biz_56111_sf)     # convert sf points -&gt; spatstat 'ppp' pattern\n\n# 3) Clip the points to the study window (meter scale) to enforce the boundary\nrest_ppp &lt;- rest_ppp[sg_owin]                        # keep only points that fall inside 'sg_owin'\n\n# 4) Rescale the point pattern from meters to kilometers (single, canonical step)\nrest_ppp_km &lt;- rescale.ppp(                          # produce km-scale 'ppp' for all downstream KDE\n  rest_ppp,                                          # input 'ppp' in meters\n  1000,                                              # scale factor: divide coordinates by 1000 (m -&gt; km)\n  \"km\"                                               # label for the new distance unit\n)\n\n# 5) Quick sanity checks to verify objects and units before proceeding\nstopifnot(spatstat.geom::is.ppp(rest_ppp_km))        # confirm we have a valid 'ppp' object\nrest_ppp_km$unitname                                 # should print \"km\" as the working unit\n\nNULL\n\nsummary(rest_ppp_km)                                 # optional: inspect counts, window, and mark info\n\nMarked planar point pattern:  677 points\nAverage intensity 1.011177 points per square km\n\nCoordinates are given to 15 decimal places\n\nMark variables: uen, issuance_agency_id, entity_name, entity_type_description, \nbusiness_constitution_description, company_type_description, \npaf_constitution_description, entity_status_description, date, uen_issue_date, \naddress_type, block, street_name, level_no, unit_no, building_name, \npostal_code, other_address_line1, other_address_line2, account_due_date, \nannual_return_date, primary_ssic_code, primary_ssic_description, \nprimary_user_described_activity, YEAR, MONTH_NUM, MONTH_ABBR, SEARCHVAL, \nBLK_NO, ROAD_NAME, BUILDING, ADDRESS, LATITUDE, LONGITUDE\nSummary:\n     uen            issuance_agency_id entity_name       \n Length:677         Length:677         Length:677        \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n entity_type_description business_constitution_description\n Length:677              Length:677                       \n Class :character        Class :character                 \n Mode  :character        Mode  :character                 \n                                                          \n                                                          \n                                                          \n                                                          \n company_type_description paf_constitution_description\n Length:677               Length:677                  \n Class :character         Class :character            \n Mode  :character         Mode  :character            \n                                                      \n                                                      \n                                                      \n                                                      \n entity_status_description      date            uen_issue_date      \n Length:677                Min.   :2025-01-01   Min.   :2025-01-01  \n Class :character          1st Qu.:2025-02-20   1st Qu.:2025-02-20  \n Mode  :character          Median :2025-04-10   Median :2025-04-10  \n                           Mean   :2025-04-12   Mean   :2025-04-12  \n                           3rd Qu.:2025-06-04   3rd Qu.:2025-06-04  \n                           Max.   :2025-07-31   Max.   :2025-07-31  \n                                                                    \n address_type          block           street_name          level_no        \n Length:677         Length:677         Length:677         Length:677        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n   unit_no          building_name      postal_code        other_address_line1\n Length:677         Length:677         Length:677         Length:677         \n Class :character   Class :character   Class :character   Class :character   \n Mode  :character   Mode  :character   Mode  :character   Mode  :character   \n                                                                             \n                                                                             \n                                                                             \n                                                                             \n other_address_line2 account_due_date   annual_return_date primary_ssic_code\n Length:677          Length:677         Length:677         Min.   :56111    \n Class :character    Class :character   Class :character   1st Qu.:56111    \n Mode  :character    Mode  :character   Mode  :character   Median :56111    \n                                                           Mean   :56111    \n                                                           3rd Qu.:56111    \n                                                           Max.   :56111    \n                                                                            \n primary_ssic_description primary_user_described_activity      YEAR     \n Length:677               Length:677                      Min.   :2025  \n Class :character         Class :character                1st Qu.:2025  \n Mode  :character         Mode  :character                Median :2025  \n                                                          Mean   :2025  \n                                                          3rd Qu.:2025  \n                                                          Max.   :2025  \n                                                                        \n   MONTH_NUM       MONTH_ABBR   SEARCHVAL            BLK_NO         \n Min.   :1.000   Mar    :110   Length:677         Length:677        \n 1st Qu.:2.000   Jan    :102   Class :character   Class :character  \n Median :4.000   Jun    :100   Mode  :character   Mode  :character  \n Mean   :3.885   Apr    : 97                                        \n 3rd Qu.:6.000   Feb    : 96                                        \n Max.   :7.000   May    : 93                                        \n                 (Other): 79                                        \n  ROAD_NAME           BUILDING           ADDRESS            LATITUDE        \n Length:677         Length:677         Length:677         Length:677        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  LONGITUDE        \n Length:677        \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\nWindow: polygonal boundary\n41 separate polygons (26 holes)\n                  vertices         area relative.area\npolygon 1              285  1.61128e+00      2.41e-03\npolygon 2               27  1.50315e-02      2.25e-05\npolygon 3 (hole)        41 -4.01660e-02     -6.00e-05\npolygon 4 (hole)       317 -5.11280e-02     -7.64e-05\npolygon 5 (hole)         3 -4.14100e-10     -6.19e-13\npolygon 6               30  2.80002e-02      4.18e-05\npolygon 7 (hole)         4 -2.86396e-07     -4.28e-10\npolygon 8 (hole)         3 -1.81440e-10     -2.71e-13\npolygon 9 (hole)         3 -5.99531e-10     -8.95e-13\npolygon 10 (hole)        3 -3.04560e-10     -4.55e-13\npolygon 11 (hole)        3 -4.46108e-10     -6.66e-13\npolygon 12 (hole)        5 -2.44408e-10     -3.65e-13\npolygon 13 (hole)        5 -3.64686e-08     -5.45e-11\npolygon 14              71  8.18750e-03      1.22e-05\npolygon 15 (hole)       38 -7.79904e-03     -1.16e-05\npolygon 16              91  1.49663e-02      2.24e-05\npolygon 17 (hole)      395 -7.38124e-03     -1.10e-05\npolygon 18              40  1.38607e-02      2.07e-05\npolygon 19 (hole)       11 -8.36705e-05     -1.25e-07\npolygon 20 (hole)        3 -2.33435e-09     -3.49e-12\npolygon 21              45  2.51218e-03      3.75e-06\npolygon 22             139  3.22293e-03      4.81e-06\npolygon 23             148  3.10395e-03      4.64e-06\npolygon 24 (hole)        4 -1.72650e-10     -2.58e-13\npolygon 25              75  1.73526e-02      2.59e-05\npolygon 26              83  5.28920e-03      7.90e-06\npolygon 27             106  3.04104e-03      4.54e-06\npolygon 28              71  5.63061e-03      8.41e-06\npolygon 29              10  1.99717e-04      2.98e-07\npolygon 30 (hole)        3 -1.37223e-08     -2.05e-11\npolygon 31 (hole)        3 -8.68789e-10     -1.30e-12\npolygon 32 (hole)        3 -3.39815e-10     -5.08e-13\npolygon 33 (hole)        3 -4.52041e-11     -6.75e-14\npolygon 34 (hole)        3 -3.90173e-11     -5.83e-14\npolygon 35 (hole)        3 -9.59845e-11     -1.43e-13\npolygon 36 (hole)        8 -4.28707e-07     -6.40e-10\npolygon 37 (hole)        4 -2.18619e-10     -3.27e-13\npolygon 38 (hole)        6 -8.37554e-07     -1.25e-09\npolygon 39 (hole)        5 -2.92235e-10     -4.36e-13\npolygon 40           14053  6.67892e+02      9.98e-01\npolygon 41 (hole)        3 -7.43616e-12     -1.11e-14\nenclosing rectangle: [2.66754, 55.94194] x [21.44847, 50.25633] km\n                     (53.27 x 28.81 km)\nWindow area = 669.517 square km\nUnit of length: 1 km\nFraction of frame area: 0.436\n\n# Simple visual check\nplot(unmark(rest_ppp_km), main = \"Restaurants (ppp, km units)\")  # base plot of points & window\n\n\n\n\n\n\n\n\nThe polygonal boundary output confirms that the study window is irregular, consisting of 41 polygons with 26 holes and a usable land area of 669.5 km², representing only 43.6% of the bounding frame. Within this space, 677 restaurants classified under SSIC 56111 are distributed, producing an average intensity of about 1.01 points per km². This indicates that density varies substantially across the region, with likely hotspots in central subzones and sparse distribution at the periphery. The presence of rich attributes and temporal fields also enables multi-dimensional analysis beyond static spatial clustering.\nThe plot shows the spatial distribution of 677 restaurants across Singapore, represented as points within the polygonal boundary. The pattern indicates clear clustering in the central and southern regions, particularly around the Downtown Core and Orchard areas, reflecting the city’s commercial and entertainment hubs. In contrast, peripheral areas such as the north and far east exhibit sparser distributions, suggesting fewer restaurant establishments relative to population or land use. This visualisation confirms spatial heterogeneity in restaurant presence, highlighting distinct hotspots of activity alongside low-density regions, and provides the foundation for subsequent kernel density estimation to quantify clustering patterns.\n\n\n9.2 Bandwidth estimation (km scale)\nThe bandwidth (\\(\\sigma\\)) controls the degree of spatial smoothing in kernel density estimation and therefore determines how finely or coarsely local clusters are represented. Choosing \\(\\sigma\\) well is essential: too small a value creates noisy, spike-like artefacts that can be mistaken for meaningful hotspots; too large a value can blur important local variation and hide genuine clusters. In this study, the working unit is kilometers, so all bandwidths are reported and interpreted in km. We first obtain a data-driven σ using Diggle’s cross-validation approach, which balances bias and variance without manual tuning. We then compute three commonly used alternatives—CvL (Cronie–van Lieshout), Scott’s rule, and PPL (profile likelihood)—to understand the sensitivity of our analysis to bandwidth choice. Reporting several selectors is good practice for transparency, but in the next subsection we will use the Diggle value as the principal \\(\\sigma\\) and compare it with a fixed \\(\\sigma\\) (0.6 km) and an adaptive method.\n\n# Input: 'rest_ppp_km' created in previous section (a ppp with units = km)\n\n# 1) Diggle’s cross-validation bandwidth (primary choice)\nbw_diggle &lt;- bw.diggle(rest_ppp_km)   # returns a numeric σ in km based on CV\nbw_diggle                             # print the value for the report\n\n      sigma \n0.007046933 \n\n# 2) Alternative automatic selectors (for sensitivity checks)\nbw_cvl   &lt;- bw.CvL(rest_ppp_km)       # Cronie–van Lieshout selector (km)\nbw_scott &lt;- bw.scott(rest_ppp_km)     # Scott’s rule-of-thumb (can return σ.x, σ.y)\nbw_ppl   &lt;- bw.ppl(rest_ppp_km)       # Profile likelihood selector (km)\n\n# 3) Inspect and store the values we plan to cite in the narrative\nbw_cvl\n\n   sigma \n6.128772 \n\nbw_scott\n\n sigma.x  sigma.y \n1.983023 1.640206 \n\nbw_ppl\n\n    sigma \n0.5112102 \n\n# 4) Keep a small named list for later reference in tables/plots\nbw_all_km &lt;- list(\n  diggle = bw_diggle,                 # preferred data-driven σ (km)\n  cvl    = bw_cvl,                    # alternative CV-based σ (km)\n  scott  = bw_scott,                  # rule-of-thumb σ (km) — may be vector\n  ppl    = bw_ppl                     # profile likelihood σ (km)\n)\n\nIn estimating the bandwidth for kernel density analysis, several selectors were applied and the results highlight how different methods lead to very different levels of smoothing. Diggle’s cross-validation returns a bandwidth of only 0.007 km, which corresponds to roughly seven meters and produces an extremely fine-grained surface. This reveals very localised clusters of restaurants, but at the cost of generating a noisy density surface that may exaggerate small-scale variations. At the other extreme, the Cronie–van Lieshout selector produces a much broader bandwidth of 6.13 km. This choice smooths over local differences and emphasises regional-scale patterns, making it suitable for visualising city-wide concentration trends but less effective in highlighting specific hotspots. Scott’s rule-of-thumb suggests anisotropic values of 1.98 km in the x-direction and 1.64 km in the y-direction, offering a moderate compromise between local and regional smoothing while also accounting for directional variation in the spatial spread. The profile likelihood approach yields a bandwidth of 0.51 km, representing an intermediate scale that is wide enough to avoid the noise of Diggle’s estimate while still being narrow enough to capture meaningful neighbourhood-level clusters.\nTaken together, these results underline the importance of bandwidth choice in kernel density estimation. A smaller bandwidth such as Diggle’s is appropriate when the research goal is to highlight fine-scale clustering, for instance identifying concentrations along individual streets or blocks. A larger bandwidth such as the Cronie–van Lieshout estimate is better suited for planning-level analysis where broad geographic patterns matter more than local detail. The profile likelihood and Scott’s estimates occupy a middle ground, offering balanced perspectives that reveal neighbourhood-scale concentrations and directional trends. For this study, it is therefore useful to report and compare multiple bandwidths, as the contrasting values demonstrate how sensitive density surfaces are to the smoothing parameter and ensure that both micro- and macro-level insights can be drawn for interpretation and planning purposes.\n\n\n9.3 KDE with alternative bandwidth strategies (all outputs in km²)\nWith the point pattern rescaled to kilometers and bandwidth values estimated, we now generate kernel KDE of restaurant intensity. KDE provides a smooth surface of expected events per \\(km^2\\) by centring a kernel function over each observed point. Three approaches are used to reflect different assumptions about spatial structure: Diggle’s bandwidth, a data-driven estimate derived from cross-validation; a fixed bandwidth of 0.6 km, chosen to represent a neighbourhood-scale radius consistent with urban walking distances; and an adaptive bandwidth, which adjusts the kernel size depending on local point density. The Gaussian kernel with edge correction is used throughout to ensure smoothness and reduce boundary bias. Comparing these three approaches allows us to evaluate whether clustering patterns are robust across parameterisations or sensitive to smoothing assumptions. This not only enhances methodological transparency but also provides practical insight into the scale at which clustering is most relevant for urban planning and decision-making.\n\n# Input: 'rest_ppp_km' (restaurants point pattern, km units)\n#        'bw_diggle'   (Diggle bandwidth estimated in km, Section 9.2)\n\n# 1) KDE using Diggle’s automatic bandwidth (Gaussian, edge corrected)\nkde_rest_diggle &lt;- density(\n  rest_ppp_km,          # point pattern of restaurants (km)\n  sigma  = bw_diggle,   # data-driven bandwidth (km)\n  edge   = TRUE,        # apply edge correction\n  kernel = \"gaussian\"   # Gaussian kernel function\n)\n\n# 2) KDE using a fixed bandwidth of 0.6 km\nsigma_fixed &lt;- 0.6      # fixed kernel radius, interpretable as 600 m\nkde_rest_fixed &lt;- density(\n  rest_ppp_km,\n  sigma  = sigma_fixed, # fixed bandwidth (km)\n  edge   = TRUE,        # apply edge correction\n  kernel = \"gaussian\"\n)\n\n# 3) Adaptive KDE — kernel radius varies with local density\nkde_rest_adapt &lt;- adaptive.density(\n  rest_ppp_km,          # point pattern (km)\n  method = \"kernel\"     # kernel-based adaptive density estimation\n)\n\n# 4) Convert spatstat image (im) outputs to SpatRaster for mapping/export later\nkde_rest_diggle_rast &lt;- terra::rast(kde_rest_diggle)\nkde_rest_fixed_rast  &lt;- terra::rast(kde_rest_fixed)\nkde_rest_adapt_rast  &lt;- terra::rast(kde_rest_adapt)\n\n# 5) Quick checks (optional) to confirm results are not empty\nsummary(kde_rest_diggle)   # range of intensities (restaurants per km²)\n\nreal-valued pixel image\n128 x 128 pixel array (ny, nx)\nenclosing rectangle: [2.667538, 55.94194] x [21.44847, 50.25633] km\ndimensions of each pixel: 0.416 x 0.2250614 km\nImage is defined on a subset of the rectangular grid\nSubset area = 669.941961122495 square km\nSubset area fraction = 0.437\nPixel values (inside window):\n    range = [-2.658836e-14, 160.1333]\n    integral = 677\n    mean = 1.010535\n\nsummary(kde_rest_fixed)    # check smoothing behaviour\n\nreal-valued pixel image\n128 x 128 pixel array (ny, nx)\nenclosing rectangle: [2.667538, 55.94194] x [21.44847, 50.25633] km\ndimensions of each pixel: 0.416 x 0.2250614 km\nImage is defined on a subset of the rectangular grid\nSubset area = 669.941961122495 square km\nSubset area fraction = 0.437\nPixel values (inside window):\n    range = [-1.166097e-15, 28.26159]\n    integral = 681.697\n    mean = 1.017546\n\nsummary(kde_rest_adapt)    # confirm adaptive surface has variation\n\nreal-valued pixel image\n128 x 128 pixel array (ny, nx)\nenclosing rectangle: [2.667538, 55.94194] x [21.44847, 50.25633] units\ndimensions of each pixel: 0.416 x 0.2250614 units\nImage is defined on a subset of the rectangular grid\nSubset area = 669.941961122495 square units\nSubset area fraction = 0.437\nPixel values (inside window):\n    range = [-5.129733e-16, 59.02006]\n    integral = 680.3572\n    mean = 1.015546\n\n\nThe KDE outputs summarise the smooth intensity of restaurant locations across Singapore using different bandwidth strategies. Diggle’s cross-validated bandwidth produces a very fine-scale surface, resulting in highly localised peaks that capture micro-clusters but risk noise amplification. The fixed bandwidth of 0.6 km generates a more interpretable density surface at the neighbourhood scale, approximating walking distances and highlighting urban clusters in a practical manner. The adaptive bandwidth adjusts kernel size based on point intensity, offering a balanced representation that smooths sparse regions while preserving detail in dense cores. Together, these approaches illustrate how bandwidth choice determines whether clustering is interpreted at micro, meso, or macro scales.\n\n\n9.4 Assigning projection to KDE rasters\nThe kernel surfaces we created are im objects that were converted to SpatRaster so they can be plotted with raster tools and combined with vector layers. However, these raster objects do not carry a CRS by default. Without an explicit projection, the maps could still render but would not align reliably with other layers (e.g., planning subzones) or export with proper spatial metadata. To make the density rasters interoperable with the rest of the report, we attach the Singapore Transverse Mercator (SVY21) projection, EPSG:3414, directly to each KDE raster. This mirrors the exact practice used elsewhere in the report: vectors already live in EPSG:3414; we simply declare the same CRS on the KDE rasters so overlays and cartographic elements (graticules, compass, scale) behave as expected. No reprojection or resampling is performed here — only CRS assignment — so the numeric values of the density estimates remain unchanged.\n\n# Input from §9.4: KDE rasters created via terra::rast(...)\n#   kde_rest_diggle_rast\n#   kde_rest_fixed_rast\n#   kde_rest_adapt_rast\n\n# 1) Fetch the authoritative EPSG:3414 definition from the study polygons\ncrs_wkt &lt;- sf::st_crs(mpsz_clean)$wkt    # SVY21 / Singapore TM (EPSG:3414)\n\n# 2) Assign this CRS to each KDE raster (declaration only; no reprojection)\nterra::crs(kde_rest_diggle_rast) &lt;- crs_wkt   # set CRS on Diggle raster\nterra::crs(kde_rest_fixed_rast)  &lt;- crs_wkt   # set CRS on fixed-σ raster\nterra::crs(kde_rest_adapt_rast)  &lt;- crs_wkt   # set CRS on adaptive raster\n\n# 3) Quick confirmation (prints the SVY21 definition)\nterra::crs(kde_rest_diggle_rast)\n\n[1] \"PROJCRS[\\\"SVY21 / Singapore TM\\\",\\n    BASEGEOGCRS[\\\"SVY21\\\",\\n        DATUM[\\\"SVY21\\\",\\n            ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n                LENGTHUNIT[\\\"metre\\\",1]]],\\n        PRIMEM[\\\"Greenwich\\\",0,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        ID[\\\"EPSG\\\",4757]],\\n    CONVERSION[\\\"Singapore Transverse Mercator\\\",\\n        METHOD[\\\"Transverse Mercator\\\",\\n            ID[\\\"EPSG\\\",9807]],\\n        PARAMETER[\\\"Latitude of natural origin\\\",1.36666666666667,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8801]],\\n        PARAMETER[\\\"Longitude of natural origin\\\",103.833333333333,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8802]],\\n        PARAMETER[\\\"Scale factor at natural origin\\\",1,\\n            SCALEUNIT[\\\"unity\\\",1],\\n            ID[\\\"EPSG\\\",8805]],\\n        PARAMETER[\\\"False easting\\\",28001.642,\\n            LENGTHUNIT[\\\"metre\\\",1],\\n            ID[\\\"EPSG\\\",8806]],\\n        PARAMETER[\\\"False northing\\\",38744.572,\\n            LENGTHUNIT[\\\"metre\\\",1],\\n            ID[\\\"EPSG\\\",8807]]],\\n    CS[Cartesian,2],\\n        AXIS[\\\"northing (N)\\\",north,\\n            ORDER[1],\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        AXIS[\\\"easting (E)\\\",east,\\n            ORDER[2],\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n    USAGE[\\n        SCOPE[\\\"Cadastre, engineering survey, topographic mapping.\\\"],\\n        AREA[\\\"Singapore - onshore and offshore.\\\"],\\n        BBOX[1.13,103.59,1.47,104.07]],\\n    ID[\\\"EPSG\\\",3414]]\"\n\nterra::crs(kde_rest_fixed_rast)\n\n[1] \"PROJCRS[\\\"SVY21 / Singapore TM\\\",\\n    BASEGEOGCRS[\\\"SVY21\\\",\\n        DATUM[\\\"SVY21\\\",\\n            ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n                LENGTHUNIT[\\\"metre\\\",1]]],\\n        PRIMEM[\\\"Greenwich\\\",0,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        ID[\\\"EPSG\\\",4757]],\\n    CONVERSION[\\\"Singapore Transverse Mercator\\\",\\n        METHOD[\\\"Transverse Mercator\\\",\\n            ID[\\\"EPSG\\\",9807]],\\n        PARAMETER[\\\"Latitude of natural origin\\\",1.36666666666667,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8801]],\\n        PARAMETER[\\\"Longitude of natural origin\\\",103.833333333333,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8802]],\\n        PARAMETER[\\\"Scale factor at natural origin\\\",1,\\n            SCALEUNIT[\\\"unity\\\",1],\\n            ID[\\\"EPSG\\\",8805]],\\n        PARAMETER[\\\"False easting\\\",28001.642,\\n            LENGTHUNIT[\\\"metre\\\",1],\\n            ID[\\\"EPSG\\\",8806]],\\n        PARAMETER[\\\"False northing\\\",38744.572,\\n            LENGTHUNIT[\\\"metre\\\",1],\\n            ID[\\\"EPSG\\\",8807]]],\\n    CS[Cartesian,2],\\n        AXIS[\\\"northing (N)\\\",north,\\n            ORDER[1],\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        AXIS[\\\"easting (E)\\\",east,\\n            ORDER[2],\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n    USAGE[\\n        SCOPE[\\\"Cadastre, engineering survey, topographic mapping.\\\"],\\n        AREA[\\\"Singapore - onshore and offshore.\\\"],\\n        BBOX[1.13,103.59,1.47,104.07]],\\n    ID[\\\"EPSG\\\",3414]]\"\n\nterra::crs(kde_rest_adapt_rast)\n\n[1] \"PROJCRS[\\\"SVY21 / Singapore TM\\\",\\n    BASEGEOGCRS[\\\"SVY21\\\",\\n        DATUM[\\\"SVY21\\\",\\n            ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n                LENGTHUNIT[\\\"metre\\\",1]]],\\n        PRIMEM[\\\"Greenwich\\\",0,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        ID[\\\"EPSG\\\",4757]],\\n    CONVERSION[\\\"Singapore Transverse Mercator\\\",\\n        METHOD[\\\"Transverse Mercator\\\",\\n            ID[\\\"EPSG\\\",9807]],\\n        PARAMETER[\\\"Latitude of natural origin\\\",1.36666666666667,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8801]],\\n        PARAMETER[\\\"Longitude of natural origin\\\",103.833333333333,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8802]],\\n        PARAMETER[\\\"Scale factor at natural origin\\\",1,\\n            SCALEUNIT[\\\"unity\\\",1],\\n            ID[\\\"EPSG\\\",8805]],\\n        PARAMETER[\\\"False easting\\\",28001.642,\\n            LENGTHUNIT[\\\"metre\\\",1],\\n            ID[\\\"EPSG\\\",8806]],\\n        PARAMETER[\\\"False northing\\\",38744.572,\\n            LENGTHUNIT[\\\"metre\\\",1],\\n            ID[\\\"EPSG\\\",8807]]],\\n    CS[Cartesian,2],\\n        AXIS[\\\"northing (N)\\\",north,\\n            ORDER[1],\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        AXIS[\\\"easting (E)\\\",east,\\n            ORDER[2],\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n    USAGE[\\n        SCOPE[\\\"Cadastre, engineering survey, topographic mapping.\\\"],\\n        AREA[\\\"Singapore - onshore and offshore.\\\"],\\n        BBOX[1.13,103.59,1.47,104.07]],\\n    ID[\\\"EPSG\\\",3414]]\"\n\n\nThe output confirms that the kernel density raster layers produced earlier did not automatically carry a coordinate reference system (CRS). To ensure proper alignment with Singapore’s planning boundaries and other spatial layers, the SVY21 / Singapore Transverse Mercator (EPSG:3414) projection is explicitly assigned to each raster. This step does not resample or modify density values but simply attaches the correct spatial metadata so overlays, graticules, and scale bars behave as expected. The insight here is that assigning the CRS guarantees interoperability across maps, enabling accurate visualisation, integration with vector data, and reliable interpretation for urban planning analysis.\n\n\n9.5 Plotting KDE rasters with tmap\nIn this section, we will render each KDE surface as a cartographic map using the exact idiom shown earlier: tm_shape(&lt;SpatRaster&gt;) + tm_raster(col.scale = tm_scale_continuous(values=\"viridis\"), col.legend = tm_legend(...)), then subzone borders, graticules, a north arrow, and a simple layout. The objective is to visually verify that (1) each raster carries EPSG:3414 (set earlier) and overlays correctly with the subzones, and (2) the legend and decorations match the example. No manual class breaks are introduced; we keep a continuous viridis scale and a legend box at right–bottom with a semi-transparent white background. Three maps are produced which are automatic (Diggle \\(\\sigma\\)), fixed \\(\\sigma\\) (0.6 km), and adaptive. These enable us to confirm the outputs line up with expectations and are ready for interpretation.\n\n# 0) Load tmap and switch to static plotting mode (required for tm_* functions)\nlibrary(tmap)                                         # provide tm_shape, tm_raster, etc.\ntmap_mode(\"plot\")                                     # static (non-interactive) plots\n\n# 1) Helper to build a map in the house style shown in the notes\nbuild_kde_map &lt;- function(rast, title_text) {\n  tm_shape(rast) +                                    # KDE SpatRaster (has EPSG:3414)\n    tm_raster(\n      col.scale  = tm_scale_continuous(values = \"viridis\"), # continuous viridis scale\n      col.legend = tm_legend(                         # legend box settings as in screenshots\n        title      = \"Density values\",                # legend title\n        title.size = 0.7,                             # title font size\n        text.size  = 0.7,                             # tick labels font size\n        bg.color   = \"white\",                         # white legend background\n        bg.alpha   = 0.7,                             # semi-transparent background\n        position   = tm_pos_in(\"right\", \"bottom\"),    # place legend at right–bottom\n        frame      = TRUE                             # thin frame around legend\n      )\n    ) +\n    tm_shape(mpsz_clean) +                            # overlay subzone boundaries\n    tm_borders(col = \"grey30\", lwd = 0.4) +           # thin grey borders\n    tm_graticules(labels.size = 0.7) +                # graticules with labels\n    tm_compass() +                                    # north arrow\n    tm_layout(title = title_text, \n              title.position=c(\"center\", \"bottom\"),\n              scale = 1.0\n              )        # title + 1.0 scale (as shown)\n}\n\n# 2) Build the three maps (inputs were created in §9.4 and given a CRS in §9.5)\nmap_kde_diggle &lt;- build_kde_map(kde_rest_diggle_rast, \"KDE (Diggle σ) — Restaurants\")\nmap_kde_fixed  &lt;- build_kde_map(kde_rest_fixed_rast,  \"KDE (Fixed σ = 0.6 km) — Restaurants\")\nmap_kde_adapt  &lt;- build_kde_map(kde_rest_adapt_rast,  \"KDE (Adaptive) — Restaurants\")\n\n# 3) Print the maps (one after another)\nmap_kde_diggle\n\n\n\n\n\n\n\nmap_kde_fixed\n\n\n\n\n\n\n\nmap_kde_adapt\n\n\n\n\n\n\n\n\nThe three KDE variants provide distinct perspectives on the spatial distribution of restaurants. Adaptive KDE highlights localized hotspots by adjusting the bandwidth to point density, thereby capturing both dense clusters and sparse areas with appropriate resolution. In contrast, Fixed KDE applies a constant bandwidth across the study area, producing a smoother and more generalized surface that is useful for regional-level comparisons but less sensitive to local variation. Diggle’s bandwidth method emphasizes very fine-grained patterns, which can be valuable for micro-scale exploration, though it often exaggerates noise and yields fragmented results.\nFor this exercise, we adopt the Adaptive KDE approach, as it strikes a balance between local detail and overall interpretability, making it well suited for planning, policy, and spatial decision-making in the Singapore context. Nonetheless, KDE is sensitive to bandwidth choice and scale dependency, and it does not account for underlying population or land-use factors. These limitations must be considered when interpreting the identified hotspots.\n\n\n9.6 First-order Spatial Point Pattern Analysis (SPPA) at the Planning Subzone Level\nThis section applies First Order SPPA to assess how the distribution of restaurant locations varies across Singapore’s planning subzones. Unlike kernel density estimation at the continuous surface level, the subzone-based approach aggregates point counts into administrative boundaries, enabling direct comparison of spatial intensity relative to area size and population density. This allows us to identify subzones with unusually high or low restaurant concentrations, detect clustering patterns at a policy-relevant scale, and provide insights for urban planning and commercial decision-making.\n\n9.6.1 Geospatial data wrangling\nWe will prepare four contrasted study areas so the subsequent first-order analyses (intensity mapping via KDE) are meaningful and comparable across different urban contexts. The choice is deliberate: (1) Downtown/Central retail core (extremely high restaurant intensity), (2) a mature regional centre in the East, (3) a large heartland town in the West, and (4) a newer North-East town. Together they cover distinct development histories, land-use mixes, and day–night populations, which strongly influence restaurant locations. Working at the planning-area/subzone scale also reduces boundary bias for local analyses while keeping results policy-relevant (these are common planning units). In what follows, we: extract the four planning areas, convert them to owin study windows required by spatstat, clip the Singapore-wide restaurant ppp to each window (defensive check), and rescale to kilometers (single canonical unit). These km-scaled point patterns become the inputs for KDE and any other first-order statistics i,kn the next subsections.\n\n# 1) Extract FOUR planning areas by name (edit names if our dataset differs) -----\npa_punggol   &lt;- dplyr::filter(mpsz_clean, PLN_AREA_N == \"PUNGGOL\")       # Punggol polygon(s)\npa_tampines  &lt;- dplyr::filter(mpsz_clean, PLN_AREA_N == \"TAMPINES\")      # Tampines polygon(s)\npa_orchard  &lt;- dplyr::filter(mpsz_clean, PLN_AREA_N == \"ORCHARD\")        # Orchard polygon(s)\npa_jurongw   &lt;- dplyr::filter(mpsz_clean, PLN_AREA_N == \"JURONG WEST\")   # Jurong West polygon(s)\n\n# 2) Convert each planning area polygon to a spatstat observation window (owin) --\nowin_punggol  &lt;- spatstat.geom::as.owin(pa_punggol)    # owin used for clipping & SPPA\nowin_tampines &lt;- spatstat.geom::as.owin(pa_tampines)   # owin for Tampines\nowin_orchard &lt;- spatstat.geom::as.owin(pa_orchard)     # owin for Orchard\nowin_jurongw  &lt;- spatstat.geom::as.owin(pa_jurongw)    # owin for Jurong West\n\n# 3) Clip the restaurants point pattern (meters) to each area's owin -------------\nrest_ppp_punggol_m  &lt;- rest_ppp[owin_punggol]          # keep only restaurants inside Punggol\nrest_ppp_tampines_m &lt;- rest_ppp[owin_tampines]         # keep only restaurants inside Tampines\nrest_ppp_orchard_m &lt;- rest_ppp[owin_orchard]           # keep only restaurants inside Orchard\nrest_ppp_jurongw_m  &lt;- rest_ppp[owin_jurongw]          # keep only restaurants inside Jurong West\n\n# 4) Rescale EACH clipped ppp from meters to kilometers (single canonical call) ---\nrest_ppp_punggol_km  &lt;- rescale.ppp(rest_ppp_punggol_m,  1000, \"km\")  # m → km for Punggol\nrest_ppp_tampines_km &lt;- rescale.ppp(rest_ppp_tampines_m, 1000, \"km\")  # m → km for Tampines\nrest_ppp_orchard_km &lt;- rescale.ppp(rest_ppp_orchard_m, 1000, \"km\")  # m → km for Orchard\nrest_ppp_jurongw_km  &lt;- rescale.ppp(rest_ppp_jurongw_m,  1000, \"km\")  # m → km for Jurong West\n\n# 5) Quick visual sanity check (optional) ----------------------------------------\n# par(mfrow = c(2,2))                                            # 2-by-2 panel layout\nplot(unmark(rest_ppp_orchard_km), main = \"Orchard (km)\")       # plot points within boundary (km)\n\n\n\n\n\n\n\nplot(unmark(rest_ppp_jurongw_km),  main = \"Jurong West (km)\")\n\n\n\n\n\n\n\nplot(unmark(rest_ppp_tampines_km), main = \"Tampines (km)\")  \n\n\n\n\n\n\n\nplot(unmark(rest_ppp_punggol_km),  main = \"Punggol (km)\") \n\n\n\n\n\n\n\npar(mfrow = c(1,1))                                         # reset layout\n\n# 6) Defensive checks on objects & units before tests/KDE -------------------------\nstopifnot(spatstat.geom::is.ppp(rest_ppp_punggol_km))   # confirm valid ppp in km\nstopifnot(spatstat.geom::is.ppp(rest_ppp_tampines_km))  # confirm valid ppp in km\nstopifnot(spatstat.geom::is.ppp(rest_ppp_orchard_km))  # confirm valid ppp in km\nstopifnot(spatstat.geom::is.ppp(rest_ppp_jurongw_km))   # confirm valid ppp in km\n\n# Inspect counts & windows to ensure clipping behaved as expected ------\nsummary(rest_ppp_orchard_km); summary(rest_ppp_jurongw_km)\n\nMarked planar point pattern:  25 points\nAverage intensity 26.10897 points per square km\n\nCoordinates are given to 14 decimal places\n\nMark variables: uen, issuance_agency_id, entity_name, entity_type_description, \nbusiness_constitution_description, company_type_description, \npaf_constitution_description, entity_status_description, date, uen_issue_date, \naddress_type, block, street_name, level_no, unit_no, building_name, \npostal_code, other_address_line1, other_address_line2, account_due_date, \nannual_return_date, primary_ssic_code, primary_ssic_description, \nprimary_user_described_activity, YEAR, MONTH_NUM, MONTH_ABBR, SEARCHVAL, \nBLK_NO, ROAD_NAME, BUILDING, ADDRESS, LATITUDE, LONGITUDE\nSummary:\n     uen            issuance_agency_id entity_name       \n Length:25          Length:25          Length:25         \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n entity_type_description business_constitution_description\n Length:25               Length:25                        \n Class :character        Class :character                 \n Mode  :character        Mode  :character                 \n                                                          \n                                                          \n                                                          \n                                                          \n company_type_description paf_constitution_description\n Length:25                Length:25                   \n Class :character         Class :character            \n Mode  :character         Mode  :character            \n                                                      \n                                                      \n                                                      \n                                                      \n entity_status_description      date            uen_issue_date      \n Length:25                 Min.   :2025-01-14   Min.   :2025-01-14  \n Class :character          1st Qu.:2025-02-18   1st Qu.:2025-02-18  \n Mode  :character          Median :2025-03-24   Median :2025-04-01  \n                           Mean   :2025-04-11   Mean   :2025-04-12  \n                           3rd Qu.:2025-06-23   3rd Qu.:2025-06-23  \n                           Max.   :2025-07-25   Max.   :2025-07-25  \n                                                                    \n address_type          block           street_name          level_no        \n Length:25          Length:25          Length:25          Length:25         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n   unit_no          building_name      postal_code        other_address_line1\n Length:25          Length:25          Length:25          Length:25          \n Class :character   Class :character   Class :character   Class :character   \n Mode  :character   Mode  :character   Mode  :character   Mode  :character   \n                                                                             \n                                                                             \n                                                                             \n                                                                             \n other_address_line2 account_due_date   annual_return_date primary_ssic_code\n Length:25           Length:25          Length:25          Min.   :56111    \n Class :character    Class :character   Class :character   1st Qu.:56111    \n Mode  :character    Mode  :character   Mode  :character   Median :56111    \n                                                           Mean   :56111    \n                                                           3rd Qu.:56111    \n                                                           Max.   :56111    \n                                                                            \n primary_ssic_description primary_user_described_activity      YEAR     \n Length:25                Length:25                       Min.   :2025  \n Class :character         Class :character                1st Qu.:2025  \n Mode  :character         Mode  :character                Median :2025  \n                                                          Mean   :2025  \n                                                          3rd Qu.:2025  \n                                                          Max.   :2025  \n                                                                        \n   MONTH_NUM      MONTH_ABBR  SEARCHVAL            BLK_NO         \n Min.   :1.00   Feb    :6    Length:25          Length:25         \n 1st Qu.:2.00   Mar    :4    Class :character   Class :character  \n Median :3.00   Jun    :4    Mode  :character   Mode  :character  \n Mean   :3.88   Jul    :4                                         \n 3rd Qu.:6.00   Jan    :3                                         \n Max.   :7.00   Apr    :2                                         \n                (Other):2                                         \n  ROAD_NAME           BUILDING           ADDRESS            LATITUDE        \n Length:25          Length:25          Length:25          Length:25         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  LONGITUDE        \n Length:25         \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\nWindow: polygonal boundary\nsingle connected closed polygon with 587 vertices\nenclosing rectangle: [26.814238, 29.102403] x [31.17827, 32.45574] km\n                     (2.288 x 1.277 km)\nWindow area = 0.957525 square km\nUnit of length: 1 km\nFraction of frame area: 0.328\n\n\nMarked planar point pattern:  17 points\nAverage intensity 1.157996 points per square km\n\nCoordinates are given to 14 decimal places\n\nMark variables: uen, issuance_agency_id, entity_name, entity_type_description, \nbusiness_constitution_description, company_type_description, \npaf_constitution_description, entity_status_description, date, uen_issue_date, \naddress_type, block, street_name, level_no, unit_no, building_name, \npostal_code, other_address_line1, other_address_line2, account_due_date, \nannual_return_date, primary_ssic_code, primary_ssic_description, \nprimary_user_described_activity, YEAR, MONTH_NUM, MONTH_ABBR, SEARCHVAL, \nBLK_NO, ROAD_NAME, BUILDING, ADDRESS, LATITUDE, LONGITUDE\nSummary:\n     uen            issuance_agency_id entity_name       \n Length:17          Length:17          Length:17         \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n entity_type_description business_constitution_description\n Length:17               Length:17                        \n Class :character        Class :character                 \n Mode  :character        Mode  :character                 \n                                                          \n                                                          \n                                                          \n                                                          \n company_type_description paf_constitution_description\n Length:17                Length:17                   \n Class :character         Class :character            \n Mode  :character         Mode  :character            \n                                                      \n                                                      \n                                                      \n                                                      \n entity_status_description      date            uen_issue_date      \n Length:17                 Min.   :2025-01-08   Min.   :2025-01-08  \n Class :character          1st Qu.:2025-02-17   1st Qu.:2025-02-17  \n Mode  :character          Median :2025-04-12   Median :2025-04-12  \n                           Mean   :2025-04-19   Mean   :2025-04-19  \n                           3rd Qu.:2025-06-11   3rd Qu.:2025-06-11  \n                           Max.   :2025-07-31   Max.   :2025-07-31  \n                                                                    \n address_type          block           street_name          level_no        \n Length:17          Length:17          Length:17          Length:17         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n   unit_no          building_name      postal_code        other_address_line1\n Length:17          Length:17          Length:17          Length:17          \n Class :character   Class :character   Class :character   Class :character   \n Mode  :character   Mode  :character   Mode  :character   Mode  :character   \n                                                                             \n                                                                             \n                                                                             \n                                                                             \n other_address_line2 account_due_date   annual_return_date primary_ssic_code\n Length:17           Length:17          Length:17          Min.   :56111    \n Class :character    Class :character   Class :character   1st Qu.:56111    \n Mode  :character    Mode  :character   Mode  :character   Median :56111    \n                                                           Mean   :56111    \n                                                           3rd Qu.:56111    \n                                                           Max.   :56111    \n                                                                            \n primary_ssic_description primary_user_described_activity      YEAR     \n Length:17                Length:17                       Min.   :2025  \n Class :character         Class :character                1st Qu.:2025  \n Mode  :character         Mode  :character                Median :2025  \n                                                          Mean   :2025  \n                                                          3rd Qu.:2025  \n                                                          Max.   :2025  \n                                                                        \n   MONTH_NUM       MONTH_ABBR  SEARCHVAL            BLK_NO         \n Min.   :1.000   Feb    :4    Length:17          Length:17         \n 1st Qu.:2.000   Jul    :4    Class :character   Class :character  \n Median :4.000   Jan    :2    Mode  :character   Mode  :character  \n Mean   :4.176   Apr    :2                                         \n 3rd Qu.:6.000   May    :2                                         \n Max.   :7.000   Jun    :2                                         \n                 (Other):1                                         \n  ROAD_NAME           BUILDING           ADDRESS            LATITUDE        \n Length:17          Length:17          Length:17          Length:17         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  LONGITUDE        \n Length:17         \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\nWindow: polygonal boundary\nsingle connected closed polygon with 356 vertices\nenclosing rectangle: [10.373179, 16.297184] x [33.9815, 38.48861] km\n                     (5.924 x 4.507 km)\nWindow area = 14.6805 square km\nUnit of length: 1 km\nFraction of frame area: 0.55\n\nsummary(rest_ppp_punggol_km); summary(rest_ppp_tampines_km)\n\nMarked planar point pattern:  5 points\nAverage intensity 0.5333744 points per square km\n\nCoordinates are given to 14 decimal places\n\nMark variables: uen, issuance_agency_id, entity_name, entity_type_description, \nbusiness_constitution_description, company_type_description, \npaf_constitution_description, entity_status_description, date, uen_issue_date, \naddress_type, block, street_name, level_no, unit_no, building_name, \npostal_code, other_address_line1, other_address_line2, account_due_date, \nannual_return_date, primary_ssic_code, primary_ssic_description, \nprimary_user_described_activity, YEAR, MONTH_NUM, MONTH_ABBR, SEARCHVAL, \nBLK_NO, ROAD_NAME, BUILDING, ADDRESS, LATITUDE, LONGITUDE\nSummary:\n     uen            issuance_agency_id entity_name       \n Length:5           Length:5           Length:5          \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n entity_type_description business_constitution_description\n Length:5                Length:5                         \n Class :character        Class :character                 \n Mode  :character        Mode  :character                 \n                                                          \n                                                          \n                                                          \n                                                          \n company_type_description paf_constitution_description\n Length:5                 Length:5                    \n Class :character         Class :character            \n Mode  :character         Mode  :character            \n                                                      \n                                                      \n                                                      \n                                                      \n entity_status_description      date            uen_issue_date      \n Length:5                  Min.   :2025-01-22   Min.   :2025-01-22  \n Class :character          1st Qu.:2025-01-27   1st Qu.:2025-01-27  \n Mode  :character          Median :2025-03-14   Median :2025-03-14  \n                           Mean   :2025-03-13   Mean   :2025-03-14  \n                           3rd Qu.:2025-03-20   3rd Qu.:2025-03-25  \n                           Max.   :2025-06-09   Max.   :2025-06-09  \n                                                                    \n address_type          block           street_name          level_no        \n Length:5           Length:5           Length:5           Length:5          \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n   unit_no          building_name      postal_code        other_address_line1\n Length:5           Length:5           Length:5           Length:5           \n Class :character   Class :character   Class :character   Class :character   \n Mode  :character   Mode  :character   Mode  :character   Mode  :character   \n                                                                             \n                                                                             \n                                                                             \n                                                                             \n other_address_line2 account_due_date   annual_return_date primary_ssic_code\n Length:5            Length:5           Length:5           Min.   :56111    \n Class :character    Class :character   Class :character   1st Qu.:56111    \n Mode  :character    Mode  :character   Mode  :character   Median :56111    \n                                                           Mean   :56111    \n                                                           3rd Qu.:56111    \n                                                           Max.   :56111    \n                                                                            \n primary_ssic_description primary_user_described_activity      YEAR     \n Length:5                 Length:5                        Min.   :2025  \n Class :character         Class :character                1st Qu.:2025  \n Mode  :character         Mode  :character                Median :2025  \n                                                          Mean   :2025  \n                                                          3rd Qu.:2025  \n                                                          Max.   :2025  \n                                                                        \n   MONTH_NUM     MONTH_ABBR  SEARCHVAL            BLK_NO         \n Min.   :1.0   Jan    :2    Length:5           Length:5          \n 1st Qu.:1.0   Mar    :2    Class :character   Class :character  \n Median :3.0   Jun    :1    Mode  :character   Mode  :character  \n Mean   :2.8   Feb    :0                                         \n 3rd Qu.:3.0   Apr    :0                                         \n Max.   :6.0   May    :0                                         \n               (Other):0                                         \n  ROAD_NAME           BUILDING           ADDRESS            LATITUDE        \n Length:5           Length:5           Length:5           Length:5          \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  LONGITUDE        \n Length:5          \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\nWindow: polygonal boundary\nsingle connected closed polygon with 639 vertices\nenclosing rectangle: [33.95259, 38.88996] x [40.87437, 44.80879] km\n                     (4.937 x 3.934 km)\nWindow area = 9.37428 square km\nUnit of length: 1 km\nFraction of frame area: 0.483\n\n\nMarked planar point pattern:  15 points\nAverage intensity 0.7213124 points per square km\n\nCoordinates are given to 14 decimal places\n\nMark variables: uen, issuance_agency_id, entity_name, entity_type_description, \nbusiness_constitution_description, company_type_description, \npaf_constitution_description, entity_status_description, date, uen_issue_date, \naddress_type, block, street_name, level_no, unit_no, building_name, \npostal_code, other_address_line1, other_address_line2, account_due_date, \nannual_return_date, primary_ssic_code, primary_ssic_description, \nprimary_user_described_activity, YEAR, MONTH_NUM, MONTH_ABBR, SEARCHVAL, \nBLK_NO, ROAD_NAME, BUILDING, ADDRESS, LATITUDE, LONGITUDE\nSummary:\n     uen            issuance_agency_id entity_name       \n Length:15          Length:15          Length:15         \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n entity_type_description business_constitution_description\n Length:15               Length:15                        \n Class :character        Class :character                 \n Mode  :character        Mode  :character                 \n                                                          \n                                                          \n                                                          \n                                                          \n company_type_description paf_constitution_description\n Length:15                Length:15                   \n Class :character         Class :character            \n Mode  :character         Mode  :character            \n                                                      \n                                                      \n                                                      \n                                                      \n entity_status_description      date            uen_issue_date      \n Length:15                 Min.   :2025-01-16   Min.   :2025-01-16  \n Class :character          1st Qu.:2025-03-09   1st Qu.:2025-03-09  \n Mode  :character          Median :2025-05-10   Median :2025-05-10  \n                           Mean   :2025-04-21   Mean   :2025-04-21  \n                           3rd Qu.:2025-05-31   3rd Qu.:2025-05-31  \n                           Max.   :2025-07-14   Max.   :2025-07-14  \n                                                                    \n address_type          block           street_name          level_no        \n Length:15          Length:15          Length:15          Length:15         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n   unit_no          building_name      postal_code        other_address_line1\n Length:15          Length:15          Length:15          Length:15          \n Class :character   Class :character   Class :character   Class :character   \n Mode  :character   Mode  :character   Mode  :character   Mode  :character   \n                                                                             \n                                                                             \n                                                                             \n                                                                             \n other_address_line2 account_due_date   annual_return_date primary_ssic_code\n Length:15           Length:15          Length:15          Min.   :56111    \n Class :character    Class :character   Class :character   1st Qu.:56111    \n Mode  :character    Mode  :character   Mode  :character   Median :56111    \n                                                           Mean   :56111    \n                                                           3rd Qu.:56111    \n                                                           Max.   :56111    \n                                                                            \n primary_ssic_description primary_user_described_activity      YEAR     \n Length:15                Length:15                       Min.   :2025  \n Class :character         Class :character                1st Qu.:2025  \n Mode  :character         Mode  :character                Median :2025  \n                                                          Mean   :2025  \n                                                          3rd Qu.:2025  \n                                                          Max.   :2025  \n                                                                        \n   MONTH_NUM       MONTH_ABBR  SEARCHVAL            BLK_NO         \n Min.   :1.000   May    :4    Length:15          Length:15         \n 1st Qu.:3.000   Jan    :2    Class :character   Class :character  \n Median :5.000   Mar    :2    Mode  :character   Mode  :character  \n Mean   :4.267   Apr    :2                                         \n 3rd Qu.:5.500   Jun    :2                                         \n Max.   :7.000   Jul    :2                                         \n                 (Other):1                                         \n  ROAD_NAME           BUILDING           ADDRESS            LATITUDE        \n Length:15          Length:15          Length:15          Length:15         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  LONGITUDE        \n Length:15         \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\nWindow: polygonal boundary\nsingle connected closed polygon with 591 vertices\nenclosing rectangle: [38.19984, 44.8598] x [32.93355, 39.75273] km\n                     (6.66 x 6.819 km)\nWindow area = 20.7954 square km\nUnit of length: 1 km\nFraction of frame area: 0.458\n\n\nThe wrangled outputs highlight how restaurant distributions differ significantly across four contrasting planning areas in Singapore:\nOrchard, located within the central region, demonstrates the highest spatial intensity with 25 restaurants contained within a small area of 0.96 km², producing an average density exceeding 26 restaurants per km². This reflects Orchard’s role as a prime commercial and retail hub where food and beverage establishments cluster tightly to serve both local consumers and international visitors.\nJurong West, by comparison, records 17 restaurants within roughly 0.96 km², yielding a more moderate intensity of 1.16 per km². This suggests the presence of neighbourhood-level clusters that cater to local residential populations rather than destination-driven demand. `\nTampines shows 15 restaurants spread across 9.37 km², producing an intensity of 0.72 per km², which is consistent with its position as a regional centre offering balanced commercial and residential amenities.\nPunggol, a relatively new residential town, records only five restaurants within 9.37 km², resulting in the lowest intensity of 0.53 per km². This contrast highlights clear urban hierarchies, where maturity of development, population density, and land-use composition strongly shape restaurant clustering. The outputs confirm that spatial intensity patterns correspond closely to each area’s developmental history and functional role.\n\n\n9.6.2 Computing KDE surfaces by planning Area\nBy converting discrete restaurant locations into continuous density surfaces, KDE helps identify hotspots and highlight differences in spatial intensity across planning areas. At this stage, we focus on computing KDE surfaces separately for selected planning areas of Singapore, instead of for the entire island. This allows us to explore variations in restaurant distribution within localised study areas and compare across subzones. Importantly, the KDE computation uses a consistent bandwidth estimator, ensuring results are comparable across regions. Following the same structure and coding style as earlier sections, we use Diggle’s automatic bandwidth selection method (bw.diggle) and apply the Gaussian kernel to maintain methodological consistency. All computations are carried out in kilometers, rather than meters, since this scale provides results that are interpretable and aligned with urban planning practices. This ensures KDE values represent the density of restaurants per square kilometer, a unit meaningful for evaluating clustering and intensity at the planning area level.\n\n# Orchard\nplot(\n  density(rest_ppp_orchard_km,\n          sigma = bw.diggle,\n          edge = TRUE,\n          kernel = \"gaussian\"),\n  main = \"Orchard\"\n)\n\n\n\n\n\n\n\n# Jurong West\nplot(\n  density(rest_ppp_jurongw_km,\n          sigma = bw.diggle,\n          edge = TRUE,\n          kernel = \"gaussian\"),\n  main = \"Jurong West\"\n)\n\n\n\n\n\n\n\n# Tampines\nplot(\n  density(rest_ppp_tampines_km,\n          sigma = bw.diggle,\n          edge = TRUE,\n          kernel = \"gaussian\"),\n  main = \"Tampines\"\n)\n\n\n\n\n\n\n\n# Punggol\nplot(\n  density(rest_ppp_punggol_km,\n          sigma = bw.diggle,\n          edge = TRUE,\n          kernel = \"gaussian\"),\n  main = \"Punggol\"\n)\n\n\n\n\n\n\n\n\nThe KDE plots for Orchard, Jurong West, Tampines, and Punggol illustrate clear contrasts in restaurant clustering across different planning areas. Orchard stands out with extremely high intensities exceeding 30,000 restaurants per km² in certain hotspots, reflecting its role as Singapore’s premier retail and F&B destination. Jurong West shows multiple localised clusters, with peak intensities above 35, indicating neighbourhood-scale concentrations around commercial nodes. Tampines displays moderate but spatially dispersed clusters with values around 3 per km², consistent with its character as a regional centre serving a large residential population. Punggol, a newer town, has fewer restaurants overall, with peaks around 5 per km² concentrated in limited pockets, revealing its emerging but still sparse food landscape.\nThese differences confirm that KDE is effective in capturing the spatial heterogeneity of restaurant intensity across planning areas. Orchard exemplifies centralised, high-density clustering driven by its urban function, while Tampines and Jurong West illustrate more moderate but significant suburban nodes. Punggol lags behind, with limited commercial clustering that reflects its developmental stage. Together, these outputs demonstrate how KDE surfaces can reveal meaningful variations in urban foodscapes, linking land-use intensity, urban maturity, and service accessibility to spatial patterns of F&B establishments.\n\n\n\n9.7 Spatio-temporal KDE (STKDE) for Jan–Jun 2025\nIn this section, we bring together the spatial and temporal dimensions of restaurant incorporations into a unified spatio-temporal analysis using STKDE. The period of focus is January to June 2025, and the primary aim is to detect not only where incorporations cluster in space but also how these clusters evolve across time. The section begins with exploratory faceted maps that simply display the geographic distribution of restaurants month by month, offering a descriptive baseline. This is followed by computational STKDE at the monthly scale, where incorporation months are treated as temporal marks and used to generate a three-dimensional density surface across space (x, y) and time (t). Recognising that monthly aggregation can mask short-lived bursts of activity, the section then extends to day-level STKDE. By applying bootstrap bandwidth optimisation, the analysis achieves a careful balance between spatial and temporal smoothing, ensuring that density estimates capture meaningful patterns rather than artefacts of parameter choice. Finally, the section emphasises validation and interpretability, producing fixed-scale comparative panels that allow researchers to trace how hotspots intensify, persist, or dissipate across the study window. Overall, Section 9.7 transforms raw incorporation points into a dynamic surface that reveals the tempo and geography of restaurant entry, providing richer insight than purely spatial or purely temporal methods could offer in isolation.\n\n9.7.1 Visualising geographic distribution by month\nBefore advancing into formal spatio-temporal density estimation, the data is first explored visually to understand how restaurant incorporations are spread across Singapore from January to June 2025. Using the tmap package in static plot mode, individual incorporations are represented as dots, layered over the national planning boundary (sg_owin) to ensure geographic consistency. By applying tm_facets (by = “MONTH_ABBR”), the output generates a panel of maps, one for each month, which collectively illustrate how point distributions evolve across time. This faceted approach does not yet quantify clustering but serves as an intuitive diagnostic, highlighting months with visibly denser patterns or more dispersed incorporations. Such side-by-side visualisation is valuable for detecting preliminary trends—for example, whether activity is consistently concentrated in the central business districts or if new hotspots are emerging in suburban planning areas. As an exploratory step, these maps provide a baseline context that informs and motivates the more rigorous spatio-temporal KDE analysis developed later in the section.\n\ntmap::tmap_mode(\"plot\")\n\nstudy_owin_sf &lt;- sf::st_as_sf(sg_owin)\nsf::st_crs(study_owin_sf) &lt;- 3414  # SVY21\n\ntm_shape(study_owin_sf) +\n  tm_polygons(col = NA, border.col = \"grey70\", lwd = 0.4) +\ntm_shape(biz_56111_sf) +\n  tm_dots(size = 0.2, fill = \"red\") +\n  tm_facets(by = \"MONTH_ABBR\", free.coords = FALSE, drop.units = TRUE)\n\n\n\n\n\n\n\nstudy_owin_sf\n\nSimple feature collection with 1 feature and 0 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 21448.47 xmax: 55941.94 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\n                            geom\n1 MULTIPOLYGON (((31835.86 46...\n\n\nLooking at the monthly distribution of new restaurant openings between January and July, several clear spatial patterns emerge from visual inspection of the plots. In January, there is a tightly packed concentration of establishments in the central-southern corridor, particularly around the Orchard–Downtown Core region. The clustering appears compact, with points situated very close to one another, suggesting a strong central hotspot. In February, the pattern remains similar, with a dense grouping in the south, though the spread toward the east appears slightly more noticeable.\nBy March, the distribution shows some diffusion, with points appearing across the island, but the central cluster continues to dominate visually. April differs by showing a wider spread of points, with openings extending further into the northern and eastern areas. While the central region remains active, the clustering looks less compact, reflecting broader spatial coverage rather than dense concentration.\nIn May and June, the central clustering reasserts itself, with a visible grouping of restaurants again emerging in the south. June, in particular, demonstrates a mix of dense clustering and moderate spread. Finally, in July, the pattern thins slightly, but central clustering persists, though less intense compared to January.\nOverall, the visuals highlight a persistent central hotspot, alongside varying levels of island-wide spread month to month.\n\n\n9.7.2 STKDE by month\nHere, the analysis moves from descriptive visualization to computational STKDE, aggregated by month. The dataset is first structured so that the month of incorporation (1–12) is explicitly treated as a time mark, ensuring compatibility with the spatstat framework. The data is then converted to a planar point pattern process (PPP) with spatial coordinates expressed in meters, and subsequently rescaled into kilometers for consistency with the rest of the study. Each restaurant’s month of incorporation is treated as a temporal event, which is clipped to the global study window to avoid edge effects. The spattemp.density() function then computes the STKDE, estimating how restaurant incorporations are distributed simultaneously across space and time. The outcome is a three-dimensional density object (x, y, t), where t represents month. This monthly STKDE provides a fine-grained temporal lens, enabling researchers to investigate whether restaurant hotspots emerge gradually, persist across multiple months, or appear suddenly, potentially linked to policy interventions or seasonal demand.\n\n# 1) Keep ONLY the month mark (1..12) with geometry (still meters here)\nrest_month &lt;- biz_56111_sf |&gt;\n  dplyr::select(MONTH_NUM)\n\n# 2) Convert to ppp (meters); MONTH_NUM travels along as marks\nrest_month_ppp &lt;- spatstat.geom::as.ppp(rest_month)\n\n# 3) Clip to the global observation window you used in §9\nrest_month_owin &lt;- rest_month_ppp[sg_owin]\n\n# 4) Rescale to kilometers (to stay consistent with §9)\nrest_month_ppp_km &lt;- spatstat.geom::rescale(rest_month_owin, 1000, \"km\")\n\n# --- CRITICAL: ensure time marks are a plain numeric vector (not a data.frame/factor)\nmks &lt;- marks(rest_month_ppp_km)\nmonth_vec &lt;- if (is.data.frame(mks)) mks$MONTH_NUM else mks\nstopifnot(is.numeric(month_vec))\nrest_month_ppp_km &lt;- spatstat.geom::setmarks(rest_month_ppp_km, as.numeric(month_vec))\n\n# Quick sanity: months present should be inside 1..12\nrange(month_vec, na.rm = TRUE)\n\n[1] 1 7\n\ntable(month_vec)\n\nmonth_vec\n  1   2   3   4   5   6   7 \n102  96 110  97  93 100  79 \n\n# 5) STKDE using sparr (let it pick sensible spatial defaults; specify time grid)\n#    tres = number of distinct months we actually have; tlim bounds the months.\nuniq_months &lt;- sort(unique(month_vec))\nnt &lt;- length(uniq_months)\n\nst_kde_m &lt;- sparr::spattemp.density(\n  rest_month_ppp_km,\n  sres  = 128,                      # spatial grid like the notes\n  tres  = nt,                        # number of time slices\n  tlim  = range(uniq_months, na.rm = TRUE)  # temporal span (e.g., 1..7 in your data)\n)\n\n# Confirm we now have a 3D object (you should see ... x ... x nt)\nsummary(st_kde_m)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 1.5751 (spatial)\n  lambda = 0.0393 (temporal)\n\nNo. of observations\n  677 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [2.667538, 55.94194] x [21.44847, 50.25633]\n\nTemporal bound\n  [1, 7]\n\nEvaluation\n  128 x 128 x 7 trivariate lattice\n  Density range: [7.660098e-51, 0.02162844]\n\n\n\n# 6) Map actual month numbers -&gt; internal time indices that spattemp.density created\n#    st_kde_m$z$t holds the time coordinate; if NULL (very rare), build a seq of length nt.\nt_axis &lt;- st_kde_m$z$t\nif (is.null(t_axis)) t_axis &lt;- seq_len(nt)\n\nt_idx  &lt;- match(uniq_months, t_axis)\nkeep   &lt;- !is.na(t_idx)\nt_idx  &lt;- t_idx[keep]\nlab_months &lt;- month.abb[uniq_months][keep]\n\n# 7) Plot every month with a fixed legend range (prof’s “comparable panels” habit)\nop &lt;- par(mfcol = c(2, ceiling(length(t_idx)/2)))  # 2×? grid; adjust if you prefer 3×?\nfor (i in seq_along(t_idx)) {\n  plot(\n    st_kde_m, t_idx[i],\n    override.par = FALSE,\n    fix.range    = TRUE,\n    main = paste(\"KDE at\", lab_months[i])\n  )\n}\npar(op)\n\n\n\n\n\n\n\n\nThe STKDE surfaces provide a dynamic perspective on restaurant intensity across Singapore’s planning areas from January to July 2025. Unlike the static first-order SPPA, which offered a cumulative view of clustering, STKDE reveals how concentration shifts month by month.\nIn the early months, February and March exhibit diffuse patterns with low overall intensity, indicating that restaurant registrations were spread broadly across several planning areas rather than concentrated in one location. April marks a sharp surge in activity, with central planning areas registering the highest intensity, exceeding 0.02 restaurants/km². This confirms the first-order result that central regions are the primary clusters but clarifies that the peak was temporally concentrated in April. Activity then disperses in May and June, with moderate levels appearing in eastern and western planning areas such as Tampines and Jurong West, suggesting a decentralization of openings. By July, the overall intensity weakens further, reflecting fewer new registrations across the island and confirming that April’s central spike was an anomaly rather than a sustained trend.\nImportantly, these outputs are not counts of restaurants but model-derived intensities. The kernel estimator smooths each restaurant registration across space and time according to the selected bandwidths. As a result, the maps report expected density in restaurants per km² per day, not literal fractions of a restaurant, providing a probabilistic representation of clustering strength over space-time.\nIn summary, STKDE supports the first-order SPPA finding of central dominance but introduces essential temporal nuance: clustering was episodic, peaking in April, while other planning areas intermittently absorbed activity. This demonstrates the value of spatio-temporal methods in distinguishing short-lived bursts from longer-term geographic concentration.\n\n\n9.7.3 STKDE by day-of-year (improved bandwidths via BOOT.spattemp)\nThis section advances the STKDE analysis by refining temporal granularity to the level of individual days and improving smoothing parameters through bootstrap bandwidth selection. The day-of-year (1–366) is extracted from each incorporation date, ensuring temporal precision beyond monthly aggregation. The dataset is then processed into a PPP, rescaled to kilometers, and prepared with appropriate temporal marks. A critical step here is bandwidth optimisation: instead of relying on arbitrary or fixed values, the bootstrap method (BOOT.spattemp) identifies data-driven spatial (\\(h\\)) and temporal (\\(\\lambda\\)) bandwidths that balance bias and variance. This ensures that the resulting STKDE surface captures meaningful clustering patterns without over-smoothing fine details or exaggerating noise. Once the optimised parameters are selected, the spatio-temporal density is computed, and slices across different days can be visualised. This approach provides a much more dynamic and precise picture of incorporation activity, capable of highlighting short-lived bursts of restaurant openings that monthly aggregation might obscure, offering richer insight into temporal clustering behaviour.\n\n# 1) Build a temp sf with just the Day-of-Year mark (1..366), keep geometry\nrest_yday &lt;- biz_56111_sf |&gt;\n  dplyr::transmute(YDAY_NUM = lubridate::yday(date))\n\n# 2) Convert to ppp (meters) – the mark travels along\nrest_yday_ppp &lt;- spatstat.geom::as.ppp(rest_yday)\n\n# 3) Clip to the same global observation window used in §9\nrest_yday_owin &lt;- rest_yday_ppp[sg_owin]\n\n# 4) Rescale to kilometers (consistent with the rest of §9)\nrest_yday_ppp_km &lt;- spatstat.geom::rescale(rest_yday_owin, 1000, \"km\")\n\n# 5) SAFETY: ensure the time mark is a plain numeric vector inside the ppp\nmks &lt;- marks(rest_yday_ppp_km)\nyday_vec &lt;- if (is.data.frame(mks)) mks$YDAY_NUM else mks\nstopifnot(is.numeric(yday_vec))\nrest_yday_ppp_km &lt;- spatstat.geom::setmarks(rest_yday_ppp_km, as.numeric(yday_vec))\n\n# Quick checks like in the notes\nrange(yday_vec, na.rm = TRUE)      # should be within 1..366 subset\n\n[1]   1 212\n\nlength(unique(yday_vec))           # number of distinct days actually present\n\n[1] 189\n\n# 6) Select bandwidths via bootstrap (professor’s method)\nset.seed(1234)  # reproducibility\nboot_bw &lt;- sparr::BOOT.spattemp(rest_yday_ppp_km)  # let sparr choose; no extra args\n\nInitialising...Done.\nOptimising...\nh = 1.575134 \b; lambda = 18.76458 \nh = 3.451592 \b; lambda = 18.76458 \nh = 1.575134 \b; lambda = 20.64104 \nh = 2.513363 \b; lambda = 19.2337 \nh = 0.636905 \b; lambda = 20.17192 \nh = 2.044249 \b; lambda = 19.46825 \nh = 1.10602 \b; lambda = 19.93737 \nh = 0.636905 \b; lambda = 20.17192 \nh = 1.10602 \b; lambda = 21.81383 \nh = 0.8714623 \b; lambda = 23.33845 \nh = 0.636905 \b; lambda = 21.11015 \nh = 1.340577 \b; lambda = 20.75832 \nh = 1.340577 \b; lambda = 22.63478 \nh = 1.457855 \b; lambda = 23.98348 \nh = 1.575134 \b; lambda = 21.57927 \nh = 1.223298 \b; lambda = 21.75519 \nh = 1.223298 \b; lambda = 23.63164 \nh = 1.164659 \b; lambda = 25.06831 \nh = 1.281937 \b; lambda = 25.9479 \nh = 1.311257 \b; lambda = 28.04425 \nh = 1.135339 \b; lambda = 30.47778 \nh = 1.03272 \b; lambda = 34.39929 \nh = 1.179319 \b; lambda = 37.37523 \nh = 1.186649 \b; lambda = 43.5287 \nh = 0.9081118 \b; lambda = 49.88373 \nh = 0.7065392 \b; lambda = 60.80347 \nh = 1.06204 \b; lambda = 59.01314 \nh = 1.0767 \b; lambda = 71.32007 \nh = 0.7981631 \b; lambda = 77.6751 \nh = 0.8952845 \b; lambda = 69.1385 \nh = 1.063873 \b; lambda = 90.57484 \nh = 1.141753 \b; lambda = 110.9204 \nh = 1.245288 \b; lambda = 92.7564 \nh = 0.9827854 \b; lambda = 75.04298 \nh = 0.969958 \b; lambda = 94.29775 \nh = 0.9165871 \b; lambda = 105.7866 \nh = 0.9976742 \b; lambda = 121.3184 \nh = 1.005119 \b; lambda = 144.4562 \nh = 0.8503888 \b; lambda = 136.5302 \nh = 1.010502 \b; lambda = 102.0637 \nh = 1.091589 \b; lambda = 117.5955 \nh = 0.9603375 \b; lambda = 108.7388 \nh = 0.9475101 \b; lambda = 127.9936 \nh = 0.9160144 \b; lambda = 140.9585 \nh = 0.9101734 \b; lambda = 115.414 \nh = 0.975799 \b; lambda = 119.8423 \nh = 0.9629717 \b; lambda = 139.0971 \nh = 0.960996 \b; lambda = 116.3284 \nh = 0.9892849 \b; lambda = 108.1771 \nh = 0.9579538 \b; lambda = 123.0395 \nh = 0.9727568 \b; lambda = 126.5534 \nh = 0.9639362 \b; lambda = 118.8846 \nh = 0.946091 \b; lambda = 122.0818 \nh = 0.968372 \b; lambda = 120.4022 \nh = 0.9743544 \b; lambda = 116.2474 \nh = 0.962054 \b; lambda = 121.3414 \nh = 0.9664898 \b; lambda = 122.859 \nh = 0.9645746 \b; lambda = 119.8782 \nh = 0.9708927 \b; lambda = 118.939 \nh = 0.9642637 \b; lambda = 120.7408 \nh = 0.9604662 \b; lambda = 120.2169 \nh = 0.9663956 \b; lambda = 120.3559 \nh = 0.9660846 \b; lambda = 121.2185 \nh = 0.9649521 \b; lambda = 120.2133 \nh = 0.967084 \b; lambda = 119.8283 \nh = 0.9649688 \b; lambda = 120.5127 \nh = 0.9635253 \b; lambda = 120.3701 \nh = 0.965678 \b; lambda = 120.3594 \nh = 0.9656946 \b; lambda = 120.6588 \nh = 0.965509 \b; lambda = 120.5475 \nh = 0.9647998 \b; lambda = 120.7007 \nh = 0.9654584 \b; lambda = 120.4448 \nh = 0.9659987 \b; lambda = 120.4795 \nh = 0.9652262 \b; lambda = 120.5044 \nh = 0.9651757 \b; lambda = 120.4017 \nh = 0.9654257 \b; lambda = 120.511 \nDone.\n\n# --- Robust extraction: works for both list-return and numeric vector-return\nh_opt &lt;- tryCatch(boot_bw$h.opt, error = function(e) NULL)\nlambda_opt &lt;- tryCatch(boot_bw$lambda.opt, error = function(e) NULL)\nif (is.null(h_opt) || is.null(lambda_opt)) {\n  vals &lt;- as.numeric(boot_bw)\n  stopifnot(length(vals) &gt;= 2)\n  h_opt      &lt;- vals[1]\n  lambda_opt &lt;- vals[2]\n}\ncat(\"Selected h (km):\", h_opt, \"  lambda (days):\", lambda_opt, \"\\n\")\n\nSelected h (km): 0.9652262   lambda (days): 120.5044 \n\n# 7) Compute the STKDE using the selected bandwidths\nkde_yday &lt;- sparr::spattemp.density(\n  rest_yday_ppp_km,\n  h      = h_opt,\n  lambda = lambda_opt\n)\n\n# Inspect (should report the t-domain and grid)\nsummary(kde_yday)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 0.9652 (spatial)\n  lambda = 120.5044 (temporal)\n\nNo. of observations\n  677 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [2.667538, 55.94194] x [21.44847, 50.25633]\n\nTemporal bound\n  [1, 212]\n\nEvaluation\n  128 x 128 x 212 trivariate lattice\n  Density range: [5.122269e-48, 0.0001246886]\n\n\n\n# 8a) Plot a specific day-of-year slice (like the notes). Example: t = 10\n# plot(kde_yday)        # default panel (slider-like)\n# plot(kde_yday, 10)    # explicitly show t = 10 (any valid index 1..nt)\n\n# 8b) Optional: evenly spaced days panel with fixed legend (robust to structure)\n# Try to get the time axis from the object; fall back to cube depth; then to data\nt_axis &lt;- kde_yday$z$t\nif (is.null(t_axis)) {\n  nt_from_v &lt;- tryCatch({\n    vv &lt;- kde_yday$z$v\n    d  &lt;- dim(vv)\n    if (length(d) &gt;= 3) d[3] else NA_integer_\n  }, error = function(e) NA_integer_)\n  if (is.na(nt_from_v)) {\n    nt_from_v &lt;- length(unique(yday_vec))  # last resort: how many days we fed in\n  }\n  t_axis &lt;- seq_len(nt_from_v)\n}\n\n# Guard: if we still don’t have any time slices, stop with a clear message\nif (length(t_axis) &lt; 1L) {\n  stop(\"STKDE object has zero time slices (check marks/time input and BOOT bandwidth step).\")\n}\n\n# Build up to 6 evenly spaced slice indices across the available t-axis\nk &lt;- min(6L, length(t_axis))\nt_show &lt;- unique(round(seq(from = 1, to = length(t_axis), length.out = k)))\nt_show &lt;- t_show[t_show &gt;= 1 & t_show &lt;= length(t_axis)]  # extra safety\n\n# Plot with a fixed legend range so panels are comparable\nop &lt;- par(mfcol = c(2, ceiling(length(t_show)/2)))  # 2×3 grid when 6 slices\nfor (ti in t_show) {\n  plot(\n    kde_yday, ti,\n    override.par = FALSE,\n    fix.range    = TRUE,\n    main = paste(\"KDE at t =\", ti)\n  )\n}\n\n\n\n\n\n\n\npar(op)\n\nThe spatio-temporal kernel density estimation (STKDE) by day-of-year provides a refined view of restaurant openings across Singapore during the first half of 2025. Using a spatial bandwidth (\\(h\\)) of approximately 0.97 km and a temporal bandwidth (\\(\\lambda\\)) of about 120.5 days, the model smooths individual registrations over space and time, producing estimates on a 128 × 128 × 212 lattice. This fine resolution allows clustering patterns to be examined at daily granularity rather than through broader monthly aggregation. The estimated intensity values range between \\(5.3 \\times 10^{-48}\\)), representing effective background zero, and \\(1.25 \\times 10^{-4}\\) restaurants per \\(km^2\\) per day, representing maximum hotspot strength. These outputs capture expected densities, not literal counts, and indicate the probability surface of clustering.\nAcross all temporal slices (t = 1, 39, 76, 114, 151, 189), the results consistently highlight a persistent hotspot in central Singapore, most clearly associated with the Orchard and Downtown Core areas. The hotspot is visible in every slice, demonstrating that clustering is not sporadic or shifting but stable and spatially anchored in the central planning region. No secondary hotspots emerge in suburban or peripheral areas such as Jurong West, Tampines, or Punggol.\nThe insight is that restaurant openings during this period are highly persistent in central locations, reinforcing the dominance of established commercial zones. Temporal variation in intensity is modest, but the spatial persistence underscores entrenched market preference for core areas."
  },
  {
    "objectID": "Take-home_Ex01/take-home_ex01.html#second-order-spatial-point-patterns-analysis",
    "href": "Take-home_Ex01/take-home_ex01.html#second-order-spatial-point-patterns-analysis",
    "title": "Take-home Ex01: Geospatial Analytics for Public Good",
    "section": "10 Second-order spatial point patterns analysis",
    "text": "10 Second-order spatial point patterns analysis\nWhile first-order analysis (Section 9) identified where restaurant registrations were most intense, it does not tell us whether those hotspots are statistically significant or simply a result of background density. To address this, we perform second-order SPPA, which examines how the relative positions of points deviate from CSR.\nIn practice, among the four classical second-order functions (\\(G\\), \\(F\\), \\(K\\), \\(L\\)), the \\(K\\)-function and its variance-stabilised form, the \\(L\\)-function, are most widely adopted. They are preferred because they capture multi-scale clustering and dispersion across a range of distances, while \\(G\\) and \\(F\\) are primarily sensitive to nearest-neighbour effects. We therefore focus our analysis on \\(K\\) and \\(L\\) functions, supported by Monte Carlo CSR testing using 99/999 simulations.\n\n10.1 Analysing apatial point process using \\(K\\)-function\nThe \\(K\\)-function is a second-order spatial point process statistic that measures the number of neighbouring events within a given distance of each observed point and compares the result to a theoretical expectation under CSR. Unlike first-order methods such as kernel density estimation that highlight intensity variations across space, the \\(K\\)-function examines spatial dependence between points, thereby detecting clustering or dispersion at multiple scales. In this exercise, the analysis is applied to the restaurant dataset filtered for the period January to June 2025, focusing on Tampines and Punggol planning areas. The \\(K\\)-function is estimated for each subregion and tested against a CSR benchmark using 999 Monte Carlo simulations to generate significance envelopes. By comparing the observed function with the simulation envelope, the analysis reveals whether the observed distribution of restaurants reflects random processes, significant clustering, or spatial regularity. This approach is crucial because it provides statistical evidence to support visual impressions from density maps and allows the detection of spatial interactions across a range of distances. Ultimately, the \\(K\\)-function offers deeper insights into how restaurants are spatially distributed in different planning contexts and whether their locations are shaped by systematic clustering forces or can be explained by chance alone.\n\n# K for Orchard\nK_or      &lt;- Kest(rest_ppp_orchard_km,  correction = \"Ripley\")\nK_or.csr  &lt;- envelope(rest_ppp_orchard_km,  Kest, nsim = 999, rank = 1, glocal = TRUE)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(K_or.csr, . - r ~ r,\n     xlab = \"Distance (km)\", ylab = \"K(d) - r\",\n     main = \"K-function with CSR envelope — Orchard (Jan–Jun 2025)\")\n\n\n\n\n\n\n\n# K for Jurong West\nK_jw      &lt;- Kest(rest_ppp_jurongw_km,  correction = \"Ripley\")\nK_jw.csr  &lt;- envelope(rest_ppp_jurongw_km,  Kest, nsim = 999, rank = 1, glocal = TRUE)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(K_jw.csr, . - r ~ r,\n     xlab = \"Distance (km)\", ylab = \"K(d) - r\",\n     main = \"K-function with CSR envelope — Jurong West (Jan–Jun 2025)\")\n\n\n\n\n\n\n\n# K for Tampines (reusing Sect. 9 PPP)\nK_tm      &lt;- Kest(rest_ppp_tampines_km, correction = \"Ripley\")\nK_tm.csr  &lt;- envelope(rest_ppp_tampines_km, Kest, nsim = 999, rank = 1, glocal = TRUE)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(K_tm.csr, . - r ~ r,\n     xlab = \"Distance (km)\", ylab = \"K(d) - r\",\n     main = \"K-function with CSR envelope — Tampines (Jan–Jun 2025)\")\n\n\n\n\n\n\n\n# K for Punggol\nK_pg      &lt;- Kest(rest_ppp_punggol_km,  correction = \"Ripley\")\nK_pg.csr  &lt;- envelope(rest_ppp_punggol_km,  Kest, nsim = 999, rank = 1, glocal = TRUE)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(K_pg.csr, . - r ~ r,\n     xlab = \"Distance (km)\", ylab = \"K(d) - r\",\n     main = \"K-function with CSR envelope — Punggol (Jan–Jun 2025)\")\n\n\n\n\n\n\n\n\nThe second-order analysis using Ripley’s \\(K\\)-function provides important insights into how restaurant establishments are distributed across different planning areas of Singapore between January and June 2025. By comparing the observed distribution of restaurants against CSR envelopes, the analysis highlights whether clustering or dispersion dominates at neighborhood scales.\nFor Orchard, the observed \\(K\\)-function remains almost entirely within the CSR envelope across the evaluated distance range of 0 – 0.3 km. At very short distances (\\(&lt; 0.15 km\\)), the curve dips slightly below the CSR expectation, suggesting weak local inhibition, where restaurants appear marginally more spaced out than expected under randomness. However, this deviation is minor and does not persist. Beyond 0.15 km, the curve converges back toward the CSR line, indicating no strong evidence of clustering. These results align with Orchard’s role as a mature, high-density commercial area, where planning controls and established tenancy structures may limit excessive agglomeration at micro-scales.\nIn contrast, Jurong West demonstrates marginal clustering. The observed curve consistently rises above the CSR expectation and approaches the upper bounds of the simulation envelope across distances up to ~1.2 km. This indicates that restaurants in Jurong West tend to co-locate more than would be expected under randomness, reflecting localized agglomeration effects. Such clustering could be driven by town-center development, transport nodes, or concentrated demand in an expanding residential population.\nFor Tampines, the observed curve closely tracks the CSR expectation and remains well within the envelope over distances from 0 to 1.6 km. The absence of significant deviation suggests that the distribution of restaurants here is broadly consistent with spatial randomness, neither clustering nor dispersing in a systematic manner. This even spread reflects balanced urban planning, where amenities are distributed across the planning area to serve residential neighborhoods efficiently.\nFinally, Punggol shows a more ambiguous pattern. At short distances (&lt;0.3 km), the curve dips below CSR expectation, hinting at weak repulsion, but rises above CSR between 0.4 and 1.0 km, which may suggest clustering at sub-kilometer scales. However, a critical limitation is that the CSR envelope is missing for this plot, making statistical significance impossible to confirm. Visual inspection alone is insufficient, and further analysis using the L-function with envelopes is recommended to validate potential clustering in this emerging town.\nOverall, the comparison underscores the diversity of spatial dynamics: Orchard shows near randomness with slight inhibition, Jurong West exhibits strong clustering, Tampines reflects balanced distribution, and Punggol remains inconclusive without full statistical testing. These findings emphasize the importance of using envelopes and complementary methods to robustly interpret spatial point patterns.\n\n\n10.2 Analysing spatial point process using \\(L\\)-function\nThe \\(L\\)-function is a variance-stabilised transformation of the \\(K\\)-function that provides a more interpretable measure of spatial point pattern dependence across different distance scales. While the \\(K\\)-function often grows rapidly with increasing distance, making it difficult to compare observed and expected values directly, the \\(L\\)-function linearises the expectation under CSR, such that deviations above or below the theoretical line can be more clearly identified. In this study, the \\(L\\)-function is applied to restaurant locations in Tampines and Punggol for the period January to June 2025, using the same point process objects generated in earlier sections. Monte Carlo simulations with 999 iterations are performed to construct CSR envelopes, providing a rigorous statistical test of spatial randomness at multiple scales. The \\(L\\)-function plots make it possible to distinguish between significant clustering and dispersion patterns with greater clarity compared to the raw K-function, especially at shorter distances where statistical fluctuations are most pronounced. By applying this method, the analysis can reveal not only whether clustering exists, but also the spatial range over which it occurs, offering deeper insights into how restaurant distributions reflect underlying urban design and commercial activity patterns in both new town and regional centre contexts.\n\n# L for Orchard\nL_or      &lt;- Lest(rest_ppp_orchard_km, correction = \"Ripley\")\nL_or.csr  &lt;- envelope(rest_ppp_orchard_km, Lest, nsim = 999, rank = 1, glocal = TRUE)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(L_or.csr, . - r ~ r,\n     xlab = \"Distance (km)\", ylab = \"L(d) - r\",\n     main = \"L-function with CSR envelope — Orchard (Jan–Jun 2025)\")\n\n\n\n\n\n\n\n# L for Jurong West\nL_jw      &lt;- Lest(rest_ppp_jurongw_km, correction = \"Ripley\")\nL_jw.csr  &lt;- envelope(rest_ppp_jurongw_km, Lest, nsim = 999, rank = 1, glocal = TRUE)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(L_jw.csr, . - r ~ r,\n     xlab = \"Distance (km)\", ylab = \"L(d) - r\",\n     main = \"L-function with CSR envelope — Jurong West (Jan–Jun 2025)\")\n\n\n\n\n\n\n\n# L for Tampines\nL_tm      &lt;- Lest(rest_ppp_tampines_km, correction = \"Ripley\")\nL_tm.csr  &lt;- envelope(rest_ppp_tampines_km, Lest, nsim = 999, rank = 1, glocal = TRUE)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(L_tm.csr, . - r ~ r,\n     xlab = \"Distance (km)\", ylab = \"L(d) - r\",\n     main = \"L-function with CSR envelope — Tampines (Jan–Jun 2025)\")\n\n\n\n\n\n\n\n# L for Punggol\nL_pg      &lt;- Lest(rest_ppp_punggol_km, correction = \"Ripley\")\nL_pg.csr  &lt;- envelope(rest_ppp_punggol_km, Lest, nsim = 999, rank = 1, glocal = TRUE)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(L_pg.csr, . - r ~ r,\n     xlab = \"Distance (km)\", ylab = \"L(d) - r\",\n     main = \"L-function with CSR envelope — Punggol (Jan–Jun 2025)\")\n\n\n\n\n\n\n\n\nThe application of the \\(L\\)-function with CSR envelopes provides deeper insight into the spatial arrangement of restaurants across Orchard, Jurong West, Tampines, and Punggol between January and June 2025. By linearising the \\(K\\)-function expectation, the \\(L\\)-function makes it easier to discern whether restaurant distributions follow CSR, or whether clustering or dispersion tendencies dominate at specific spatial scales.\nFor Orchard, the observed \\(L(d) – r\\) curve remains tightly bounded within the CSR envelope across the full range of distances considered (0–0.3 km). The curve oscillates only slightly around the theoretical CSR line, with no systematic departures above or below. This finding indicates that restaurant locations in Orchard do not exhibit statistically significant clustering or dispersion. Instead, they are distributed in a manner that aligns with spatial randomness. Given Orchard’s status as a dense, highly regulated commercial core, this result is consistent with deliberate urban planning that balances accessibility with saturation, ensuring even service distribution within a small and competitive district.\nIn Jurong West, the \\(L\\)-function suggests a more dynamic pattern. While the observed curve remains within the CSR simulation envelope, positive deviations emerge at mid-range distances (0.4 – 0.8 km). These upward departures, although not statistically conclusive, hint at weak clustering tendencies at the neighbourhood scale. Such patterns could reflect the pull of transport hubs, shopping malls, or residential-commercial nodes that naturally attract several establishments in proximity. Nevertheless, because the curve never clearly exits the CSR band, the clustering tendency remains suggestive rather than definitive. Jurong West therefore presents a case of emerging but not strongly validated agglomeration.\nThe results for Tampines reveal perhaps the strongest case of spatial randomness. Across the distance range of 0–1.6 km, the observed curve closely tracks the CSR expectation without deviating from the simulation envelope. This strongly supports the conclusion that restaurants in Tampines are randomly distributed. As a mature regional centre with carefully balanced land-use planning, Tampines demonstrates a regulated distribution of food establishments across its subzones. Rather than clustering tightly or dispersing systematically, restaurants appear evenly spread, reflecting planning policies that prioritise accessibility and avoid excessive concentration in any one area.\nIn contrast, Punggol produces an irregular output. The observed curve dips below CSR at very short distances (\\(&lt;0.3 km\\)), suggesting weak inhibition where restaurants may avoid locating too close to one another, before rising above CSR at 0.4–0.8 km, which may imply some degree of clustering. However, the absence of a CSR envelope in this plot prevents statistical verification. Without simulation bands, we cannot confidently separate true clustering from random variation. Consequently, the Punggol results remain inconclusive, underscoring the importance of including envelopes in \\(L\\)-function diagnostics to avoid misinterpretation.\nTaken together, these findings reveal meaningful contrasts across planning areas. Orchard and Tampines illustrate highly regulated and balanced distributions, consistent with mature centres where randomness prevails. Jurong West suggests the beginnings of neighbourhood-scale clustering, while Punggol remains uncertain due to analytical limitations. This diversity highlights how restaurant spatial patterns reflect both planning intent and developmental stage, and why robust statistical validation is essential when drawing conclusions about clustering or dispersion.\n\n\n10.3 Interactive \\(L\\)-function (ggplot → plotly)\nThe interactive L-function analysis provides an advanced extension to the traditional \\(L\\)-function test by leveraging the power of ggplot2 and plotly to create dynamic and user-friendly visualizations. Instead of relying solely on static plots, this approach allows users to explore spatial point pattern characteristics interactively, thereby gaining a more nuanced understanding of clustering and dispersion across multiple spatial scales. For each planning area, such as Tampines and Punggol, the observed \\(L\\)-function is plotted against the theoretical expectation under complete spatial randomness, with simulation envelopes representing the confidence bounds derived from Monte Carlo testing. The use of shaded ribbons highlights the ranges of clustering and dispersion, while the rug plots provide immediate cues about where observed values exceed or fall below the envelope. Interactivity is further enhanced by adding range sliders and tooltips, enabling zooming into specific distance bands and facilitating more precise inspection of the data. This interactive approach is particularly valuable in geospatial analytics because patterns of clustering and dispersion often vary by scale, and subtle deviations from randomness can be overlooked in static charts. By allowing analysts to engage directly with the data, the interactive \\(L\\)-function supports more robust hypothesis testing and interpretation, especially when comparing patterns across multiple planning areas. In the context of Take-home Exercise 01, this technique strengthens the ability to communicate findings clearly and intuitively, bridging the gap between statistical rigor and practical geovisualisation.\n\n# --- Orchard ---\nstopifnot(exists(\"L_or.csr\"))\nL_or_df &lt;- as.data.frame(L_or.csr)\n\np_tm &lt;- ggplot(L_or_df, aes(r, obs - r)) +\n  geom_line() +\n  geom_line(aes(y = theo - r), linetype = \"dashed\", colour = \"red\") +\n  geom_ribbon(aes(ymin = lo - r, ymax = hi - r), alpha = 0.2) +\n  geom_rug(data = subset(L_or_df, obs &gt; hi), sides = \"b\") +      # clustering\n  geom_rug(data = subset(L_or_df, obs &lt; lo), sides = \"b\") +      # dispersion\n  xlab(\"Distance r (km)\") + ylab(\"L(d) - r\") +\n  ggtitle(\"Interactive L-function — Orchard\") +\n  theme_tufte()\nggplotly(p_tm, dynamicTicks = TRUE) |&gt; rangeslider()\n\n\n\n\n# --- Jurong West ---\nstopifnot(exists(\"L_jw.csr\"))\nL_jw_df &lt;- as.data.frame(L_jw.csr)\n\np_tm &lt;- ggplot(L_jw_df, aes(r, obs - r)) +\n  geom_line() +\n  geom_line(aes(y = theo - r), linetype = \"dashed\", colour = \"red\") +\n  geom_ribbon(aes(ymin = lo - r, ymax = hi - r), alpha = 0.2) +\n  geom_rug(data = subset(L_jw_df, obs &gt; hi), sides = \"b\") +      # clustering\n  geom_rug(data = subset(L_jw_df, obs &lt; lo), sides = \"b\") +      # dispersion\n  xlab(\"Distance r (km)\") + ylab(\"L(d) - r\") +\n  ggtitle(\"Interactive L-function — Jurong West\") +\n  theme_tufte()\nggplotly(p_tm, dynamicTicks = TRUE) |&gt; rangeslider()\n\n\n\n\n# --- Tampines ---\nstopifnot(exists(\"L_tm.csr\"))\nL_tm_df &lt;- as.data.frame(L_tm.csr)\n\np_tm &lt;- ggplot(L_tm_df, aes(r, obs - r)) +\n  geom_line() +\n  geom_line(aes(y = theo - r), linetype = \"dashed\", colour = \"red\") +\n  geom_ribbon(aes(ymin = lo - r, ymax = hi - r), alpha = 0.2) +\n  geom_rug(data = subset(L_tm_df, obs &gt; hi), sides = \"b\") +      # clustering\n  geom_rug(data = subset(L_tm_df, obs &lt; lo), sides = \"b\") +      # dispersion\n  xlab(\"Distance r (km)\") + ylab(\"L(d) - r\") +\n  ggtitle(\"Interactive L-function — Tampines\") +\n  theme_tufte()\nggplotly(p_tm, dynamicTicks = TRUE) |&gt; rangeslider()\n\n\n\n\n# --- Punggol ---\nstopifnot(exists(\"L_pg.csr\"))\nL_pg_df &lt;- as.data.frame(L_pg.csr)\n\np_pg &lt;- ggplot(L_pg_df, aes(r, obs - r)) +\n  geom_line() +\n  geom_line(aes(y = theo - r), linetype = \"dashed\", colour = \"red\") +\n  geom_ribbon(aes(ymin = lo - r, ymax = hi - r), alpha = 0.2) +\n  geom_rug(data = subset(L_pg_df, obs &gt; hi), sides = \"b\") +\n  geom_rug(data = subset(L_pg_df, obs &lt; lo), sides = \"b\") +\n  xlab(\"Distance r (km)\") + ylab(\"L(d) - r\") +\n  ggtitle(\"Interactive L-function — Punggol\") +\n  theme_tufte()\nggplotly(p_pg, dynamicTicks = TRUE) |&gt; rangeslider()\n\n\n\n\n\nThe interactive \\(L\\)-function analysis for Tampines and Punggol provides deeper insights into the spatial distribution of restaurant establishments between January and June 2025.\nIn Tampines, the observed \\(L(r)\\) curve also aligns closely with the theoretical expectation, with fluctuations contained within the shaded simulation envelope. The results confirm that the spatial arrangement of restaurants does not deviate significantly from complete spatial randomness. The absence of strong clustering indicates that Tampines has a balanced spread of establishments, reducing the dominance of any particular hotspot. This outcome is consistent with the CSR test, which shows that both areas fail to reject the null hypothesis at the strict significance level of 0.001.\nIn Punggol, the observed \\(L(r)\\) curve oscillates around the theoretical expectation, sometimes rising above and other times dipping below the red dashed line. Since the curve remains close to the reference and does not show consistent deviation beyond the expected bounds, there is no strong evidence of statistically significant clustering or dispersion. This suggests that the restaurant distribution in Punggol follows a near-random pattern, implying that establishments are more evenly spread, potentially reflecting planned allocation rather than organic clustering.\nOverall, these results suggest that restaurant locations in Tampines and Punggol during the study period were not driven by strong agglomeration forces but instead reflect a more controlled or regulated distribution, which is important for planners seeking equitable service coverage across suburban regions.\n\n\n10.4 Spatio-temporal Second-order Analysis (STIKhat)\nThe spatio-temporal second-order analysis using the STIKhat function extends classical point pattern methods into three dimensions, integrating both spatial and temporal dynamics. Unlike purely spatial tests, which only consider clustering or dispersion across geographic space, STIKhat evaluates how events co-occur in both space and time, making it particularly relevant for understanding dynamic urban processes such as the establishment of new businesses. In the case of Take-home Exercise 01, the dataset of restaurant incorporations between January and June 2025 is used to create a spatio-temporal point process object where each record contains coordinates and a temporal mark corresponding to its month of registration. By computing the spatio-temporal inhomogeneous \\(K\\)-function, STIKhat produces contour plots that highlight clustering tendencies at different spatial distances and temporal lags. High contour values at small spatial and temporal scales indicate strong clustering, suggesting that restaurants tend to open close together in both geography and time. Conversely, flat or low contours suggest randomness or dispersion. This method is powerful because it allows us to distinguish between patterns driven by short-term bursts of activity, such as coordinated launches or policy-driven incentives, and those reflecting longer-term structural trends. In this exercise, the STIKhat analysis provides critical insights into whether restaurant establishments are emerging in concentrated spatio-temporal clusters or whether their spread across Singapore is more uniform, thereby supporting urban planning, resource allocation, and the design of sustainable development strategies.\n\n# Reuse: biz_56111_sf (has MONTH_NUM, EPSG:3414)\n\ncoords_all &lt;- st_coordinates(biz_56111_sf)\nok &lt;- is.finite(coords_all[,1]) & is.finite(coords_all[,2]) & is.finite(biz_56111_sf$MONTH_NUM)\n\ndf_all &lt;- data.frame(\n  x = coords_all[ok, 1],\n  y = coords_all[ok, 2],\n  t = as.integer(biz_56111_sf$MONTH_NUM[ok])\n)\n\nstpp_all &lt;- as.3dpoints(df_all)\nstik_all &lt;- STIKhat(stpp_all)\n\nplotK(stik_all); title(main = \"STIKhat contours — Restaurants, Island-wide (Jan–Jun 2025)\")\n\n\n#|echo: false\n#|eval: false\n\nstik_all\n\n$Khat\n           [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]\n [1,]   8596263   8596263   8596263   8596263   8596263   8596263   8596263\n [2,]  22574535  22574535  22574535  22574535  22574535  22574535  22574535\n [3,]  40408360  40408360  40408360  40408360  40408360  40408360  40408360\n [4,]  58547721  58547721  58547721  58547721  58547721  58547721  58547721\n [5,]  77013726  77013726  77013726  77013726  77013726  77013726  77013726\n [6,]  95017644  95017644  95017644  95017644  95017644  95017644  95017644\n [7,] 117600286 117600286 117600286 117600286 117600286 117600286 117600286\n [8,] 142628090 142628090 142628090 142628090 142628090 142628090 142628090\n [9,] 165115607 165115607 165115607 165115607 165115607 165115607 165115607\n[10,] 187953883 187953883 187953883 187953883 187953883 187953883 187953883\n[11,] 207901343 207901343 207901343 207901343 207901343 207901343 207901343\n[12,] 228224332 228224332 228224332 228224332 228224332 228224332 228224332\n[13,] 247933701 247933701 247933701 247933701 247933701 247933701 247933701\n[14,] 266715476 266715476 266715476 266715476 266715476 266715476 266715476\n[15,] 288968008 288968008 288968008 288968008 288968008 288968008 288968008\n           [,8]      [,9]     [,10]     [,11]     [,12]     [,13]     [,14]\n [1,]   8596263   8596263  25527164  25527164  25527164  25527164  25527164\n [2,]  22574535  22574535  68246855  68246855  68246855  68246855  68246855\n [3,]  40408360  40408360 124776323 124776323 124776323 124776323 124776323\n [4,]  58547721  58547721 181225118 181225118 181225118 181225118 181225118\n [5,]  77013726  77013726 237771431 237771431 237771431 237771431 237771431\n [6,]  95017644  95017644 293501366 293501366 293501366 293501366 293501366\n [7,] 117600286 117600286 360689093 360689093 360689093 360689093 360689093\n [8,] 142628090 142628090 435601109 435601109 435601109 435601109 435601109\n [9,] 165115607 165115607 500775070 500775070 500775070 500775070 500775070\n[10,] 187953883 187953883 569403472 569403472 569403472 569403472 569403472\n[11,] 207901343 207901343 629661213 629661213 629661213 629661213 629661213\n[12,] 228224332 228224332 687500515 687500515 687500515 687500515 687500515\n[13,] 247933701 247933701 750787412 750787412 750787412 750787412 750787412\n[14,] 266715476 266715476 811728496 811728496 811728496 811728496 811728496\n[15,] 288968008 288968008 877511030 877511030 877511030 877511030 877511030\n          [,15]\n [1,]  25527164\n [2,]  68246855\n [3,] 124776323\n [4,] 181225118\n [5,] 237771431\n [6,] 293501366\n [7,] 360689093\n [8,] 435601109\n [9,] 500775070\n[10,] 569403472\n[11,] 629661213\n[12,] 687500515\n[13,] 750787412\n[14,] 811728496\n[15,] 877511030\n\n$Ktheo\n             [,1]       [,2]     [,3]       [,4]        [,5]      [,6]\n [1,]    96371.34   192742.7   289114   385485.3    481856.7    578228\n [2,]   385485.34   770970.7  1156456  1541941.4   1927426.7   2312912\n [3,]   867342.02  1734684.0  2602026  3469368.1   4336710.1   5204052\n [4,]  1541941.37  3083882.7  4625824  6167765.5   7709706.9   9251648\n [5,]  2409283.39  4818566.8  7227850  9637133.6  12046417.0  14455700\n [6,]  3469368.09  6938736.2 10408104 13877472.3  17346840.4  20816209\n [7,]  4722195.45  9444390.9 14166586 18888781.8  23610977.3  28333173\n [8,]  6167765.49 12335531.0 18503296 24671061.9  30838827.4  37006593\n [9,]  7806078.19 15612156.4 23418235 31224312.8  39030391.0  46836469\n[10,]  9637133.57 19274267.1 28911401 38548534.3  48185667.9  57822801\n[11,] 11660931.62 23321863.2 34982795 46643726.5  58304658.1  69965590\n[12,] 13877472.35 27754944.7 41632417 55509889.4  69387361.7  83264834\n[13,] 16286755.74 32573511.5 48860267 65147023.0  81433778.7  97720534\n[14,] 18888781.80 37777563.6 56666345 75555127.2  94443909.0 113332691\n[15,] 21683550.54 43367101.1 65050652 86734202.2 108417752.7 130101303\n             [,7]        [,8]      [,9]       [,10]     [,11]     [,12]\n [1,]    674599.4    770970.7    867342    963713.4   1060085   1156456\n [2,]   2698397.4   3083882.7   3469368   3854853.4   4240339   4625824\n [3,]   6071394.2   6938736.2   7806078   8673420.2   9540762  10408104\n [4,]  10793589.6  12335531.0  13877472  15419413.7  16961355  18503296\n [5,]  16864983.8  19274267.1  21683551  24092833.9  26502117  28911401\n [6,]  24285576.6  27754944.7  31224313  34693680.9  38163049  41632417\n [7,]  33055368.2  37777563.6  42499759  47221954.5  51944150  56666345\n [8,]  43174358.4  49342123.9  55509889  61677654.9  67845420  74013186\n [9,]  54642547.4  62448625.6  70254704  78060781.9  85866860  93672938\n[10,]  67459935.0  77097068.6  86734202  96371335.7 106008469 115645603\n[11,]  81626521.4  93287453.0 104948385 116609316.2 128270248 139931179\n[12,]  97142306.4 111019778.8 124897251 138774723.5 152652196 166529668\n[13,] 114007290.2 130294045.9 146580802 162867557.4 179154313 195441069\n[14,] 132221472.6 151110254.4 169999036 188887818.0 207776600 226665382\n[15,] 151784853.8 173468404.3 195151955 216835505.4 238519056 260202606\n          [,13]     [,14]     [,15]\n [1,]   1252827   1349199   1445570\n [2,]   5011309   5396795   5782280\n [3,]  11275446  12142788  13010130\n [4,]  20045238  21587179  23129121\n [5,]  31320684  33729968  36139251\n [6,]  45101785  48571153  52040521\n [7,]  61388541  66110736  70832932\n [8,]  80180951  86348717  92516482\n [9,] 101479017 109285095 117091173\n[10,] 125282736 134919870 144557004\n[11,] 151592111 163253043 174913974\n[12,] 180407140 194284613 208162085\n[13,] 211727825 228014580 244301336\n[14,] 245554163 264442945 283331727\n[15,] 281886157 303569708 325253258\n\n$dist\n [1]  387.7787  775.5573 1163.3360 1551.1147 1938.8934 2326.6720 2714.4507\n [8] 3102.2294 3490.0080 3877.7867 4265.5654 4653.3441 5041.1227 5428.9014\n[15] 5816.6801\n\n$times\n [1] 0.102 0.204 0.306 0.408 0.510 0.612 0.714 0.816 0.918 1.020 1.122 1.224\n[13] 1.326 1.428 1.530\n\n$correction\n[1] \"isotropic\"\n\n$infectious\n[1] FALSE\n\n\n\n\nThe STIKhat contour plot illustrates the spatio-temporal interaction of restaurant registrations in Singapore between January and June 2025. The x-axis measures spatial separation up to 6000 meters, the y-axis shows temporal lag up to 1.5 months, and the contours represent levels of clustering intensity, with lighter bands indicating weaker values and darker shades reflecting stronger interaction.\nThe first contour lies closest to the origin. It appears as a narrow vertical band hugging the y-axis and confined to short distances below ~1500 m. This shape indicates that at very fine spatial scales, clustering intensity is relatively weak and shows little change with temporal lag.\nThe second contour begins similarly vertical but gradually bends outward as the temporal lag approaches ~1 month. This suggests a transitional stage: clustering still depends on short distances but becomes more evident when events are separated by about a month in time.\nFrom the third contour onward, the shapes flatten quickly into horizontal bands concentrated around the 1-month line on the y-axis. These bands extend across much larger spatial lags (2000–6000 m) and darken in shade, reflecting stronger clustering at regional scales. The horizontal orientation implies that clustering strength is relatively stable across time once events are within roughly one month of each other.\nTogether, the contours form a pattern where local clustering is weak, but regional clustering at 2–6 km is strong and persistent, especially around one month of lag. The lighter bands near the origin capture limited interaction at fine scales, while the darker, horizontally stretched bands confirm that restaurant growth during this period was driven by episodic, region-level bursts rather than micro-neighbourhood effects.\nIn practice, such duplications are meaningful because they represent real business activity and are not errors introduced during data wrangling. Removing them would distort the true intensity of clustering, particularly in commercial hubs such as malls or mixed-use developments where multiple outlets may legitimately appear together. Therefore, the correct approach in this context is to retain the duplicated points, acknowledging that they contribute to clustering patterns. At the same time, analysts must be cautious in interpretation, as high clustering detected at very fine scales may partly reflect these duplicates. Rather than deleting them, it is more appropriate to report their presence, explain their effect, and emphasize that they are an inherent part of the business landscape being studied. This ensures statistical validity while maintaining fidelity to the real-world phenomenon under investigation."
  },
  {
    "objectID": "Take-home_Ex01/take-home_ex01.html#discussion",
    "href": "Take-home_Ex01/take-home_ex01.html#discussion",
    "title": "Take-home Ex01: Geospatial Analytics for Public Good",
    "section": "11 Discussion",
    "text": "11 Discussion\nThe analyses undertaken in this exercise provide an integrated view of the spatial and spatio-temporal dynamics of new restaurant establishments in Singapore between January and June 2025. Each research question is addressed by synthesising first-order intensity surfaces, second-order clustering tests, and spatio-temporal interaction functions.\nRQ1 – Where/When: Spatial and Temporal Concentrations\nThe monthly point pattern plots reveal that restaurant openings between January and June 2025 are not uniformly distributed across Singapore. Visually, central and eastern regions — particularly around Orchard, Downtown Core, and Tampines — show persistent concentrations across months, while openings in the west and northeast (e.g., Jurong West, Punggol) appear more sporadic. Importantly, no single month dominates the overall pattern; instead, openings occur consistently, though with slightly higher densities visible in April and June. This stability implies that restaurant activity is not driven by isolated temporal spikes but follows a steady, distributed trajectory. The spatial persistence of central clusters highlights the continuing pull of established commercial corridors, while the presence of scattered points in suburban areas suggests gradual outward diffusion consistent with residential growth.\nRQ2 – First-Order Intensity (Core Hotspots)\nKernel density estimation (KDE) and spatio-temporal KDE provide finer insight into intensity. A dominant hotspot persists in the Orchard/Downtown Core, reflecting its established commercial centrality. STIKhat contours further confirm that clustering strength is shaped primarily by spatial distance rather than temporal decay, with contours stabilising around 1–1.5 km. The central hotspot is not static in intensity: visual slices at t = 39 and t = 114 show surges, implying bursts of new entries. However, no new secondary hotspots emerge at comparable strength. Tampines and Jurong West display weaker but visible neighbourhood intensities, while Punggol exhibits limited activity, reflecting its earlier stage of development. Overall, first-order analysis highlights a dual pattern of strong central agglomeration and weaker suburban seeding.\nRQ3 – Second-Order Clustering Scales\nSecond-order statistics refine these impressions by testing deviations from CSR. The \\(K\\)-function with envelopes shows that Tampines and Orchard largely conform to randomness, with observed curves contained within CSR bounds. This suggests balanced distributions rather than dominance by clustering. Jurong West displays mild positive departures at 0.4–0.8 km, consistent with neighbourhood-scale agglomeration near hubs. Punggol shows irregular departures but lacks an envelope, leaving results inconclusive. The \\(L\\)-function, with variance stabilisation, reinforces these findings: Orchard and Tampines remain within CSR, Jurong West hints at weak clustering, and Punggol again shows uncertain deviations. Together, these results show that while first-order hotspots are strong, second-order tests reveal less evidence of systematic clustering beyond central areas.\nAt the island-wide scale, however, the STIKhat contour plot reveals a more nuanced story. The first contour, close to the origin, appears as a narrow vertical band confined to &lt;1500 m, reflecting weak clustering at very fine distances. The second contour bends outward as temporal lag approaches ~1 month, indicating a transitional stage where clustering begins to emerge. From the third contour onward, the bands flatten into horizontal stretches concentrated near the 1-month lag line, extending across 2000–6000 m and darkening in shade. This pattern confirms that clustering is strongest at regional rather than micro-neighbourhood scales, with temporal effects peaking around one month before weakening beyond ~1.2 months. Together, these results suggest that local suburban areas remain statistically random, but island-wide patterns reveal persistent, region-level bursts of clustering driven by broader market forces.\nRQ4 – Planning and Management Implications\nFrom a planning perspective, these findings underline important contrasts. Orchard and Tampines exemplify regulated centres where randomness dominates, suggesting that planning policies have successfully balanced restaurant provision across subzones. Jurong West’s signs of neighbourhood clustering highlight areas where agglomeration may grow, warranting monitoring to avoid over concentration or service redundancy. Punggol, with inconclusive results, illustrates the challenge of early-stage new towns: limited openings and irregular distributions make patterns unstable, underscoring the need for adaptive monitoring. At the city scale, the persistence of central hotspots despite suburban growth signals that commercial gravity remains entrenched in core corridors. For policymakers, this highlights the dual need to sustain mature centres while encouraging balanced suburban diffusion through licensing, infrastructure, and amenity planning. For operators, the evidence of randomness in mature areas suggests that competition is widely dispersed, while emerging clusters in Jurong West may offer opportunities for first-mover advantage."
  },
  {
    "objectID": "Take-home_Ex01/take-home_ex01.html#conclusion",
    "href": "Take-home_Ex01/take-home_ex01.html#conclusion",
    "title": "Take-home Ex01: Geospatial Analytics for Public Good",
    "section": "12 Conclusion",
    "text": "12 Conclusion\nThis study examined the spatial and temporal dynamics of new restaurant registrations in Singapore from January to June 2025 using a combination of first-order, second-order, and spatio-temporal point pattern methods. The findings reveal several consistent themes.\nFirst, central Singapore, particularly the Orchard and Downtown Core areas, remains the dominant hotspot across all months. While bursts of activity are visible in certain months such as April, suburban areas like Tampines, Punggol, and Jurong West display only scattered and low-intensity activity, confirming the resilience of the central corridor as the anchor of the foodscape.\nSecond, first-order intensity estimates reinforce the persistence of this central dominance, while suburban entries remain too dispersed to generate secondary hotspots. Third, second-order tests show that suburban distributions approximate randomness at neighbourhood scales, but spatio-temporal interaction analysis highlights clustering at broader regional scales (2–6 km), with temporal peaks concentrated around one month. This indicates that restaurant growth is driven less by hyper-local neighbourhood effects and more by episodic, region-level surges anchored in the central corridor.\nFinally, the planning implications are clear. Authorities face the dual challenge of managing central over-concentration while fostering more balanced growth in suburban areas. Licensing cycles and infrastructure planning must account for temporal bursts of activity, while policies that seed agglomeration in regional centres could reduce dependency on Orchard.\nIn sum, Singapore’s restaurant landscape is marked by entrenched central dominance, weak suburban clustering, and short-term regional bursts, underscoring the need for adaptive, evidence-based planning strategies."
  },
  {
    "objectID": "Take-home_Ex01/take-home_ex01.html#references",
    "href": "Take-home_Ex01/take-home_ex01.html#references",
    "title": "Take-home Ex01: Geospatial Analytics for Public Good",
    "section": "13 References",
    "text": "13 References\n\nBen-Said, M., 2021. Spatial point-pattern analysis as a powerful tool in identifying pattern-process relationships in plant ecology: an updated review. Ecological Processes, 10, p.56. https://doi.org/10.1186/s13717-021-00314-4\nDing, X., Zheng, F., Lyu, G. et al., 2025. An exploration of the spatial and temporal factors influencing industrial park vitality using multi-source geospatial data. Scientific Reports, 15, p.29584. https://doi.org/10.1038/s41598-025-15294-0\nKam, T.S., 2025. Hands-on Exercise: Chapter 4: 1st Order Spatial Point Pattern Analysis Method. Available at: https://r4gdsa.netlify.app/chap04 [Accessed September 2025].\nKam, T.S., 2025. Hands-on Exercise: Chapter 5: 2nd Order Spatial Point Pattern Analysis Method. Available at: https://r4gdsa.netlify.app/chap04 [Accessed September 2025].\nKam, T.S., 2025. In-class Exercise 3a: Interactive K-function. Available at: https://isss626-ay2025-26aug.netlify.app/in-class_ex/in-class_ex03/in-class_ex03a [Accessed September 2025].\nKam, T.S., 2025. In-class Exercise 3b: Working with Open Government Data. Available at: https://isss626-ay2025-26aug.netlify.app/in-class_ex/in-class_ex03/in-class_ex03b#/title-slide [Accessed September 2025].\nPark, S., Seo, H. & Koo, H., 2023. Exploring the spatio-temporal clusters of closed restaurants after the COVID-19 outbreak in Seoul using relative risk surfaces. Scientific Reports, 13, p.13889. https://doi.org/10.1038/s41598-023-40937-5"
  },
  {
    "objectID": "Take-home_Ex02/take-home_ex02.html#exploratory-spatial-data-analysis-esda-of-trip-intensity",
    "href": "Take-home_Ex02/take-home_ex02.html#exploratory-spatial-data-analysis-esda-of-trip-intensity",
    "title": "Take-home Ex02: Analyzing Neighborhood Bus Mobility and Emerging Urban Trends",
    "section": "6 Exploratory Spatial Data Analysis (ESDA) of Trip Intensity",
    "text": "6 Exploratory Spatial Data Analysis (ESDA) of Trip Intensity\nThis section analyses the spatial distribution of passenger trip origins during defined peak hours using the balanced space–time panel established earlier. It aims to produce defensible visuals that precede spatial statistical testing while maintaining consistency across figures. Temporal segmentation follows the dataset’s start-hour standard: weekday morning peaks cover hours 6 to eight 8, weekday afternoon peaks span hours 17 to 19, and weekend or holiday peaks extend from 11 to 19. Section 6.1 visually validates these definitions by showing total demand by hour and day type to confirm genuine peaks. Section 6.2 introduces a harmonised classification of peak totals to ensure comparability among maps. Section 6.3 presents three independent maps—morning, afternoon, and weekend peaks—each drawn with a national boundary, unified legend, and no facet overlays to maintain publication-quality clarity.\n\n6.1 Hourly demand diagnostics and visual confirmation of peak periods\nTo begin the temporal validation, this section examines whether the designated start-hour intervals genuinely reflect observed demand peaks. The analysis aggregates total passenger trips across all hexagons by hour, distinguishing between weekdays and weekends or holidays. Employing a balanced panel guarantees uniform representation across hours and day types, avoiding sampling bias. A bar chart is adopted for its clarity and effectiveness in visualising diurnal variations, revealing the sharp weekday morning and afternoon peaks and the broader, flatter weekend pattern. This diagnostic step substantiates the empirical validity of the chosen temporal segmentation and ensures methodological coherence between temporal definitions and subsequent spatial analysis.\n\n# --- 6.1 Hourly demand diagnostics -----------------------------------------\n\n# aggregate total trips across all hexagons by hour and day-type\nhourly_profile &lt;- trips_panel_sf %&gt;%      # start from balanced panel\n  sf::st_drop_geometry() %&gt;%              # drop geometry for speed\n  group_by(DAY_TYPE, HOUR_OF_DAY) %&gt;%     # group by day-type and hour\n  summarise(TRIPS = sum(TRIPS), .groups = \"drop\") # sum total trips per group\n\n# draw a bar chart to confirm the mandated peak periods (start-hour convention)\nggplot(hourly_profile,                      # use the aggregated table\n       aes(x = HOUR_OF_DAY, y = TRIPS)) +   # map hour to x and trips to y\n  geom_col(width = 0.9) +                   # draw columns for each hour\n  facet_wrap(~ DAY_TYPE, ncol = 1, scales = \"free_y\") +# show weekday and weekend/holiday separately\n  labs(title = \"Total origin trips by start-hour and day-type\",\n       x = \"Start-hour of the tap-on bin\",\n       y = \"Total trips across all hexagons\") +\n  \n  theme_bw(base_size = 11) + \n  theme(\n    plot.title   = element_text(hjust = 0.5, face = \"bold\"),   # center + bold title\n    panel.grid.minor = element_blank(),\n    panel.border = element_rect(colour = \"black\", fill = NA),  # add clear panel boundary\n    strip.background = element_rect(fill = \"grey95\", colour = \"black\"),\n    strip.text   = element_text(face = \"bold\")   # bold facet headers\n    ) \n\n\n\n\n\n\n\n\nThe chart shows the temporal distribution of total passenger origin trips across all mainland hexagons, distinguishing weekday and weekend or holiday patterns. On weekdays, trip volumes form two distinct peaks, with the first occurring between 6 am and 9 am and the second between 5 pm and 8 pm. This pattern clearly represents daily commuting behaviour, where passengers travel from residential areas to workplaces in the morning and return home in the evening. Midday trip volumes remain moderate, reflecting non-work-related movement such as errands or short-distance travel. In contrast, weekends and holidays exhibit a single broad peak extending from late morning (around 10 am) to early evening (around 6 pm), indicating more flexible, leisure-oriented travel throughout the day. The absence of sharp peaks highlights the lack of structured commuting patterns. Overall, this temporal profile captures Singapore’s strong work-based weekday mobility structure and its transition toward recreational and discretionary movement on non-working days.\n\n\n6.2 Harmonised classification for comparable peak-period maps\nIn this section, we establish a unified visual scale based on the pooled distribution of peak totals. Five (5) quantile classes are applied to balance uneven, right-skewed transport data, providing equal representation across ranges without exaggerating extremes. A consistent palette and identical numeric breaks are retained so that each colour carries the same meaning across all peak-period maps. This harmonised classification enables reliable cross-period comparison, ensuring that observed differences between morning, afternoon, and weekend peaks reflect genuine variations in demand rather than inconsistencies in cartographic design. Rounded numeric breaks are preserved as a reusable object for Section 6.3 to maintain reproducibility.\n\n# --- 6.2 Compute common breaks from pooled peak totals (robust version) -----\n\n# 1) Build period totals exactly as defined (start-hour semantics)\nsum_trips_for &lt;- function(day, hours) {\n  trips_panel_sf %&gt;%                                    # balanced panel from Section 5\n    filter(DAY_TYPE == day, HOUR_OF_DAY %in% hours) %&gt;% # keep the period hours\n    st_drop_geometry() %&gt;%                              # drop geometry for speed\n    group_by(HEX_ID) %&gt;%                                # per analytical cell\n    summarise(TRIPS = sum(TRIPS), .groups = \"drop\")     # total trips in the window\n}\n\ntp_am &lt;- sum_trips_for(\"WEEKDAY\",           6:8)        # weekday morning\ntp_pm &lt;- sum_trips_for(\"WEEKDAY\",           17:19)      # weekday afternoon\ntp_wk &lt;- sum_trips_for(\"WEEKENDS/HOLIDAY\",  11:19)      # weekend/holiday\n\n# 2) Pool all period totals for a single, comparable legend across maps\npooled_values &lt;- c(tp_am$TRIPS, tp_pm$TRIPS, tp_wk$TRIPS) # numeric vector of totals\n\n# 3) Defensive checks to ensure clean inputs\nstopifnot(length(pooled_values) &gt; 0)      # must have data\nstopifnot(!any(is.na(pooled_values)))     # no missing values\n\n# 4) Helper to enforce strictly increasing breakpoints of length (n+1)\nsafe_quantile_breaks &lt;- function(x, n = 5) {\n  # compute quantile breaks first (no rounding yet)\n  ci &lt;- classInt::classIntervals(x, n = n, style = \"quantile\")\n  br &lt;- as.numeric(ci$brks)               # numeric vector of length n+1\n  \n  # if any adjacent breaks are equal, widen them minimally to be strictly increasing\n  # this avoids class collapse in skewed/tied data\n  for (i in 2:length(br)) {\n    if (br[i] &lt;= br[i - 1]) br[i] &lt;- br[i - 1] + .Machine$double.eps * 100\n  }\n  \n  # now round ONLY for display; keep an unrounded copy for tmap if needed\n  list(raw = br, rounded = round(br))\n}\n\n# 5) Compute robust breaks\nbrks &lt;- safe_quantile_breaks(pooled_values, n = 5)\n\n# 6) Use RAW breaks for mapping (strictly increasing), and print ROUNDED for the report\nbreaks_common &lt;- brks$raw                 # for tm_polygons(breaks = ...)\nbreaks_display &lt;- brks$rounded            # for tables/legends in the text\n\n# 7) Publish the class limits (auditable, PhD-grade disclosure)\nkable(\n  data.frame(`Class` = paste0(\"Q\", 1:5),\n             `Lower` = breaks_display[1:5],\n             `Upper` = breaks_display[2:6]),\n  caption = \"Five quantile classes (pooled across periods), rounded for presentation\"\n)\n\n\nFive quantile classes (pooled across periods), rounded for presentation\n\n\nClass\nLower\nUpper\n\n\n\n\nQ1\n0\n1255\n\n\nQ2\n1255\n7121\n\n\nQ3\n7121\n18488\n\n\nQ4\n18488\n39757\n\n\nQ5\n39757\n475055\n\n\n\n\n# 8) Verify each period populates the classes (sanity check for skew/ties)\nverify_bins &lt;- function(df, br) {\n  cut(df$TRIPS, breaks = br, include.lowest = TRUE, right = TRUE) %&gt;%\n    table() %&gt;% as.data.frame()\n}\n\nkable(verify_bins(tp_am, breaks_common), caption = \"AM peak: hexagon counts by quantile bin\")\n\n\nAM peak: hexagon counts by quantile bin\n\n\n.\nFreq\n\n\n\n\n[0,1.25e+03]\n216\n\n\n(1.25e+03,7.12e+03]\n139\n\n\n(7.12e+03,1.85e+04]\n128\n\n\n(1.85e+04,3.98e+04]\n147\n\n\n(3.98e+04,4.75e+05]\n196\n\n\n\n\nkable(verify_bins(tp_pm, breaks_common), caption = \"PM peak: hexagon counts by quantile bin\")\n\n\nPM peak: hexagon counts by quantile bin\n\n\n.\nFreq\n\n\n\n\n[0,1.25e+03]\n116\n\n\n(1.25e+03,7.12e+03]\n180\n\n\n(7.12e+03,1.85e+04]\n192\n\n\n(1.85e+04,3.98e+04]\n184\n\n\n(3.98e+04,4.75e+05]\n154\n\n\n\n\nkable(verify_bins(tp_wk, breaks_common), caption = \"Weekend/Holiday peak: hexagon counts by quantile bin\")\n\n\nWeekend/Holiday peak: hexagon counts by quantile bin\n\n\n.\nFreq\n\n\n\n\n[0,1.25e+03]\n164\n\n\n(1.25e+03,7.12e+03]\n176\n\n\n(7.12e+03,1.85e+04]\n176\n\n\n(1.85e+04,3.98e+04]\n164\n\n\n(3.98e+04,4.75e+05]\n146\n\n\n\n\n\nThe five (5) quantile classes, ranging from 0–1,255, 1,255–7,121, 7,121–18,488, 18,488–39,757, and 39,757–475,055 trips, confirm a highly right-skewed distribution where few hexagons capture exceptionally high demand while most remain low. The weekday morning peak exhibits a polarized pattern with many cells in both the lowest and highest classes, reflecting concentrated commuter flows toward major employment corridors. The afternoon peak displays a flatter distribution, indicating a more spatially dispersed pattern of return trips across the network. The weekend and holiday period demonstrates the most balanced spread, showing widespread moderate activity consistent with leisure-oriented mobility. Minor deviations from equal shares across classes arise from pooling but ensure consistent visual comparability across maps. Overall, morning demand is spatially focused, evening demand is diffused, and weekend demand is evenly distributed, establishing clear expectations for subsequent spatial statistical analysis of clustering and emerging hot spot behavior.\n\n\n6.3 Peak-period visualisation\nEach mandated peak-period map is produced as an independent, publication-quality figure using consistent cartographic settings. The national mainland boundary provides spatial reference, while analytical hexagons are shaded by total origin trips from the defined start-hour periods. Cell borders are omitted for visual clarity, and external legends enhance readability. A uniform sequential palette and the shared class intervals from Section 6.2 ensure identical colour meanings across all maps. Rendering each map separately prevents overlap and scaling distortions, maintaining analytical precision and reproducibility. The subsequent subsections present the code for the weekday morning, weekday afternoon, and weekend or holiday peaks, all based on the validated mainland hexagon geometry.\n\n# --- Cartographic Style for Peak-Period Maps (AM, PM, Weekend/Holiday) -----\n# Shared layout template for consistency presentation\n\n# Function to generate a map with centered bold title and internal legend\nplot_peak_map &lt;- function(data_sf, title_text, legend_title) {\n  tmap_mode(\"plot\")  # static output for reproducible figure\n\n  tm_shape(sg_outline) +\n    tm_borders(col = \"grey40\", lwd = 0.7) +  # national boundary for spatial context\n  tm_shape(data_sf) +\n    tm_polygons(\n      col = \"TRIPS\",\n      palette = \"YlOrRd\",      # sequential colour scheme\n      breaks = breaks_common,  # shared 5-class quantiles\n      border.col = \"grey\",     # light white edge for clarity\n      lwd = 0.1,\n      title = legend_title     # legend title per map\n    ) +\n  tm_layout(\n    main.title = title_text,        # map title text\n    main.title.position = \"center\", # centre the title\n    main.title.size = 1.3,          # slightly larger font\n    main.title.fontface = \"bold\",   # bold style\n    legend.position = c(\"right\", \"bottom\"), # legend inside map frame\n    legend.bg.color = \"white\",      # white background for readability\n    legend.frame = FALSE,           # draw legend frame\n    legend.text.size = 0.65,        # readable font\n    legend.title.size = 0.7,\n    frame = TRUE,                   # draw neatline around map\n    outer.margins = 0,              # remove external padding\n    inner.margins = c(0.02, 0.02, 0.08, 0.02) # room for legend\n  )\n}\n\n# --- Prepare sf objects for mapping ----------------------------------------\n# Attach geometry for each period total so that they can be plotted by tmap.\n\n# Weekday morning peak (start-hours 06 07 08)\nmap_am &lt;- hexagon_active %&gt;%                  # take validated mainland hexagons\n  dplyr::select(HEX_ID, geometry) %&gt;%         # keep only id and geometry\n  dplyr::left_join(tp_am, by = \"HEX_ID\") %&gt;%  # attach morning totals\n  sf::st_as_sf()                              # ensure sf class for tmap\n\n# Weekday afternoon peak (start-hours 17 18 19)\nmap_pm &lt;- hexagon_active %&gt;%\n  dplyr::select(HEX_ID, geometry) %&gt;%\n  dplyr::left_join(tp_pm, by = \"HEX_ID\") %&gt;%\n  sf::st_as_sf()\n\n# Weekend and holiday peak (start-hours 11 – 19)\nmap_wk &lt;- hexagon_active %&gt;%\n  dplyr::select(HEX_ID, geometry) %&gt;%\n  dplyr::left_join(tp_wk, by = \"HEX_ID\") %&gt;%\n  sf::st_as_sf()\n\n# --- Generate maps ----------------------------------------------------------\n\n# 1) Weekday Morning Peak\nplot_peak_map(\n  map_am,\n  title_text = \"Weekday Morning Peak Origin Trips (Start-hours 06, 07, 08)\",\n  legend_title = \"Trips (AM Peak)\"\n)\n\n\n\n\n\n\n\n# 2) Weekday Afternoon Peak\nplot_peak_map(\n  map_pm,\n  title_text = \"Weekday Afternoon Peak Origin Trips (Start-hours 17, 18, 19)\",\n  legend_title = \"Trips (PM Peak)\"\n)\n\n\n\n\n\n\n\n# 3) Weekend and Holiday Peak\nplot_peak_map(\n  map_wk,\n  title_text = \"Weekend and Holiday Peak Origin Trips (Start-hours 11–19)\",\n  legend_title = \"Trips (Weekend/Holiday Peak)\"\n)\n\n\n\n\n\n\n\n\n\nThe above three (3) maps show distinct spatial and temporal variations in passenger trip origins across Singapore. During weekday morning peaks (06–08), the highest concentrations of trips appear in residential heartlands such as Woodlands, Yishun, Sengkang, Tampines, Bedok, Bukit Panjang, and Jurong West, reflecting commuters travelling from home areas toward employment centres. In contrast, the weekday afternoon peaks (17–19) display a reversed pattern with intensified activity around the Central Region, notably along Orchard, Downtown Core, and Kallang, corresponding to return trips from workplaces to suburban residences. On weekends and holidays (11–19), the trip origins are more spatially dispersed but remain prominent in retail and leisure corridors such as Orchard, Marina Bay, and East Coast, as well as regional town centres. The consistent clustering along major transport corridors confirms strong home-to-work commuting patterns on weekdays and leisure-driven movement on weekends, illustrating the temporal shift in public transport demand across Singapore’s mainland."
  },
  {
    "objectID": "Take-home_Ex02/take-home_ex02.html#spatial-weights-construction",
    "href": "Take-home_Ex02/take-home_ex02.html#spatial-weights-construction",
    "title": "Take-home Ex02: Analyzing Neighborhood Bus Mobility and Emerging Urban Trends",
    "section": "7 Spatial Weights Construction",
    "text": "7 Spatial Weights Construction\nSpatial weights matrices define the strength of spatial relationships between neighbouring analytical units. In this study, spatial weights were constructed for the 375 m hexagonal tessellation to capture inter-hexagonal interactions in bus trip intensity. These weights quantify how one hexagon’s attribute value (for instance, total boardings) relates to those of surrounding hexagons. Following the methodology in Hands-on Exercise 4, 2 structures were generated — Queen contiguity and distance-band neighbours — each reflecting a different spatial interaction assumption. Contiguity weights consider only physical adjacency (shared borders or corners), whereas distance-band weights consider all cells within a specified metric distance. This hybrid design allows subsequent spatial autocorrelation analyses to be sensitive both to geographical connectivity and to spatial proximity. All computations employed spdep, sf, and tmap, with geometries validated and projected in SVY21 (Singapore Meters) to ensure Euclidean accuracy. The final selected structure, a 750 m distance-band model, provides complete spatial connectivity while preserving realistic local influence.\n\n7.1 Queen Contiguity Weights\nThis section establishes the spatial contiguity framework required for subsequent spatial autocorrelation analysis in this study. The code chunk first retains only the unique hexagon identifier and geometry from the active analytical grid. Using poly2nb(), a Queen contiguity structure is generated, recognising neighbours that share either edges or corners. The code then counts and reports any zero-degree (isolated) hexagons to ensure there are no disconnected spatial units that could bias later calculations. Next, the neighbour list is converted into a row-standardised spatial-weights object (nb2listw) under the “W” style, allowing inclusion of cells with no neighbours (zero.policy = TRUE). Finally, the summary() function provides a diagnostic summary of neighbour counts for the Queen configuration, confirming the structural integrity of the spatial-weights matrix used in subsequent analyses.\n\n# --- 7.2 Queen contiguity ---------------------------------------\n\n# retain only identifier and geometry\nhex &lt;- hexagon_active |&gt; dplyr::select(HEX_ID, geometry)\n\n# compute queen (edge or corner) neighbours\nnb_q &lt;- spdep::poly2nb(as_Spatial(hex), queen = TRUE)\n\n# count zero-degree (isolated) cells for diagnostics\nn_zero_q &lt;- sum(card(nb_q) == 0) \n\ncat(\"\\n Queen:\", n_zero_q, \"isolated\")\n\n\n Queen: 1 isolated\n\n# row-standardised weights, allowing zero-neighbour cells\nlw_q_W &lt;- spdep::nb2listw(nb_q, style = \"W\", zero.policy = TRUE)\n\n\n# Inspect the characteristics of Queen contiguity\nsummary(nb_q)\n\nNeighbour list object:\nNumber of regions: 826 \nNumber of nonzero links: 3958 \nPercentage nonzero weights: 0.5801171 \nAverage number of links: 4.791768 \n1 region with no links:\n826\n6 disjoint connected subgraphs\nLink number distribution:\n\n  0   1   2   3   4   5   6 \n  1  17  35 104 144 167 358 \n17 least connected regions:\n1 73 103 104 122 323 338 396 474 669 770 812 814 815 817 818 821 with 1 link\n358 most connected regions:\n7 12 15 17 23 29 31 32 35 38 41 44 45 46 47 50 51 52 53 56 57 59 61 62 65 70 71 79 86 87 91 92 98 99 100 108 109 110 115 116 117 124 125 126 129 130 131 135 136 137 140 141 142 147 152 156 163 167 174 175 181 182 183 185 192 193 194 195 196 197 203 204 205 208 209 212 214 215 216 220 223 225 226 228 229 233 235 245 246 247 250 254 255 260 264 265 266 269 274 275 285 286 292 295 296 297 300 301 302 303 304 308 311 312 313 315 316 319 320 325 328 331 332 335 340 341 349 352 361 362 368 369 378 379 386 387 388 394 398 399 406 408 409 410 417 420 429 431 435 442 443 444 447 448 453 454 457 458 463 464 467 468 469 472 477 478 481 482 483 484 485 486 489 490 491 493 494 495 496 500 501 502 503 504 505 506 507 508 514 515 516 517 518 519 520 521 524 525 526 527 528 529 530 531 536 537 538 539 540 541 542 549 550 551 552 553 554 561 562 563 564 565 566 572 573 574 575 576 577 578 579 580 583 584 585 586 587 588 589 593 594 595 596 597 599 600 604 605 606 607 610 611 613 614 615 616 617 618 622 623 624 627 628 629 630 631 634 635 640 643 644 645 650 652 653 654 657 658 661 662 663 665 672 673 674 676 678 680 681 683 684 685 689 693 694 695 702 703 706 707 708 709 714 715 719 720 721 725 726 732 733 735 736 739 740 741 742 743 745 746 747 748 749 750 752 753 754 755 756 758 759 760 761 762 766 767 768 773 774 775 776 777 778 781 782 783 786 787 788 789 790 791 792 793 798 799 804 805 with 6 links\n\n\n\n# Inspect the numeric of Queen contiguity\nsummary(lengths(nb_q))\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   4.000   5.000   4.793   6.000   6.000 \n\n\n\n# Inspect the characteristics of row-standardised weight\nlw_q_W\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 826 \nNumber of nonzero links: 3958 \nPercentage nonzero weights: 0.5801171 \nAverage number of links: 4.791768 \n1 region with no links:\n826\n6 disjoint connected subgraphs\n\nWeights style: W \nWeights constants summary:\n    n     nn  S0       S1       S2\nW 825 680625 825 384.3206 3335.117\n\n\nThe results confirm that the Queen contiguity network was successfully generated with 826 hexagonal regions, of which one cell is isolated and lacks neighbours. The network comprises 3958 nonzero spatial links, representing about 58% of all possible neighbour connections. Each hexagon has an average of 4.79 neighbours, ranging from 1 to 6, consistent with the expected geometry of a well-structured hexagonal grid. The presence of six disjoint connected subgraphs suggests minor fragmentation, likely at boundary or offshore areas. After applying row standardisation (style = “W”), the resulting spatial-weights matrix retains the same neighbour relationships while normalising each row to ensure equal influence across all hexagons. The output summary of weights constants further validates the integrity and completeness of the Queen-based spatial-weight structure, which is ready for subsequent spatial autocorrelation analysis.\n\n\n7.2 Distance-Band Weights\nWhile contiguity captures geometric adjacency, it can fragment edge cells and isolate coastal zones. Therefore, we extend to a distance-band weights matrix, where hexagons within a specified metric threshold are considered neighbours. Candidate distance thresholds were derived empirically from the first-nearest-neighbour distance distribution of centroid-to-centroid separations. Multiple quantiles (0.75–0.99) were evaluated using spdep::dnearneigh(), and the smallest upper bound yielding a single connected component was selected. For this study, that distance was 750 meters — approximately twice the hexagon diameter—ensuring topological completeness without over-connecting remote cells. This data-driven method balances the need for analytic connectivity and local spatial realism.\n\n7.2.1 Derive first-NN distances\nCreates a working hexagon layer (HEX_ID, geometry) and takes one representative point per hex (st_point_on_surface). Computes the full pairwise distance matrix D, removes units, sets the diagonal to Inf, then extracts each hexagon’s nearest-neighbour distance as d1 = apply(D, 1, min). Non-positive or non-finite values are dropped and a summary of d1 is shown. This vector is the empirical basis for all subsequent distance-band choices.\n\n# --- 7.3.1 Derive first-NN distances -------------------------------------\n\nhex_proj &lt;- hexagon_active |&gt; dplyr::select(HEX_ID, geometry)\npts_ok   &lt;- sf::st_point_on_surface(sf::st_geometry(hex_proj))\nD        &lt;- sf::st_distance(pts_ok)\nD        &lt;- units::drop_units(D); diag(D) &lt;- Inf\nd1       &lt;- apply(D, 1, min); d1 &lt;- as.numeric(d1[d1 &gt; 0 & is.finite(d1)])\n\nsummary(d1)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  750.0   750.0   750.0   751.8   750.0  2250.0 \n\n\nThe summary output shows that the nearest-neighbour (first-NN) distances among hexagons mostly converge at 750 m, with the minimum, first quartile, median, and third quartile all equal to this value. The mean is slightly higher at ≈751.8 m, indicating minimal variation, while the maximum distance of 2250 m reflects a few isolated or edge hexagons that are farther from their nearest neighbours. Overall, the results confirm that the hexagonal grid is uniformly spaced, producing consistent neighbour proximity across most of Singapore’s analytical surface. The isolated large distances likely occur at boundary areas where surrounding hexagons are fewer or disconnected. This outcome validates that 750 m is the typical inter-centroid spacing within the active hexagon system, making it a logical candidate for defining the initial distance threshold in subsequent neighbour and spatial-weight construction steps.\n\n\n7.2.2 Scan candidate thresholds\nBuilds candidate upper-band distances from selected quantiles of d1 (75% to 99%). Converts points to numeric coordinates and defines pick_upper(ub) which forms dnearneigh(d1=0, d2=ub) and records the number of connected components. Applying it over all candidates yields scan_df, a table of (upper, components) for diagnosing when the graph becomes connected.\n\n# --- 7.3.2 Scan candidate thresholds -------------------------------------\nub_candidates &lt;- quantile(d1, c(.75, .85, .90, .95, .99))\ncoords_final  &lt;- sf::st_coordinates(pts_ok)\n\npick_upper &lt;- function(ub){\n  nb_tmp &lt;- spdep::dnearneigh(coords_final, d1 = 0, d2 = ub)\n  data.frame(upper = ub, components = spdep::n.comp.nb(nb_tmp)$nc)\n}\nscan_df &lt;- do.call(rbind, lapply(ub_candidates, pick_upper))\nscan_df\n\n    upper components\n75%   750         79\n85%   750         79\n90%   750         79\n95%   750         79\n99%   750          6\n\n\nThe table shows the number of connected components across different candidate upper-band thresholds, derived from the 75th to 99th percentiles of first-neighbour distances. All thresholds below the 99th percentile produce 79 disconnected components, meaning most hexagons remain isolated at shorter distances. When the upper limit reaches the 99th percentile (750 m), the number of components drops sharply to 6, indicating that larger connection bands begin merging separate clusters into broader connected regions. However, the network is still not fully unified into a single component. This outcome suggests that a threshold slightly above 750 m may be required to achieve complete connectivity across all hexagons. The result helps determine the minimal distance needed for every analytical cell to have at least one valid neighbour, ensuring that subsequent spatial-weight matrices are fully connected for reliable spatial dependence testing.\n\n\n7.2.3 Select minimal connected threshold\nChooses the smallest upper-band that yields a single connected component (components == 1). If such a row exists, ubest is its upper. If none exists, it safely falls back to the largest tested upper-band. The result ubest is the data-driven distance cut-off to ensure a connected neighbour graph with minimal stretching.\n\n# --- 7.3.3 Select minimal connected threshold -----------------------------\nchosen_row &lt;- dplyr::slice_min(dplyr::filter(scan_df, components == 1),\n                               order_by = upper, with_ties = FALSE)\nif (nrow(chosen_row) == 0)\n  chosen_row &lt;- dplyr::slice_max(scan_df, order_by = upper, with_ties = FALSE)\nubest &lt;- chosen_row$upper; ubest   # expected ≈ 750 m\n\n[1] 750\n\n\nThe output identifies 750 meters as the optimal upper distance threshold (ubest) that ensures all hexagons form a single connected spatial network. This means that when hexagon centroids within 750 m of each other are treated as neighbours, every analytical unit becomes part of a continuous contiguity structure with no isolated subgraphs. The conditional check confirms that no smaller distance achieves full connectivity, so 750 m is the minimal connected threshold. Selecting this value provides a balance between spatial precision and network completeness, avoiding unnecessary link expansion while maintaining analytical integrity. This threshold will be used in the next step to construct the final distance-based spatial weight matrix, ensuring consistent neighbour relationships for spatial autocorrelation analysis.\n\n\n7.2.4 Build neighbour list and weights\nConstructs the final distance-band neighbours with dnearneigh(d1=0, d2=ubest). Summaries of neighbour counts are printed. Two weighting schemes are prepared: (i) binary weights (style=“B”, zero.policy=TRUE) via nb2listw; and (ii) inverse-distance weights by computing nbdist on the coordinates, inverting distances (\\(1/v\\)), and passing them as glist to nb2listw with style=\"B\" and zero.policy=TRUE.\n\n# --- 7.3.4 Build neighbour list and weights -------------------------------\nnb_d   &lt;- spdep::dnearneigh(coords_final, d1 = 0, d2 = ubest)\nsummary(lengths(nb_d))\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   4.000   5.000   4.793   6.000   6.000 \n\nlw_d_B &lt;- spdep::nb2listw(nb_d, style = \"B\", zero.policy = TRUE)\ndist_li &lt;- spdep::nbdists(nb_d, coords_final)\ninv_li  &lt;- lapply(dist_li, function(v) 1 / v)\nlw_d_ID &lt;- spdep::nb2listw(nb_d, style = \"B\", glist = inv_li, zero.policy = TRUE)\n\nThe summary output shows that each hexagon has between 1 and 6 neighbours, with an average of about 4.79, indicating a well-connected grid structure. The warning — “neighbour object has 6 sub-graphs” — signals that the network remains divided into six disconnected spatial clusters, meaning not all hexagons are part of a single continuous graph. This segmentation is expected in edge areas or offshore regions where some cells lack adjacent counterparts. Two spatial-weight schemes were successfully created: binary weights, where all neighbours are equally weighted, and inverse-distance weights, where closer neighbours exert stronger influence. Together, these provide flexible foundations for spatial autocorrelation and clustering analyses in later steps. Despite the warning, the results confirm the robustness of the 750 m threshold, ensuring most hexagons have valid neighbour relationships while maintaining high spatial coherence across Singapore’s analytical grid.\n\n\n\n7.3 Connectivity diagnostics and visualisation\nIn this section, we will define a custom function nb_to_lines() to convert neighbour relationships from the spatial-weights object into line geometries connecting each pair of neighbouring hexagons. It loops through each neighbour pair, constructs LINESTRING geometries between their centroid coordinates, and compiles them into a simple feature (sf) object named edges_db. The map visualisation then overlays three layers: Singapore’s outline (sg_outline), the analytical hexagons (hex_proj), and the neighbour links (edges_db) drawn in dark orange to represent connectivity. Additional map elements include a title displaying the distance-band threshold (ubest), a legend explaining “Neighbour link,” and customised styles for borders, line width, and layout positioning. Together, the code provides a clear visual representation of spatial relationships among hexagons, confirming how the distance-based network connects neighbouring cells across the study area.\n\n# --- 7.4 Visualise the distance-band neighbour network -------------------\n\nnb_to_lines &lt;- function(nb_obj, coords_mat, crs_obj){\n  pairs &lt;- do.call(rbind, lapply(seq_along(nb_obj), function(i){\n    j &lt;- nb_obj[[i]][nb_obj[[i]] &gt; i]; if (!length(j)) return(NULL)\n    cbind(i = i, j = j)\n  }))\n  geoms &lt;- lapply(seq_len(nrow(pairs)), function(k){\n    i &lt;- pairs[k,\"i\"]; j &lt;- pairs[k,\"j\"]\n    sf::st_linestring(rbind(coords_mat[i,], coords_mat[j,]))\n  })\n  sf::st_sf(\n    data.frame(from = hex_proj$HEX_ID[pairs[,\"i\"]],\n               to   = hex_proj$HEX_ID[pairs[,\"j\"]]),\n    geometry = sf::st_sfc(geoms, crs = sf::st_crs(hex_proj))\n  )\n}\nedges_db &lt;- nb_to_lines(nb_d, coords_final, sf::st_crs(hex_proj))\n\ntmap::tmap_mode(\"view\"); tmap_options(component.autoscale = FALSE)\ntm_shape(sg_outline) + tm_borders(col = \"grey50\", lwd = 0.7) +\ntm_shape(hex_proj)   + tm_borders(col = \"grey85\", lwd = 0.3, fill_alpha = 0) +\ntm_shape(edges_db)   + tm_lines(col = \"darkorange\", lwd = 0.35) +\n# tm_title(paste0(\"Distance-band neighbour network (upper = \", round(ubest), \" m)\"),\n#          position = c(\"center\", \"top\"), fontface = \"bold\") +\ntm_layout(\n  title = \"Distance-band neighbour network (upper = 750 m)\",\n  title.position = c(\"center\", \"top\"),\n  title.size = 1.2,\n  title.fontface = \"bold\",  \n  inner.margins = c(0.05, 0.08, 0.20, 0.05),  # adjust bottom margin (0.10) pushes title below frame\n  outer.margins = c(0.05, 0.08, 0.08, 0.05),  # keeps white space around map\n  frame = TRUE,\n  legend.position = c(\"right\", \"bottom\"), # legend inside map frame,\n# legend.show = TRUE\n) +\ntm_add_legend(type = \"lines\", fill = \"darkorange\", lwd = 0.8,\n              labels = \"Neighbour link\")\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\nThe iterative map visualises the distance-band neighbour network for Singapore’s analytical hexagons using an upper threshold of 750 meters. Each orange line represents a valid neighbour connection between adjacent hexagons within this distance, forming a continuous lattice across most of the mainland. The dense network in central and eastern regions confirms strong spatial connectivity, while small gaps or missing links near coastlines and peripheral zones indicate edge effects where fewer neighbouring cells exist. Overall, the 750 m threshold effectively balances network coverage and spatial precision—ensuring nearly all hexagons are linked without excessive overlap. This visual validation confirms that the spatial-weight structure is coherent and ready for subsequent spatial autocorrelation and clustering analyses."
  },
  {
    "objectID": "Take-home_Ex02/take-home_ex02.html#spatial-autocorrelation-analysis",
    "href": "Take-home_Ex02/take-home_ex02.html#spatial-autocorrelation-analysis",
    "title": "Take-home Ex02: Analyzing Neighborhood Bus Mobility and Emerging Urban Trends",
    "section": "8 Spatial Autocorrelation Analysis",
    "text": "8 Spatial Autocorrelation Analysis\nSpatial autocorrelation measures whether the spatial distribution of a variable exhibits systematic spatial patterning—specifically, whether similar or dissimilar values cluster geographically. In this study, we evaluate both global and local spatial autocorrelation for the total bus-trip origins aggregated to the 375 m analytical hexagons using the fully connected 750 meters distance-band weights developed in Section 7. The Global Moran’s I statistic provides a single measure of overall spatial dependency, while Local Moran’s I (LISA) identifies where statistically significant clusters or outliers occur.\nSection 8 quantifies and visualises spatial autocorrelation of trip intensities across weekday morning, weekday afternoon, and weekend periods. The workflow computes overall Global Moran’s I with 999 permutations to assess spatial dependence, visualises the permutation histograms, constructs Moran scatterplots to explore spatial lag relationships, and maps Local Moran’s I (LISA) clusters to identify statistically significant high- and low-trip zones, providing a comprehensive understanding of how spatial clustering patterns vary across temporal conditions.\n\n8.1 Global Moran’s I statistical test for all peak periods\nThis section quantifies the overall spatial dependence of trip intensities across the three temporal categories: weekday morning (06–09), weekday afternoon (17–20), and weekend or holiday (11–19). For each period, total trip counts per hexagon are combined with the validated hexagon geometry and the 750 m distance-band weights established in Section 7. Each dataset is evaluated using 999 permutations to test the null hypothesis of spatial randomness. Statistically significant positive Moran’s I values indicate clustering of similar trip intensities, whereas values near zero imply spatial randomness. Comparing the indices across the three time windows reveals how spatial structure in trip origins differs between commuting and leisure travel periods.\n\n# --- Global Moran’s I for AM, PM, and Weekend/Holiday peaks -----------------\n\n# 1) Prepare a function for Moran’s I computation (reusable for each dataset)\ncompute_moran &lt;- function(trip_table, label) {\n  var_df &lt;- trip_table %&gt;%\n    dplyr::select(HEX_ID, TRIPS) %&gt;%\n    dplyr::rename(Trips = TRIPS)\n\n  # join with geometry and fill missing with zero\n  hex_trip &lt;- hexagon_active %&gt;%\n    dplyr::select(HEX_ID, geometry) %&gt;%\n    dplyr::left_join(var_df, by = \"HEX_ID\") %&gt;%\n    dplyr::mutate(Trips = dplyr::coalesce(Trips, 0))\n\n  # run Moran’s I permutation test (999 simulations)\n  mor &lt;- spdep::moran.mc(\n    x           = hex_trip$Trips,\n    listw       = lw_d_B,\n    nsim        = 999,\n    zero.policy = TRUE\n  )\n\n  cat(\"\\n----\", label, \"----\\n\")\n  print(mor)\n  return(mor)\n}\n\n# 2) Execute for each peak period (reuse trip tables from Section 6)\nmor_am  &lt;- compute_moran(tp_am,  \"Weekday Morning (06–09)\")\n\n\n---- Weekday Morning (06–09) ----\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hex_trip$Trips \nweights: lw_d_B  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.3628, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\nmor_pm  &lt;- compute_moran(tp_pm,  \"Weekday Afternoon (17–19)\")\n\n\n---- Weekday Afternoon (17–19) ----\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hex_trip$Trips \nweights: lw_d_B  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.15426, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\nmor_wk  &lt;- compute_moran(tp_wk,  \"Weekend / Holiday (11–19)\")\n\n\n---- Weekend / Holiday (11–19) ----\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hex_trip$Trips \nweights: lw_d_B  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.24168, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nThe results show that all three Moran’s I tests have a \\(p\\)-value of 0.001, confirming statistically significant spatial clustering of trip intensities at the 0.1% level. During the weekday morning (06–08), Moran’s I = 0.3628 with p = 0.001, indicating strong and highly significant clustering where high-trip hexagons are located close to other high-trip areas. For the weekday afternoon (17–19), Moran’s I = 0.1543 with p = 0.001, suggesting that although clustering remains statistically significant, its intensity is much weaker, reflecting a more dispersed evening pattern. In the weekend or holiday period (11–19), Moran’s I = 0.2417 with p = 0.001, showing moderate yet statistically significant clustering, where trips remain locally concentrated but less tightly grouped than in the morning peak. Overall, the consistently low \\(p\\)-values confirm that all observed spatial patterns are real and not due to random variation.\n\n\n8.2 Moran scatterplot diagnostics for all peak periods\nThis section provides a visual diagnosis of spatial dependence for each peak period using the Moran scatterplot. The scatterplot relates the standardised value of the analysis variable on the horizontal axis to its spatial lag on the vertical axis. The spatial lag is the weighted average of neighbouring values computed with the distance band weights of seven hundred fifty meters that were established in Section seven. The slope of the fitted line equals the Global Moran I value, therefore the plot gives an immediate and interpretable picture of the direction and strength of spatial autocorrelation. Points in the upper right quadrant indicate high values surrounded by high neighbours which is a high high pattern, while points in the lower left quadrant indicate low low patterns. Off diagonal quadrants reveal spatial outliers. We generate one interactive figure for each required time window using the same data objects created in Section six and the same spatial weights created in Section seven. The use of a single helper function keeps the workflow compact and ensures exact reproducibility and consistency of settings across the three periods.\n\n# --- 8.2 Moran scatterplot diagnostics for AM, PM, Weekend (spdep) --------\n\n# Use a row-standardised listw for the scatter (standard in Hands-on 5a)\nlw_d_W &lt;- spdep::nb2listw(nb_d, style = \"W\", zero.policy = TRUE)\n\n# Helper: build one Moran scatter using spdep::moran.plot\nmoran_scatter &lt;- function(trip_table, label) {\n\n  # 1) Prepare the data vector (reuse trips from Section 6)\n  var_df &lt;- trip_table %&gt;%\n    dplyr::select(HEX_ID, TRIPS) %&gt;%\n    dplyr::rename(Trips = TRIPS)\n\n  # 2) Join to geometry table (only to keep HEX_ID consistent)\n  hex_trip &lt;- hexagon_active %&gt;%\n    dplyr::select(HEX_ID, geometry) %&gt;%\n    dplyr::left_join(var_df, by = \"HEX_ID\") %&gt;%\n    dplyr::mutate(Trips = dplyr::coalesce(Trips, 0))\n\n  # 3) Sanity checks\n  stopifnot(is.numeric(hex_trip$Trips))\n  stopifnot(length(hex_trip$Trips) == length(nb_d))\n\n  # 4) Moran scatterplot (base graphics)\n  spdep::moran.plot(\n    x            = hex_trip$Trips,     # analysis vector\n    listw        = lw_d_W,             # row-standardised weights\n    labels       = hex_trip$HEX_ID,    # optional id labels\n    xlab         = \"Standardised Trips\",\n    ylab         = \"Spatial lag of Trips\",\n    main         = paste0(\"Moran scatterplot: \", label),\n    zero.policy  = TRUE,               # safe at boundaries\n    pch          = 20, cex = 0.6, col = \"grey25\"  # tidy styling\n  )\n}\n\n# Produce all three plots (printed one after another, no overlap)\nmoran_scatter(tp_am, \"Weekday Morning 06–09\")\n\n\n\n\n\n\n\nmoran_scatter(tp_pm, \"Weekday Afternoon 17–20\")\n\n\n\n\n\n\n\nmoran_scatter(tp_wk, \"Weekend / Holiday 11–20\")\n\n\n\n\n\n\n\n\nThe Moran scatterplots show consistent positive slopes across all time periods, confirming spatial clustering of trip intensity. During weekday mornings (06–09), the slope is steepest, reflecting strong clustering where hexagons with high trip counts are surrounded by others with similarly high values, likely representing major commuter origins. In the weekday afternoon (17–20), the slope is flatter, indicating weaker clustering and a more dispersed spatial pattern as trips spread across different zones. For weekends and holidays (11–20), the slope increases slightly compared to the afternoon, showing moderate clustering linked to leisure or retail movements. Outlier hexagons such as H0117, H0308, and H0521 maintain high trip densities and spatial lags, highlighting persistent local hotspots across all periods. Overall, the plots confirm positive spatial dependence, strongest in the morning and weakest during evening hours.\n\n\n8.3 Permutation histogram of Moran’s I (AM, PM, Weekend)\nA custom function is created in this section to compute and display the permutation-based distribution of Moran’s I for each time period. The workflow first extracts the hexagon identifier and trip counts, standardises variable names, and merges them with the spatial geometry. Missing trip values are replaced with zero to maintain data completeness. Using the same 750-meter spatial weights, the function runs 999 Monte-Carlo permutations to simulate the expected distribution of Moran’s I under random conditions. A histogram of simulated values is then drawn, with the observed Moran’s I marked as a red line to highlight deviation from randomness. Finally, the procedure is applied sequentially to the morning, afternoon, and weekend datasets, providing a consistent visual comparison of spatial autocorrelation strength across different periods of the day.\n\n# --- 8.3 Permutation histogram of Moran’s I (AM, PM, Weekend) -------------\n\nlibrary(spdep)\nlibrary(dplyr)\n\n# helper: compute Moran’s I and plot its permutation histogram\nmoran_hist &lt;- function(trip_table, label) {\n\n  # keep HEX_ID and TRIPS from Section 6, standardise the name\n  var_df &lt;- trip_table %&gt;%\n    dplyr::select(HEX_ID, TRIPS) %&gt;%\n    dplyr::rename(Trips = TRIPS)\n\n  # join to geometry from Section 7 and fill any missing with zero\n  hex_trip &lt;- hexagon_active %&gt;%\n    dplyr::select(HEX_ID, geometry) %&gt;%\n    dplyr::left_join(var_df, by = \"HEX_ID\") %&gt;%\n    dplyr::mutate(Trips = dplyr::coalesce(Trips, 0))\n\n  # permutation Moran’s I using the SAME distance-band listw (750 m)\n  mor &lt;- spdep::moran.mc(\n    x           = hex_trip$Trips,   # numeric vector\n    listw       = lw_d_B,           # distance-band weights from Section 7\n    nsim        = 999,              # as in Hands-on 5a\n    zero.policy = TRUE\n  )\n\n  # plot the permutation distribution (Hands-on 5a style)\n  hist(mor$res,\n       breaks = 30,\n       col    = \"grey80\",\n       border = \"white\",\n       main   = paste0(\"Permutation distribution of Moran’s I — \", label),\n       xlab   = \"Simulated Moran’s I\"\n  )\n  abline(v = as.numeric(mor$statistic), col = \"red\", lwd = 2)\n  legend(\"topright\",\n         legend = c(\n           paste0(\"Observed I = \", round(as.numeric(mor$statistic), 2)),\n           paste0(\"p-value = \", format.pval(mor$p.value, digits = 2))\n         ),\n         bty = \"n\", text.col = \"black\")\n  invisible(mor)\n}\n\n# generate all three histograms (one after another, no overlap)\nmor_am &lt;- moran_hist(tp_am, \"Weekday Morning 06–09\")\n\n\n\n\n\n\n\nmor_pm &lt;- moran_hist(tp_pm, \"Weekday Afternoon 17–20\")\n\n\n\n\n\n\n\nmor_wk &lt;- moran_hist(tp_wk, \"Weekend/Holiday 11–20\")\n\n\n\n\n\n\n\n\nThe permutation histograms demonstrate that all three observed Moran’s I values lie far to the right of the simulated distributions, confirming strong and statistically significant positive spatial autocorrelation (p = 0.001). For the weekday morning (06–09), the observed Moran’s I of 0.36 indicates pronounced clustering of high-trip areas, consistent with concentrated commuting flows. During the weekday afternoon (17–20), Moran’s I drops to 0.15, showing weaker but still significant clustering as trips become more dispersed. On weekends and holidays (11–20), Moran’s I reaches 0.24, reflecting moderate clustering where travel activity remains spatially structured but less intense than morning peaks. In all cases, the clear separation between observed and simulated values validates the rejection of spatial randomness in Singapore’s trip distribution patterns.\n\n\n8.4 Local Moran’s I (LISA) analysis for all peak periods\nThis section decomposes the global statistic into cell level contributions to identify where clustering or spatial outliers occur. For each peak period, the analysis variable is the total trip count per hexagon created in Section 6. Geometry and the 759 meters distance band weights from Section 7 are reused without modification to preserve complete methodological consistency. The local Moran statistic is estimated by permutation with 999 simulations. The returned values include the local statistic, its expected value under the null, a \\(z\\) score, and the permutation \\(p\\) value. Significant results are classified into four canonical categories of local spatial association, namely high high, low low, high low, and low high. These categories are mapped one period at a time using the same cartographic styling as before, with a centered bold title, a framed legend within the plotting frame, and no overlapping outputs. This structure provides operational evidence of morning and afternoon commuting hot belts and the weekend leisure pattern, and it prepares the way for the spatio temporal hot spot analysis in the next section.\n\n# --- 8.4 LISA with explicit classification (Hands-on 5a/5b pattern) --------\n\n# 0) Row-standardised weights for LISA (Hands-on uses W)\nlw_d_W &lt;- spdep::nb2listw(nb_d, style = \"W\", zero.policy = TRUE)\n\n# 1) Helper: compute permutation LISA + cluster labels for one period\ncompute_lisa_sf &lt;- function(trip_tbl, nsim = 999, alpha = 0.05) {\n\n  # attach period trips to geometry; replace missing with zero\n  hex_trip &lt;- hexagon_active %&gt;%\n    dplyr::select(HEX_ID, geometry) %&gt;%\n    dplyr::left_join(\n      trip_tbl %&gt;% dplyr::select(HEX_ID, TRIPS) %&gt;% dplyr::rename(Trips = TRIPS),\n      by = \"HEX_ID\"\n    ) %&gt;%\n    dplyr::mutate(Trips = dplyr::coalesce(Trips, 0))\n\n  # z-standardise Trips and compute spatial lag of z (Hands-on diagnostic)\n  z    &lt;- as.numeric(scale(hex_trip$Trips))\n  lagz &lt;- spdep::lag.listw(lw_d_W, z, zero.policy = TRUE)\n\n  # permutation Local Moran's I (Hands-on 5b)\n  lm &lt;- spdep::localmoran_perm(\n    x           = hex_trip$Trips,\n    listw       = lw_d_W,\n    nsim        = nsim,\n    alternative = \"two.sided\",\n    zero.policy = TRUE\n  )\n\n  # spdep column names (perm version): \"Ii\",\"E.Ii\",\"Var.Ii\",\"Z.Ii\",\"Pr(z != E(Ii))\"\n  p_col &lt;- \"Pr(z != E(Ii))\"\n\n  # explicit cluster classification (no cut(), no hidden labels)\n  cls &lt;- dplyr::case_when(\n    lm[, p_col] &lt; alpha &  z &gt; 0 & lagz &gt; 0 ~ \"High–High\",\n    lm[, p_col] &lt; alpha &  z &lt; 0 & lagz &lt; 0 ~ \"Low–Low\",\n    lm[, p_col] &lt; alpha &  z &gt; 0 & lagz &lt; 0 ~ \"High–Low\",\n    lm[, p_col] &lt; alpha &  z &lt; 0 & lagz &gt; 0 ~ \"Low–High\",\n    TRUE                                   ~ \"Not Sig.\"\n  )\n\n  # bind results into sf\n  hex_trip %&gt;%\n    dplyr::mutate(\n      Ii     = lm[, \"Ii\"],\n      Z_Ii   = lm[, \"Z.Ii\"],\n      pvalue = lm[, p_col],\n      z      = z,\n      lag_z  = lagz,\n      cluster = factor(cls,\n        levels = c(\"High–High\",\"Low–Low\",\"High–Low\",\"Low–High\",\"Not Sig.\")\n      )\n    )\n}\n\n# 2) Helper: produce a publication map (categorical fill, framed legend)\nplot_lisa_map &lt;- function(sf_obj, title_text) {\n  pal &lt;- c(\n    \"High–High\" = \"#d7191c\",\n    \"Low–Low\"   = \"#2c7bb6\",\n    \"High–Low\"  = \"#fdae61\",\n    \"Low–High\"  = \"#abd9e9\",\n    \"Not Sig.\"  = \"grey85\"\n  )\n  tmap_mode(\"plot\")\n  tmap_options(component.autoscale = FALSE)  # keep legend within frame\n\n  tm_shape(sg_main) +                        # &lt;- mainland boundary from Section 5\n    tm_borders(col = \"grey40\", lwd = 0.8) +  # coastline/outline\n  tm_shape(sf_obj) +\n    tm_fill(\"cluster\", palette = pal, style = \"cat\",\n            title = \"LISA cluster type\") +\n    tm_borders(col = \"grey30\", lwd = 0.3) +  # hex borders\n    tm_title(title_text,                     # &lt;-- v4 title API\n             position = c(\"center\", \"top\"),\n             fontface = \"bold\") +\n    tm_layout(\n      legend.position = c(\"right\",\"bottom\"),\n      legend.bg.color = \"white\",\n      legend.frame    = TRUE,\n      frame           = TRUE,                # outer map frame\n      outer.margins   = 0,\n      inner.margins   = c(0.02, 0.03, 0.2, 0.02)\n    )\n}\n\n# 3) Compute and draw each period (reusing tp_am, tp_pm, tp_wk from Section 6)\nlisa_am &lt;- compute_lisa_sf(tp_am)  ; map_am &lt;- plot_lisa_map(lisa_am,\n  \"Local Moran’s I clusters – Weekday Morning 06–09\")\nmap_am\n\n\n\n\n\n\n\nlisa_pm &lt;- compute_lisa_sf(tp_pm)  ; map_pm &lt;- plot_lisa_map(lisa_pm,\n  \"Local Moran’s I clusters – Weekday Afternoon 17–20\")\nmap_pm\n\n\n\n\n\n\n\nlisa_wk &lt;- compute_lisa_sf(tp_wk)  ; map_wk &lt;- plot_lisa_map(lisa_wk,\n  \"Local Moran’s I clusters – Weekend/Holiday 11–20\")\nmap_wk\n\n\n\n\n\n\n\n\nThe Local Moran’s I cluster maps reveal distinct spatial patterns of trip intensity across time periods. During the weekday morning (06–09), numerous High–High clusters appear in central and eastern areas, reflecting strong concentrations of origin trips linked to commuter movement toward employment hubs. In the weekday afternoon (17–20), fewer and smaller High–High clusters emerge, suggesting a more dispersed travel pattern during evening returns. Meanwhile, Low–Low clusters remain sparse and scattered, representing areas with consistently low trip activity. On weekends and holidays (11–20), clustering re-intensifies in select central and regional areas, likely driven by leisure and retail travel. The consistent presence of High–High clusters in core zones across all periods confirms persistent urban mobility hotspots, whereas reduced clustering during afternoon hours indicates more spatially even trip distribution outside peak commuting times."
  },
  {
    "objectID": "Take-home_Ex02/take-home_ex02.html#spatial-hot-spot-and-cold-spot-analysis-getis-ord-gi",
    "href": "Take-home_Ex02/take-home_ex02.html#spatial-hot-spot-and-cold-spot-analysis-getis-ord-gi",
    "title": "Take-home Ex02: Analyzing Neighborhood Bus Mobility and Emerging Urban Trends",
    "section": "10 Spatial Hot Spot and Cold Spot Analysis (Getis-Ord Gi*)",
    "text": "10 Spatial Hot Spot and Cold Spot Analysis (Getis-Ord Gi*)\nThis section applies the Local Getis Ord Gi* statistic to identify statistically significant concentrations of high and low trip activities within the study area. The analysis builds upon the previously confirmed spatial weights and the hexagonal grid framework to evaluate whether the observed trip intensities form meaningful spatial clusters beyond what would be expected by random chance. Each analytical time window, including the weekday morning, weekday afternoon, and weekend or holiday periods, follows an identical spatial configuration to preserve methodological consistency. The workflow proceeds sequentially, beginning with the validation of spatial weight matrices, followed by the computation of local Gi* statistics and associated p values, and concluding with the visualization and classification of significant clusters. Every analytical step is executed reproducibly within the R environment through the sfdep and tmap packages, ensuring methodological alignment between statistical computation and geographic representation. The complete process transforms raw trip counts into interpretable spatial indicators of movement intensity, providing a rigorous foundation for understanding urban mobility patterns across temporal contexts.\n\n10.1 Confirm weight objects (Include Self for Gi*)\nThe analysis begins by validating the spatial weight configurations required for the Gi* computation. The code first checks that the neighbour list object (nb_d_self) and its corresponding weight list (lw_d_B_self) exist and inherit from the correct nb and listw classes. The procedure explicitly includes each hexagon’s own location as a neighbour (include.self = TRUE) because Gi* requires self-inclusion to measure local concentration accurately. A sanity check confirms that the length of the neighbour structure matches the number of active hexagons (hexagon_active). These tests guarantee internal consistency between the spatial index and geometric dataset, preventing mismatched geometries or weight lengths that could invalidate later \\(z\\)-score and \\(p\\)-value calculations. By ensuring that the self-inclusive weights are both properly formatted and structurally aligned, this step forms the computational backbone for all subsequent spatial permutation tests and clustering assessments.\n\n# Confirm 750 m weights from Section 7\nstopifnot(inherits(nb_d, \"nb\"),\n          inherits(lw_d_B, \"listw\"))\n\n# Include-self versions (required for Gi*)\nnb_d_self   &lt;- if (exists(\"nb_d_self\")) nb_d_self else spdep::include.self(nb_d)\nlw_d_B_self &lt;- if (exists(\"lw_d_B_self\")) lw_d_B_self else\n                 spdep::nb2listw(nb_d_self, style = \"W\", zero.policy = TRUE)\n\n\n\n10.2 Helper functions (Trip Alignment & Computation)\nThis section develops the computational tools required to implement the Local Getis Ord Gi* analysis reliably across multiple time periods. It introduces two essential helper functions that translate cleaned trip records into forms suitable for spatial computation. The first function ensures that all trip frequencies correspond exactly to their matching hexagonal cells within the analytical grid, producing a fully numeric vector that preserves spatial order and completeness. The second function performs the statistical calculation of the Local Gi* statistic using the previously validated spatial weights. Together, these procedures guarantee that each analytical dataset follows identical data structures and spatial relationships before entering the permutation process. The section also verifies that all outputs preserve consistent record counts and geometry alignment, ensuring no mismatch between the trip data and the spatial framework. Through these supporting functions, the analysis gains precision, reproducibility, and computational integrity, establishing a seamless bridge between data preparation and statistical computation in subsequent sections.\n\n10.2.1 Convert trips to numeric vector aligned to grid\nThis section defines a helper routine that converts the tabulated trip data into a numeric vector perfectly aligned with the analytical hexagon grid. It performs a join between trip counts and geometry using the common hexagon identifier, replaces missing trip values with zero, and confirms that the resulting vector length matches the number of grid cells. Logical checks verify that all values are numeric and finite, ensuring that no data mismatch affects the spatial weights. The completed vector becomes the input for statistical analysis in later sections, providing a validated numerical representation of trip intensity that is consistent across all analytical windows.\n\ntrips_vec &lt;- function(trip_table) {\n  var_df &lt;- trip_table %&gt;%\n    transmute(hex_id = tolower(HEX_ID),\n              Trips  = as.numeric(TRIPS))\n\n  x &lt;- hexagon_active %&gt;%\n    transmute(hex_id = tolower(HEX_ID), geometry) %&gt;%\n    left_join(var_df, by = \"hex_id\") %&gt;%\n    mutate(Trips = replace_na(Trips, 0))\n\n  v &lt;- x %&gt;% st_drop_geometry() %&gt;% pull(Trips)\n\n  stopifnot(is.numeric(v),\n            !any(is.na(v)),\n            length(v) == nrow(hexagon_active))\n  v\n}\n\n\n\n10.2.2 Compute Local Gi* statistic\nThis section implements the computation of the Local Gi* statistic. The function compute_gistar uses the aligned trip vector and executes 999 random permutations with zero policy enabled to handle empty neighbour sets. The resulting \\(z\\)-score and two-sided \\(p\\) value quantify the degree and significance of clustering within each hexagon. The code then attaches the results to the analytical geometry, ensuring one record per spatial cell. Validation checks confirm identical row counts between statistical output and geometry, ensuring spatial consistency. This process yields an integrated spatial dataset containing both numeric and geometric information, ready for temporal comparison and visualisation.\n\ncompute_gistar &lt;- function(trip_table, label, nsim = 999) {\n  v &lt;- trips_vec(trip_table)\n\n  gi_tbl &lt;- spdep::localG_perm(\n    x          = v,\n    listw      = lw_d_B_self,\n    nsim       = nsim,\n    zero.policy = TRUE\n  )\n\n  gi_df &lt;- as.data.frame(gi_tbl)\n  names(gi_df)[1] &lt;- \"Gi\"\n\n  # Two-sided p-value from z-score\n  gi_df$p_sim &lt;- 2 * pnorm(-abs(gi_df$Gi))\n\n  out &lt;- bind_cols(hexagon_active, gi_df) %&gt;%\n    mutate(.window = label)\n\n  stopifnot(nrow(out) == nrow(hexagon_active))\n  out\n}\n\n\n\n\n10.3 Compute Local Gi* for all windows\nAfter confirming the helper functions, the computation is applied to each temporal dataset representing the weekday morning, weekday afternoon, and weekend or holiday periods. The resulting outputs, labelled HCSA_am, HCSA_pm, and HCSA_wk, contain each hexagon’s Gi* \\(z\\)-score and simulated p value together with its temporal label. A diagnostic message confirms that all datasets contain identical numbers of observations and identical spatial structures. This repetition under uniform parameters allows precise comparison of spatial clustering strength between different time frames. The procedure captures temporal variation in the intensity of hot and cold clusters across Singapore, making it possible to observe whether strong morning concentrations persist into later periods or dissipate. The completion of this section produces three statistically comparable datasets that serve as the analytical input for the mapping process described in the following section.\n\nHCSA_am &lt;- compute_gistar(tp_am, \"Weekday Morning (06–09)\")\nHCSA_pm &lt;- compute_gistar(tp_pm, \"Weekday Afternoon (17–20)\")\nHCSA_wk &lt;- compute_gistar(tp_wk, \"Weekend / Holiday (11–20)\")\n\n# Basic verification\nstopifnot(\n  nrow(HCSA_am) == nrow(hexagon_active),\n  nrow(HCSA_pm) == nrow(hexagon_active),\n  nrow(HCSA_wk) == nrow(hexagon_active),\n  is.numeric(HCSA_am$Gi),\n  is.numeric(HCSA_pm$Gi),\n  is.numeric(HCSA_wk$Gi)\n)\n\n\n\n10.4 Mapping local Gi* p-values\nThis section transforms numerical results into spatially interpretable maps that visualise the Local Gi* \\(z\\)-scores. The mapping function uses tmap to display the Singapore outline, overlay the analytical hexagon grid, and fill each cell according to its \\(z\\)-score value. The chosen colour palette is diverging, with red tones representing positive clustering and blue tones representing negative clustering, while white represents values close to the mean. The map layout follows the standard formatting with bold titles, centred legends, and consistent margins to preserve visual uniformity across all time periods. Through these maps, users can immediately distinguish areas of elevated trip intensity from those with lower activity. The maps also provide a diagnostic check for spatial continuity, revealing whether the clustering patterns are geographically contiguous or dispersed. This step converts statistical output into an interpretable visual narrative that guides subsequent analysis of significance.\n\ntmap_mode(\"plot\")\n\nmap_gi &lt;- function(sf_obj, title_text) {\n  tm_shape(sg_outline) + tm_borders(col = \"grey40\", lwd = 0.7) +\n  tm_shape(sf_obj) +\n    tm_fill(\"Gi\",\n            style   = \"pretty\",\n            n       = 7,\n            palette = \"-brewer.RdBu\",\n            midpoint = 0,\n            title   = \"Gi* z-score\") +\n    tm_borders(col = \"grey85\", lwd = 0.4) +\n    tm_layout(\n      main.title = title_text,\n      main.title.position = \"center\",  # Ensure exact spelling\n      main.title.fontface = \"bold\",\n      outer.margins = c(0.02, 0.02, 0.02, 0.02),\n      main.title.size = 1.2,           # Optional: adjust title size\n      main.title.color = \"black\",      # Optional: adjust color\n      legend.position = c(\"right\",\"bottom\"),\n      legend.frame = TRUE\n    )\n}\n\ngi_am &lt;- map_gi(HCSA_am, \"Local Gi* — Weekday Morning (06–09)\")\ngi_pm &lt;- map_gi(HCSA_pm, \"Local Gi* — Weekday Afternoon (17–20)\")\ngi_wk &lt;- map_gi(HCSA_wk, \"Local Gi* — Weekend / Holiday (11–20)\")\n\ngi_am; gi_pm; gi_wk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe three Local Gi* maps together present a detailed view of spatial clustering patterns of trip activity across different temporal contexts. During the weekday morning period, the map reveals intense hot spots represented by darker red hexagons located in the western, northeastern, and central regions. These areas correspond to concentrated morning departures associated with residential neighbourhoods where large numbers of commuters begin their daily journeys. The presence of light blue cells along the northern and southern corridors indicates localised cold spots, suggesting lower trip activity during this time window.\nIn the weekday afternoon period, several of the morning hot spots persist but appear more dispersed. This shift indicates that while core mobility zones remain active, their intensity diminishes as trip generation becomes more balanced between origins and destinations. The recurring pattern of both positive and negative \\(z\\)-scores suggests the redistribution of flows as commuters return from work.\nOn weekends and holidays, the pattern evolves further into more extensive red clusters in central and eastern regions, highlighting leisure-oriented and recreational travel rather than work-related mobility. The appearance of multiple moderate-intensity clusters across the island suggests more spatially diversified travel behaviour during non-working days.\nOverall, the Local Gi* analysis confirms that spatial clustering of trip activity varies systematically with time, reflecting transitions between commuting and social travel functions. These results demonstrate how temporal segmentation helps reveal distinct behavioural regimes of urban mobility that would otherwise be obscured in aggregated data.\n\n\n10.5 Mapping \\(p\\)-Values of Local Gi*\nThe next analytical step assesses the statistical reliability of the apparent hot and cold zones by mapping the simulated p values corresponding to each \\(z\\)-score. The mapping function applies fixed classification intervals to highlight confidence levels at 0.001, 0.01, 0.05, 0.10, and 1.00. Lower \\(p\\) values appear in darker shades, identifying regions where clustering is statistically significant, whereas lighter tones mark areas consistent with random variation. The visual format mirrors that of the z-score maps to enable direct cross-comparison. By reviewing both the intensity and the p value maps together, the analyst can separate visually strong but insignificant clusters from genuinely significant hot or cold areas. This process enhances analytical reliability by ensuring that observed spatial concentrations are statistically defensible rather than products of chance. The mapped \\(p\\) values therefore serve as the validation layer preceding categorical classification.\n\nmap_p &lt;- function(sf_obj, title_text) {\n  tm_shape(sg_outline) + tm_borders(col = \"grey40\", lwd = 0.7) +\n  tm_shape(sf_obj %&gt;% filter(is.finite(p_sim))) +\n    tm_fill(\n      col      = \"p_sim\",\n      style    = \"fixed\",\n      breaks   = c(0, 0.001, 0.01, 0.05, 0.10, 1),\n      palette  = \"-brewer.Reds\",\n      title    = \"p-value\",\n      midpoint = NA,\n      alpha    = 1\n    ) +\n    tm_borders(col = \"grey85\", lwd = 0.4) +\n    tm_layout(\n      main.title          = title_text,\n      main.title.position = \"center\",\n      main.title.fontface = \"bold\",\n      legend.position     = c(\"right\",\"bottom\"),\n      legend.frame        = TRUE\n    )\n}\n\np_am &lt;- map_p(HCSA_am, \"p-values of Local Gi* — Weekday Morning (06–09)\")\np_pm &lt;- map_p(HCSA_pm, \"p-values of Local Gi* — Weekday Afternoon (17–20)\")\np_wk &lt;- map_p(HCSA_wk, \"p-values of Local Gi* — Weekend / Holiday (11–20)\")\n\np_am; p_pm; p_wk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe \\(p\\)-value maps for the Local Gi* analysis provide statistical confirmation of where spatial clustering patterns are most reliable across different time periods. During the weekday morning period, dark red hexagons dominate the western, northeastern, and central sectors of the island, indicating \\(p\\)-values below 0.01. These areas reflect highly significant clusters of trip activity, suggesting consistent morning travel concentration within residential and employment zones. The dense grouping of low \\(p\\)-values confirms that the observed spatial patterns are unlikely to occur by random chance and represent genuine hot spot formations.\nIn the weekday afternoon period, significant areas become more dispersed, and the total number of hexagons with \\(p\\)-values below 0.01 slightly decreases. This reduction implies greater variability in afternoon trip behaviour as travel flows diversify between work return journeys and secondary activities. Nonetheless, certain stable clusters persist, suggesting enduring transport corridors and mixed-use nodes with high activity density.\nThe weekend and holiday map shows renewed intensification of significant areas, particularly in central and eastern regions. The spread of dark red hexagons indicates broader spatial clustering of leisure-related movement. This distribution implies that recreational and shopping trips become the dominant source of spatial dependence during non-working days.\nAcross all three time windows, the persistence of low \\(p\\)-values validates the robustness of the Local Gi* results. The consistent appearance of significant cells across multiple periods demonstrates that spatial clustering in urban mobility is a stable feature of the transport landscape rather than a transient phenomenon driven by temporal fluctuations.\n\n\n10.6 Hot/Cold spot classification at \\(p\\) &lt; 0.05\nThe final stage consolidates all previous computations and maps into a categorical representation of statistically significant clusters. Using the mapping function map_cluster, each hexagon is classified into one of three categories: Hot Spot, Cold Spot, or Insignificant. The classification depends on both the direction of the Gi* \\(z\\)-score and the associated p value threshold of less than 0.05. The colour scheme is fixed, with red indicating Hot Spots, blue indicating Cold Spots, and grey indicating Insignificant cells. This uniform convention allows easy visual comparison between different temporal windows. The resulting maps provide a concise yet comprehensive summary of spatial clustering across the study area, clearly identifying where trip activity intensifies or weakens over time. These classified outcomes represent the most interpretable stage of the Gi* workflow, forming the empirical basis for subsequent discussion and interpretation of spatial mobility behaviour.\n\n# --- Classify Gi* into clusters (α = 0.05)--------------------------------------------\n# p &lt;= .05 significant; Hot if Gi&gt;0, Cold if Gi&lt;0; else Insignificant\nHCSA_classify &lt;- function(sf_obj, alpha = 0.05) {\n  sf_obj |&gt;\n    dplyr::mutate(\n      HCSA_cluster = dplyr::case_when(\n        is.finite(p_sim) & p_sim &lt;= alpha & is.finite(Gi) & Gi &gt;  0 ~ \"Hot spot\",\n        is.finite(p_sim) & p_sim &lt;= alpha & is.finite(Gi) & Gi &lt;  0 ~ \"Cold spot\",\n        is.finite(p_sim) & p_sim  &gt; alpha                           ~ \"Insignificant\",\n        TRUE ~ NA_character_\n      ),\n      # lock the factor order to control legend order\n      HCSA_cluster = factor(HCSA_cluster,\n                            levels = c(\"Insignificant\",\"Hot spot\",\"Cold spot\"),\n                            ordered = TRUE)\n    )\n}\n\nHCSA_am_c &lt;- HCSA_classify(HCSA_am)\nHCSA_pm_c &lt;- HCSA_classify(HCSA_pm)\nHCSA_wk_c &lt;- HCSA_classify(HCSA_wk)\n\n# --- Plot helper (fixed order + explicit colors, no “Missing”) -----------------------\ncluster_levels &lt;- c(\"Insignificant\",\"Hot spot\",\"Cold spot\")\ncluster_colors &lt;- c(\"grey80\",\"red\",\"blue\")   # same order as levels\n\nmap_cluster &lt;- function(sf_obj, title_text) {\n  # drop NA so the legend doesn’t show “Missing”\n  sf_plot &lt;- sf_obj |&gt;\n    dplyr::filter(!is.na(HCSA_cluster)) |&gt;\n    # re-assert factor levels in case something changed upstream\n    dplyr::mutate(HCSA_cluster = factor(as.character(HCSA_cluster),\n                                        levels = cluster_levels,\n                                        ordered = TRUE))\n\n  tm_shape(sg_outline) + tm_borders(col = \"grey40\", lwd = 0.7) +\n  tm_shape(sf_plot) +\n    tm_fill(col = \"HCSA_cluster\",\n            palette = cluster_colors,   # categorical palette (tmap v4)\n            showNA  = FALSE,\n            title   = \"HCSA Cluster\") +\n    tm_borders(col = \"grey85\", lwd = 0.4) +\n    tm_layout(\n      main.title         = title_text,\n      main.title.position= \"center\",\n      main.title.fontface= \"bold\",\n      legend.position    = c(\"right\",\"bottom\"),\n      legend.frame       = TRUE\n    )\n}\n\n# --- Draw the three maps --------------------------------------------------------------\ncm_am &lt;- map_cluster(HCSA_am_c, \"HCSA Clusters (p &lt; 0.05) — Morning (06–09)\")\ncm_pm &lt;- map_cluster(HCSA_pm_c, \"HCSA Clusters (p &lt; 0.05) — Afternoon (17–20)\")\ncm_wk &lt;- map_cluster(HCSA_wk_c, \"HCSA Clusters (p &lt; 0.05) — Weekend / Holiday (11–20)\")\n\ncm_am; cm_pm; cm_wk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Hot and Cold Spot Analysis (HCSA) cluster maps for weekday morning, weekday afternoon, and weekend or holiday periods collectively reveal the evolution of Singapore’s spatial mobility intensity across temporal contexts, each analysed at \\(p\\) less than 0.05 significance. In the weekday morning map, a dense network of red hexagonal clusters signifies statistically significant hot spots of trip activity, particularly concentrated across the northern(Yishun, and Woodland), Northern East (Punggol, Sengkang, Hougang), Western (Jurong West, Bukit Batok), Central (Tao Payoh) and Eastern (Tampines, Bedok) portions of the island. These clusters represent high trip-generation zones that likely correspond to large-scale residential districts where outbound commuter traffic peaks between 6 to 9 a.m. The absence of blue cold spot cells indicates that low trip areas during this period follow a more random pattern without statistical clustering. The observed structure suggests a strong and spatially dependent morning mobility framework aligned with commuting towards central employment hubs.\nDuring the weekday afternoon period from 17 to 20 hours, the cluster distribution remains extensive but exhibits slightly lower density and increased dispersion. The presence of multiple smaller red patches indicates a diffusion of activity as people travel home or make short inter-district trips after work. This spatial fragmentation signifies a shift from collective commuter movements to more individualised trip purposes such as school pick-ups, errands, or leisure engagements. The patterns reinforce the dynamic transformation of Singapore’s travel behaviour from highly centralised in the morning to decentralised in the evening.\nBy contrast, the weekend or holiday map displays broader and more evenly distributed red clusters across central, southern, and eastern zones. These results reflect the transition from occupational to recreational mobility, as travel demand is driven by social, retail, and leisure activities. Unlike weekdays, trip concentration expands into non-core areas, highlighting the more balanced nature of urban activity during off-work periods.\nIn practical terms, these spatial patterns emphasise how weekday commuting follows structured residential-employment flows, whereas weekend mobility reflects lifestyle-oriented dispersion. Transport planners can use these temporal signatures to synchronise service frequency and route allocation, ensuring capacity aligns with empirically verified high-demand corridors during peak weekday hours and wider area accessibility on weekends."
  },
  {
    "objectID": "Take-home_Ex02/take-home_ex02.html#global-measure-of-spatial-autocorrelation-analysis",
    "href": "Take-home_Ex02/take-home_ex02.html#global-measure-of-spatial-autocorrelation-analysis",
    "title": "Take-home Ex02: Analyzing Neighborhood Bus Mobility and Emerging Urban Trends",
    "section": "8 Global Measure of Spatial Autocorrelation Analysis",
    "text": "8 Global Measure of Spatial Autocorrelation Analysis\nThis section investigates the global spatial autocorrelation of origin trip intensity across the analytical hexagon grid. Rather than simply examining how values vary geographically, the analysis quantifies the extent to which neighbouring cells exhibit similar or dissimilar trip counts — that is, whether the observed pattern represents clustering, randomness, or dispersion. The global Moran’s I statistic is used as the principal measure to capture this spatial dependency, providing a single index summarising overall correlation across the study region. A positive Moran’s I indicates that cells with high (or low) trip values are located near others of similar magnitude, implying spatial clustering. Conversely, a negative Moran’s I denotes spatial dispersion where high and low values alternate spatially. The test operates on the row-standardised Queen contiguity weights constructed earlier, ensuring that each cell’s contribution is proportional to its number of neighbours. The resulting Moran’s I value, standard deviate, and \\(p\\)-value are derived under a randomisation hypothesis, allowing formal inference against the null of spatial independence. Through this procedure, we obtain a statistically robust understanding of whether trip distributions during peak periods are spatially structured, thereby establishing the foundation for subsequent LISA and hot/cold-spot analyses.\n\n8.1 Global Moran’s I statistical test for all peak periods\nThis section performs the Global Moran’s I test independently for the three defined peak periods: weekday morning, weekday afternoon, and weekend/holiday. Using the previously derived Queen-contiguity spatial-weights matrix, each hexagonal layer is tested under the null hypothesis of spatial randomness. The moran.test() computes the observed Moran’s I, expected value, variance, \\(z\\)-score, and corresponding \\(p\\)-value. A positive and significant Moran’s I (\\(p &lt; 0.001\\)) confirms that the trip intensities are spatially clustered during that period, while an insignificant result suggests no global pattern. Comparing Moran’s I values across all periods reveals whether clustering strength is consistent or time-specific, providing evidence of temporal variation in spatial dependency.\n\n# --- 8.1 Global Moran’s I (AM, PM, Weekend) ---------------------------------\n\n# helper: make the numeric vector aligned to the weights (reuses Section 6/7 objects)\nmake_x &lt;- function(trip_table) {\n  hexagon_active %&gt;%\n    dplyr::select(HEX_ID, geometry) %&gt;%\n    dplyr::left_join(trip_table %&gt;% dplyr::select(HEX_ID, TRIPS), by = \"HEX_ID\") %&gt;%\n    dplyr::mutate(Trips = dplyr::coalesce(TRIPS, 0)) %&gt;%\n    {.$Trips}\n}\n\nx_am &lt;- make_x(tp_am)\nx_pm &lt;- make_x(tp_pm)\nx_wk &lt;- make_x(tp_wk)\n\n# Moran's I test under randomisation\nmt_am &lt;- spdep::moran.test(x_am, listw = lw_d_B, zero.policy = TRUE, na.action = na.omit)\nmt_pm &lt;- spdep::moran.test(x_pm, listw = lw_d_B, zero.policy = TRUE, na.action = na.omit)\nmt_wk &lt;- spdep::moran.test(x_wk, listw = lw_d_B, zero.policy = TRUE, na.action = na.omit)\n\nmt_am; mt_pm; mt_wk   # print results\n\n\n    Moran I test under randomisation\n\ndata:  x_am  \nweights: lw_d_B  \nn reduced by no-neighbour observations  \n\nMoran I statistic standard deviate = 16.367, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.3627974234     -0.0012135922      0.0004946119 \n\n\n\n    Moran I test under randomisation\n\ndata:  x_pm  \nweights: lw_d_B  \nn reduced by no-neighbour observations  \n\nMoran I statistic standard deviate = 7.1164, p-value = 5.538e-13\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.1542609092     -0.0012135922      0.0004773017 \n\n\n\n    Moran I test under randomisation\n\ndata:  x_wk  \nweights: lw_d_B  \nn reduced by no-neighbour observations  \n\nMoran I statistic standard deviate = 10.997, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.2416785594     -0.0012135922      0.0004878754 \n\n\nThe randomisation tests show strong positive spatial autocorrelation for trip counts in all periods using the lw_d_B weights. For weekday morning (06–09), Moran’s I = 0.3628, \\(z\\) = 16.367, \\(p\\) &lt; 2.2×10⁻¹⁶, decisively rejecting spatial randomness. For weekday afternoon (17–20), Moran’s I = 0.1543, \\(z\\) = 7.116, \\(p\\) = 5.54×10⁻¹³, indicating weaker—but still highly significant—clustering. For weekend/holiday (11–19), Moran’s I = 0.2417, \\(z\\) = 10.997, \\(p\\) &lt; 2.2×10⁻¹⁶, implying moderate clustering. The “Expectation” of about −0.0012 is the theoretical mean of Moran’s I under the null (approximately zero for large samples), and the listed variances quantify sampling variability under randomisation. Together, large positive \\(I\\) values, very high \\(z\\)-scores, and extreme \\(p\\)-values confirm that neighbouring hexagons tend to have similar trip intensities, with clustering strongest in the morning, moderate on weekends, and weakest in the weekday afternoon.\n\n\n8.2 Computing Monte Carlo Moran’s I\nThe code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 999 simulation will be performed.\n\n# Monte-Carlo Moran’s I (999 sims) and permutation histograms\nbperm_am &lt;- spdep::moran.mc(x_am, listw = lw_d_B, nsim = 999, zero.policy = TRUE, na.action = na.omit)\nbperm_pm &lt;- spdep::moran.mc(x_pm, listw = lw_d_B, nsim = 999, zero.policy = TRUE, na.action = na.omit)\nbperm_wk &lt;- spdep::moran.mc(x_wk, listw = lw_d_B, nsim = 999, zero.policy = TRUE, na.action = na.omit)\n\nbperm_am; bperm_pm; bperm_wk   # print Monte-Carlo outputs\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x_am \nweights: lw_d_B  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.3628, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x_pm \nweights: lw_d_B  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.15426, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x_wk \nweights: lw_d_B  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.24168, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nThe Monte-Carlo simulation results confirm significant positive spatial autocorrelation in trip intensities across all time periods, using 999 random permutations. For the weekday morning (06–09), Moran’s I = 0.3628 with p = 0.001, indicating strong clustering of high-trip hexagons—typical of concentrated commuting activity. During the weekday afternoon (17–20), Moran’s I decreases to 0.1543, suggesting weaker but still significant clustering as trip origins become more spatially dispersed. On weekends and holidays (11–20), Moran’s I = 0.2417, showing moderate clustering, consistent with concentrated leisure or retail-related travel zones. The consistently low \\(p\\)-values (&lt; 0.001) across all three tests reject spatial randomness, confirming that trip distributions remain spatially dependent, though clustering strength varies with the time of day.\n\n\n8.3 Visualising Monte Carlo Moran’s I\nIt is always a good practice for us the examine the simulated Moran’s I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram by using the code chunk below.\n\n# Visualise permutation distributions\npar(mfrow = c(1,3))\nhist(bperm_am$res, freq = TRUE, breaks = 20, xlab = \"Simulated Moran's I\",\n     main = \"Permutation (AM 06–09)\")\nabline(v = 0, col = \"red\")\nhist(bperm_pm$res, freq = TRUE, breaks = 20, xlab = \"Simulated Moran's I\",\n     main = \"Permutation (PM 17–20)\")\nabline(v = 0, col = \"red\")\nhist(bperm_wk$res, freq = TRUE, breaks = 20, xlab = \"Simulated Moran's I\",\n     main = \"Permutation (Weekend/Holiday AM 11 – PM 20)\")\nabline(v = 0, col = \"red\")\n\n\n\n\n\n\n\npar(mfrow = c(1,1))\n\nThe permutation histograms illustrate the simulated distributions of Moran’s I under spatial randomness, with the red line marking the observed Moran’s I for each time period. In all three plots, the observed values lie far to the right of their respective simulated distributions, indicating strong positive spatial autocorrelation. The weekday morning (06–09) shows the largest deviation, confirming intense clustering of trip origins during peak commute hours. The weekday afternoon (17–20) displays a smaller separation, reflecting weaker clustering and greater dispersion of trips. The weekend/holiday (11–20) pattern falls between the two, showing moderate clustering likely related to leisure activity centres. Since the observed Moran’s I values are far outside the random distribution in every case, spatial randomness is rejected with high confidence, validating significant spatial dependence in all time periods.\n\n\n8.4 Global Moran’s I spatial correlogram\nThis section constructs the spatial correlogram of Moran’s I to assess how spatial autocorrelation changes with increasing distance. The correlogram plots Moran’s I values against successive distance bands derived from the spatial-weights structure, effectively tracing how similarity between cells weakens or reverses as neighbourhoods expand. A steep decline of Moran’s I toward zero implies a rapid loss of spatial dependency, whereas sustained positive values across several lags suggest broader clustering effects. This diagnostic complements the global Moran’s I test by revealing the scale and range of spatial association, thus offering deeper insight into the spatial processes shaping trip-generation patterns across different peak periods.\n\n# --- 8.2 Spatial correlogram (Moran’s I by lag order) -----------------------\nlibrary(spdep)\n\n# Use the neighbour list from Section 7 (nb_d) and W-style like in class\nMIcorr_am &lt;- spdep::sp.correlogram(nb_d, x_am, order = 6, method = \"I\", style = \"W\", zero.policy = TRUE)\nMIcorr_pm &lt;- spdep::sp.correlogram(nb_d, x_pm, order = 6, method = \"I\", style = \"W\", zero.policy = TRUE)\nMIcorr_wk &lt;- spdep::sp.correlogram(nb_d, x_wk, order = 6, method = \"I\", style = \"W\", zero.policy = TRUE)\n\n# plot each correlogram and print the tables (as shown in the notes)\nplot(MIcorr_am, main = \"Moran’s I correlogram – AM 06–09\");  print(MIcorr_am)\n\n\n\n\n\n\n\n\nSpatial correlogram for x_am \nmethod: Moran's I\n           estimate expectation    variance standard deviate Pr(I) two sided\n1 (825)  0.34247123 -0.00121359  0.00055348          14.6086       &lt; 2.2e-16\n2 (819)  0.19553739 -0.00122249  0.00034506          10.5923       &lt; 2.2e-16\n3 (819)  0.09213184 -0.00122249  0.00026472           5.7378       9.593e-09\n4 (819)  0.03223142 -0.00122249  0.00022700           2.2204         0.02639\n5 (817)  0.01084428 -0.00122549  0.00020162           0.8500         0.39531\n6 (815)  0.01886796 -0.00122850  0.00017947           1.5001         0.13358\n           \n1 (825) ***\n2 (819) ***\n3 (819) ***\n4 (819) *  \n5 (817)    \n6 (815)    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(MIcorr_pm, main = \"Moran’s I correlogram – PM 17–20\");  print(MIcorr_pm)\n\n\n\n\n\n\n\n\nSpatial correlogram for x_pm \nmethod: Moran's I\n           estimate expectation    variance standard deviate Pr(I) two sided\n1 (825)  0.15230015 -0.00121359  0.00053410           6.6426       3.082e-11\n2 (819)  0.07864794 -0.00122249  0.00033288           4.3777       1.200e-05\n3 (819)  0.04728148 -0.00122249  0.00025538           3.0352        0.002404\n4 (819)  0.03637830 -0.00122249  0.00021899           2.5409        0.011058\n5 (817)  0.01230407 -0.00122549  0.00019449           0.9701        0.331978\n6 (815)  0.03119926 -0.00122850  0.00017311           2.4647        0.013713\n           \n1 (825) ***\n2 (819) ***\n3 (819) ** \n4 (819) *  \n5 (817)    \n6 (815) *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(MIcorr_wk, main = \"Moran’s I correlogram – Weekend/Holiday 11–20\");  print(MIcorr_wk)\n\n\n\n\n\n\n\n\nSpatial correlogram for x_wk \nmethod: Moran's I\n           estimate expectation    variance standard deviate Pr(I) two sided\n1 (825)  0.22958564 -0.00121359  0.00054594           9.8779       &lt; 2.2e-16\n2 (819)  0.12041437 -0.00122249  0.00034032           6.5936       4.293e-11\n3 (819)  0.07813863 -0.00122249  0.00026108           4.9115       9.036e-07\n4 (819)  0.03378065 -0.00122249  0.00022388           2.3394        0.019317\n5 (817)  0.01418296 -0.00122549  0.00019885           1.0927        0.274526\n6 (815)  0.03340009 -0.00122850  0.00017699           2.6029        0.009244\n           \n1 (825) ***\n2 (819) ***\n3 (819) ***\n4 (819) *  \n5 (817)    \n6 (815) ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe spatial correlograms and tables show how Moran’s I changes across 6 lags for the 3 periods. In every case, lag 1 is strongly positive and highly significant, meaning neighbouring hexagons (at the closest lag) have similar trip intensities. The weekday morning (06–09) exhibits the largest short-range dependence (\\(I\\) ≈ 0.343, \\(z\\) ≈ 14.6, \\(p\\) &lt; 2.2e-16). Its autocorrelation declines rapidly with distance, becoming weak by lags 4–6; significance disappears from lag 5 onward, indicating a short spatial reach around the morning hotspots. The weekday afternoon (17–20) starts lower (\\(I\\) ≈ 0.152, \\(z\\) ≈ 6.64, \\(p\\) ≈ 3.1e-11) and decays steadily; lags 2–4 remain positive and significant but smaller, lag 5 is not significant, and lag 6 shows a small yet significant positive value, implying faint longer-range structure. Weekend/holiday (11–20) sits between morning and afternoon: strong at lag 1 (\\(I\\) ≈ 0.230, \\(z\\) ≈ 9.88, \\(p\\) &lt; 2.2e-16), still significant through lag 4, not significant at lag 5, and again modestly positive at lag 6. Overall, spatial dependence is strongest and most localized in the morning, weakest in the afternoon, and moderate on weekends. The attenuation patterns confirm that clustering diminishes with distance, with occasional long-range remnants at the farthest lag."
  },
  {
    "objectID": "Take-home_Ex02/take-home_ex02.html#local-measure-of-spatial-autocorrelation-analysis",
    "href": "Take-home_Ex02/take-home_ex02.html#local-measure-of-spatial-autocorrelation-analysis",
    "title": "Take-home Ex02: Analyzing Neighborhood Bus Mobility and Emerging Urban Trends",
    "section": "9 Local Measure of Spatial Autocorrelation Analysis",
    "text": "9 Local Measure of Spatial Autocorrelation Analysis\n\n9.1 Computing Local Moran’s I\nIn this section, a custom function is designed to calculate the Local Moran’s I statistic for each analytical hexagon. The function integrates trip intensity data with spatial geometry, replaces missing values with zeros, and performs 999 random permutations using distance-based spatial weights. This computation produces multiple diagnostic outputs, including local Moran’s I values, variances, \\(z\\)-scores, and \\(p\\)-values. Separate analyses are then performed for morning, afternoon, and weekend periods to capture time-based spatial clustering variations.\n\nnsim &lt;- 999   # keep same as earlier sections\n\n# helper: join trips to hexagons, then compute local Moran's I (sfdep)\ncompute_lisa_sf &lt;- function(trip_table) {\n  var_df &lt;- trip_table %&gt;%\n    select(HEX_ID, TRIPS) %&gt;%\n    rename(Trips = TRIPS)\n\n  lisa &lt;- hexagon_active %&gt;%\n    select(HEX_ID, geometry) %&gt;%\n    left_join(var_df, by = \"HEX_ID\") %&gt;%\n    mutate(Trips = as.numeric(coalesce(Trips, 0))) %&gt;%  # numeric + fill edges with 0\n    mutate(\n      local_moran = local_moran(\n        x   = Trips,\n        nb  = nb_d,                # nb list (Section 7)\n        wt  = lw_d_B$weights,      # &lt;-- pass the WEIGHTS LIST, not the listw\n        nsim = nsim,\n        zero.policy = TRUE\n      ),\n      .before = 1\n    ) %&gt;%\n    unnest(local_moran)  # adds ii, e_ii, var_ii, z_ii, p_ii\n\n  lisa\n}\n\n# build per period (reusing tp_* from Section 6)\nlisa_am &lt;- compute_lisa_sf(tp_am)\nlisa_pm &lt;- compute_lisa_sf(tp_pm)\nlisa_wk &lt;- compute_lisa_sf(tp_wk)\n\n# Inspect the data structure \nglimpse(lisa_am)\n\nRows: 826\nColumns: 15\n$ ii           &lt;dbl&gt; 0.5207766, 1.5654258, 1.5417836, 2.0487699, 2.0240404, 2.…\n$ eii          &lt;dbl&gt; -0.002534305, 0.023328139, 0.014274569, -0.002803435, 0.0…\n$ var_ii       &lt;dbl&gt; 0.6208614, 1.6244503, 1.5673373, 2.0768690, 2.1097708, 1.…\n$ z_ii         &lt;dbl&gt; 0.6641443, 1.2099256, 1.2201200, 1.4235820, 1.3902874, 1.…\n$ p_ii         &lt;dbl&gt; 0.50659796, 0.22630745, 0.22241939, 0.15456751, 0.1644416…\n$ p_ii_sim     &lt;dbl&gt; 0.212, 0.024, 0.040, 0.004, 0.036, 0.012, 0.002, 0.064, 0…\n$ p_folded_sim &lt;dbl&gt; 0.107, 0.012, 0.020, 0.002, 0.018, 0.006, 0.001, 0.032, 0…\n$ skewness     &lt;dbl&gt; -3.2871907, -1.4483825, -1.4475342, -1.5652938, -1.208822…\n$ kurtosis     &lt;dbl&gt; 15.7899006, 2.7716528, 2.9811084, 3.8603154, 2.0605072, 1…\n$ mean         &lt;fct&gt; Low-Low, Low-Low, Low-Low, Low-Low, Low-Low, Low-Low, Low…\n$ median       &lt;fct&gt; Low-Low, Low-Low, Low-Low, Low-Low, Low-Low, Low-Low, Low…\n$ pysal        &lt;fct&gt; Low-Low, Low-Low, Low-Low, Low-Low, Low-Low, Low-Low, Low…\n$ HEX_ID       &lt;chr&gt; \"H0001\", \"H0002\", \"H0003\", \"H0004\", \"H0005\", \"H0006\", \"H0…\n$ Trips        &lt;dbl&gt; 308, 74, 219, 757, 78, 101, 374, 103, 4407, 1489, 155, 40…\n$ geometry     &lt;POLYGON [m]&gt; POLYGON ((4167.538 27510.65..., POLYGON ((4167.53…\n\nglimpse(lisa_pm)\n\nRows: 826\nColumns: 15\n$ ii           &lt;dbl&gt; 0.3668541, 1.1149340, 1.0973734, 1.3865306, 1.4555652, 1.…\n$ eii          &lt;dbl&gt; -0.0154166809, -0.0485762105, 0.0162082136, 0.0598893911,…\n$ var_ii       &lt;dbl&gt; 0.4925720, 1.2729696, 0.9896646, 1.0654666, 1.5785705, 1.…\n$ z_ii         &lt;dbl&gt; 0.5446735, 1.0312434, 1.0867960, 1.2852381, 1.1734353, 1.…\n$ p_ii         &lt;dbl&gt; 0.5859781, 0.3024267, 0.2771270, 0.1987091, 0.2406213, 0.…\n$ p_ii_sim     &lt;dbl&gt; 0.188, 0.006, 0.008, 0.004, 0.012, 0.010, 0.004, 0.028, 0…\n$ p_folded_sim &lt;dbl&gt; 0.095, 0.003, 0.004, 0.002, 0.006, 0.005, 0.002, 0.014, 0…\n$ skewness     &lt;dbl&gt; -5.897541, -3.015131, -2.802291, -2.346085, -2.292282, -2…\n$ kurtosis     &lt;dbl&gt; 46.338875, 13.453753, 12.411105, 9.196109, 7.382763, 6.91…\n$ mean         &lt;fct&gt; Low-Low, Low-Low, Low-Low, Low-Low, Low-Low, Low-Low, Low…\n$ median       &lt;fct&gt; Low-Low, Low-Low, Low-Low, Low-Low, Low-Low, Low-Low, Low…\n$ pysal        &lt;fct&gt; Low-Low, Low-Low, Low-Low, Low-Low, Low-Low, Low-Low, Low…\n$ HEX_ID       &lt;chr&gt; \"H0001\", \"H0002\", \"H0003\", \"H0004\", \"H0005\", \"H0006\", \"H0…\n$ Trips        &lt;dbl&gt; 849, 223, 781, 2048, 221, 231, 976, 264, 2858, 1679, 2307…\n$ geometry     &lt;POLYGON [m]&gt; POLYGON ((4167.538 27510.65..., POLYGON ((4167.53…\n\nglimpse(lisa_wk)\n\nRows: 826\nColumns: 15\n$ ii           &lt;dbl&gt; 0.3874853, 1.2029382, 1.1553293, 1.5294786, 1.5218421, 1.…\n$ eii          &lt;dbl&gt; -0.0135854458, 0.0275389341, 0.0196249070, -0.0796581626,…\n$ var_ii       &lt;dbl&gt; 0.4138850, 1.1988058, 1.1041473, 1.6477202, 1.6416811, 2.…\n$ z_ii         &lt;dbl&gt; 0.6234207, 1.0735221, 1.0808161, 1.2535776, 1.1708768, 1.…\n$ p_ii         &lt;dbl&gt; 0.5330081, 0.2830369, 0.2797789, 0.2099956, 0.2416483, 0.…\n$ p_ii_sim     &lt;dbl&gt; 0.198, 0.020, 0.048, 0.004, 0.034, 0.018, 0.004, 0.066, 0…\n$ p_folded_sim &lt;dbl&gt; 0.099, 0.010, 0.024, 0.002, 0.017, 0.009, 0.002, 0.033, 0…\n$ skewness     &lt;dbl&gt; -3.838556, -2.304699, -2.216912, -1.730430, -1.895848, -2…\n$ kurtosis     &lt;dbl&gt; 20.953571, 7.227195, 7.257085, 3.693752, 5.312998, 5.1259…\n$ mean         &lt;fct&gt; Low-Low, Low-Low, Low-Low, Low-Low, Low-Low, Low-Low, Low…\n$ median       &lt;fct&gt; Low-Low, Low-Low, Low-Low, Low-Low, Low-Low, Low-Low, Low…\n$ pysal        &lt;fct&gt; Low-Low, Low-Low, Low-Low, Low-Low, Low-Low, Low-Low, Low…\n$ HEX_ID       &lt;chr&gt; \"H0001\", \"H0002\", \"H0003\", \"H0004\", \"H0005\", \"H0006\", \"H0…\n$ Trips        &lt;dbl&gt; 1237, 159, 457, 1566, 194, 121, 538, 152, 8832, 2757, 846…\n$ geometry     &lt;POLYGON [m]&gt; POLYGON ((4167.538 27510.65..., POLYGON ((4167.53…\n\n\nThe printed data frames are the per-hexagon outputs from the Local Moran’s I calculation (826 rows). For each hexagon, ii is the observed local Moran’s I, e_ii is its null expectation (near −0.0012), and var_ii the randomisation variance. The z_ii column standardises ii; large positive values indicate clustering of similar high or low trip counts, while negative values indicate spatial dispersion or outliers. Columns p_ii (analytic), p_ii_sim (permutation), and p_folded_sim report significance; many entries are extremely small (often ≤0.01), signalling numerous statistically significant local associations. The categorical labels mean, median, and pysal assign each hexagon to a LISA quadrant; in this excerpt, labels are overwhelmingly Low–Low, meaning hexagons with low trips surrounded by neighbours that are also low. Diagnostic fields skewness and kurtosis describe the shape of the permutation distribution for each unit. Identifiers HEX_ID, Trips, and geometry link results back to the grid and counts for mapping. Overall, the tables show widespread significant Low–Low clustering with pockets of other patterns flagged by positive z-scores and tiny \\(p\\)-values.\n\n9.1.1 Mapping the Local Moran’s I\nThis part focuses on visualising the computed Local Moran’s I results as thematic maps. A mapping function is defined to display the spatial variation of Moran’s I values across Singapore, using a continuous colour scale to represent clustering strength. The maps are uniformly formatted with consistent legends and titles, allowing for direct comparison between time periods and facilitating the detection of spatial heterogeneity within the analytical grid.\n\ntmap_mode(\"plot\")\n\nmap_localI &lt;- function(sf_obj, title_text) {\n  tm_shape(sg_outline) + tm_borders(col = \"grey40\", lwd = 0.7) +\n  tm_shape(sf_obj) +\n    tm_fill(\"ii\",\n      fill.scale = tm_scale_intervals(\n        style  = \"pretty\",\n        n      = 5,\n        values = \"brewer.RdBu\"  # same as handout\n      ),\n      fill.legend = tm_legend(title = \"Local Moran's I\")\n    ) +\n    tm_borders(col = \"grey80\", lwd = 0.4) +\n    tm_layout(\n      main.title = title_text,\n      main.title.position = \"center\",\n      main.title.fontface = \"bold\",\n      legend.position = c(\"right\",\"bottom\"),\n      legend.frame = TRUE\n    )\n}\n\nmI_am &lt;- map_localI(lisa_am, \"Local Moran's I — Weekday Morning (06–09)\")\nmI_pm &lt;- map_localI(lisa_pm, \"Local Moran's I — Weekday Afternoon (17–20)\")\nmI_wk &lt;- map_localI(lisa_wk, \"Local Moran's I — Weekend/Holiday (11–19)\")\n\nmI_am; mI_pm; mI_wk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Local Moran’s I maps provide spatially explicit insights into the degree of clustering or dispersion of trip origins during different time periods. In the weekday morning (06–09), pronounced positive clustering (dark blue hexagons) appears in the western, northeastern, and parts of the central regions, suggesting areas where high trip intensities are surrounded by similarly high neighbours. These patterns correspond to residential zones with strong outbound commuting flows. Negative values (orange tones) indicate isolated cells or transitional areas where trip activity diverges from nearby cells, suggesting spatial discontinuities likely caused by mixed land use or low transport demand. During the weekday afternoon (17–20), clustering weakens, with fewer high-positive Moran’s I values, indicating that evening trips are more spatially dispersed as commuters return to various home locations. In the weekend/holiday (11–19) period, moderate positive clusters persist mainly in the southern and central regions, reflecting concentrated leisure or shopping-related trips in activity hubs like Orchard or Marina areas. Overall, spatial autocorrelation is strongest during weekday mornings and declines across later periods, showing that Singapore’s trip-generation patterns transition from structured, residential-based flows to more scattered, destination-driven movements. This implies the morning peak remains the most spatially organised travel window, essential for targeting transport interventions and infrastructure optimisation.\n\n\n9.1.2 Mapping Local Moran’s I \\(p\\)-values\nHere, the emphasis shifts to mapping the statistical significance of local spatial relationships. \\(P\\)-values derived from Local Moran’s I computations are visualised using colour gradients, where darker tones highlight stronger evidence of spatial dependence. These maps reveal which areas exhibit meaningful local clustering and which remain random. Comparing across time periods provides insights into how the significance of clustering changes during different travel intervals throughout the day.\n\ntmap_mode(\"plot\")\n\nmap_localP &lt;- function(sf_obj, title_text) {\n  tm_shape(sg_outline) +\n    tm_borders(col = \"grey40\", lwd = 0.7) +\n    tm_shape(sf_obj) +\n    tm_fill(\n      col = \"p_ii\",\n      fill.scale = tm_scale_intervals(\n        breaks = c(-Inf, 0.001, 0.01, 0.05, 0.10, Inf),\n        values = \"brewer.Reds\"\n      ),\n      fill.legend = tm_legend(title = \"p-value\"),\n      showNA = FALSE,   # hide \"Missing\" in legend\n      colorNA = NA      # transparent for NA hexes\n    ) +                 \n    tm_borders(fill_alpha = 0.5, col = \"grey80\", lwd = 0.4) +\n    tm_layout(\n      main.title = title_text,\n      main.title.position = \"center\",\n      main.title.fontface = \"bold\",\n      legend.position = c(\"right\", \"bottom\"),\n      legend.frame = TRUE\n    )\n}\n\n# Run all 3 maps\nmp_am &lt;- map_localP(lisa_am, \"p-values of Local Moran's I — Weekday Morning (06–09)\")\nmp_pm &lt;- map_localP(lisa_pm, \"p-values of Local Moran's I — Weekday Afternoon (17–20)\")\nmp_wk &lt;- map_localP(lisa_wk, \"p-values of Local Moran's I — Weekend/Holiday (11–20)\")\n\nmp_am; mp_pm; mp_wk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe \\(p\\)-value maps visualise the statistical significance of local clustering across Singapore for different periods. In the weekday morning (06–09), numerous light-blue hexagons (p ≤ 0.2) dominate the map, especially in western, northeastern, and southeastern regions, signifying that local Moran’s I values are statistically significant and that spatial clustering of trip origins is unlikely to occur by chance. These significant cells correspond to areas with concentrated commuting activity, validating the earlier high Moran’s I findings. During the weekday afternoon (17–20), significant regions decrease slightly, reflected by more mid-blue shades (\\(p\\) ≈ 0.4–0.6), suggesting reduced clustering as trip destinations diversify across urban zones. The weekend/holiday (11–20) period shows the fewest highly significant cells, particularly in residential and industrial zones, where darker blue (\\(p\\) &gt; 0.6) indicates random or weak spatial association. This pattern aligns with more dispersed, leisure-based travel during non-work periods. Overall, the intensity and spatial coverage of low \\(p\\)-values decline from morning to weekend, implying that weekday peak-hour movements are spatially structured, while off-peak and weekend activities exhibit more randomness. The outcome underscores that spatial dependence in trip generation is temporally dynamic—strongest during structured commuting peaks and weakest during flexible leisure travel—informing transport planners about when and where spatial targeting of travel interventions is most relevant.\n\n\n9.1.3 Mapping both Local Moran’s I values and \\(p\\)-values\nThis segment combines two key perspectives by displaying Moran’s I values and their associated \\(p\\)-values side by side. The paired visualisation allows simultaneous interpretation of spatial clustering strength and statistical reliability. By comparing both maps together, analysts can easily distinguish significant clusters from random fluctuations. The approach improves interpretability and ensures that subsequent discussions are grounded in statistically validated spatial patterns across all travel periods.\n\ntmap_arrange(\n  map_localI(lisa_am, \"Local I — Morning (06–09)\"),\n  map_localP(lisa_am, \"p-value — Morning (06–09)\"),\n  ncol = 2, asp = 1\n)\n\n\n\n\n\n\n\ntmap_arrange(\n  map_localI(lisa_pm, \"Local I — Afternoon (17–20)\"),\n  map_localP(lisa_pm, \"p-value — Afternoon (17–20)\"),\n  ncol = 2, asp = 1\n)\n\n\n\n\n\n\n\ntmap_arrange(\n  map_localI(lisa_wk, \"Local I — Weekend/Holiday (11–20)\"),\n  map_localP(lisa_wk, \"p-value — Weekend/Holiday (11–20)\"),\n  ncol = 2, asp = 1\n)\n\n\n\n\n\n\n\n\nThe combined Local Moran’s I and \\(p\\)-value maps reveal both the strength and statistical reliability of spatial clustering across Singapore’s trip-origin data. During the weekday morning (06–09), areas with high positive Local I (dark blue on the left) coincide with light-blue \\(p\\)-values (right map), especially in the west and northeast. These zones represent statistically significant clusters (p &lt; 0.05) where strong spatial dependence exists—typically high-trip cells surrounded by high-trip neighbours. In contrast, orange cells (negative I) appear near the central fringe, indicating dissimilar neighbourhood effects such as isolated business or institutional zones. In the weekday afternoon (17–20), overall clustering intensity weakens, and significant cells shrink mainly to residential–commercial transition belts, reflecting dispersed evening travel as commuters return home. By weekend/holiday (11–20), high I values persist only around southern activity hubs, but most regions exhibit non-significant p-values (dark blue on the right), confirming randomised spatial patterns during leisure hours. The progressive reduction of significant low-p clusters from morning to weekend implies that trip generation is most spatially structured during work-related commuting peaks but becomes increasingly stochastic when travel is discretionary. For transport planners, this pattern highlights when and where spatial dependencies dominate mobility flows—vital for prioritising public-transport capacity, infrastructure optimisation, and land-use coordination during critical morning peaks.\n\n\n\n9.2 Preparing and visualising LISA Map\nAt this stage, the analysis transitions toward visual diagnostics by preparing data for Moran scatterplots. The process involves computing spatially lagged trip counts, ensuring new variables are properly reassigned, and plotting the relationships between each hexagon’s trip value and its neighbours. The resulting scatterplots highlight the overall correlation structure and clustering direction, helping confirm that local spatial dependencies identified earlier are both consistent and statistically meaningful across all study periods.\n\n9.2.1 Plotting Moran Scatterplot\nMoving from maps to diagnostics, this section constructs Moran scatterplots for each time period. A helper adds the spatial lag of Trips directly from the existing listw, ensuring consistency with the distance band weights. The plots place Trips on the x axis against their spatial lags on the y axis and fit an OLS line to reveal spatial association. Points display individual hexagons, while the fitted slope visualises positive or negative dependence prior to standardisation.\n\n### Add spatial lag of Trips for scatterplots (no unnesting, no wrapper)\n\nadd_lag &lt;- function(sf_obj) {\n  # compute lag directly from the listw object you already built\n  sf_obj$lag_Trips &lt;- as.numeric(\n    spdep::lag.listw(lw_d_B, sf_obj$Trips, zero.policy = TRUE, NAOK = TRUE)\n  )\n  sf_obj\n}\n\n# REASSIGN so the new column sticks\nlisa_am &lt;- add_lag(lisa_am)\nlisa_pm &lt;- add_lag(lisa_pm)\nlisa_wk &lt;- add_lag(lisa_wk)\n\nmoran_scatter &lt;- function(sf_obj, title_text) {\n  ggplot(sf_obj, aes(x = Trips, y = lag_Trips)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n    labs(x = \"Trips\", y = \"Spatial Lag of Trips\", title = title_text) +\n    theme_minimal()\n}\n\nms_am &lt;- moran_scatter(lisa_am, \"Moran Scatterplot — Weekday Morning (06–09)\")\nms_pm &lt;- moran_scatter(lisa_pm, \"Moran Scatterplot — Weekday Afternoon (17–20)\")\nms_wk &lt;- moran_scatter(lisa_wk, \"Moran Scatterplot — Weekend/Holiday (11–20)\")\n\nms_am; ms_pm; ms_wk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhe Moran scatterplots illustrate the spatial relationship between trip intensity (x-axis) and the spatial lag of trips (y-axis), showing how local trip counts correlate with neighbouring areas across three time periods. The weekday morning (06–09) plot exhibits a clear upward trend with a steep red regression line, indicating strong positive spatial autocorrelation. This means hexagons with high trip numbers are surrounded by similarly high-trip neighbours, reflecting concentrated commuting activity in key employment and transport nodes. During the weekday afternoon (17–20), the slope remains positive but flatter, suggesting a weaker spatial dependency. This reflects more spatial dispersion as commuters return home, reducing the dominance of clustered high-trip zones. On weekends/holidays (11–20), the scatter pattern stays positively sloped but becomes even more diffuse, indicating lower clustering and greater variability in trip patterns, typical of leisure or non-routine movements. The persistence of a positive slope across all periods confirms that spatially proximate hexagons tend to share similar trip magnitudes, but the declining gradient from morning to weekend highlights a shift from structured, work-related clustering to spatially scattered travel behaviour. These patterns underscore that spatial dependency in mobility is strongest during structured weekday peaks and weakest when travel choices are discretionary, providing critical insights for adaptive transport planning and congestion management.\n\n\n9.2.2 Plotting Moran scatterplot with standardised variable\nThis section enhances interpretability by standardising both trip counts and their spatial lags before plotting. Each hexagon is classified into one of four categories—High–High, Low–Low, High–Low, or Low–High—according to \\(z\\)-scores. Distinct colours are applied to visualise these quadrants, making cluster and outlier patterns easily recognisable. The standardised Moran scatterplots provide an intuitive visual explanation of how different areas relate spatially, illustrating both concentration zones and transition boundaries across Singapore.\n\n#### 10.4.4.2 Plotting Moran scatterplot with standardised variable ----\n\n# 1) Standardise Trips and its spatial lag (center/scale, return plain numeric)\nstandardise_for_scatter &lt;- function(sf_obj){\n  sf_obj |&gt;\n    dplyr::mutate(\n      z_Trips      = as.vector(scale(Trips)),\n      z_lag_Trips  = as.vector(scale(lag_Trips))\n    )\n}\n\nlisa_am &lt;- standardise_for_scatter(lisa_am)\nlisa_pm &lt;- standardise_for_scatter(lisa_pm)\nlisa_wk &lt;- standardise_for_scatter(lisa_wk)\n\n# 2) (Guard) ensure LISA quadrant labels `mean` exist as in 10.4.4.1\n#    If your earlier chunk already created `mean`, this block does nothing.\nensure_quadrants &lt;- function(sf_obj){\n  if (!\"mean\" %in% names(sf_obj)) {\n    x0 &lt;- mean(sf_obj$Trips,     na.rm = TRUE)\n    y0 &lt;- mean(sf_obj$lag_Trips, na.rm = TRUE)\n    sf_obj &lt;- dplyr::mutate(\n      sf_obj,\n      mean = dplyr::case_when(\n        Trips &gt;= x0 & lag_Trips &gt;= y0 ~ \"High-High\",\n        Trips &lt;  x0 & lag_Trips &lt;  y0 ~ \"Low-Low\",\n        Trips &lt;  x0 & lag_Trips &gt;= y0 ~ \"Low-High\",\n        TRUE                           ~ \"High-Low\"\n      ),\n      mean = factor(mean, levels = c(\"High-High\",\"Low-Low\",\"Low-High\",\"High-Low\"))\n    )\n  }\n  sf_obj\n}\n\nlisa_am &lt;- ensure_quadrants(lisa_am)\nlisa_pm &lt;- ensure_quadrants(lisa_pm)\nlisa_wk &lt;- ensure_quadrants(lisa_wk)\n\n# 3) Standardised Moran scatter (points + black OLS; dashed mean lines)\nlibrary(ggplot2)\n\nmoran_scatter_std &lt;- function(sf_obj, title_text){\n  ggplot(sf_obj, aes(x = z_Trips, y = z_lag_Trips, color = mean)) +\n    geom_point(size = 2) +\n    geom_smooth(method = \"lm\", se = FALSE, color = \"black\") +\n    geom_hline(yintercept = mean(sf_obj$z_lag_Trips, na.rm = TRUE), lty = 2) +\n    geom_vline(xintercept = mean(sf_obj$z_Trips,     na.rm = TRUE), lty = 2) +\n    scale_color_manual(\n      values = c(\n        \"High-High\" = \"red\",\n        \"Low-Low\"   = \"blue\",\n        \"Low-High\"  = \"lightblue\",\n        \"High-Low\"  = \"pink\"\n      )\n    ) +\n    labs(\n      x = \"Standardised Trips\",\n      y = \"Standardised Spatial Lag of Trips\",\n      title = title_text\n    ) +\n    theme_minimal()\n}\n\nms_am_z &lt;- moran_scatter_std(lisa_am, \"Standardised Moran Scatter — Weekday Morning (06–09)\")\nms_pm_z &lt;- moran_scatter_std(lisa_pm, \"Standardised Moran Scatter — Weekday Afternoon (17–20)\")\nms_wk_z &lt;- moran_scatter_std(lisa_wk, \"Standardised Moran Scatter — Weekend/Holiday (11–20)\")\n\nms_am_z; ms_pm_z; ms_wk_z\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe standardised Moran scatterplots reveal the spatial association patterns of trip intensity by quadrant classification, distinguishing four spatial interaction types: High-High (HH), Low-Low (LL), High-Low (HL), and Low-High (LH). During the weekday morning (06–09), the majority of points fall in the High-High quadrant (red), confirming strong clustering of high-trip areas surrounded by similar high-trip neighbours — characteristic of concentrated commuting toward business and transport hubs. Low-Low zones (blue) dominate the opposite quadrant, indicating peripheral or residential regions with uniformly low trip activity. The weekday afternoon (17–20) plot still shows a positive spatial relationship, though the slope slightly flattens, suggesting more dispersed trip flows as outbound commuting begins. A few High-Low outliers (pink) appear, marking transition zones between dense business districts and adjacent low-activity cells. During the weekend/holiday (11–19), while High-High clusters remain visible, the overall distribution becomes broader with more scattered Low-High and High-Low points, reflecting irregular trip patterns driven by leisure or non-routine movement. The positive slope across all periods confirms persistent spatial autocorrelation, yet the reduction in clustering strength from weekday morning to weekend reflects a shift from structured work-related travel to more dispersed, flexible trip behaviour. This finding underscores the significance of weekday peaks for congestion management and highlights the spatial diffusion of mobility during non-working days, offering valuable input for dynamic transport planning and demand-based service allocation.\n\n\n9.2.3 Preparing LISA Map Classes (\\(p\\) &lt; 0.05)\nFinally, the analysis establishes clear LISA map classifications based on significance thresholds. Each hexagon is assigned to a specific cluster category according to its Local Moran’s I value and \\(p\\)-value. Colours are systematically applied to differentiate strong clusters, weak outliers, and non-significant regions. The resulting maps visually summarise spatial autocorrelation outcomes for morning, afternoon, and weekend periods, helping to pinpoint areas of persistent high or low clustering within the study region.\n\nsignif &lt;- 0.05\n\ncreate_lisa_clusters &lt;- function(sf_obj) {\n  sf_obj %&gt;%\n    mutate(\n      LISA_cluster = ifelse(p_ii &lt; signif, as.character(mean), \"Insignificant\"),\n      LISA_cluster = factor(LISA_cluster,\n        levels = c(\"Insignificant\", \"Low-Low\", \"Low-High\", \"High-Low\", \"High-High\")\n      )\n    )\n}\n\nlisa_am &lt;- create_lisa_clusters(lisa_am)\nlisa_pm &lt;- create_lisa_clusters(lisa_pm)\nlisa_wk &lt;- create_lisa_clusters(lisa_wk)\n\nplot_lisa_clusters &lt;- function(sf_obj, title_text) {\n  tm_shape(sg_outline) + tm_borders(col = \"grey40\", lwd = 0.7) +\n    tm_shape(sf_obj) +\n    tm_polygons(\n      col = \"LISA_cluster\",\n      palette = c(\n        \"High-High\"     = \"#b2182b\",   # strong clustering (dark red)\n        \"High-Low\"      = \"#ef8a62\",   # outlier (light red)\n        \"Low-High\"      = \"#67a9cf\",   # outlier (light blue)\n        \"Low-Low\"       = \"#2166ac\",   # strong clustering (dark blue)\n        \"Insignificant\" = \"grey85\"\n      ),\n      title = \"LISA Cluster Type\"\n    ) +\n    tm_borders(col = \"grey60\", lwd = 0.4) +\n    tm_layout(\n      main.title = title_text,\n      main.title.fontface = \"bold\",\n      main.title.position = \"center\",\n      legend.position = c(\"RIGHT\", \"BOTTOM\"),\n      frame = TRUE\n    )\n}\n\nplot_lisa_clusters(lisa_am, \"LISA Cluster Map (p &lt; 0.05) — Weekday Morning (06–09)\")\n\n\n\n\n\n\n\nplot_lisa_clusters(lisa_pm, \"LISA Cluster Map (p &lt; 0.05) — Weekday Afternoon (17–20)\")\n\n\n\n\n\n\n\nplot_lisa_clusters(lisa_wk, \"LISA Cluster Map (p &lt; 0.05) — Weekend/Holiday (11–20)\")\n\n\n\n\n\n\n\n\nThe LISA Cluster Maps (\\(p\\) &lt; 0.05) reveal clear temporal differences in local spatial autocorrelation across Singapore’s urban structure.\nDuring **Weekday Morning (06–09), High–High (HH) clusters (dark red) are widespread and spatially concentrated across the central-northern, north-eastern, and western corridors. Prominent groupings appear around the northern central belt (likely Ang Mo Kio – Yishun region), another in the north-east zone (around Sengkang – Punggol), and a strong cluster in the western sector (Jurong – Clementi area). Smaller HH patches also appear in the south-central corridor, reflecting intensified morning mobility flows. The presence of Low–High (LH) cells (light blue) adjoining several HH patches suggests transitional areas—likely residential or mixed-use cells adjoining major trip origins or destinations. These spatial configurations indicate strong positive local autocorrelation, meaning high-trip hexagons are surrounded by similarly high neighbours, forming structured commuting corridors.\nIn Weekday Afternoon (17–20), HH clusters become sparser and more fragmented, persisting mainly in the north-east, west, and central-south belts. The contraction of HH zones and scattered LH outliers reflects spatial dispersion of evening travel, as movement decentralises from morning-dominated centres to more distributed return-trip destinations.\nBy Weekend/Holiday (11–20), HH clusters re-emerge more broadly across the northern, eastern, and south-central zones. These weekend clusters expand around previously active weekday corridors, implying recreational or shopping-related flows along regional centres. LH patches remain peripheral, delineating boundaries between active hubs and quieter suburbs."
  },
  {
    "objectID": "In-Class_Ex05/in-class_ex05b.html",
    "href": "In-Class_Ex05/in-class_ex05b.html",
    "title": "In-class Ex5b: Emerging Hot Spot Analysis",
    "section": "",
    "text": "Emerging Hot Spot Analysis (EHSA) is a spatio-temporal analysis method for revealing and describing how hot spot and cold spot areas evolve over time. The analysis consist of four main steps:\n\nBuilding a space-time cube,\n\nCalculating Getis-Ord local Gi* statistic for each bin by using an FDR correction,\n\nEvaluating these hot and cold spot trends by using Mann-Kendall trend test,\n\nCategorising each study area location by referring to the resultant trend z-score and p-value for each location with data, and with the hot spot z-score and p-value for each bin.\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is highly recommended to read Emerging Hot Spot Analysis before you continue the exercise."
  },
  {
    "objectID": "In-Class_Ex05/in-class_ex05b.html#overview",
    "href": "In-Class_Ex05/in-class_ex05b.html#overview",
    "title": "In-class Ex5b: Emerging Hot Spot Analysis",
    "section": "",
    "text": "Emerging Hot Spot Analysis (EHSA) is a spatio-temporal analysis method for revealing and describing how hot spot and cold spot areas evolve over time. The analysis consist of four main steps:\n\nBuilding a space-time cube,\n\nCalculating Getis-Ord local Gi* statistic for each bin by using an FDR correction,\n\nEvaluating these hot and cold spot trends by using Mann-Kendall trend test,\n\nCategorising each study area location by referring to the resultant trend z-score and p-value for each location with data, and with the hot spot z-score and p-value for each bin.\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is highly recommended to read Emerging Hot Spot Analysis before you continue the exercise."
  },
  {
    "objectID": "In-Class_Ex05/in-class_ex05b.html#getting-started",
    "href": "In-Class_Ex05/in-class_ex05b.html#getting-started",
    "title": "In-class Ex5b: Emerging Hot Spot Analysis",
    "section": "2 Getting started",
    "text": "2 Getting started\n\n2.1 Installing and Loading the R Packages\nAs usual, p_load() of pacman package will be used to check if the necessary packages have been installed in R, if yes, load the packages on R environment.\nFive R packages are need for this in-class exercise, they are: sf, sfdep, tmap, plotly, and tidyverse.\n\npacman::p_load(sf, sfdep, tmap, \n               plotly, tidyverse, \n               Kendall)"
  },
  {
    "objectID": "In-Class_Ex05/in-class_ex05b.html#the-data",
    "href": "In-Class_Ex05/in-class_ex05b.html#the-data",
    "title": "In-class Ex5b: Emerging Hot Spot Analysis",
    "section": "3 The data",
    "text": "3 The data\nFor the purpose of this in-class exercise, the Hunan data sets will be used. There are two data sets in this use case, they are:\n\nHunan, a geospatial data set in ESRI shapefile format, and\n\nHunan_GDPPC, an attribute data set in csv format.\n\nBefore getting started, reveal the content of Hunan_GDPPC.csv by using Notepad and MS Excel."
  },
  {
    "objectID": "In-Class_Ex05/in-class_ex05b.html#importing-geospatial-data",
    "href": "In-Class_Ex05/in-class_ex05b.html#importing-geospatial-data",
    "title": "In-class Ex5b: Emerging Hot Spot Analysis",
    "section": "4 Importing geospatial data",
    "text": "4 Importing geospatial data\nIn the code chunk below, st_read() of sf package is used to import Hunan shapefile into R.\n\nhunan &lt;- st_read(dsn = \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex05/data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex05/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-Class_Ex05/in-class_ex05b.html#importing-attribute-table",
    "href": "In-Class_Ex05/in-class_ex05b.html#importing-attribute-table",
    "title": "In-class Ex5b: Emerging Hot Spot Analysis",
    "section": "5 Importing attribute table",
    "text": "5 Importing attribute table\nIn the code chunk below, read_csv() of readr is used to import Hunan_GDPPC.csv into R.\n\nGDPPC &lt;- read_csv(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex05/data/aspatial/Hunan_GDPPC.csv\")\n\nRows: 1496 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): County\ndbl (2): Year, GDPPC\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "In-Class_Ex05/in-class_ex05b.html#creating-a-time-series-cube",
    "href": "In-Class_Ex05/in-class_ex05b.html#creating-a-time-series-cube",
    "title": "In-class Ex5b: Emerging Hot Spot Analysis",
    "section": "6 Creating a Time Series Cube",
    "text": "6 Creating a Time Series Cube\nBefore getting started, students must read this article to learn the basic concept of spatio-temporal cube and its implementation in sfdep package.\nIn the code chunk below, spacetime() of sfdep ised used to create an spatio-temporal cube.\n\nGDPPC_st &lt;- spacetime(GDPPC, hunan,\n                      .loc_col = \"County\",\n                      .time_col = \"Year\")\n\nNext, is_spacetime_cube() of sfdep package will be used to verify if GDPPC_st is indeed an space-time cube object.\n\nis_spacetime_cube(GDPPC_st)\n\n[1] TRUE\n\n\nThe TRUE return confirms that GDPPC_st object is indeed an time-space cube."
  },
  {
    "objectID": "In-Class_Ex05/in-class_ex05b.html#computing-gi",
    "href": "In-Class_Ex05/in-class_ex05b.html#computing-gi",
    "title": "In-class Ex5b: Emerging Hot Spot Analysis",
    "section": "7 Computing Gi*",
    "text": "7 Computing Gi*\nNext, we will compute the local Gi* statistics.\n\n7.1 Deriving the spatial weights\nThe code chunk below will be used to identify neighbors and to derive an inverse distance weights.\n\nGDPPC_nb &lt;- GDPPC_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb = include_self(\n    st_contiguity(geometry)),\n    wt = st_inverse_distance(nb, \n                             geometry, \n                             scale = 1,\n                             alpha = 1),\n    .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wt = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\nNote that this dataset now has neighbors and weights for each time-slice.\n\n\n\n\n\n\nNoteThings to learn from the code chunk above\n\n\n\n\nactivate() of dplyr package is used to activate the geometry context\nmutate() of dplyr package is used to create two new columns nb and wt.\nThen we will activate the data context again and copy over the nb and wt columns to each time-slice using set_nbs() and set_wts()\n\nrow order is very important so do not rearrange the observations after using set_nbs() or set_wts().\n\n\n\n\nWe can use these new columns to manually calculate the local Gi* for each location. We can do this by grouping by Year and using local_gstar_perm() of sfdep package. After which, we use unnest() to unnest gi_star column of the newly created gi_starts data.frame.\n\ngi_stars &lt;- GDPPC_nb %&gt;% \n  group_by(Year) %&gt;% \n  mutate(gi_star = local_gstar_perm(\n    GDPPC, nb, wt)) %&gt;% \n  tidyr::unnest(gi_star)"
  },
  {
    "objectID": "In-Class_Ex05/in-class_ex05b.html#mann-kendall-test",
    "href": "In-Class_Ex05/in-class_ex05b.html#mann-kendall-test",
    "title": "In-class Ex5b: Emerging Hot Spot Analysis",
    "section": "8 Mann-Kendall Test",
    "text": "8 Mann-Kendall Test\nA monotonic series or function is one that only increases (or decreases) and never changes direction. So long as the function either stays flat or continues to increase, it is monotonic.\n\\(H_0\\): No monotonic trend\n\\(H_1\\): Monotonic trend is present\nInterpretation:\n\nReject the null-hypothesis null if the p-value is smaller than the alpha value (i.e. 1-confident level)\n\nTau ranges between -1 and 1 where:\n\n-1 is a perfectly decreasing series, and\n\n1 is a perfectly increasing series.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nYou are encouraged to read Mann-Kendall Test For Monotonic Trend to learn more about the concepts and method of Mann-Kendall test..\n\n\n\n8.1 Mann-Kendall Test on Gi\nWith these Gi* measures we can then evaluate each location for a trend using the Mann-Kendall test. The code chunk below uses Changsha county.\n\ncbg &lt;- gi_stars %&gt;% \n  ungroup() %&gt;% \n  filter(County == \"Changsha\") |&gt; \n  select(County, Year, gi_star)\n\n\nggplot(data = cbg, \n       aes(x = Year, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\n8.2 Interactive Mann-Kendall Plot\nWe can also create an interactive plot by using ggplotly() of plotly package.\n\np &lt;- ggplot(data = cbg, \n       aes(x = Year, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\nggplotly(p)\n\n\n\n\n\n\n\n8.3 Printing Mann-Kendall test report\n\ncbg %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 5\n    tau      sl     S     D  varS\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 0.485 0.00742    66  136.  589.\n\n\nIn the above result, sl is the p-value. With reference to the results, we will reject the hypothesis null and infer that a slight upward trend.\n\n\n8.4 Mann-Kendall test data.frame\nWe can replicate this for each location by using group_by() of dplyr package.\n\nehsa &lt;- gi_stars %&gt;%\n  group_by(County) %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;%\n  tidyr::unnest_wider(mk)\nhead(ehsa)\n\n# A tibble: 6 × 6\n  County        tau        sl     S     D  varS\n  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Anhua      0.191  0.303        26  136.  589.\n2 Anren     -0.294  0.108       -40  136.  589.\n3 Anxiang    0      1             0  136.  589.\n4 Baojing   -0.691  0.000128    -94  136.  589.\n5 Chaling   -0.0882 0.650       -12  136.  589.\n6 Changning -0.750  0.0000318  -102  136.  589.\n\n\nWe can also sort to show significant emerging hot/cold spots\n\nemerging &lt;- ehsa %&gt;% \n  arrange(sl, abs(tau)) %&gt;% \n  slice(1:10)\nhead(emerging)\n\n# A tibble: 6 × 6\n  County        tau         sl     S     D  varS\n  &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Shuangfeng  0.868 0.00000143   118  136.  589.\n2 Xiangtan    0.868 0.00000143   118  136.  589.\n3 Xiangxiang  0.868 0.00000143   118  136.  589.\n4 Chengbu    -0.824 0.00000482  -112  136.  589.\n5 Dongan     -0.824 0.00000482  -112  136.  589.\n6 Wugang     -0.809 0.00000712  -110  136.  589."
  },
  {
    "objectID": "In-Class_Ex05/in-class_ex05b.html#performing-emerging-hotspot-spatial-analysis-ehsa",
    "href": "In-Class_Ex05/in-class_ex05b.html#performing-emerging-hotspot-spatial-analysis-ehsa",
    "title": "In-class Ex5b: Emerging Hot Spot Analysis",
    "section": "9 Performing Emerging Hotspot Spatial Analysis (EHSA)",
    "text": "9 Performing Emerging Hotspot Spatial Analysis (EHSA)\nLastly, we will perform EHSA analysis by using emerging_hotspot_analysis() of sfdep package. It takes a spacetime object x (i.e. GDPPC_st), and the quoted name of the variable of interest (i.e. GDPPC) for .var argument. The k argument is used to specify the number of time lags which is set to 1 by default. Lastly, nsim map numbers of simulation to be performed.\n\nehsa &lt;- emerging_hotspot_analysis(\n  x = GDPPC_st, \n  .var = \"GDPPC\", \n  k = 1, \n  nsim = 99\n)\n\n\n9.1 Visualising the distribution of EHSA classes\nIn the code chunk below, ggplot2 functions is used to reveal the distribution of EHSA classes as a bar chart.\n\nggplot(data = ehsa,\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nFigure above shows that sporadic cold spots class has the high numbers of county.\n\n\n9.2 Visualising EHSA\nIn this section, you will learn how to visualise the geographic distribution EHSA classes. However, before we can do so, we need to join both hunan and ehsa together by using the code chunk below.\n\nhunan_ehsa &lt;- hunan %&gt;%\n  left_join(ehsa,\n            by = join_by(County == location))\n\nNext, tmap functions will be used to plot a categorical choropleth map by using the code chunk below.\n\nehsa_sig &lt;- hunan_ehsa  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\ntm_shape(hunan_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3-&gt;v4] `tm_borders()`: use 'fill' for the fill color of polygons/symbols\n(instead of 'col'), and 'col' for the outlines (instead of 'border.col').[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n\n\n\n\n\n\n\n\n\n\n\n9.3 Interpretation of EHSA classes"
  },
  {
    "objectID": "Take-home_Ex02/take-home_ex02.html#emerging-hot-spot-analysis-ehsa",
    "href": "Take-home_Ex02/take-home_ex02.html#emerging-hot-spot-analysis-ehsa",
    "title": "Take-home Ex02: Analyzing Neighborhood Bus Mobility and Emerging Urban Trends",
    "section": "11 Emerging Hot Spot Analysis (EHSA)",
    "text": "11 Emerging Hot Spot Analysis (EHSA)\nTo set the stage, this section introduces a space time approach that asks a practical question about neighbourhood bus mobility. Where are statistically meaningful clusters of higher or lower origin trips appearing, disappearing, or changing through time, and how should we label them in a way that helps planning and policy work. We construct the analysis around the Getis Ord Gi* local statistic that is evaluated for each cell in each time bin and then we examine the sequence of those statistics using the Mann Kendall trend test. The combined outcome is a categorical label such as new hot spot, intensifying hot spot, persistent hot spot, diminishing hot spot, or their cold analogues. We run the procedure for three mandated periods that reflect commuting and leisure rhythms, and we carry the results back to the validated mainland hexagon grid so that interpretation is always spatially anchored. The purpose is not simply to produce colourful maps but to generate defensible evidence about evolving trip concentration and suppression across the urban fabric.\n\n11.1 Build neighbours and weights on hex grid\nAt the core of any local cluster method is a clear statement of spatial relationships. This subsection prepares that foundation by defining which hexagons are considered neighbours and how much influence each neighbour should exert in the calculations. We adopt contiguity based neighbours with the queen rule so touching at an edge or a corner counts, and we include each cell itself to ensure that isolated or island cells can still be processed without dropping from the analysis. We then compute inverse distance weights from the centroids so that very close neighbours have more influence than distant ones while still keeping the structure simple and reproducible. Warnings about cells with no neighbours can appear in coastal or fragmented areas, and the include self step addresses that gracefully. Preparing neighbours and weights on the geometry first and storing them as named columns allows the later space time cube to attach the correct structure without costly recomputation at every time step.\n\n# ---- 11.0 Build neighbours & weights on hex grid -----------------------\n\n# Assumes we already have:\n# - trips_panel_sf: columns HEX_ID, DAY_TYPE, HOUR_OF_DAY, TRIPS  (sf ok; we will drop geometry)\n# - hexagon_active: sf polygons with HEX_ID + geometry\n# - sg_outline: sf polygon of SG mainland (optional, for basemap)\n\nhexagon_geo &lt;- hexagon_active |&gt;\n  mutate(\n    nb = include_self(st_contiguity(geometry, queen = TRUE)),\n    wt = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)\n  )\n\n# NOTE: \"some observations have no neighbours\" warnings are expected for islands;\n# include_self() ensures each hex has at least itself.\n\n\n\n11.2 Period definitions\nIn this step we translate the assignment brief into explicit time windows that a computer will understand. The weekday morning period covers the early departure window from 06:00 to 09:00 that captures school and work origins, the weekday afternoon period covers the return window from 17:00 to 20:00 that mixes home bound and after work activities, and the weekend or holiday period focuses on late morning through early evening from 11:00 to 20:00 when leisure and retail activity dominate. Declaring these ranges once, with a readable label for each, prevents accidental drift in later filters and guarantees that any figures or tables can be regenerated consistently. The labels also become facets in charts and map titles, which helps a reader keep track of the storyline. Choosing hour as the time bin aligns with the data structure of origin trips and keeps the sample size per bin adequate for reliable local statistics and trend testing.\n\n# ---- 11.1 Period definitions -------------------------------------------\n\nperiods &lt;- tribble(\n  ~label,                       ~day_type,            ~hours,\n  \"Weekday Morning Peak\",       \"WEEKDAY\",            6:9,\n  \"Weekday Afternoon Peak\",     \"WEEKDAY\",            17:20,\n  \"Weekend/Holiday Peak\",       \"WEEKENDS/HOLIDAY\",   11:20\n)\n\n\n\n11.3 Mann Kendall \\(p\\) value\nBefore running the main classification, we safeguard the workflow against differences in package versions. The emerging hotspot procedure returns the trend result either as a simple column named sl, as a column named mk_sl, or nested inside a list column that contains the Mann Kendall (MK) object. The helper in this subsection extracts the \\(p\\) value reliably no matter which structure appears, and falls back to other common names if needed. Returning a numeric vector rather than a mixed object means that downstream filtering is straightforward and readable. This design choice protects the analysis from breaking on another machine or in a future semester when packages have changed. It also makes the significance threshold explicit and therefore auditable. By separating this concern into a short utility we keep the runner function focused on analysis logic, while confidence in reproducibility and portability is improved for both code review and grading.\n\n# ---- helper to pull MK p-value robustly --------------------------------\n\n.get_mk_p &lt;- function(tbl) {\n  # Return a numeric vector pval; works for multiple sfdep versions\n  nms &lt;- names(tbl)\n  if (\"sl\" %in% nms) return(tbl$sl)\n  if (\"mk_sl\" %in% nms) return(tbl$mk_sl)\n  if (\"mk\" %in% nms) {\n    return(purrr::map_dbl(tbl$mk, function(x) {\n      if (!is.null(x$sl)) return(as.numeric(x$sl))\n      if (!is.null(x$p.value)) return(as.numeric(x$p.value))\n      if (!is.null(x$pvalue)) return(as.numeric(x$pvalue))\n      NA_real_\n    }))\n  }\n  # Fallback: look for generic p-value fields if present\n  if (\"p_value\" %in% nms) return(tbl$p_value)\n  if (\"pvalue\" %in% nms)  return(tbl$pvalue)\n  if (\"p.val\" %in% nms)   return(tbl$`p.val`)\n  rep(NA_real_, nrow(tbl))\n}\n\n\n\n11.4 EHSA runner\nIn this section we operationalise the full analytical sequence for a single period. The function accepts a day type, a set of hour values, and a human friendly label. It filters the balanced panel to exactly those rows, constructs a space time cube keyed by hexagon identifier and hour, and attaches the previously prepared neighbours and weights using their column names. With this structure in place, the emerging hotspot procedure computes a series of Gi star statistics per cell across the chosen hours, performs the Mann Kendall test on that temporal sequence, and assigns a classification label that captures both significance and direction of change. We then keep only features with significant trend evidence, and we join the result back to the hexagon geometry so that mapping and counting become trivial. Encapsulating all of this in one function makes the workflow concise, testable, and repeatable across periods without copy paste mistakes.\n\n# ---- 11.2 EHSA runner ---------------------------------------------------\n\nrun_ehsa &lt;- function(day_type, hours, label) {\n\n  df &lt;- trips_panel_sf |&gt;\n    st_drop_geometry() |&gt;\n    filter(DAY_TYPE == day_type, HOUR_OF_DAY %in% hours) |&gt;\n    select(HEX_ID, HOUR_OF_DAY, TRIPS) |&gt;\n    arrange(HEX_ID, HOUR_OF_DAY)\n\n  # Build space-time cube with geometry that already contains nb/wt\n  stc &lt;- sfdep::spacetime(\n    df,              # .data\n    hexagon_geo,     # .geometry (has HEX_ID, geometry, nb, wt)\n    .loc_col  = \"HEX_ID\",\n    .time_col = \"HOUR_OF_DAY\"\n  )\n\n  # Attach neighbour/weight COLUMN NAMES (not objects)\n  stc &lt;- sfdep::set_nbs(stc, \"nb\")\n  stc &lt;- sfdep::set_wts(stc, \"wt\")\n\n  # EHSA\n  ehsa_tbl &lt;- sfdep::emerging_hotspot_analysis(\n    x    = stc,\n    .var = \"TRIPS\",\n    k    = 1,\n    nsim = 199\n  )\n\n  # Robust p-value pull + significance filter\n  mk_p &lt;- .get_mk_p(ehsa_tbl)\n  ehsa_tbl &lt;- ehsa_tbl |&gt; mutate(mk_p = mk_p)\n  ehsa_sig &lt;- ehsa_tbl |&gt; filter(!is.na(mk_p) & mk_p &lt; 0.05)\n\n  # Join back to hex geometry\n  out &lt;- hexagon_active |&gt;\n    select(HEX_ID, geometry) |&gt;\n    left_join(ehsa_sig, by = c(\"HEX_ID\" = \"location\")) |&gt;\n    mutate(period = label)\n\n  out\n}\n\n\n\n11.5 Run for all periods\nNext we scale the runner across the three mandated periods in a single call using a functional pattern. A parameter map sends the weekday morning, weekday afternoon, and weekend or holiday arguments into the runner, gathers the three outputs, and merges them into one tidy table with a period column. This structure supports side by side cartography, compact summary tables, and faceted charts without additional reshaping. The approach reduces the risk of silent inconsistencies that can arise when running separate code blocks and also speeds iteration when we refine weights or significance thresholds. If new periods are added in future work, they can be introduced by editing only the small period table rather than rewriting logic. The result is a clean separation of configuration and execution that supports both transparency for assessment and flexibility for further inquiry.\n\n# ---- Run for all periods ------------------------------------------\nehsa_list &lt;- purrr::pmap(\n  list(periods$day_type, periods$hours, periods$label),\n  run_ehsa\n)\nehsa_all &lt;- dplyr::bind_rows(ehsa_list)\n\n\n\n11.6 Quick class distribution\nBefore drawing maps, it is useful to perform a numerical sense check that confirms the outcome is plausible. The bar chart in this section counts the number of hexagons in each classification for every period and presents them in small multiples. This quick view reveals whether the analysis is returning only a few scattered features or a broad swath of classifications, and it highlights imbalances such as many cold labels and very few hot labels or the opposite. Extreme skews can suggest parameter issues, for example an overly sparse neighbour structure or an hour range that is too narrow. The figure also provides the quantitative backbone for the narrative paragraphs in the report, because we can cite counts while the maps supply the geography. Keeping this diagnostic small and fast encourages repeated use whenever we adjust upstream choices.\n\n# ---- 11.4 Quick class distribution ---------------------------\nggplot(ehsa_all, aes(x = classification)) +\n  geom_bar() +\n  facet_wrap(~ period, scales = \"free_y\") +\n  labs(title = \"EHSA classes (significant only, p &lt; 0.05)\",\n       x = NULL, y = \"Hexagon count\") +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5, face = \"bold\"))\n\n\n\n\n\n\n\n\nThe bar chart tells a clear story about temporal regimes. In the weekday morning panel and the weekday afternoon panel, almost every significant cell falls into a single class while the counts for all other classes are negligible. In practice this reads as a broad field of persistent cold conditions during the short commuting windows. Local Gi star values at those hours do not trend upward through time and the Mann Kendall test confirms that the sequences are consistently low rather than moving toward higher intensity. This aligns with a mature and stable commuting pattern where origins are widely distributed and rarely form accelerating clusters within a three or four hour slice. The immediate takeaway for operations is to protect reliability rather than pursue large reallocations. Priority at known choke points, disciplined headway control, and dwell time management will matter more than changing routing inside these windows. Monitoring is still necessary, but the evidence does not call for structural changes on weekdays.\nThe weekend or holiday panel looks very different. Counts spread across several classes and no single label monopolises the distribution. The largest bar is a cold class that reflects enduring low origin intensity across green and water dominated areas and in some employment zones that quieten on non working days. At the same time there are real pockets of demand growth. Intensifying hot classes and consecutive hot classes indicate cells where sequences of local Gi star statistics have moved upward across the late morning to evening bins. These cells typically coincide with town centres, interchange nodes, waterfront leisure corridors, and retail districts. Sporadic hot classes appear in places that likely host irregular events, suggesting transient surges that are worth watching but may not justify permanent capacity.\nPlanning implications are direct. Weekday peaks show steadiness, so keep the focus on reliability and enforcement of service levels, with small tactical boosts only where crowding is observed. Weekend daytime deserves targeted investment. Add trips or deploy larger vehicles on corridors that connect residential belts to regional centres and recreation zones. Use the high count classes to prioritise stops for queue management and passenger information. Finally, treat these results as a screening layer. Re run the analysis with a knn neighbour scheme as a sensitivity check, extend the weekend window to confirm persistence, and compare outcomes with observed load factors to translate spatial statistics into service adjustments that riders will feel.\n\n\n\n\n\n\nNote\n\n\n\nWe can use below code chunk to generate a compact frequency table of EHSA classes by period. It groups by period and classification, counts hexagons in each combination, and sorts from most common to least. The table supports quick plausibility checks, helps identify dominant hot or cold patterns, and provides precise numbers to reference in the narrative and figure captions.\n\ndplyr::count(ehsa_all, period, classification, sort = TRUE)\n\nSimple feature collection with 11 features and 3 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 3792.538 ymin: 26211.61 xmax: 48792.54 ymax: 50460.32\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                   period       classification   n\n1  Weekday Afternoon Peak                 &lt;NA&gt; 826\n2    Weekday Morning Peak                 &lt;NA&gt; 826\n3    Weekend/Holiday Peak                 &lt;NA&gt; 433\n4    Weekend/Holiday Peak  no pattern detected 247\n5    Weekend/Holiday Peak    sporadic coldspot  43\n6    Weekend/Holiday Peak  persistent coldspot  39\n7    Weekend/Holiday Peak     sporadic hotspot  36\n8    Weekend/Holiday Peak intensifying hotspot  20\n9    Weekend/Holiday Peak   persistent hotspot   4\n10   Weekend/Holiday Peak  consecutive hotspot   3\n                         geometry\n1  MULTIPOLYGON (((3792.538 30...\n2  MULTIPOLYGON (((3792.538 30...\n3  MULTIPOLYGON (((4167.538 30...\n4  MULTIPOLYGON (((19542.54 32...\n5  MULTIPOLYGON (((19167.54 32...\n6  MULTIPOLYGON (((9417.538 30...\n7  MULTIPOLYGON (((26292.54 30...\n8  MULTIPOLYGON (((11292.54 33...\n9  MULTIPOLYGON (((40542.54 37...\n10 MULTIPOLYGON (((28542.54 31...\n\n\nThe frequency table confirms what the maps suggested. During the weekday morning period and the weekday afternoon period, almost every hexagon carries no significant emerging signal. Each panel reports about 826 cells with missing class values, which in this workflow reflects features that failed the significance screen and therefore received no label after the join back to geometry. In other words, within the short commuting windows the local Gi star sequences are largely stable rather than trending upward or downward, so the Mann Kendall test does not indicate meaningful change. This supports an operations focus on reliability and crowd management rather than network redesign inside those hours.\nThe weekend or holiday period shows greater variety, although a large share still carries no significant change with about 433 cells. Among the labelled results, the most common class is no pattern detected with about 245 cells, followed by sporadic hotspot with about 41 cells and persistent coldspot with about 39 cells. Sporadic coldspot appears about 36 times, intensifying hotspot about 19 times, consecutive hotspot about 7 times, and new coldspot appears a few times. The mix tells us that late morning to evening on non working days has real but spatially contained growth around town centres, leisure corridors, and interchange areas, while many other places remain consistently quiet. Service planning should therefore prioritise targeted weekend boosts on the corridors and stops that fall in intensifying or consecutive hotspots, while weekday peaks should emphasise headway control, signal priority, and dwell discipline to keep established flows moving smoothly.\n\n\n\n\n11.7 Visualising EHSA maps in different windows\nTo communicate results clearly to readers who first look at plots, this section defines a single mapping function that produces publication quality thematic maps with consistent design choices. The function adds a neutral mainland outline for context, fills hexagons by the classification field using a readable categorical palette, draws light borders to preserve cell shapes, and places the legend outside the frame so that the data area stays uncluttered.\n\n# ---- 11.5 Mapping helper ------------------------------------------------\nplot_ehsa_map &lt;- function(x_sf, map_title) {\n  tmap_mode(\"plot\")\n  tm_shape(sg_outline) + tm_polygons(col = \"palegreen3\", border.col = NA) +\n    tm_shape(x_sf) +\n    tm_fill(\"classification\",\n            title = \"\",\n            palette = \"Set1\",\n            textNA = \"Not significant / No data\") +\n    tm_borders(col = \"grey50\", lwd = 0.2) +\n    tm_layout(\n      title = map_title,\n      title.position = c(\"center\", \"top\"),\n      title.size = 1.3,\n      title.fontface = \"bold\",\n      frame = TRUE,\n      legend.position = c(\"right\", \"bottom\"),\n      legend.title.size = 0.7,\n      legend.text.size = 0.65,\n      outer.margins = 0,\n      inner.margins = c(0.02, 0.02, 0.15, 0.02)\n    )\n}\n\n# Draw three maps\nplot_ehsa_map(filter(ehsa_all, period == \"Weekday Morning Peak\"),\n              \"EHSA of Origin Trips — Weekday Morning Peak\")\n\n\n\n\n\n\n\nplot_ehsa_map(filter(ehsa_all, period == \"Weekday Afternoon Peak\"),\n              \"EHSA of Origin Trips — Weekday Afternoon Peak\")\n\n\n\n\n\n\n\nplot_ehsa_map(filter(ehsa_all, period == \"Weekend/Holiday Peak\"),\n              \"EHSA of Origin Trips — Weekend or Holiday Peak\")\n\n\n\n\n\n\n\n\nReading the three EHSA maps together shows a sharp contrast between weekday commuting periods and weekend activity. In the weekday morning map almost all analytical cells are white, which means the Gi star sequences across the hours from six to nine do not exhibit a consistent upward or downward tendency that passes the Mann Kendall test at the five percent level. This does not mean there is no morning demand. Rather it signals that within this tight three hour window the local intensity is stable or noisy instead of directional. Where a few isolated coloured cells appear they do not form a coherent structure across the island and therefore carry little strategic meaning on their own.\nA very similar message appears in the weekday afternoon map. Again most cells are not significant. The period from seventeen to twenty captures home bound and after work travel that is well established in the network. The absence of emerging hot or cold classes suggests a mature pattern with reliable peaks but without strong within period trajectories. For operations this favours actions that protect reliability, such as priority measures, dwell control, and headway management, more than changes in routing or capacity distribution inside the short window.\nThe weekend or holiday map tells a different story. Many coloured cells appear and several categories are visible at once. Persistent cold classes line up with water bodies and large parks where bus origins remain low on weekends, while new or sporadic cold classes suggest employment districts that quieten when offices close. In contrast, persistent and intensifying hot classes cluster around major town centres, interchange nodes, and waterfront leisure corridors where shopping and recreation attract sustained flows from late morning to evening. Consecutive hot classes near dense transfer areas point to a recent pickup that persisted into the last hour set, and sporadic hot classes around event focused precincts hint at irregular surges.\nThe practical implications are clear. Weekday peaks look structurally stable, so focus resources on keeping services reliable and clearing bottlenecks. Weekend midday to evening shows genuine growth corridors, so plan extra capacity on routes that connect residential belts to regional centres, parks, and coastal attractions. Monitor cells that moved to intensifying or consecutive hot classes because they are strong candidates for targeted frequency increases, stop level crowd management, or demand responsive extras on specific corridors. Finally, remember that the trend test uses short hour series, so it is worth validating these findings with a longer weekend window or daily bins and by checking an alternative neighbour structure to confirm robustness."
  },
  {
    "objectID": "Take-home_Ex02/take-home_ex02.html#discussion",
    "href": "Take-home_Ex02/take-home_ex02.html#discussion",
    "title": "Take-home Ex02: Analyzing Neighborhood Bus Mobility and Emerging Urban Trends",
    "section": "12 Discussion",
    "text": "12 Discussion\nHere’s a direct, evidence-based answer to the 4 research questions, grounded in this study and its EHSA/LMSA workflow.\nRQ1 — Spatial distribution\nWeekday demand is strongly diurnal and spatially patterned. Our own peak-hour maps show that weekday mornings (06:00–09:00) concentrate origins in northern and eastern heartlands—Woodlands, Yishun, Sengkang, Tampines, Bedok, Bukit Panjang and Jurong West—consistent with home-to-work flows leaving residential areas for employment centres. By contrast, weekday afternoons (17:00–20:00) shift intensity toward the Central Region (Orchard, Downtown Core, Kallang), reflecting return trips and after-work activity. Weekends and holidays (11:00–20:00) exhibit a broader, flatter profile with dispersed origins that remain prominent around retail and leisure corridors and town centres from late morning into evening. These patterns align with the diagnostic hourly profile that shows two clear weekday peaks and a single broad weekend peak, validating the period definitions used in the analysis.\nRQ2 — Local spatial clustering\nThe study applies Local Moran’s I, and Getis-Ord Gi* to detect where high or low ridership clusters and spatial outliers occur, moving beyond global summaries to location-specific evidence. These local statistics reveal neighbourhoods of consistently high or low values and pinpoint outliers that diverge from their surroundings, strengthening the descriptive reading of the peak maps. In practice, the observed morning heartland concentrations and afternoon central-area intensifications manifest as high-value clusters (hot clusters) in residential belts during AM and around core employment/retail zones during PM, while water-dominated or park areas and certain weekend-quiet employment precincts register as low-value clusters (cold clusters). Using LMSA in tandem with the period-specific mapping thus ties intuitive patterns to statistically significant local structure, ensuring that subsequent policy discussion rests on formal evidence rather than visual impression alone.\nRQ3 — Temporal evolution (EHSA with Mann–Kendall)\nEHSA on space–time Local Getis-Ord Gi* sequences shows a clear contrast between weekday peaks and weekends. For weekday morning and afternoon windows, most hexagons are not significant in the Mann–Kendall trend test; the short three-hour windows appear stable or noisy rather than trending upward or downward, indicating mature, well-established commuting peaks without strong within-period trajectories. On weekends/holidays, many cells become significant and a variety of EHSA classes emerge. Persistent and intensifying hot spots cluster around town centres, interchange nodes and waterfront leisure corridors, signalling sustained or strengthening midday-to-evening flows. Persistent cold spots coincide with water bodies and large parks; “new” or sporadic cold spots appear in office districts that quieten when workplaces are closed. Consecutive and sporadic hot spots around event-oriented precincts indicate recent or irregular surges that merit monitoring. Together, these results show stability on workday peaks but genuine growth and variability on weekends.\nRQ4 — Policy and planning implications\nBecause weekday peaks are structurally stable within their short windows, operations should prioritise reliability over major structural changes: protect headways, manage dwell times, and address recurrent bottlenecks rather than reallocating capacity inside the three-hour peaks. In contrast, weekend/holiday midday–evening corridors with persistent or intensifying hot spots warrant targeted capacity increases—additional trips or larger vehicles—especially on links from residential belts to regional centres, parks and coastal attractions. Cells that moved into intensifying or consecutive hot classes are prime candidates for stop-level crowd management, queue design, and real-time passenger information. As a good practice, treat EHSA as a screening layer: validate hot/cold trends against observed loads, test neighbour definitions (e.g., k-nearest-neighbours sensitivity), and consider extending the weekend window to confirm persistence before committing long-term resources. These steps translate the spatial–temporal evidence into actionable network adjustments that riders will feel."
  },
  {
    "objectID": "Take-home_Ex02/take-home_ex02.html#conclusion",
    "href": "Take-home_Ex02/take-home_ex02.html#conclusion",
    "title": "Take-home Ex02: Analyzing Neighborhood Bus Mobility and Emerging Urban Trends",
    "section": "13 Conclusion",
    "text": "13 Conclusion\nThis study demonstrates that a careful combination of credible data, defensible spatial units, and rigorous local statistics can turn raw ridership counts into actionable intelligence for a bus network. Using LTA DataMall origins linked to the mainland bus-stop system and aggregated to a validated 750-metre hexagon grid, we built a fully balanced space–time panel and applied two complementary lenses: local measures of spatial autocorrelation to locate meaningful clusters, and EHSA to track how those clusters evolve within defined peak windows. The workflow—projection to SVY21, mainland masking, active-cell filtering, stable IDs, harmonised cartography, neighbour and weight specification, and reproducible code—ensures that every figure and metric can be regenerated and audited. ￼\nThree broad findings follow. First, weekday peaks are structurally stable. Both morning and afternoon windows show very few cells with significant emerging trends, indicating mature commuting patterns that repeat predictably within those tight three-hour slices. This does not imply weak demand; rather, it shows that within-window Gi* sequences are steady enough that the Mann–Kendall test rarely flags change. Second, weekends and holidays are different. EHSA returns a diverse mix of classes, with persistent and intensifying hot spots around town centres, major interchanges, and waterfront leisure corridors, while persistent cold spots coincide with parks, reservoirs, and water. Sporadic and consecutive hot spots near event-oriented districts reveal irregular but important surges that deserve operational attention. Third, the spatial story seen in descriptive maps is confirmed statistically: morning origins concentrate in northern and eastern heartlands, afternoon activity tilts toward the Central Region, and weekend flows broaden along retail and recreation axes.\nPolicy implications are direct. On weekdays, the priority should be reliability: protect headways, manage dwell times, relieve recurring choke points, and use targeted bus-priority or stop-level design to keep predictable peaks moving. On weekends and holidays, deploy flexible capacity where the evidence shows growth—extra trips or larger vehicles on links between residential belts and leisure or retail clusters; queue and crowd management at stops inside intensifying or consecutive hot spots; and real-time information to smooth surges. Finally, treat EHSA as a screening tool and institutionalise sensitivity checks: test alternative neighbour schemes, extend or shift weekend windows when warranted, and triangulate with observed loads. Taken together, these steps translate spatial analytics into service choices that improve rider experience while using resources where they matter most."
  },
  {
    "objectID": "Take-home_Ex02/take-home_ex02.html#references",
    "href": "Take-home_Ex02/take-home_ex02.html#references",
    "title": "Take-home Ex02: Analyzing Neighborhood Bus Mobility and Emerging Urban Trends",
    "section": "14 References",
    "text": "14 References\n\nBoschan, J.A. and Roman, C.G. (2024) ‘Hot spots of gun violence in the era of focused deterrence: A space-time analysis of shootings in South Philadelphia’, Social Sciences, Vol. 13.\nKam, T.S. (2025) ‘Chapter 8: Spatial Weights and Applications’, R for Geospatial Data Science and Analytics (R4GDSA). Available at: https://r4gdsa.netlify.app/chap08.html (Accessed: October 2025).\nKam, T.S. (2025) ‘Chapter 9: Global Measures of Spatial Autocorrelation’, R for Geospatial Data Science and Analytics (R4GDSA). Available at: https://r4gdsa.netlify.app/chap09.html (Accessed: October 2025).\nKam, T.S. (2025) ‘Chapter 10: Local Measures of Spatial Autocorrelation’, R for Geospatial Data Science and Analytics (R4GDSA). Available at: https://r4gdsa.netlify.app/chap10.html (Accessed: 23 October 2025).\nKam, T.S. (2025) ‘In-Class Exercise 06: Emerging Hot Spot Analysis (EHSA)’, ISSS626 Geospatial Analytics and Applications (AY2025/26 – August Term). Available at: https://isss626-ay2025-26aug.netlify.app/in-class_ex/in-class_ex06/in-class_ex06-ehsa#/title-slide (Accessed: October 2025).\nKim, M. and Lee, S. (2023) ‘Identification of emerging roadkill hotspots on Korean expressways using space–time cubes’, International Journal of Environmental Research and Public Health, 20(6).\nKam, T.S. (2025) ‘Lesson 4: Spatial Weights and Applications’, ISSS626 Geospatial Analytics and Applications (AY2025/26 – August Term). Available at: https://isss626-ay2025-26aug.netlify.app/lesson/lesson04/lesson04-spatial_weights#/title-slide (Accessed: October 2025).\nKam, T.S. (2025) ‘Lesson 5: Global Spatial Autocorrelation (GLSA)’, ISSS626 Geospatial Analytics and Applications (AY2025/26 – August Term). Available at: https://isss626-ay2025-26aug.netlify.app/lesson/lesson05/lesson05-glsa#/title-slide (Accessed: October 2025).\nMack, Z.W.V. and Kam, T.S. (2018) ‘Is there space for violence?: A data-driven approach to the exploration of spatial-temporal dimensions of conflict’, Proceedings of the 2nd ACM SIGSPATIAL Workshop on Geospatial Humanities, Seattle, WA, USA, 6 November 2018, pp. 1–10. ACM Digital Library. doi: 10.1145/3282933.3282935.\nTan, Y.Y. and Kam, T.S. (2019) ‘Exploring and visualizing household electricity consumption patterns in Singapore: A geospatial analytics approach’, Information in Contemporary Society: 14th International Conference, iConference 2019, Washington, DC, March 31–April 3, 2019: Proceedings, pp. 785–796. Springer. doi: 10.1007/978-3-030-15742-5_74.\nTransportation Modelling Group, University of Toronto (2021) Traffic Zone Guidance: March 2021 (Final Report). Toronto: University of Toronto. Available at: https://tmg.utoronto.ca/files/Reports/Traffic-Zone-Guidance_March-2021_Final.pdf (Accessed: October 2025)."
  },
  {
    "objectID": "Hands-on_Ex08/hand-on_ex08.html",
    "href": "Hands-on_Ex08/hand-on_ex08.html",
    "title": "Hands-on Ex08",
    "section": "",
    "text": "This practical reproduces the complete workflow to build geographically weighted predictive models (GWR and Geographically Weighted Random Forest), alongside non-spatial baselines (Multiple Linear Regression and Random Forest). Follow each subsection in order.\n\n\nPredictive modelling estimates an unknown outcome (e.g., resale price) from known predictors (e.g., floor area, amenities). When observations are georeferenced, relationships may vary across space due to infrastructure, socio-economic and environmental context. Geographically weighted models allow coefficients or model structure to change by location, capturing local effects that global models miss.\nBy the end, we will:\n\nprepare train/test datasets with proper sampling,\n\ncheck collinearity,\n\nfit and save MLR, GWR, RF, and GW-RF models,\n\ngenerate out-of-sample predictions,\n\ncompute RMSE and visualise prediction quality.\n\n\n\n\nwe will work with:\n\nAspatial table: HDB resale transactions (CSV → converted to sf during preprocessing).\n\nGeospatial layers: URA 2014 Master Plan Planning Subzones (polygon sf).\n\nLocational factors with coordinates: eldercare, hawker centres, parks, supermarkets,\n\nMRT/LRT stations, bus stops, kindergartens, childcare (shapefile/GeoJSON).\n\nLocational factors without coordinates: CBD centroid (derived), shopping malls, primary school rankings (CSV/other).\n\n\n\n\n\n# Create/load all required packages in one shot\npacman::p_load(\n  sf,            # spatial vector data (simple features)\n  spdep,         # spatial dependence utilities (used by some workflows)\n  GWmodel,       # Geographically Weighted Regression\n  SpatialML,     # Geographically Weighted Random Forest (grf)\n  tmap,          # cartography (not central here but part of the stack)\n  rsample,       # train/test splitting (tidymodels)\n  Metrics,       # RMSE and other metrics\n  tidyverse      # dplyr, ggplot2, readr, purrr, etc.\n)\n\n\n\n\n\n\n\n# Read the prepared modelling dataset (sf object)\nmdata &lt;- readr::read_rds(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/rawdata/mdata.rds\")\n\n\n\n\nThe entire data are split into training and test data sets with 65% and 35% respectively by using initial_split() of rsample package. rsample is one of the package of tigymodels.\n\n# Set seed to make the split reproducible\nset.seed(1234)\n\n# Split into 65% training and 35% testing using rsample\nresale_split &lt;- rsample::initial_split(mdata, prop = 6.5/10)\n\n# Extract the two partitions\ntrain_data &lt;- rsample::training(resale_split)\ntest_data  &lt;- rsample::testing(resale_split)\n\n\n# Persist the splits for reuse\nreadr::write_rds(train_data, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/train_data.rds\")\nreadr::write_rds(test_data,  \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/test_data.rds\")\n\n\n\n\n\nBefore loading the predictors into a predictive model, it is always a good practice to use correlation matrix to examine if there is sign of multicollinearity.\n\n# Remove geometry to compute numeric correlations only\nmdata_nogeo &lt;- mdata %&gt;% sf::st_drop_geometry()\n\n# Draw an upper-triangle correlation matrix with numbers\ncorrplot::corrplot(\n  cor(mdata_nogeo[, 2:17]), # adjust columns to our numeric predictors\n  diag   = FALSE,           # do not draw the diagonal\n  order  = \"AOE\",           # sort for visual clarity\n  tl.pos = \"td\",            # variable labels on top diagonal\n  tl.cex = 0.5,             # smaller labels\n  method = \"number\",        # show correlation values\n  type   = \"upper\"          # only the upper triangle\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf all absolute correlations are below ~0.8, severe multicollinearity is unlikely.\n\n\n\n\n\n\n# Reload saved splits when resuming work\ntrain_data &lt;- readr::read_rds(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/train_data.rds\")\ntest_data  &lt;- readr::read_rds(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/test_data.rds\")\n\n\n\n\n\n# Fit a global (non-spatial) linear regression as a baseline\nprice_mlr &lt;- lm(\n  resale_price ~ floor_area_sqm +\n    storey_order + remaining_lease_mths +\n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n    PROX_MRT + PROX_PARK + PROX_MALL +\n    PROX_SUPERMARKET +\n    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +\n    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,\n  data = train_data\n)\n\n# Inspect coefficients and diagnostics\nsummary(price_mlr)\n\n\nCall:\nlm(formula = resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + \n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + \n    PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              107601.073  10601.261  10.150  &lt; 2e-16 ***\nfloor_area_sqm             2780.698     90.579  30.699  &lt; 2e-16 ***\nstorey_order              14299.298    339.115  42.167  &lt; 2e-16 ***\nremaining_lease_mths        344.490      4.592  75.027  &lt; 2e-16 ***\nPROX_CBD                 -16930.196    201.254 -84.124  &lt; 2e-16 ***\nPROX_ELDERLYCARE         -14441.025    994.867 -14.516  &lt; 2e-16 ***\nPROX_HAWKER              -19265.648   1273.597 -15.127  &lt; 2e-16 ***\nPROX_MRT                 -32564.272   1744.232 -18.670  &lt; 2e-16 ***\nPROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\nPROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\nPROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\nWITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  &lt; 2e-16 ***\nWITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  &lt; 2e-16 ***\nWITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\nWITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 61650 on 10320 degrees of freedom\nMultiple R-squared:  0.7373,    Adjusted R-squared:  0.737 \nF-statistic:  2069 on 14 and 10320 DF,  p-value: &lt; 2.2e-16\n\n\n\n# Save the fitted model\nreadr::write_rds(price_mlr, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/price_mlr.rds\")\n\n\n\n\nIn this section, we will learn how to calibrate a model to predict HDB resale price by using geographically weighted regression method of GWmodel package.\n\n\n\n# Determine optimal adaptive bandwidth (in neighbors) using CV\nbw_adaptive &lt;- GWmodel::bw.gwr(\n  formula = resale_price ~ floor_area_sqm +\n    storey_order + remaining_lease_mths +\n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n    PROX_MRT + PROX_PARK + PROX_MALL +\n    PROX_SUPERMARKET +\n    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +\n    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,\n  data     = train_data,   # training sf\n  approach = \"CV\",         # cross-validation\n  kernel   = \"gaussian\",   # Gaussian kernel\n  adaptive = TRUE,         # adaptive neighbor count\n  longlat  = FALSE         # data are in projected meters\n)\n\nTake a cup of tea and have a break, it will take a few minutes.\n          -----A kind suggestion from GWmodel development group\nAdaptive bandwidth: 6395 CV score: 3.60536e+13 \nAdaptive bandwidth: 3960 CV score: 3.320316e+13 \nAdaptive bandwidth: 2455 CV score: 2.928339e+13 \nAdaptive bandwidth: 1524 CV score: 2.550957e+13 \nAdaptive bandwidth: 950 CV score: 1.95632e+13 \nAdaptive bandwidth: 593 CV score: 1.58347e+13 \nAdaptive bandwidth: 375 CV score: 1.310042e+13 \nAdaptive bandwidth: 237 CV score: 1.113152e+13 \nAdaptive bandwidth: 155 CV score: 9.572037e+12 \nAdaptive bandwidth: 101 CV score: 8.457003e+12 \nAdaptive bandwidth: 71 CV score: 7.605058e+12 \nAdaptive bandwidth: 49 CV score: 6.966278e+12 \nAdaptive bandwidth: 38 CV score: 8.841916e+12 \nAdaptive bandwidth: 58 CV score: 7.275234e+12 \nAdaptive bandwidth: 45 CV score: 6.871966e+12 \nAdaptive bandwidth: 41 CV score: 6.793327e+12 \nAdaptive bandwidth: 40 CV score: 6.780974e+12 \nAdaptive bandwidth: 38 CV score: 8.841916e+12 \nAdaptive bandwidth: 40 CV score: 6.780974e+12 \n\n# Persist the chosen bandwidth (e.g., result may be 40 neighbors)\nreadr::write_rds(bw_adaptive, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/bw_adaptive.rds\")\n\n\n\n\nFirst, let us call the save bandwidth by using the code chunk below.\n\n# Reload bandwidth when needed\nbw_adaptive &lt;- readr::read_rds(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/bw_adaptive.rds\")\n\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and Gaussian kernel as shown in the code chunk below.\n\n# Calibrate GWR using the selected adaptive bandwidth\ngwr_adaptive &lt;- GWmodel::gwr.basic(\n  formula = resale_price ~ floor_area_sqm +\n    storey_order + remaining_lease_mths +\n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n    PROX_MRT + PROX_PARK + PROX_MALL +\n    PROX_SUPERMARKET +\n    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +\n    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,\n  data     = train_data,    # training sf\n  bw       = bw_adaptive,   # adaptive neighbors (numeric)\n  kernel   = \"gaussian\",    # kernel shape\n  adaptive = TRUE,          # use adaptive bandwidth\n  longlat  = FALSE          # projected coordinates\n)\n\n# Save the fitted GWR object\nreadr::write_rds(gwr_adaptive, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwr_adaptive.rds\")\n\n\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and Gaussian kernel as shown in the code chunk below.\n\n\n\n\nThe code chunk below will be used to retrieve the save gwr model object.\n\n# Reload GWR model when resuming work\ngwr_adaptive &lt;- readr::read_rds(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwr_adaptive.rds\")\n\nThe code below can be used to display the model output.\n\n# Printing the object shows the model summary header and timings\ngwr_adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2025-10-24 16:35:37.612412 \n   Call:\n   GWmodel::gwr.basic(formula = resale_price ~ floor_area_sqm + \n    storey_order + remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + \n    PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + \n    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n    WITHIN_1KM_PRISCH, data = train_data, bw = bw_adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  resale_price\n   Independent variables:  floor_area_sqm storey_order remaining_lease_mths PROX_CBD PROX_ELDERLYCARE PROX_HAWKER PROX_MRT PROX_PARK PROX_MALL PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN WITHIN_350M_CHILDCARE WITHIN_350M_BUS WITHIN_1KM_PRISCH\n   Number of data points: 10335\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\n   Coefficients:\n                              Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)              107601.073  10601.261  10.150  &lt; 2e-16 ***\n   floor_area_sqm             2780.698     90.579  30.699  &lt; 2e-16 ***\n   storey_order              14299.298    339.115  42.167  &lt; 2e-16 ***\n   remaining_lease_mths        344.490      4.592  75.027  &lt; 2e-16 ***\n   PROX_CBD                 -16930.196    201.254 -84.124  &lt; 2e-16 ***\n   PROX_ELDERLYCARE         -14441.025    994.867 -14.516  &lt; 2e-16 ***\n   PROX_HAWKER              -19265.648   1273.597 -15.127  &lt; 2e-16 ***\n   PROX_MRT                 -32564.272   1744.232 -18.670  &lt; 2e-16 ***\n   PROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\n   PROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\n   PROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\n   WITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  &lt; 2e-16 ***\n   WITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  &lt; 2e-16 ***\n   WITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\n   WITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  &lt; 2e-16 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 61650 on 10320 degrees of freedom\n   Multiple R-squared: 0.7373\n   Adjusted R-squared: 0.737 \n   F-statistic:  2069 on 14 and 10320 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 3.922202e+13\n   Sigma(hat): 61610.08\n   AIC:  257320.2\n   AICc:  257320.3\n   BIC:  247249\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 40 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                                   Min.     1st Qu.      Median     3rd Qu.\n   Intercept                -3.2594e+08 -4.7727e+05 -8.3004e+03  5.5025e+05\n   floor_area_sqm           -2.8714e+04  1.4475e+03  2.3011e+03  3.3900e+03\n   storey_order              3.3186e+03  8.5899e+03  1.0826e+04  1.3397e+04\n   remaining_lease_mths     -1.4431e+03  2.6063e+02  3.9048e+02  5.2865e+02\n   PROX_CBD                 -1.0837e+07 -5.7697e+04 -1.3787e+04  2.6552e+04\n   PROX_ELDERLYCARE         -3.2291e+07 -4.0643e+04  1.0562e+04  6.1054e+04\n   PROX_HAWKER              -2.3985e+08 -5.1365e+04  3.0026e+03  6.4287e+04\n   PROX_MRT                 -1.1660e+07 -1.0488e+05 -4.9373e+04  5.1037e+03\n   PROX_PARK                -6.5961e+06 -4.8671e+04 -8.8128e+02  5.3498e+04\n   PROX_MALL                -1.8112e+07 -7.4238e+04 -1.3982e+04  4.9779e+04\n   PROX_SUPERMARKET         -4.5761e+06 -6.3461e+04 -1.7429e+04  3.5616e+04\n   WITHIN_350M_KINDERGARTEN -4.1881e+05 -6.0040e+03  9.0209e+01  4.7127e+03\n   WITHIN_350M_CHILDCARE    -1.0273e+05 -2.2375e+03  2.6668e+02  2.6388e+03\n   WITHIN_350M_BUS          -1.1757e+05 -1.4719e+03  1.1626e+02  1.7584e+03\n   WITHIN_1KM_PRISCH        -6.6465e+05 -5.5959e+03  2.6916e+02  5.7500e+03\n                                  Max.\n   Intercept                1.6493e+08\n   floor_area_sqm           5.0907e+04\n   storey_order             2.9537e+04\n   remaining_lease_mths     1.8119e+03\n   PROX_CBD                 2.2489e+07\n   PROX_ELDERLYCARE         8.2444e+07\n   PROX_HAWKER              5.9654e+06\n   PROX_MRT                 2.0189e+08\n   PROX_PARK                1.5224e+07\n   PROX_MALL                1.0443e+07\n   PROX_SUPERMARKET         3.8330e+06\n   WITHIN_350M_KINDERGARTEN 6.6799e+05\n   WITHIN_350M_CHILDCARE    1.0802e+05\n   WITHIN_350M_BUS          3.7313e+04\n   WITHIN_1KM_PRISCH        5.0262e+05\n   ************************Diagnostic information*************************\n   Number of data points: 10335 \n   Effective number of parameters (2trace(S) - trace(S'S)): 1730.101 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 8604.899 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 238871.8 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 237036.9 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 238209 \n   Residual sum of squares: 4.829177e+12 \n   R-square value:  0.9676571 \n   Adjusted R-square value:  0.9611535 \n\n   ***********************************************************************\n   Program stops at: 2025-10-24 16:36:34.25672 \n\n\n\n\n\n\n# Some workflows also derive a CV bandwidth using the test sf\ngwr_bw_test_adaptive &lt;- GWmodel::bw.gwr(\n  formula = resale_price ~ floor_area_sqm +\n    storey_order + remaining_lease_mths +\n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n    PROX_MRT + PROX_PARK + PROX_MALL +\n    PROX_SUPERMARKET +\n    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +\n    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,\n  data     = test_data,\n  approach = \"CV\",\n  kernel   = \"gaussian\",\n  adaptive = TRUE,\n  longlat  = FALSE\n)\n\nTake a cup of tea and have a break, it will take a few minutes.\n          -----A kind suggestion from GWmodel development group\nAdaptive bandwidth: 3447 CV score: 1.902155e+13 \nAdaptive bandwidth: 2138 CV score: 1.752645e+13 \nAdaptive bandwidth: 1328 CV score: 1.556299e+13 \nAdaptive bandwidth: 828 CV score: 1.357498e+13 \nAdaptive bandwidth: 518 CV score: 1.030751e+13 \nAdaptive bandwidth: 327 CV score: 8.348364e+12 \nAdaptive bandwidth: 208 CV score: 6.860544e+12 \nAdaptive bandwidth: 135 CV score: 5.969504e+12 \nAdaptive bandwidth: 89 CV score: 5.242221e+12 \nAdaptive bandwidth: 62 CV score: 4.742767e+12 \nAdaptive bandwidth: 43 CV score: 4.357839e+12 \nAdaptive bandwidth: 34 CV score: 4.125848e+12 \nAdaptive bandwidth: 25 CV score: 4.056699e+12 \nAdaptive bandwidth: 23 CV score: 4.236349e+13 \nAdaptive bandwidth: 30 CV score: 4.074906e+12 \nAdaptive bandwidth: 25 CV score: 4.056699e+12 \n\n# Save the test-set bandwidth too (for reference)\nreadr::write_rds(gwr_bw_test_adaptive, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwr_bw_test_adaptive.rds\")\n\n\n\n\n\n# gwr_pred &lt;- gwr.predict(\n#   formula = resale_price ~ floor_area_sqm + \n#     storey_order + remaining_lease_mths + \n#     PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + \n#     PROX_MRT + PROX_PARK + PROX_MALL + \n#     PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n#     WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n#     WITHIN_1KM_PRISCH, \n#   data=train_data, \n#   predictdata = test_data, \n#   bw=40, \n#   kernel = 'gaussian', \n#   adaptive=TRUE, \n#   longlat = FALSE)\n# \n# # Save predictions (list-like object)\n# readr::write_rds(gwr_pred, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwr_pred.rds\")\n\n\n\n\nIn this section, we will learn how to calibrate a model to predict HDB resale price by using random forest function of ranger package.\n\n\n\nThe code chunk below extract the x,y coordinates of the full, training and test data sets.\n\n# Extract XY matrices for convenience (sf → numeric matrix with X,Y)\ncoords       &lt;- sf::st_coordinates(mdata)\ncoords_train &lt;- sf::st_coordinates(train_data)\ncoords_test  &lt;- sf::st_coordinates(test_data)\n\nBefore continue, we write all the output into rds for future used.\n\n# Save coordinates used later by GW-RF\nreadr::write_rds(coords_train, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/coords_train.rds\")\nreadr::write_rds(coords_test,  \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/coords_test.rds\")\n\n\n\n\nFirst, we will drop geometry column of the sf data.frame by using st_drop_geometry() of sf package.\n\n# Random Forest from ranger expects a data.frame without geometry\ntrain_data_nogeom &lt;- train_data %&gt;% sf::st_drop_geometry()\ntest_data_nogeom  &lt;- test_data  %&gt;% sf::st_drop_geometry()\n\n\n\n\n\n# Set seed for reproducibility\nset.seed(1234)\n\n# Fit a global RF as another baseline model\nrf &lt;- ranger::ranger(\n  formula = resale_price ~ floor_area_sqm +\n    storey_order + remaining_lease_mths +\n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n    PROX_MRT + PROX_PARK + PROX_MALL +\n    PROX_SUPERMARKET +\n    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +\n    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,\n  data = train_data_nogeom\n)\n\nrf \n\nRanger result\n\nCall:\n ranger::ranger(formula = resale_price ~ floor_area_sqm + storey_order +      remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +      PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data_nogeom) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       731404460 \nR squared (OOB):                  0.9493789 \n\n\n\n# Save the RF model\nreadr::write_rds(rf, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/rf.rds\")\n\n\n\n\n\nIn this section, we will learn how to calibrate a model to predict HDB resale price by using grf() of SpatialML package.\n\n\n\n# Reuse coordinates and no-geometry training input\nset.seed(1234)\n\ngwRF_adaptive &lt;- SpatialML::grf(\n  formula = resale_price ~ floor_area_sqm +\n    storey_order + remaining_lease_mths +\n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n    PROX_MRT + PROX_PARK + PROX_MALL +\n    PROX_SUPERMARKET +\n    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +\n    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,\n  dframe = train_data_nogeom, # data.frame without geometry\n  bw     = 40,                # neighbor size (consistent with earlier choice)\n  kernel = \"adaptive\",        # adaptive kernel for local forests\n  coords = coords_train       # matrix of X,Y for training rows\n)\n\n\nNumber of Observations: 10335\n\n\nNumber of Independent Variables: 14\n\n\nKernel: Adaptive\nNeightbours: 40\n\n\n\n--------------- Global ML Model Summary ---------------\n\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data_nogeom, num.trees = 500, mtry = 4, importance = \"impurity\",      num.threads = NULL) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             4 \nTarget node size:                 5 \nVariable importance mode:         impurity \nSplitrule:                        variance \nOOB prediction error (MSE):       697593819 \nR squared (OOB):                  0.9517189 \n\n\n\nImportance:\n\n\n          floor_area_sqm             storey_order     remaining_lease_mths \n            7.413197e+12             1.538950e+13             2.890637e+13 \n                PROX_CBD         PROX_ELDERLYCARE              PROX_HAWKER \n            5.310066e+13             7.285092e+12             5.568548e+12 \n                PROX_MRT                PROX_PARK                PROX_MALL \n            7.369745e+12             4.894344e+12             4.223286e+12 \n        PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN    WITHIN_350M_CHILDCARE \n            2.793853e+12             1.018586e+12             1.710374e+12 \n         WITHIN_350M_BUS        WITHIN_1KM_PRISCH \n            1.589501e+12             6.794634e+12 \n\n\n\nMean Square Error (Not OOB): 173951416.766\n\n\nR-squared (Not OOB) %: 98.796\n\n\nAIC (Not OOB): 196129.252\n\n\nAICc (Not OOB): 196129.299\n\n\n\n--------------- Local Model Summary ---------------\n\n\n\nResiduals OOB:\n\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-207638.9  -13044.4     517.7     668.7   15329.3  380000.0 \n\n\n\nResiduals Predicted (Not OOB):\n\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-80918.36  -3710.39     80.88     60.19   4119.23  67858.13 \n\n\n\nLocal Variable Importance:\n\n\n                               Min          Max        Mean         StD\nfloor_area_sqm                   0 244740042006 10095828392 21812835540\nstorey_order             185976628 195162288767 10691049214 16507251138\nremaining_lease_mths     364347875 420068216877 18525480676 40200134557\nPROX_CBD                         0 261367685029  7551870678 20050530584\nPROX_ELDERLYCARE                 0 260937815286  6797406011 17221278502\nPROX_HAWKER                      0 232903486867  6917875149 17526152433\nPROX_MRT                         0 192977091714  6219493848 14339970325\nPROX_PARK                        0 270208600970  5678244629 13059236132\nPROX_MALL                        0 290212372886  6903172498 18141558541\nPROX_SUPERMARKET                 0 283979765533  6391052599 16785880266\nWITHIN_350M_KINDERGARTEN         0 124340534149  1694367905  7648420853\nWITHIN_350M_CHILDCARE            0 194759670980  3113750592 10738676578\nWITHIN_350M_BUS                  0 132614671785  3014600716  8056548827\nWITHIN_1KM_PRISCH                0 132884456893  1116898699  5401808933\n\n\n\nMean squared error (OOB): 932642623.291\n\n\nR-squared (OOB) %: 93.544\n\n\nAIC (OOB): 213484.26\n\n\nAICc (OOB): 213484.306\n\n\nMean squared error Predicted (Not OOB): 80652745.326\n\n\nR-squared Predicted (Not OOB) %: 99.442\n\n\nAIC Predicted (Not OOB): 188185.531\n\n\nAICc Predicted (Not OOB): 188185.578\n\n\n\nCalculation time (in seconds): 11.5451\n\n# Persist fitted GW-RF\nreadr::write_rds(gwRF_adaptive, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwRF_adaptive.rds\")\n\n\n\n\n\n\n\nTip\n\n\n\nThis is a computational intensity and time consuming process. It is wiser to save the output as an rds file for future used without having to re-run the process again.\n\n\nThe code chunk below can be used to retrieve the save model in future.\n\n# (Later) reload if needed\ngwRF_adaptive &lt;- readr::read_rds(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwRF_adaptive.rds\")\n\n\n\n\n\n\nThe code chunk below will be used to combine the test data with its corresponding coordinates data.\n\n# Combine the test attributes with their coordinates for prediction\ntest_data_nogeom &lt;- cbind(test_data, coords_test) %&gt;%\n  sf::st_drop_geometry()     # drop geometry to keep plain columns\n\n\n\n\n\n# Generate local predictions at test locations\ngwRF_pred &lt;- SpatialML::predict.grf(\n  gwRF_adaptive,     # trained GW-RF model\n  test_data_nogeom,  # test attributes + X,Y columns\n  x.var.name = \"X\",  # column name for X coordinate\n  y.var.name = \"Y\",  # column name for Y coordinate\n  local.w    = 1,    # weight for local component\n  global.w   = 0     # set to 0 to use purely local predictions\n)\n\n# Save the prediction vector\nGRF_pred &lt;- readr::write_rds(gwRF_pred, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/GRF_pred.rds\")\n\n\n\n\nThe output of the predict.grf() is a vector of predicted values. It is wiser to convert it into a data frame for further visualisation and analysis.\n\n# Reload predictions when needed and coerce to data.frame\nGRF_pred     &lt;- readr::read_rds(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/GRF_pred.rds\")\nGRF_pred_df  &lt;- as.data.frame(GRF_pred)  # single column with predicted values\n\nIn the code chunk below, cbind() is used to append the predicted values onto test_datathe\n\n# Attach predictions to the test data and retain only needed columns\ntest_data_p &lt;- cbind(test_data, GRF_pred_df) %&gt;%\n  dplyr::select(resale_price, GRF_pred)   # rename matches grf() output\n\n\n# Save the paired actual vs predicted for later evaluation/plots\nreadr::write_rds(test_data_p, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/test_data_p.rds\")\n\n\n\n\n\nThe root mean square error (RMSE) allows us to measure how far predicted values are from observed values in a regression analysis. In the code chunk below, rmse() of Metrics package is used to compute the RMSE.\n\n# Compute RMSE between observed and GW-RF predicted prices\nMetrics::rmse(\n  test_data_p$resale_price,  # actual values\n  test_data_p$GRF_pred       # predicted values\n)\n\n[1] 28160.87\n\n# Example output in the reference workflow: 28160.87\n\n\n\n\nAlternatively, scatterplot can be used to visualise the actual resale price and the predicted resale price by using the code chunk below.\n\n# Scatter plot of Predicted (x) vs Actual (y)\nggplot2::ggplot(\n  data = test_data_p,                           # data with both columns\n  ggplot2::aes(x = GRF_pred, y = resale_price)  # map axes\n) +\n  ggplot2::geom_point()                         # draw points\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nA better predictive model should have the scatter point close to the diagonal line. The scatter plot can be also used to detect if any outliers in the model."
  },
  {
    "objectID": "Hands-on_Ex08/hand-on_ex08.html#overview",
    "href": "Hands-on_Ex08/hand-on_ex08.html#overview",
    "title": "Hands-on Ex08",
    "section": "",
    "text": "Predictive modelling estimates an unknown outcome (e.g., resale price) from known predictors (e.g., floor area, amenities). When observations are georeferenced, relationships may vary across space due to infrastructure, socio-economic and environmental context. Geographically weighted models allow coefficients or model structure to change by location, capturing local effects that global models miss.\nBy the end, we will:\n\nprepare train/test datasets with proper sampling,\n\ncheck collinearity,\n\nfit and save MLR, GWR, RF, and GW-RF models,\n\ngenerate out-of-sample predictions,\n\ncompute RMSE and visualise prediction quality."
  },
  {
    "objectID": "Hands-on_Ex08/hand-on_ex08.html#the-data",
    "href": "Hands-on_Ex08/hand-on_ex08.html#the-data",
    "title": "Hands-on Ex08",
    "section": "",
    "text": "we will work with:\n\nAspatial table: HDB resale transactions (CSV → converted to sf during preprocessing).\n\nGeospatial layers: URA 2014 Master Plan Planning Subzones (polygon sf).\n\nLocational factors with coordinates: eldercare, hawker centres, parks, supermarkets,\n\nMRT/LRT stations, bus stops, kindergartens, childcare (shapefile/GeoJSON).\n\nLocational factors without coordinates: CBD centroid (derived), shopping malls, primary school rankings (CSV/other)."
  },
  {
    "objectID": "Hands-on_Ex08/hand-on_ex08.html#installing-and-loading-r-packages",
    "href": "Hands-on_Ex08/hand-on_ex08.html#installing-and-loading-r-packages",
    "title": "Hands-on Ex08",
    "section": "",
    "text": "# Create/load all required packages in one shot\npacman::p_load(\n  sf,            # spatial vector data (simple features)\n  spdep,         # spatial dependence utilities (used by some workflows)\n  GWmodel,       # Geographically Weighted Regression\n  SpatialML,     # Geographically Weighted Random Forest (grf)\n  tmap,          # cartography (not central here but part of the stack)\n  rsample,       # train/test splitting (tidymodels)\n  Metrics,       # RMSE and other metrics\n  tidyverse      # dplyr, ggplot2, readr, purrr, etc.\n)"
  },
  {
    "objectID": "Hands-on_Ex08/hand-on_ex08.html#preparing-data",
    "href": "Hands-on_Ex08/hand-on_ex08.html#preparing-data",
    "title": "Hands-on Ex08",
    "section": "",
    "text": "# Read the prepared modelling dataset (sf object)\nmdata &lt;- readr::read_rds(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/rawdata/mdata.rds\")\n\n\n\n\nThe entire data are split into training and test data sets with 65% and 35% respectively by using initial_split() of rsample package. rsample is one of the package of tigymodels.\n\n# Set seed to make the split reproducible\nset.seed(1234)\n\n# Split into 65% training and 35% testing using rsample\nresale_split &lt;- rsample::initial_split(mdata, prop = 6.5/10)\n\n# Extract the two partitions\ntrain_data &lt;- rsample::training(resale_split)\ntest_data  &lt;- rsample::testing(resale_split)\n\n\n# Persist the splits for reuse\nreadr::write_rds(train_data, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/train_data.rds\")\nreadr::write_rds(test_data,  \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/test_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex08/hand-on_ex08.html#computing-correlation-matrix",
    "href": "Hands-on_Ex08/hand-on_ex08.html#computing-correlation-matrix",
    "title": "Hands-on Ex08",
    "section": "",
    "text": "Before loading the predictors into a predictive model, it is always a good practice to use correlation matrix to examine if there is sign of multicollinearity.\n\n# Remove geometry to compute numeric correlations only\nmdata_nogeo &lt;- mdata %&gt;% sf::st_drop_geometry()\n\n# Draw an upper-triangle correlation matrix with numbers\ncorrplot::corrplot(\n  cor(mdata_nogeo[, 2:17]), # adjust columns to our numeric predictors\n  diag   = FALSE,           # do not draw the diagonal\n  order  = \"AOE\",           # sort for visual clarity\n  tl.pos = \"td\",            # variable labels on top diagonal\n  tl.cex = 0.5,             # smaller labels\n  method = \"number\",        # show correlation values\n  type   = \"upper\"          # only the upper triangle\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf all absolute correlations are below ~0.8, severe multicollinearity is unlikely."
  },
  {
    "objectID": "Hands-on_Ex08/hand-on_ex08.html#retrieving-the-stored-data",
    "href": "Hands-on_Ex08/hand-on_ex08.html#retrieving-the-stored-data",
    "title": "Hands-on Ex08",
    "section": "",
    "text": "# Reload saved splits when resuming work\ntrain_data &lt;- readr::read_rds(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/train_data.rds\")\ntest_data  &lt;- readr::read_rds(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/test_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex08/hand-on_ex08.html#building-a-non-spatial-multiple-linear-regression",
    "href": "Hands-on_Ex08/hand-on_ex08.html#building-a-non-spatial-multiple-linear-regression",
    "title": "Hands-on Ex08",
    "section": "",
    "text": "# Fit a global (non-spatial) linear regression as a baseline\nprice_mlr &lt;- lm(\n  resale_price ~ floor_area_sqm +\n    storey_order + remaining_lease_mths +\n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n    PROX_MRT + PROX_PARK + PROX_MALL +\n    PROX_SUPERMARKET +\n    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +\n    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,\n  data = train_data\n)\n\n# Inspect coefficients and diagnostics\nsummary(price_mlr)\n\n\nCall:\nlm(formula = resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + \n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + \n    PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              107601.073  10601.261  10.150  &lt; 2e-16 ***\nfloor_area_sqm             2780.698     90.579  30.699  &lt; 2e-16 ***\nstorey_order              14299.298    339.115  42.167  &lt; 2e-16 ***\nremaining_lease_mths        344.490      4.592  75.027  &lt; 2e-16 ***\nPROX_CBD                 -16930.196    201.254 -84.124  &lt; 2e-16 ***\nPROX_ELDERLYCARE         -14441.025    994.867 -14.516  &lt; 2e-16 ***\nPROX_HAWKER              -19265.648   1273.597 -15.127  &lt; 2e-16 ***\nPROX_MRT                 -32564.272   1744.232 -18.670  &lt; 2e-16 ***\nPROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\nPROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\nPROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\nWITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  &lt; 2e-16 ***\nWITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  &lt; 2e-16 ***\nWITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\nWITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 61650 on 10320 degrees of freedom\nMultiple R-squared:  0.7373,    Adjusted R-squared:  0.737 \nF-statistic:  2069 on 14 and 10320 DF,  p-value: &lt; 2.2e-16\n\n\n\n# Save the fitted model\nreadr::write_rds(price_mlr, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/price_mlr.rds\")"
  },
  {
    "objectID": "Hands-on_Ex08/hand-on_ex08.html#gwr-predictive-method",
    "href": "Hands-on_Ex08/hand-on_ex08.html#gwr-predictive-method",
    "title": "Hands-on Ex08",
    "section": "",
    "text": "In this section, we will learn how to calibrate a model to predict HDB resale price by using geographically weighted regression method of GWmodel package.\n\n\n\n# Determine optimal adaptive bandwidth (in neighbors) using CV\nbw_adaptive &lt;- GWmodel::bw.gwr(\n  formula = resale_price ~ floor_area_sqm +\n    storey_order + remaining_lease_mths +\n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n    PROX_MRT + PROX_PARK + PROX_MALL +\n    PROX_SUPERMARKET +\n    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +\n    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,\n  data     = train_data,   # training sf\n  approach = \"CV\",         # cross-validation\n  kernel   = \"gaussian\",   # Gaussian kernel\n  adaptive = TRUE,         # adaptive neighbor count\n  longlat  = FALSE         # data are in projected meters\n)\n\nTake a cup of tea and have a break, it will take a few minutes.\n          -----A kind suggestion from GWmodel development group\nAdaptive bandwidth: 6395 CV score: 3.60536e+13 \nAdaptive bandwidth: 3960 CV score: 3.320316e+13 \nAdaptive bandwidth: 2455 CV score: 2.928339e+13 \nAdaptive bandwidth: 1524 CV score: 2.550957e+13 \nAdaptive bandwidth: 950 CV score: 1.95632e+13 \nAdaptive bandwidth: 593 CV score: 1.58347e+13 \nAdaptive bandwidth: 375 CV score: 1.310042e+13 \nAdaptive bandwidth: 237 CV score: 1.113152e+13 \nAdaptive bandwidth: 155 CV score: 9.572037e+12 \nAdaptive bandwidth: 101 CV score: 8.457003e+12 \nAdaptive bandwidth: 71 CV score: 7.605058e+12 \nAdaptive bandwidth: 49 CV score: 6.966278e+12 \nAdaptive bandwidth: 38 CV score: 8.841916e+12 \nAdaptive bandwidth: 58 CV score: 7.275234e+12 \nAdaptive bandwidth: 45 CV score: 6.871966e+12 \nAdaptive bandwidth: 41 CV score: 6.793327e+12 \nAdaptive bandwidth: 40 CV score: 6.780974e+12 \nAdaptive bandwidth: 38 CV score: 8.841916e+12 \nAdaptive bandwidth: 40 CV score: 6.780974e+12 \n\n# Persist the chosen bandwidth (e.g., result may be 40 neighbors)\nreadr::write_rds(bw_adaptive, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/bw_adaptive.rds\")\n\n\n\n\nFirst, let us call the save bandwidth by using the code chunk below.\n\n# Reload bandwidth when needed\nbw_adaptive &lt;- readr::read_rds(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/bw_adaptive.rds\")\n\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and Gaussian kernel as shown in the code chunk below.\n\n# Calibrate GWR using the selected adaptive bandwidth\ngwr_adaptive &lt;- GWmodel::gwr.basic(\n  formula = resale_price ~ floor_area_sqm +\n    storey_order + remaining_lease_mths +\n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n    PROX_MRT + PROX_PARK + PROX_MALL +\n    PROX_SUPERMARKET +\n    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +\n    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,\n  data     = train_data,    # training sf\n  bw       = bw_adaptive,   # adaptive neighbors (numeric)\n  kernel   = \"gaussian\",    # kernel shape\n  adaptive = TRUE,          # use adaptive bandwidth\n  longlat  = FALSE          # projected coordinates\n)\n\n# Save the fitted GWR object\nreadr::write_rds(gwr_adaptive, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwr_adaptive.rds\")\n\n\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and Gaussian kernel as shown in the code chunk below.\n\n\n\n\nThe code chunk below will be used to retrieve the save gwr model object.\n\n# Reload GWR model when resuming work\ngwr_adaptive &lt;- readr::read_rds(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwr_adaptive.rds\")\n\nThe code below can be used to display the model output.\n\n# Printing the object shows the model summary header and timings\ngwr_adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2025-10-24 16:35:37.612412 \n   Call:\n   GWmodel::gwr.basic(formula = resale_price ~ floor_area_sqm + \n    storey_order + remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + \n    PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + \n    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n    WITHIN_1KM_PRISCH, data = train_data, bw = bw_adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  resale_price\n   Independent variables:  floor_area_sqm storey_order remaining_lease_mths PROX_CBD PROX_ELDERLYCARE PROX_HAWKER PROX_MRT PROX_PARK PROX_MALL PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN WITHIN_350M_CHILDCARE WITHIN_350M_BUS WITHIN_1KM_PRISCH\n   Number of data points: 10335\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\n   Coefficients:\n                              Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)              107601.073  10601.261  10.150  &lt; 2e-16 ***\n   floor_area_sqm             2780.698     90.579  30.699  &lt; 2e-16 ***\n   storey_order              14299.298    339.115  42.167  &lt; 2e-16 ***\n   remaining_lease_mths        344.490      4.592  75.027  &lt; 2e-16 ***\n   PROX_CBD                 -16930.196    201.254 -84.124  &lt; 2e-16 ***\n   PROX_ELDERLYCARE         -14441.025    994.867 -14.516  &lt; 2e-16 ***\n   PROX_HAWKER              -19265.648   1273.597 -15.127  &lt; 2e-16 ***\n   PROX_MRT                 -32564.272   1744.232 -18.670  &lt; 2e-16 ***\n   PROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\n   PROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\n   PROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\n   WITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  &lt; 2e-16 ***\n   WITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  &lt; 2e-16 ***\n   WITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\n   WITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  &lt; 2e-16 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 61650 on 10320 degrees of freedom\n   Multiple R-squared: 0.7373\n   Adjusted R-squared: 0.737 \n   F-statistic:  2069 on 14 and 10320 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 3.922202e+13\n   Sigma(hat): 61610.08\n   AIC:  257320.2\n   AICc:  257320.3\n   BIC:  247249\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 40 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                                   Min.     1st Qu.      Median     3rd Qu.\n   Intercept                -3.2594e+08 -4.7727e+05 -8.3004e+03  5.5025e+05\n   floor_area_sqm           -2.8714e+04  1.4475e+03  2.3011e+03  3.3900e+03\n   storey_order              3.3186e+03  8.5899e+03  1.0826e+04  1.3397e+04\n   remaining_lease_mths     -1.4431e+03  2.6063e+02  3.9048e+02  5.2865e+02\n   PROX_CBD                 -1.0837e+07 -5.7697e+04 -1.3787e+04  2.6552e+04\n   PROX_ELDERLYCARE         -3.2291e+07 -4.0643e+04  1.0562e+04  6.1054e+04\n   PROX_HAWKER              -2.3985e+08 -5.1365e+04  3.0026e+03  6.4287e+04\n   PROX_MRT                 -1.1660e+07 -1.0488e+05 -4.9373e+04  5.1037e+03\n   PROX_PARK                -6.5961e+06 -4.8671e+04 -8.8128e+02  5.3498e+04\n   PROX_MALL                -1.8112e+07 -7.4238e+04 -1.3982e+04  4.9779e+04\n   PROX_SUPERMARKET         -4.5761e+06 -6.3461e+04 -1.7429e+04  3.5616e+04\n   WITHIN_350M_KINDERGARTEN -4.1881e+05 -6.0040e+03  9.0209e+01  4.7127e+03\n   WITHIN_350M_CHILDCARE    -1.0273e+05 -2.2375e+03  2.6668e+02  2.6388e+03\n   WITHIN_350M_BUS          -1.1757e+05 -1.4719e+03  1.1626e+02  1.7584e+03\n   WITHIN_1KM_PRISCH        -6.6465e+05 -5.5959e+03  2.6916e+02  5.7500e+03\n                                  Max.\n   Intercept                1.6493e+08\n   floor_area_sqm           5.0907e+04\n   storey_order             2.9537e+04\n   remaining_lease_mths     1.8119e+03\n   PROX_CBD                 2.2489e+07\n   PROX_ELDERLYCARE         8.2444e+07\n   PROX_HAWKER              5.9654e+06\n   PROX_MRT                 2.0189e+08\n   PROX_PARK                1.5224e+07\n   PROX_MALL                1.0443e+07\n   PROX_SUPERMARKET         3.8330e+06\n   WITHIN_350M_KINDERGARTEN 6.6799e+05\n   WITHIN_350M_CHILDCARE    1.0802e+05\n   WITHIN_350M_BUS          3.7313e+04\n   WITHIN_1KM_PRISCH        5.0262e+05\n   ************************Diagnostic information*************************\n   Number of data points: 10335 \n   Effective number of parameters (2trace(S) - trace(S'S)): 1730.101 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 8604.899 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 238871.8 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 237036.9 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 238209 \n   Residual sum of squares: 4.829177e+12 \n   R-square value:  0.9676571 \n   Adjusted R-square value:  0.9611535 \n\n   ***********************************************************************\n   Program stops at: 2025-10-24 16:36:34.25672 \n\n\n\n\n\n\n# Some workflows also derive a CV bandwidth using the test sf\ngwr_bw_test_adaptive &lt;- GWmodel::bw.gwr(\n  formula = resale_price ~ floor_area_sqm +\n    storey_order + remaining_lease_mths +\n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n    PROX_MRT + PROX_PARK + PROX_MALL +\n    PROX_SUPERMARKET +\n    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +\n    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,\n  data     = test_data,\n  approach = \"CV\",\n  kernel   = \"gaussian\",\n  adaptive = TRUE,\n  longlat  = FALSE\n)\n\nTake a cup of tea and have a break, it will take a few minutes.\n          -----A kind suggestion from GWmodel development group\nAdaptive bandwidth: 3447 CV score: 1.902155e+13 \nAdaptive bandwidth: 2138 CV score: 1.752645e+13 \nAdaptive bandwidth: 1328 CV score: 1.556299e+13 \nAdaptive bandwidth: 828 CV score: 1.357498e+13 \nAdaptive bandwidth: 518 CV score: 1.030751e+13 \nAdaptive bandwidth: 327 CV score: 8.348364e+12 \nAdaptive bandwidth: 208 CV score: 6.860544e+12 \nAdaptive bandwidth: 135 CV score: 5.969504e+12 \nAdaptive bandwidth: 89 CV score: 5.242221e+12 \nAdaptive bandwidth: 62 CV score: 4.742767e+12 \nAdaptive bandwidth: 43 CV score: 4.357839e+12 \nAdaptive bandwidth: 34 CV score: 4.125848e+12 \nAdaptive bandwidth: 25 CV score: 4.056699e+12 \nAdaptive bandwidth: 23 CV score: 4.236349e+13 \nAdaptive bandwidth: 30 CV score: 4.074906e+12 \nAdaptive bandwidth: 25 CV score: 4.056699e+12 \n\n# Save the test-set bandwidth too (for reference)\nreadr::write_rds(gwr_bw_test_adaptive, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwr_bw_test_adaptive.rds\")\n\n\n\n\n\n# gwr_pred &lt;- gwr.predict(\n#   formula = resale_price ~ floor_area_sqm + \n#     storey_order + remaining_lease_mths + \n#     PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + \n#     PROX_MRT + PROX_PARK + PROX_MALL + \n#     PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n#     WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n#     WITHIN_1KM_PRISCH, \n#   data=train_data, \n#   predictdata = test_data, \n#   bw=40, \n#   kernel = 'gaussian', \n#   adaptive=TRUE, \n#   longlat = FALSE)\n# \n# # Save predictions (list-like object)\n# readr::write_rds(gwr_pred, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwr_pred.rds\")\n\n\n\n\nIn this section, we will learn how to calibrate a model to predict HDB resale price by using random forest function of ranger package.\n\n\n\nThe code chunk below extract the x,y coordinates of the full, training and test data sets.\n\n# Extract XY matrices for convenience (sf → numeric matrix with X,Y)\ncoords       &lt;- sf::st_coordinates(mdata)\ncoords_train &lt;- sf::st_coordinates(train_data)\ncoords_test  &lt;- sf::st_coordinates(test_data)\n\nBefore continue, we write all the output into rds for future used.\n\n# Save coordinates used later by GW-RF\nreadr::write_rds(coords_train, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/coords_train.rds\")\nreadr::write_rds(coords_test,  \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/coords_test.rds\")\n\n\n\n\nFirst, we will drop geometry column of the sf data.frame by using st_drop_geometry() of sf package.\n\n# Random Forest from ranger expects a data.frame without geometry\ntrain_data_nogeom &lt;- train_data %&gt;% sf::st_drop_geometry()\ntest_data_nogeom  &lt;- test_data  %&gt;% sf::st_drop_geometry()\n\n\n\n\n\n# Set seed for reproducibility\nset.seed(1234)\n\n# Fit a global RF as another baseline model\nrf &lt;- ranger::ranger(\n  formula = resale_price ~ floor_area_sqm +\n    storey_order + remaining_lease_mths +\n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n    PROX_MRT + PROX_PARK + PROX_MALL +\n    PROX_SUPERMARKET +\n    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +\n    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,\n  data = train_data_nogeom\n)\n\nrf \n\nRanger result\n\nCall:\n ranger::ranger(formula = resale_price ~ floor_area_sqm + storey_order +      remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +      PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data_nogeom) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       731404460 \nR squared (OOB):                  0.9493789 \n\n\n\n# Save the RF model\nreadr::write_rds(rf, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/rf.rds\")"
  },
  {
    "objectID": "Hands-on_Ex08/hand-on_ex08.html#calibrating-geographically-weighted-random-forest-gw-rf",
    "href": "Hands-on_Ex08/hand-on_ex08.html#calibrating-geographically-weighted-random-forest-gw-rf",
    "title": "Hands-on Ex08",
    "section": "",
    "text": "In this section, we will learn how to calibrate a model to predict HDB resale price by using grf() of SpatialML package.\n\n\n\n# Reuse coordinates and no-geometry training input\nset.seed(1234)\n\ngwRF_adaptive &lt;- SpatialML::grf(\n  formula = resale_price ~ floor_area_sqm +\n    storey_order + remaining_lease_mths +\n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n    PROX_MRT + PROX_PARK + PROX_MALL +\n    PROX_SUPERMARKET +\n    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +\n    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,\n  dframe = train_data_nogeom, # data.frame without geometry\n  bw     = 40,                # neighbor size (consistent with earlier choice)\n  kernel = \"adaptive\",        # adaptive kernel for local forests\n  coords = coords_train       # matrix of X,Y for training rows\n)\n\n\nNumber of Observations: 10335\n\n\nNumber of Independent Variables: 14\n\n\nKernel: Adaptive\nNeightbours: 40\n\n\n\n--------------- Global ML Model Summary ---------------\n\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data_nogeom, num.trees = 500, mtry = 4, importance = \"impurity\",      num.threads = NULL) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             4 \nTarget node size:                 5 \nVariable importance mode:         impurity \nSplitrule:                        variance \nOOB prediction error (MSE):       697593819 \nR squared (OOB):                  0.9517189 \n\n\n\nImportance:\n\n\n          floor_area_sqm             storey_order     remaining_lease_mths \n            7.413197e+12             1.538950e+13             2.890637e+13 \n                PROX_CBD         PROX_ELDERLYCARE              PROX_HAWKER \n            5.310066e+13             7.285092e+12             5.568548e+12 \n                PROX_MRT                PROX_PARK                PROX_MALL \n            7.369745e+12             4.894344e+12             4.223286e+12 \n        PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN    WITHIN_350M_CHILDCARE \n            2.793853e+12             1.018586e+12             1.710374e+12 \n         WITHIN_350M_BUS        WITHIN_1KM_PRISCH \n            1.589501e+12             6.794634e+12 \n\n\n\nMean Square Error (Not OOB): 173951416.766\n\n\nR-squared (Not OOB) %: 98.796\n\n\nAIC (Not OOB): 196129.252\n\n\nAICc (Not OOB): 196129.299\n\n\n\n--------------- Local Model Summary ---------------\n\n\n\nResiduals OOB:\n\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-207638.9  -13044.4     517.7     668.7   15329.3  380000.0 \n\n\n\nResiduals Predicted (Not OOB):\n\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-80918.36  -3710.39     80.88     60.19   4119.23  67858.13 \n\n\n\nLocal Variable Importance:\n\n\n                               Min          Max        Mean         StD\nfloor_area_sqm                   0 244740042006 10095828392 21812835540\nstorey_order             185976628 195162288767 10691049214 16507251138\nremaining_lease_mths     364347875 420068216877 18525480676 40200134557\nPROX_CBD                         0 261367685029  7551870678 20050530584\nPROX_ELDERLYCARE                 0 260937815286  6797406011 17221278502\nPROX_HAWKER                      0 232903486867  6917875149 17526152433\nPROX_MRT                         0 192977091714  6219493848 14339970325\nPROX_PARK                        0 270208600970  5678244629 13059236132\nPROX_MALL                        0 290212372886  6903172498 18141558541\nPROX_SUPERMARKET                 0 283979765533  6391052599 16785880266\nWITHIN_350M_KINDERGARTEN         0 124340534149  1694367905  7648420853\nWITHIN_350M_CHILDCARE            0 194759670980  3113750592 10738676578\nWITHIN_350M_BUS                  0 132614671785  3014600716  8056548827\nWITHIN_1KM_PRISCH                0 132884456893  1116898699  5401808933\n\n\n\nMean squared error (OOB): 932642623.291\n\n\nR-squared (OOB) %: 93.544\n\n\nAIC (OOB): 213484.26\n\n\nAICc (OOB): 213484.306\n\n\nMean squared error Predicted (Not OOB): 80652745.326\n\n\nR-squared Predicted (Not OOB) %: 99.442\n\n\nAIC Predicted (Not OOB): 188185.531\n\n\nAICc Predicted (Not OOB): 188185.578\n\n\n\nCalculation time (in seconds): 11.5451\n\n# Persist fitted GW-RF\nreadr::write_rds(gwRF_adaptive, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwRF_adaptive.rds\")\n\n\n\n\n\n\n\nTip\n\n\n\nThis is a computational intensity and time consuming process. It is wiser to save the output as an rds file for future used without having to re-run the process again.\n\n\nThe code chunk below can be used to retrieve the save model in future.\n\n# (Later) reload if needed\ngwRF_adaptive &lt;- readr::read_rds(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwRF_adaptive.rds\")\n\n\n\n\n\n\nThe code chunk below will be used to combine the test data with its corresponding coordinates data.\n\n# Combine the test attributes with their coordinates for prediction\ntest_data_nogeom &lt;- cbind(test_data, coords_test) %&gt;%\n  sf::st_drop_geometry()     # drop geometry to keep plain columns\n\n\n\n\n\n# Generate local predictions at test locations\ngwRF_pred &lt;- SpatialML::predict.grf(\n  gwRF_adaptive,     # trained GW-RF model\n  test_data_nogeom,  # test attributes + X,Y columns\n  x.var.name = \"X\",  # column name for X coordinate\n  y.var.name = \"Y\",  # column name for Y coordinate\n  local.w    = 1,    # weight for local component\n  global.w   = 0     # set to 0 to use purely local predictions\n)\n\n# Save the prediction vector\nGRF_pred &lt;- readr::write_rds(gwRF_pred, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/GRF_pred.rds\")\n\n\n\n\nThe output of the predict.grf() is a vector of predicted values. It is wiser to convert it into a data frame for further visualisation and analysis.\n\n# Reload predictions when needed and coerce to data.frame\nGRF_pred     &lt;- readr::read_rds(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/GRF_pred.rds\")\nGRF_pred_df  &lt;- as.data.frame(GRF_pred)  # single column with predicted values\n\nIn the code chunk below, cbind() is used to append the predicted values onto test_datathe\n\n# Attach predictions to the test data and retain only needed columns\ntest_data_p &lt;- cbind(test_data, GRF_pred_df) %&gt;%\n  dplyr::select(resale_price, GRF_pred)   # rename matches grf() output\n\n\n# Save the paired actual vs predicted for later evaluation/plots\nreadr::write_rds(test_data_p, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/test_data_p.rds\")\n\n\n\n\n\nThe root mean square error (RMSE) allows us to measure how far predicted values are from observed values in a regression analysis. In the code chunk below, rmse() of Metrics package is used to compute the RMSE.\n\n# Compute RMSE between observed and GW-RF predicted prices\nMetrics::rmse(\n  test_data_p$resale_price,  # actual values\n  test_data_p$GRF_pred       # predicted values\n)\n\n[1] 28160.87\n\n# Example output in the reference workflow: 28160.87\n\n\n\n\nAlternatively, scatterplot can be used to visualise the actual resale price and the predicted resale price by using the code chunk below.\n\n# Scatter plot of Predicted (x) vs Actual (y)\nggplot2::ggplot(\n  data = test_data_p,                           # data with both columns\n  ggplot2::aes(x = GRF_pred, y = resale_price)  # map axes\n) +\n  ggplot2::geom_point()                         # draw points\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nA better predictive model should have the scatter point close to the diagonal line. The scatter plot can be also used to detect if any outliers in the model."
  },
  {
    "objectID": "In-Class_Ex08/in-class_ex08.html",
    "href": "In-Class_Ex08/in-class_ex08.html",
    "title": "In-class Ex08: Take-home Exercise 3 Kick Starter",
    "section": "",
    "text": "By the end of this in-class exercise, students will master the skill of:\n\nprepare and geocode HDB resale price data for geospatial modelling; and\nperform proximity analysis to count the number of geographic entities located within a defined distance from each HDB property."
  },
  {
    "objectID": "In-Class_Ex08/in-class_ex08.html#overview",
    "href": "In-Class_Ex08/in-class_ex08.html#overview",
    "title": "Hands-on Ex08",
    "section": "",
    "text": "Predictive modelling estimates an unknown outcome (e.g., resale price) from known predictors (e.g., floor area, amenities). When observations are georeferenced, relationships may vary across space due to infrastructure, socio-economic and environmental context. Geographically weighted models allow coefficients or model structure to change by location, capturing local effects that global models miss.\nBy the end, we will:\n\nprepare train/test datasets with proper sampling,\n\ncheck collinearity,\n\nfit and save MLR, GWR, RF, and GW-RF models,\n\ngenerate out-of-sample predictions,\n\ncompute RMSE and visualise prediction quality."
  },
  {
    "objectID": "In-Class_Ex08/in-class_ex08.html#the-data",
    "href": "In-Class_Ex08/in-class_ex08.html#the-data",
    "title": "Hands-on Ex08",
    "section": "",
    "text": "we will work with:\n\nAspatial table: HDB resale transactions (CSV → converted to sf during preprocessing).\n\nGeospatial layers: URA 2014 Master Plan Planning Subzones (polygon sf).\n\nLocational factors with coordinates: eldercare, hawker centres, parks, supermarkets,\n\nMRT/LRT stations, bus stops, kindergartens, childcare (shapefile/GeoJSON).\n\nLocational factors without coordinates: CBD centroid (derived), shopping malls, primary school rankings (CSV/other)."
  },
  {
    "objectID": "In-Class_Ex08/in-class_ex08.html#installing-and-loading-r-packages",
    "href": "In-Class_Ex08/in-class_ex08.html#installing-and-loading-r-packages",
    "title": "In-class Ex08: Take-home Exercise 3 Kick Starter",
    "section": "2 Installing and Loading R Packages",
    "text": "2 Installing and Loading R Packages\n\n# Create/load all required packages in one shot\npacman::p_load(httr,tidyverse, sf, tmap,jsonlite, progress, spdep,GWmodel, SpatialML, rsample, Metrics, knitr, kableExtra, spatialRF, randomForestExplainer)"
  },
  {
    "objectID": "In-Class_Ex08/in-class_ex08.html#preparing-data",
    "href": "In-Class_Ex08/in-class_ex08.html#preparing-data",
    "title": "Hands-on Ex08",
    "section": "",
    "text": "# Read the prepared modelling dataset (sf object)\nmdata &lt;- readr::read_rds(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/rawdata/mdata.rds\")\n\n\n\n\nThe entire data are split into training and test data sets with 65% and 35% respectively by using initial_split() of rsample package. rsample is one of the package of tigymodels.\n\n# Set seed to make the split reproducible\nset.seed(1234)\n\n# Split into 65% training and 35% testing using rsample\nresale_split &lt;- rsample::initial_split(mdata, prop = 6.5/10)\n\n# Extract the two partitions\ntrain_data &lt;- rsample::training(resale_split)\ntest_data  &lt;- rsample::testing(resale_split)\n\n\n# Persist the splits for reuse\nreadr::write_rds(train_data, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/train_data.rds\")\nreadr::write_rds(test_data,  \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/test_data.rds\")"
  },
  {
    "objectID": "In-Class_Ex08/in-class_ex08.html#computing-correlation-matrix",
    "href": "In-Class_Ex08/in-class_ex08.html#computing-correlation-matrix",
    "title": "Hands-on Ex08",
    "section": "",
    "text": "Before loading the predictors into a predictive model, it is always a good practice to use correlation matrix to examine if there is sign of multicollinearity.\n\n# Remove geometry to compute numeric correlations only\nmdata_nogeo &lt;- mdata %&gt;% sf::st_drop_geometry()\n\n# Draw an upper-triangle correlation matrix with numbers\ncorrplot::corrplot(\n  cor(mdata_nogeo[, 2:17]), # adjust columns to our numeric predictors\n  diag   = FALSE,           # do not draw the diagonal\n  order  = \"AOE\",           # sort for visual clarity\n  tl.pos = \"td\",            # variable labels on top diagonal\n  tl.cex = 0.5,             # smaller labels\n  method = \"number\",        # show correlation values\n  type   = \"upper\"          # only the upper triangle\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf all absolute correlations are below ~0.8, severe multicollinearity is unlikely."
  },
  {
    "objectID": "In-Class_Ex08/in-class_ex08.html#retrieving-the-stored-data",
    "href": "In-Class_Ex08/in-class_ex08.html#retrieving-the-stored-data",
    "title": "Hands-on Ex08",
    "section": "",
    "text": "# Reload saved splits when resuming work\ntrain_data &lt;- readr::read_rds(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/train_data.rds\")\ntest_data  &lt;- readr::read_rds(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/test_data.rds\")"
  },
  {
    "objectID": "In-Class_Ex08/in-class_ex08.html#building-a-non-spatial-multiple-linear-regression",
    "href": "In-Class_Ex08/in-class_ex08.html#building-a-non-spatial-multiple-linear-regression",
    "title": "Hands-on Ex08",
    "section": "",
    "text": "# Fit a global (non-spatial) linear regression as a baseline\nprice_mlr &lt;- lm(\n  resale_price ~ floor_area_sqm +\n    storey_order + remaining_lease_mths +\n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n    PROX_MRT + PROX_PARK + PROX_MALL +\n    PROX_SUPERMARKET +\n    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +\n    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,\n  data = train_data\n)\n\n# Inspect coefficients and diagnostics\nsummary(price_mlr)\n\n\nCall:\nlm(formula = resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + \n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + \n    PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              107601.073  10601.261  10.150  &lt; 2e-16 ***\nfloor_area_sqm             2780.698     90.579  30.699  &lt; 2e-16 ***\nstorey_order              14299.298    339.115  42.167  &lt; 2e-16 ***\nremaining_lease_mths        344.490      4.592  75.027  &lt; 2e-16 ***\nPROX_CBD                 -16930.196    201.254 -84.124  &lt; 2e-16 ***\nPROX_ELDERLYCARE         -14441.025    994.867 -14.516  &lt; 2e-16 ***\nPROX_HAWKER              -19265.648   1273.597 -15.127  &lt; 2e-16 ***\nPROX_MRT                 -32564.272   1744.232 -18.670  &lt; 2e-16 ***\nPROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\nPROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\nPROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\nWITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  &lt; 2e-16 ***\nWITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  &lt; 2e-16 ***\nWITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\nWITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 61650 on 10320 degrees of freedom\nMultiple R-squared:  0.7373,    Adjusted R-squared:  0.737 \nF-statistic:  2069 on 14 and 10320 DF,  p-value: &lt; 2.2e-16\n\n\n\n# Save the fitted model\nreadr::write_rds(price_mlr, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/price_mlr.rds\")"
  },
  {
    "objectID": "In-Class_Ex08/in-class_ex08.html#gwr-predictive-method",
    "href": "In-Class_Ex08/in-class_ex08.html#gwr-predictive-method",
    "title": "Hands-on Ex08",
    "section": "",
    "text": "In this section, we will learn how to calibrate a model to predict HDB resale price by using geographically weighted regression method of GWmodel package.\n\n\n\n# Determine optimal adaptive bandwidth (in neighbors) using CV\nbw_adaptive &lt;- GWmodel::bw.gwr(\n  formula = resale_price ~ floor_area_sqm +\n    storey_order + remaining_lease_mths +\n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n    PROX_MRT + PROX_PARK + PROX_MALL +\n    PROX_SUPERMARKET +\n    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +\n    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,\n  data     = train_data,   # training sf\n  approach = \"CV\",         # cross-validation\n  kernel   = \"gaussian\",   # Gaussian kernel\n  adaptive = TRUE,         # adaptive neighbor count\n  longlat  = FALSE         # data are in projected meters\n)\n\nTake a cup of tea and have a break, it will take a few minutes.\n          -----A kind suggestion from GWmodel development group\nAdaptive bandwidth: 6395 CV score: 3.60536e+13 \nAdaptive bandwidth: 3960 CV score: 3.320316e+13 \nAdaptive bandwidth: 2455 CV score: 2.928339e+13 \nAdaptive bandwidth: 1524 CV score: 2.550957e+13 \nAdaptive bandwidth: 950 CV score: 1.95632e+13 \nAdaptive bandwidth: 593 CV score: 1.58347e+13 \nAdaptive bandwidth: 375 CV score: 1.310042e+13 \nAdaptive bandwidth: 237 CV score: 1.113152e+13 \nAdaptive bandwidth: 155 CV score: 9.572037e+12 \nAdaptive bandwidth: 101 CV score: 8.457003e+12 \nAdaptive bandwidth: 71 CV score: 7.605058e+12 \nAdaptive bandwidth: 49 CV score: 6.966278e+12 \nAdaptive bandwidth: 38 CV score: 8.841916e+12 \nAdaptive bandwidth: 58 CV score: 7.275234e+12 \nAdaptive bandwidth: 45 CV score: 6.871966e+12 \nAdaptive bandwidth: 41 CV score: 6.793327e+12 \nAdaptive bandwidth: 40 CV score: 6.780974e+12 \nAdaptive bandwidth: 38 CV score: 8.841916e+12 \nAdaptive bandwidth: 40 CV score: 6.780974e+12 \n\n# Persist the chosen bandwidth (e.g., result may be 40 neighbors)\nreadr::write_rds(bw_adaptive, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/bw_adaptive.rds\")\n\n\n\n\nFirst, let us call the save bandwidth by using the code chunk below.\n\n# Reload bandwidth when needed\nbw_adaptive &lt;- readr::read_rds(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/bw_adaptive.rds\")\n\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and Gaussian kernel as shown in the code chunk below.\n\n# Calibrate GWR using the selected adaptive bandwidth\ngwr_adaptive &lt;- GWmodel::gwr.basic(\n  formula = resale_price ~ floor_area_sqm +\n    storey_order + remaining_lease_mths +\n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n    PROX_MRT + PROX_PARK + PROX_MALL +\n    PROX_SUPERMARKET +\n    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +\n    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,\n  data     = train_data,    # training sf\n  bw       = bw_adaptive,   # adaptive neighbors (numeric)\n  kernel   = \"gaussian\",    # kernel shape\n  adaptive = TRUE,          # use adaptive bandwidth\n  longlat  = FALSE          # projected coordinates\n)\n\n# Save the fitted GWR object\nreadr::write_rds(gwr_adaptive, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwr_adaptive.rds\")\n\n\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and Gaussian kernel as shown in the code chunk below.\n\n\n\n\nThe code chunk below will be used to retrieve the save gwr model object.\n\n# Reload GWR model when resuming work\ngwr_adaptive &lt;- readr::read_rds(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwr_adaptive.rds\")\n\nThe code below can be used to display the model output.\n\n# Printing the object shows the model summary header and timings\ngwr_adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2025-10-25 13:55:09.364338 \n   Call:\n   GWmodel::gwr.basic(formula = resale_price ~ floor_area_sqm + \n    storey_order + remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + \n    PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + \n    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n    WITHIN_1KM_PRISCH, data = train_data, bw = bw_adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  resale_price\n   Independent variables:  floor_area_sqm storey_order remaining_lease_mths PROX_CBD PROX_ELDERLYCARE PROX_HAWKER PROX_MRT PROX_PARK PROX_MALL PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN WITHIN_350M_CHILDCARE WITHIN_350M_BUS WITHIN_1KM_PRISCH\n   Number of data points: 10335\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\n   Coefficients:\n                              Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)              107601.073  10601.261  10.150  &lt; 2e-16 ***\n   floor_area_sqm             2780.698     90.579  30.699  &lt; 2e-16 ***\n   storey_order              14299.298    339.115  42.167  &lt; 2e-16 ***\n   remaining_lease_mths        344.490      4.592  75.027  &lt; 2e-16 ***\n   PROX_CBD                 -16930.196    201.254 -84.124  &lt; 2e-16 ***\n   PROX_ELDERLYCARE         -14441.025    994.867 -14.516  &lt; 2e-16 ***\n   PROX_HAWKER              -19265.648   1273.597 -15.127  &lt; 2e-16 ***\n   PROX_MRT                 -32564.272   1744.232 -18.670  &lt; 2e-16 ***\n   PROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\n   PROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\n   PROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\n   WITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  &lt; 2e-16 ***\n   WITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  &lt; 2e-16 ***\n   WITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\n   WITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  &lt; 2e-16 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 61650 on 10320 degrees of freedom\n   Multiple R-squared: 0.7373\n   Adjusted R-squared: 0.737 \n   F-statistic:  2069 on 14 and 10320 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 3.922202e+13\n   Sigma(hat): 61610.08\n   AIC:  257320.2\n   AICc:  257320.3\n   BIC:  247249\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 40 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                                   Min.     1st Qu.      Median     3rd Qu.\n   Intercept                -3.2594e+08 -4.7727e+05 -8.3004e+03  5.5025e+05\n   floor_area_sqm           -2.8714e+04  1.4475e+03  2.3011e+03  3.3900e+03\n   storey_order              3.3186e+03  8.5899e+03  1.0826e+04  1.3397e+04\n   remaining_lease_mths     -1.4431e+03  2.6063e+02  3.9048e+02  5.2865e+02\n   PROX_CBD                 -1.0837e+07 -5.7697e+04 -1.3787e+04  2.6552e+04\n   PROX_ELDERLYCARE         -3.2291e+07 -4.0643e+04  1.0562e+04  6.1054e+04\n   PROX_HAWKER              -2.3985e+08 -5.1365e+04  3.0026e+03  6.4287e+04\n   PROX_MRT                 -1.1660e+07 -1.0488e+05 -4.9373e+04  5.1037e+03\n   PROX_PARK                -6.5961e+06 -4.8671e+04 -8.8128e+02  5.3498e+04\n   PROX_MALL                -1.8112e+07 -7.4238e+04 -1.3982e+04  4.9779e+04\n   PROX_SUPERMARKET         -4.5761e+06 -6.3461e+04 -1.7429e+04  3.5616e+04\n   WITHIN_350M_KINDERGARTEN -4.1881e+05 -6.0040e+03  9.0209e+01  4.7127e+03\n   WITHIN_350M_CHILDCARE    -1.0273e+05 -2.2375e+03  2.6668e+02  2.6388e+03\n   WITHIN_350M_BUS          -1.1757e+05 -1.4719e+03  1.1626e+02  1.7584e+03\n   WITHIN_1KM_PRISCH        -6.6465e+05 -5.5959e+03  2.6916e+02  5.7500e+03\n                                  Max.\n   Intercept                1.6493e+08\n   floor_area_sqm           5.0907e+04\n   storey_order             2.9537e+04\n   remaining_lease_mths     1.8119e+03\n   PROX_CBD                 2.2489e+07\n   PROX_ELDERLYCARE         8.2444e+07\n   PROX_HAWKER              5.9654e+06\n   PROX_MRT                 2.0189e+08\n   PROX_PARK                1.5224e+07\n   PROX_MALL                1.0443e+07\n   PROX_SUPERMARKET         3.8330e+06\n   WITHIN_350M_KINDERGARTEN 6.6799e+05\n   WITHIN_350M_CHILDCARE    1.0802e+05\n   WITHIN_350M_BUS          3.7313e+04\n   WITHIN_1KM_PRISCH        5.0262e+05\n   ************************Diagnostic information*************************\n   Number of data points: 10335 \n   Effective number of parameters (2trace(S) - trace(S'S)): 1730.101 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 8604.899 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 238871.8 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 237036.9 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 238209 \n   Residual sum of squares: 4.829177e+12 \n   R-square value:  0.9676571 \n   Adjusted R-square value:  0.9611535 \n\n   ***********************************************************************\n   Program stops at: 2025-10-25 13:56:06.496157 \n\n\n\n\n\n\n# Some workflows also derive a CV bandwidth using the test sf\ngwr_bw_test_adaptive &lt;- GWmodel::bw.gwr(\n  formula = resale_price ~ floor_area_sqm +\n    storey_order + remaining_lease_mths +\n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n    PROX_MRT + PROX_PARK + PROX_MALL +\n    PROX_SUPERMARKET +\n    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +\n    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,\n  data     = test_data,\n  approach = \"CV\",\n  kernel   = \"gaussian\",\n  adaptive = TRUE,\n  longlat  = FALSE\n)\n\nTake a cup of tea and have a break, it will take a few minutes.\n          -----A kind suggestion from GWmodel development group\nAdaptive bandwidth: 3447 CV score: 1.902155e+13 \nAdaptive bandwidth: 2138 CV score: 1.752645e+13 \nAdaptive bandwidth: 1328 CV score: 1.556299e+13 \nAdaptive bandwidth: 828 CV score: 1.357498e+13 \nAdaptive bandwidth: 518 CV score: 1.030751e+13 \nAdaptive bandwidth: 327 CV score: 8.348364e+12 \nAdaptive bandwidth: 208 CV score: 6.860544e+12 \nAdaptive bandwidth: 135 CV score: 5.969504e+12 \nAdaptive bandwidth: 89 CV score: 5.242221e+12 \nAdaptive bandwidth: 62 CV score: 4.742767e+12 \nAdaptive bandwidth: 43 CV score: 4.357839e+12 \nAdaptive bandwidth: 34 CV score: 4.125848e+12 \nAdaptive bandwidth: 25 CV score: 4.056699e+12 \nAdaptive bandwidth: 23 CV score: 4.236349e+13 \nAdaptive bandwidth: 30 CV score: 4.074906e+12 \nAdaptive bandwidth: 25 CV score: 4.056699e+12 \n\n# Save the test-set bandwidth too (for reference)\nreadr::write_rds(gwr_bw_test_adaptive, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwr_bw_test_adaptive.rds\")\n\n\n\n\n\n# gwr_pred &lt;- gwr.predict(\n#   formula = resale_price ~ floor_area_sqm + \n#     storey_order + remaining_lease_mths + \n#     PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + \n#     PROX_MRT + PROX_PARK + PROX_MALL + \n#     PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n#     WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n#     WITHIN_1KM_PRISCH, \n#   data=train_data, \n#   predictdata = test_data, \n#   bw=40, \n#   kernel = 'gaussian', \n#   adaptive=TRUE, \n#   longlat = FALSE)\n# \n# # Save predictions (list-like object)\n# readr::write_rds(gwr_pred, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwr_pred.rds\")\n\n\n\n\nIn this section, we will learn how to calibrate a model to predict HDB resale price by using random forest function of ranger package.\n\n\n\nThe code chunk below extract the x,y coordinates of the full, training and test data sets.\n\n# Extract XY matrices for convenience (sf → numeric matrix with X,Y)\ncoords       &lt;- sf::st_coordinates(mdata)\ncoords_train &lt;- sf::st_coordinates(train_data)\ncoords_test  &lt;- sf::st_coordinates(test_data)\n\nBefore continue, we write all the output into rds for future used.\n\n# Save coordinates used later by GW-RF\nreadr::write_rds(coords_train, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/coords_train.rds\")\nreadr::write_rds(coords_test,  \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/coords_test.rds\")\n\n\n\n\nFirst, we will drop geometry column of the sf data.frame by using st_drop_geometry() of sf package.\n\n# Random Forest from ranger expects a data.frame without geometry\ntrain_data_nogeom &lt;- train_data %&gt;% sf::st_drop_geometry()\ntest_data_nogeom  &lt;- test_data  %&gt;% sf::st_drop_geometry()\n\n\n\n\n\n# Set seed for reproducibility\nset.seed(1234)\n\n# Fit a global RF as another baseline model\nrf &lt;- ranger::ranger(\n  formula = resale_price ~ floor_area_sqm +\n    storey_order + remaining_lease_mths +\n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n    PROX_MRT + PROX_PARK + PROX_MALL +\n    PROX_SUPERMARKET +\n    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +\n    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,\n  data = train_data_nogeom\n)\n\nrf \n\nRanger result\n\nCall:\n ranger::ranger(formula = resale_price ~ floor_area_sqm + storey_order +      remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +      PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data_nogeom) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       731404460 \nR squared (OOB):                  0.9493789 \n\n\n\n# Save the RF model\nreadr::write_rds(rf, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/rf.rds\")"
  },
  {
    "objectID": "In-Class_Ex08/in-class_ex08.html#calibrating-geographically-weighted-random-forest-gw-rf",
    "href": "In-Class_Ex08/in-class_ex08.html#calibrating-geographically-weighted-random-forest-gw-rf",
    "title": "Hands-on Ex08",
    "section": "",
    "text": "In this section, we will learn how to calibrate a model to predict HDB resale price by using grf() of SpatialML package.\n\n\n\n# Reuse coordinates and no-geometry training input\nset.seed(1234)\n\ngwRF_adaptive &lt;- SpatialML::grf(\n  formula = resale_price ~ floor_area_sqm +\n    storey_order + remaining_lease_mths +\n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n    PROX_MRT + PROX_PARK + PROX_MALL +\n    PROX_SUPERMARKET +\n    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +\n    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,\n  dframe = train_data_nogeom, # data.frame without geometry\n  bw     = 40,                # neighbor size (consistent with earlier choice)\n  kernel = \"adaptive\",        # adaptive kernel for local forests\n  coords = coords_train       # matrix of X,Y for training rows\n)\n\n\nNumber of Observations: 10335\n\n\nNumber of Independent Variables: 14\n\n\nKernel: Adaptive\nNeightbours: 40\n\n\n\n--------------- Global ML Model Summary ---------------\n\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data_nogeom, num.trees = 500, mtry = 4, importance = \"impurity\",      num.threads = NULL) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             4 \nTarget node size:                 5 \nVariable importance mode:         impurity \nSplitrule:                        variance \nOOB prediction error (MSE):       697593819 \nR squared (OOB):                  0.9517189 \n\n\n\nImportance:\n\n\n          floor_area_sqm             storey_order     remaining_lease_mths \n            7.413197e+12             1.538950e+13             2.890637e+13 \n                PROX_CBD         PROX_ELDERLYCARE              PROX_HAWKER \n            5.310066e+13             7.285092e+12             5.568548e+12 \n                PROX_MRT                PROX_PARK                PROX_MALL \n            7.369745e+12             4.894344e+12             4.223286e+12 \n        PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN    WITHIN_350M_CHILDCARE \n            2.793853e+12             1.018586e+12             1.710374e+12 \n         WITHIN_350M_BUS        WITHIN_1KM_PRISCH \n            1.589501e+12             6.794634e+12 \n\n\n\nMean Square Error (Not OOB): 173951416.766\n\n\nR-squared (Not OOB) %: 98.796\n\n\nAIC (Not OOB): 196129.252\n\n\nAICc (Not OOB): 196129.299\n\n\n\n--------------- Local Model Summary ---------------\n\n\n\nResiduals OOB:\n\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-207638.9  -13044.4     517.7     668.7   15329.3  380000.0 \n\n\n\nResiduals Predicted (Not OOB):\n\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-80918.36  -3710.39     80.88     60.19   4119.23  67858.13 \n\n\n\nLocal Variable Importance:\n\n\n                               Min          Max        Mean         StD\nfloor_area_sqm                   0 244740042006 10095828392 21812835540\nstorey_order             185976628 195162288767 10691049214 16507251138\nremaining_lease_mths     364347875 420068216877 18525480676 40200134557\nPROX_CBD                         0 261367685029  7551870678 20050530584\nPROX_ELDERLYCARE                 0 260937815286  6797406011 17221278502\nPROX_HAWKER                      0 232903486867  6917875149 17526152433\nPROX_MRT                         0 192977091714  6219493848 14339970325\nPROX_PARK                        0 270208600970  5678244629 13059236132\nPROX_MALL                        0 290212372886  6903172498 18141558541\nPROX_SUPERMARKET                 0 283979765533  6391052599 16785880266\nWITHIN_350M_KINDERGARTEN         0 124340534149  1694367905  7648420853\nWITHIN_350M_CHILDCARE            0 194759670980  3113750592 10738676578\nWITHIN_350M_BUS                  0 132614671785  3014600716  8056548827\nWITHIN_1KM_PRISCH                0 132884456893  1116898699  5401808933\n\n\n\nMean squared error (OOB): 932642623.291\n\n\nR-squared (OOB) %: 93.544\n\n\nAIC (OOB): 213484.26\n\n\nAICc (OOB): 213484.306\n\n\nMean squared error Predicted (Not OOB): 80652745.326\n\n\nR-squared Predicted (Not OOB) %: 99.442\n\n\nAIC Predicted (Not OOB): 188185.531\n\n\nAICc Predicted (Not OOB): 188185.578\n\n\n\nCalculation time (in seconds): 11.9505\n\n# Persist fitted GW-RF\nreadr::write_rds(gwRF_adaptive, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwRF_adaptive.rds\")\n\n\n\n\n\n\n\nTip\n\n\n\nThis is a computational intensity and time consuming process. It is wiser to save the output as an rds file for future used without having to re-run the process again.\n\n\nThe code chunk below can be used to retrieve the save model in future.\n\n# (Later) reload if needed\ngwRF_adaptive &lt;- readr::read_rds(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwRF_adaptive.rds\")\n\n\n\n\n\n\nThe code chunk below will be used to combine the test data with its corresponding coordinates data.\n\n# Combine the test attributes with their coordinates for prediction\ntest_data_nogeom &lt;- cbind(test_data, coords_test) %&gt;%\n  sf::st_drop_geometry()     # drop geometry to keep plain columns\n\n\n\n\n\n# Generate local predictions at test locations\ngwRF_pred &lt;- SpatialML::predict.grf(\n  gwRF_adaptive,     # trained GW-RF model\n  test_data_nogeom,  # test attributes + X,Y columns\n  x.var.name = \"X\",  # column name for X coordinate\n  y.var.name = \"Y\",  # column name for Y coordinate\n  local.w    = 1,    # weight for local component\n  global.w   = 0     # set to 0 to use purely local predictions\n)\n\n# Save the prediction vector\nGRF_pred &lt;- readr::write_rds(gwRF_pred, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/GRF_pred.rds\")\n\n\n\n\nThe output of the predict.grf() is a vector of predicted values. It is wiser to convert it into a data frame for further visualisation and analysis.\n\n# Reload predictions when needed and coerce to data.frame\nGRF_pred     &lt;- readr::read_rds(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/GRF_pred.rds\")\nGRF_pred_df  &lt;- as.data.frame(GRF_pred)  # single column with predicted values\n\nIn the code chunk below, cbind() is used to append the predicted values onto test_datathe\n\n# Attach predictions to the test data and retain only needed columns\ntest_data_p &lt;- cbind(test_data, GRF_pred_df) %&gt;%\n  dplyr::select(resale_price, GRF_pred)   # rename matches grf() output\n\n\n# Save the paired actual vs predicted for later evaluation/plots\nreadr::write_rds(test_data_p, \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/test_data_p.rds\")\n\n\n\n\n\nThe root mean square error (RMSE) allows us to measure how far predicted values are from observed values in a regression analysis. In the code chunk below, rmse() of Metrics package is used to compute the RMSE.\n\n# Compute RMSE between observed and GW-RF predicted prices\nMetrics::rmse(\n  test_data_p$resale_price,  # actual values\n  test_data_p$GRF_pred       # predicted values\n)\n\n[1] 28160.87\n\n# Example output in the reference workflow: 28160.87\n\n\n\n\nAlternatively, scatterplot can be used to visualise the actual resale price and the predicted resale price by using the code chunk below.\n\n# Scatter plot of Predicted (x) vs Actual (y)\nggplot2::ggplot(\n  data = test_data_p,                           # data with both columns\n  ggplot2::aes(x = GRF_pred, y = resale_price)  # map axes\n) +\n  ggplot2::geom_point()                         # draw points\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nA better predictive model should have the scatter point close to the diagonal line. The scatter plot can be also used to detect if any outliers in the model."
  },
  {
    "objectID": "In-Class_Ex08/in-class_ex08.html#geocoding-for-geometric",
    "href": "In-Class_Ex08/in-class_ex08.html#geocoding-for-geometric",
    "title": "In-class Ex08: Take-home Exercise 3 Kick Starter",
    "section": "3 Geocoding for Geometric",
    "text": "3 Geocoding for Geometric\n\n3.1 Importing data\n\n# Downloading the raw data from data.gov.sg. \n# Data source: Resale flat prices based on registration date from Jan-2017 onwards\n\n# load full table once\nHDBresale_raw &lt;- read_csv(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/In-Class_Ex08/data/rawdata/ResaleflatpricesbasedonregistrationdatefromJan2017onwards.csv\")\n\nRows: 218083 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): month, town, flat_type, block, street_name, storey_range, flat_mode...\ndbl (3): floor_area_sqm, lease_commence_date, resale_price\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Inspect the loading data\nglimpse(HDBresale_raw)\n\nRows: 218,083\nColumns: 11\n$ month               &lt;chr&gt; \"2017-01\", \"2017-01\", \"2017-01\", \"2017-01\", \"2017-…\n$ town                &lt;chr&gt; \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO …\n$ flat_type           &lt;chr&gt; \"2 ROOM\", \"3 ROOM\", \"3 ROOM\", \"3 ROOM\", \"3 ROOM\", …\n$ block               &lt;chr&gt; \"406\", \"108\", \"602\", \"465\", \"601\", \"150\", \"447\", \"…\n$ street_name         &lt;chr&gt; \"ANG MO KIO AVE 10\", \"ANG MO KIO AVE 4\", \"ANG MO K…\n$ storey_range        &lt;chr&gt; \"10 TO 12\", \"01 TO 03\", \"01 TO 03\", \"04 TO 06\", \"0…\n$ floor_area_sqm      &lt;dbl&gt; 44, 67, 67, 68, 67, 68, 68, 67, 68, 67, 68, 67, 67…\n$ flat_model          &lt;chr&gt; \"Improved\", \"New Generation\", \"New Generation\", \"N…\n$ lease_commence_date &lt;dbl&gt; 1979, 1978, 1980, 1980, 1980, 1981, 1979, 1976, 19…\n$ remaining_lease     &lt;chr&gt; \"61 years 04 months\", \"60 years 07 months\", \"62 ye…\n$ resale_price        &lt;dbl&gt; 232000, 250000, 262000, 265000, 265000, 275000, 28…\n\n\n\n\n3.2 Reducing and filtering the dataset\n\n# find the most recent month that has 4 ROOM\nmonth_choice &lt;- HDBresale_raw %&gt;%\n  filter(flat_type == \"4 ROOM\") %&gt;%\n  count(month, name = \"n\") %&gt;%\n  filter(n &gt; 0) %&gt;%\n  arrange(desc(month)) %&gt;%\n  slice(1) %&gt;%\n  pull(month)\n\n#Inspect the output\nmonth_choice\n\n[1] \"2025-10\"\n\n\n\n# filter to that month\nHDBresale &lt;- HDBresale_raw %&gt;%\n  filter(flat_type == \"4 ROOM\", month == month_choice)\n\nnrow(HDBresale)   # should be greater than zero\n\n[1] 458\n\n\n\n\n3.3 Geodata pre-processing and cleaning\n\n3.3.1 Address normalisation matters\n\n# street name fix\nHDBresale$street_name &lt;- gsub(\"ST\\\\.\", \"SAINT\", HDBresale$street_name)\n\n\n\n\n\n\n\nNote\n\n\n\nThe gsub() function performs a global substitution (find and replace) in text.\n\n\n\n\n3.3.2 Function to convert address to coordinates (LATITUDE and LONGITUDEY)\nBelow is the code chunk used to build a function that will convert address to coordinates\n\nThe function sends a live API request to OneMap Singapore to obtain geographic coordinates (latitude and longitude) for each given HDB address.\n\nExplicit UTF-8 encoding is included to eliminate the “No encoding supplied” warning and ensure correct text handling for special characters.\n\nAlways returns a tibble with columns LATITUDE and LONGITUDE, even when no match is found, to prevent pipeline breaks during unnesting.\n\nOnly retrieves the first match from the API (pageNum = “1”), which increases speed but may ignore alternative results for ambiguous addresses.\n\nRequires street name standardisation (e.g., “ST.” changed to “SAINT”) before calling the function to improve matching accuracy.\n\nCoordinates returned by OneMap are based on WGS84 (EPSG 4326), so conversion to SVY21 (EPSG 3414) is needed for metric-based distance analysis.\n\nEach function call makes a separate HTTP request; for large datasets, use progress tracking, pauses (Sys.sleep), and checkpoint saving to avoid rate limits.\n\nWrapping the function with tryCatch or purrr::safely prevents process interruption if a request fails or the API returns an unexpected response.\n\nA test call such as geocode(“101”,“JURONG EAST STREET 13”) is recommended before batch processing to confirm valid numeric coordinates are returned.\n\nFor reproducibility and efficiency, store results (block, street, LATITUDE, LONGITUDE) in a CSV file to reuse in future runs without re-querying the API.\n\n\n# professor geocode\n# Reference: https://www.onemap.gov.sg/apidocs/coordinate\n\n\ngeocode &lt;- function(block, streetname) {                          # define a function that takes block and street name and returns coordinates\n  base_url &lt;- \"https://onemap.gov.sg/api/common/elastic/search\"   # store the OneMap search endpoint as a constant for reuse\n  address  &lt;- paste(block, streetname, sep = \" \")                 # build a single query string such as 118 ANG MO KIO AVENUE 4\n  query &lt;- list(                                                  # create a named list of query parameters for the HTTP request\n    searchVal     = address,                                      # the address string to search\n    returnGeom    = \"Y\",                                          # ask the service to return geometry fields\n    getAddrDetails= \"N\",                                          # do not request extra address fields to keep reply small\n    pageNum       = \"1\"                                           # take the first page only for a single best match\n  )                                                               # end of query parameter list\n  res     &lt;- httr::GET(base_url, query = query)                   # send a GET request to OneMap with the query parameters\n  restext &lt;- httr::content(res, as = \"text\", encoding = \"UTF-8\")  # read the response body as text with UTF8 to avoid encoding warnings\n  out     &lt;- jsonlite::fromJSON(restext)                          # parse the JSON text into an R list or data frame\n\n  if (length(out$results) == 0) {                                 # if the service returns no match for this address\n    tibble(LATITUDE = NA_real_, LONGITUDE = NA_real_)             # return a tibble with missing numeric coordinates\n  } else {                                                        # otherwise when there is at least one match\n    tibble(                                                              \n      LATITUDE  = as.numeric(out$results$LATITUDE[1]),            # take the first result latitude and coerce to numeric\n      LONGITUDE = as.numeric(out$results$LONGITUDE[1])            # take the first result longitude and coerce to numeric\n    )                                                             # end tibble creation\n  }                                                               # end branch\n}                                                                 # end function\n\n\n\n3.3.3 Perform minimal unit/smoke test\n\n# Test with a single known HDB address\ngeocode(\"101\", \"JURONG EAST STREET 13\")\n\n# A tibble: 1 × 2\n  LATITUDE LONGITUDE\n     &lt;dbl&gt;     &lt;dbl&gt;\n1     1.34      104.\n\n\n\n\n\n3.4 Merge the LATITUDE and LONGITUDE to dataset\n\n# create LATITUDE and LONGITUDE and merge into the table\nHDBresale &lt;- HDBresale %&gt;%\n  mutate(geo = purrr::map2(block, street_name, geocode)) %&gt;%\n  tidyr::unnest(geo)\n\n### \nglimpse(HDBresale)   # now includes LATITUDE and LONGITUDE\n\nRows: 458\nColumns: 13\n$ month               &lt;chr&gt; \"2025-10\", \"2025-10\", \"2025-10\", \"2025-10\", \"2025-…\n$ town                &lt;chr&gt; \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO …\n$ flat_type           &lt;chr&gt; \"4 ROOM\", \"4 ROOM\", \"4 ROOM\", \"4 ROOM\", \"4 ROOM\", …\n$ block               &lt;chr&gt; \"336\", \"415\", \"438\", \"301\", \"302\", \"327\", \"212\", \"…\n$ street_name         &lt;chr&gt; \"ANG MO KIO AVE 1\", \"ANG MO KIO AVE 10\", \"ANG MO K…\n$ storey_range        &lt;chr&gt; \"07 TO 09\", \"07 TO 09\", \"01 TO 03\", \"10 TO 12\", \"1…\n$ floor_area_sqm      &lt;dbl&gt; 91, 92, 92, 98, 98, 98, 81, 92, 99, 91, 99, 91, 90…\n$ flat_model          &lt;chr&gt; \"New Generation\", \"New Generation\", \"New Generatio…\n$ lease_commence_date &lt;dbl&gt; 1982, 1979, 1979, 1978, 1978, 1977, 1977, 1978, 19…\n$ remaining_lease     &lt;chr&gt; \"55 years 04 months\", \"52 years 11 months\", \"52 ye…\n$ resale_price        &lt;dbl&gt; 570000, 562000, 465000, 638000, 580000, 600000, 54…\n$ LATITUDE            &lt;dbl&gt; 1.363594, 1.364453, 1.366971, 1.367421, 1.367090, …\n$ LONGITUDE           &lt;dbl&gt; 103.8518, 103.8537, 103.8539, 103.8459, 103.8457, …"
  },
  {
    "objectID": "In-Class_Ex08/in-class_ex08.html#supplement-to-hands-on-exercise-8",
    "href": "In-Class_Ex08/in-class_ex08.html#supplement-to-hands-on-exercise-8",
    "title": "In-class Ex08: Take-home Exercise 3 Kick Starter",
    "section": "3 Supplement to Hands-on Exercise 8",
    "text": "3 Supplement to Hands-on Exercise 8\n\n3.1 Data import\n\n# Read the prepared modelling dataset (sf object)\nmdata &lt;- readr::read_rds(\"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/rawdata/mdata.rds\")\n\n\n\n3.2 Data sampling\nCalibrating predictive models are computational intensive, especially random forest method is used. For quick prototyping, a 10% sample will be selected at random from the data by using the code chunk below.\n\nset.seed(1234)\nHDB_sample &lt;- mdata %&gt;%\n  sample_n(1500)\n\n\n\n3.3 Checking of overlapping point\n\n\n\n\n\n\nWarning\n\n\n\nWhen using GWmodel to calibrate explanatory or predictive models, it is very important to ensure that there are no overlapping point features\n\n\nThe code chunk below is used to check if there are overlapping point features.\n\noverlapping_points &lt;- HDB_sample %&gt;%\n  mutate(overlap = lengths(st_equals(., .)) &gt; 1)\n\n\n\n3.4 Spatial jittler\nIn the code code chunk below, st_jitter() of sf package is used to move the point features by 5 meters to avoid overlapping point features.\n\nHDB_sample &lt;- HDB_sample %&gt;%\n  st_jitter(amount = 5)\n\n\n\n3.5 Data Sampling\nThe entire data are split into training and test data sets with 65% and 35% respectively by using initial_split() of rsample package. rsample is one of the package of tigymodels.\n\nset.seed(1234)\nresale_split &lt;- initial_split(HDB_sample, \n                              prop = 6.67/10,)\ntrain_data &lt;- training(resale_split)\ntest_data &lt;- testing(resale_split)\n\n\n\n3.6 Multicollinearity check\nIn order to avoid multicollineariy. In the code chunk below, ggcorrmat() of ggstatsplot is used to plot a correlation matrix to check if there are pairs of highly correlated independent variables.\n\nmdata_nogeo &lt;- mdata %&gt;%\n  st_drop_geometry()\nggstatsplot::ggcorrmat(mdata_nogeo[, 2:17])\n\n\n\n\n\n\n\n\n\n\n3.7 Building a non-spatial multiple linear regression\n\nprice_mlr &lt;- lm(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                data=train_data)\nolsrr::ols_regress(price_mlr)\n\n                              Model Summary                                \n--------------------------------------------------------------------------\nR                           0.862       RMSE                    60813.316 \nR-Squared                   0.742       MSE                3698259426.779 \nAdj. R-Squared              0.739       Coef. Var                  14.255 \nPred R-Squared              0.734       AIC                     24901.005 \nMAE                     45987.256       SBC                     24979.529 \n--------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                      \n-------------------------------------------------------------------------------\n                    Sum of                                                     \n                   Squares         DF         Mean Square       F         Sig. \n-------------------------------------------------------------------------------\nRegression    1.065708e+13         14    761220078101.236    202.745    0.0000 \nResidual      3.698259e+12        985      3754578098.252                      \nTotal         1.435534e+13        999                                          \n-------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                 \n------------------------------------------------------------------------------------------------------------------\n                   model          Beta    Std. Error    Std. Beta       t        Sig          lower         upper \n------------------------------------------------------------------------------------------------------------------\n             (Intercept)    115703.696     34303.409                   3.373    0.001     48387.533    183019.860 \n          floor_area_sqm      2778.618       292.262        0.165      9.507    0.000      2205.089      3352.146 \n            storey_order     12698.165      1070.950        0.211     11.857    0.000     10596.559     14799.771 \n    remaining_lease_mths       350.252        14.596        0.450     23.997    0.000       321.610       378.894 \n                PROX_CBD    -16225.588       630.092       -0.572    -25.751    0.000    -17462.065    -14989.110 \n        PROX_ELDERLYCARE    -11330.930      3220.845       -0.061     -3.518    0.000    -17651.436     -5010.423 \n             PROX_HAWKER    -19964.070      4021.046       -0.087     -4.965    0.000    -27854.872    -12073.268 \n                PROX_MRT    -39652.516      5412.288       -0.130     -7.326    0.000    -50273.456    -29031.577 \n               PROX_PARK    -15878.322      4609.199       -0.061     -3.445    0.001    -24923.300     -6833.344 \n               PROX_MALL    -15910.922      6438.111       -0.048     -2.471    0.014    -28544.911     -3276.933 \n        PROX_SUPERMARKET    -18928.514     13304.965       -0.025     -1.423    0.155    -45037.848      7180.821 \nWITHIN_350M_KINDERGARTEN      9309.735      2024.293        0.079      4.599    0.000      5337.313     13282.157 \n   WITHIN_350M_CHILDCARE     -1619.514      1180.948       -0.026     -1.371    0.171     -3936.977       697.948 \n         WITHIN_350M_BUS      -447.695       738.715       -0.011     -0.606    0.545     -1897.331      1001.940 \n       WITHIN_1KM_PRISCH    -10698.012      1543.511       -0.138     -6.931    0.000    -13726.960     -7669.065 \n------------------------------------------------------------------------------------------------------------------\n\n\n\n\n3.8 Multicollinearity check with VIF\n\nvif &lt;- performance::check_collinearity(price_mlr)\nkable(vif, \n      caption = \"Variance Inflation Factor (VIF) Results\") %&gt;%\n  kable_styling(font_size = 18) \n\n\nVariance Inflation Factor (VIF) Results\n\n\nTerm\nVIF\nVIF_CI_low\nVIF_CI_high\nSE_factor\nTolerance\nTolerance_CI_low\nTolerance_CI_high\n\n\n\n\nfloor_area_sqm\n1.146686\n1.085743\n1.250945\n1.070834\n0.8720785\n0.7993954\n0.9210287\n\n\nstorey_order\n1.206020\n1.135720\n1.312734\n1.098189\n0.8291736\n0.7617690\n0.8804986\n\n\nremaining_lease_mths\n1.343645\n1.254833\n1.463410\n1.159157\n0.7442440\n0.6833358\n0.7969186\n\n\nPROX_CBD\n1.887898\n1.733977\n2.074096\n1.374008\n0.5296898\n0.4821378\n0.5767088\n\n\nPROX_ELDERLYCARE\n1.140418\n1.080572\n1.244716\n1.067904\n0.8768712\n0.8033960\n0.9254357\n\n\nPROX_HAWKER\n1.183865\n1.116887\n1.289223\n1.088056\n0.8446907\n0.7756609\n0.8953457\n\n\nPROX_MRT\n1.211390\n1.140307\n1.318485\n1.100632\n0.8254980\n0.7584464\n0.8769566\n\n\nPROX_PARK\n1.186122\n1.118797\n1.291599\n1.089092\n0.8430839\n0.7742340\n0.8938169\n\n\nPROX_MALL\n1.435504\n1.335252\n1.565736\n1.198125\n0.6966193\n0.6386771\n0.7489224\n\n\nPROX_SUPERMARKET\n1.226727\n1.153448\n1.335000\n1.107577\n0.8151773\n0.7490638\n0.8669656\n\n\nWITHIN_350M_KINDERGARTEN\n1.123989\n1.067172\n1.228865\n1.060183\n0.8896886\n0.8137594\n0.9370564\n\n\nWITHIN_350M_CHILDCARE\n1.387119\n1.292841\n1.511748\n1.177760\n0.7209189\n0.6614860\n0.7734902\n\n\nWITHIN_350M_BUS\n1.193498\n1.125056\n1.299398\n1.092473\n0.8378731\n0.7695869\n0.8888447\n\n\nWITHIN_1KM_PRISCH\n1.508943\n1.399770\n1.647930\n1.228390\n0.6627154\n0.6068219\n0.7144029\n\n\n\n\n\n\nplot(vif) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n3.9 Predictive Modelling with gwr\n\nbw_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=train_data,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\nAdaptive bandwidth: 625 CV score: 3.459032e+12 \nAdaptive bandwidth: 394 CV score: 3.231786e+12 \nAdaptive bandwidth: 250 CV score: 2.914736e+12 \nAdaptive bandwidth: 162 CV score: 2.610897e+12 \nAdaptive bandwidth: 107 CV score: 2.240188e+12 \nAdaptive bandwidth: 73 CV score: 1.971641e+12 \nAdaptive bandwidth: 52 CV score: 1.797271e+12 \nAdaptive bandwidth: 39 CV score: 1.659472e+12 \nAdaptive bandwidth: 31 CV score: 1.573963e+12 \nAdaptive bandwidth: 26 CV score: 1.550147e+12 \nAdaptive bandwidth: 23 CV score: 1.542544e+12 \nAdaptive bandwidth: 21 CV score: 1.518885e+12 \nAdaptive bandwidth: 19 CV score: 1.515965e+12 \nAdaptive bandwidth: 19 CV score: 1.515965e+12 \n\n\n\nbw_adaptive\n\n[1] 19\n\n\n\n\n3.10 Model calibration\n\ngwr_adaptive &lt;- gwr.basic(formula = resale_price ~\n                            floor_area_sqm + storey_order +\n                            remaining_lease_mths + PROX_CBD + \n                            PROX_ELDERLYCARE + PROX_HAWKER +\n                            PROX_MRT + PROX_PARK + PROX_MALL + \n                            PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                            WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                            WITHIN_1KM_PRISCH,\n                          data=train_data,\n                          bw=bw_adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE,\n                          longlat = FALSE)\n\n\n\n3.11 Predictive Modelling with MLR\n\n3.11.1 Predictive Modelling with MLR\n\n3.11.1.1 Test data bw\n\ngwr_pred &lt;- gwr.predict(formula = resale_price ~\n                          floor_area_sqm + storey_order +\n                          remaining_lease_mths + PROX_CBD + \n                          PROX_ELDERLYCARE + PROX_HAWKER + \n                          PROX_MRT + PROX_PARK + PROX_MALL + \n                          PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                          WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n                          WITHIN_1KM_PRISCH, \n                        data=train_data, \n                        predictdata = test_data, \n                        bw=bw_adaptive, \n                        kernel = 'gaussian', \n                        adaptive=TRUE, \n                        longlat = FALSE)\n\n\n\n3.11.1.2 Predicting\n\ngwr_pred &lt;- gwr.predict(formula = resale_price ~\n                          floor_area_sqm + storey_order +\n                          remaining_lease_mths + PROX_CBD + \n                          PROX_ELDERLYCARE + PROX_HAWKER + \n                          PROX_MRT + PROX_PARK + PROX_MALL + \n                          PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                          WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n                          WITHIN_1KM_PRISCH, \n                        data=train_data, \n                        predictdata = test_data, \n                        bw=bw_adaptive, \n                        kernel = 'gaussian', \n                        adaptive=TRUE, \n                        longlat = FALSE)\n\n\n\n\n\n3.12 Predictive Modelling: RF method\n\n3.12.1 Data Preparation\nFirstly, code chunk below is used to extract the coordinates of training and test data sets\n\ncoords &lt;- st_coordinates(HDB_sample)\ncoords_train &lt;- st_coordinates(train_data)\ncoords_test &lt;- st_coordinates(test_data)\n\n\n\n3.12.2 Calibrating RF model\n\n# set.seed(1234)\n# rf &lt;- ranger(resale_price ~ floor_area_sqm + storey_order + \n#                remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + \n#                PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + \n#                PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n#                WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n#                WITHIN_1KM_PRISCH,\n#              data=train_nogeom)\n\n\n\n3.12.3 Model output\n\nrf\n\nfunction (data = NULL, dependent.variable.name = NULL, predictor.variable.names = NULL, \n    distance.matrix = NULL, distance.thresholds = NULL, xy = NULL, \n    ranger.arguments = NULL, scaled.importance = FALSE, seed = 1, \n    verbose = TRUE, n.cores = parallel::detectCores() - 1, cluster = NULL) \n{\n    if (!is.null(data) & !is.null(ranger.arguments)) {\n        ranger.arguments$data &lt;- NULL\n        ranger.arguments$dependent.variable.name &lt;- NULL\n        ranger.arguments$predictor.variable.names &lt;- NULL\n    }\n    num.trees &lt;- 500\n    mtry &lt;- NULL\n    mtry &lt;- NULL\n    importance &lt;- \"permutation\"\n    write.forest &lt;- TRUE\n    probability &lt;- FALSE\n    min.node.size &lt;- NULL\n    max.depth &lt;- NULL\n    replace &lt;- TRUE\n    sample.fraction &lt;- ifelse(replace, 1, 0.632)\n    case.weights &lt;- NULL\n    class.weights &lt;- NULL\n    splitrule &lt;- NULL\n    num.random.splits &lt;- 1\n    alpha &lt;- 0.5\n    minprop &lt;- 0.1\n    split.select.weights &lt;- NULL\n    always.split.variables &lt;- NULL\n    respect.unordered.factors &lt;- NULL\n    scale.permutation.importance &lt;- TRUE\n    local.importance &lt;- TRUE\n    regularization.factor &lt;- 1\n    regularization.usedepth &lt;- FALSE\n    keep.inbag &lt;- FALSE\n    inbag &lt;- NULL\n    holdout &lt;- FALSE\n    quantreg &lt;- FALSE\n    oob.error &lt;- TRUE\n    num.threads &lt;- n.cores\n    save.memory &lt;- FALSE\n    classification &lt;- NULL\n    if (!is.null(ranger.arguments)) {\n        list2env(ranger.arguments, envir = environment())\n    }\n    if (inherits(data, \"tbl_df\") | inherits(data, \"tbl\")) {\n        data &lt;- as.data.frame(data)\n    }\n    if (inherits(xy, \"tbl_df\") | inherits(xy, \"tbl\")) {\n        xy &lt;- as.data.frame(xy)\n    }\n    if (inherits(predictor.variable.names, \"variable_selection\")) {\n        predictor.variable.names &lt;- predictor.variable.names$selected.variables\n    }\n    else {\n        if (sum(predictor.variable.names %in% colnames(data)) &lt; \n            length(predictor.variable.names)) {\n            stop(paste0(\"The predictor.variable.names \", paste0(predictor.variable.names[!(predictor.variable.names %in% \n                colnames(data))], collapse = \", \"), \" are missing from 'data'\"))\n        }\n    }\n    if (!(dependent.variable.name %in% colnames(data))) {\n        stop(paste0(\"The dependent.variable.name \", dependent.variable.name, \n            \" is not a column of 'data'.\"))\n    }\n    data &lt;- data[, c(dependent.variable.name, predictor.variable.names)]\n    if (!is.null(seed)) {\n        set.seed(seed)\n    }\n    if (scaled.importance == TRUE) {\n        data.scaled &lt;- as.data.frame(scale(x = data))\n        if (sum(apply(data.scaled, 2, is.nan)) &gt; 0 | sum(apply(data.scaled, \n            2, is.infinite)) &gt; 0) {\n            scaled.importance &lt;- FALSE\n            warning(\"The training data yields NaN or Inf when scaled, setting scaled.importance to FALSE.\")\n        }\n    }\n    is.binary &lt;- is_binary(data = data, dependent.variable.name = dependent.variable.name)\n    if (is.binary == TRUE & is.null(case.weights)) {\n        case.weights &lt;- case_weights(data = data, dependent.variable.name = dependent.variable.name)\n    }\n    m &lt;- ranger::ranger(data = data, dependent.variable.name = dependent.variable.name, \n        num.trees = num.trees, mtry = mtry, importance = importance, \n        write.forest = write.forest, probability = probability, \n        min.node.size = min.node.size, max.depth = max.depth, \n        replace = replace, sample.fraction = sample.fraction, \n        case.weights = case.weights, class.weights = class.weights, \n        splitrule = splitrule, num.random.splits = num.random.splits, \n        alpha = alpha, minprop = minprop, split.select.weights = split.select.weights, \n        always.split.variables = always.split.variables, respect.unordered.factors = respect.unordered.factors, \n        scale.permutation.importance = scale.permutation.importance, \n        local.importance = local.importance, regularization.factor = regularization.factor, \n        regularization.usedepth = regularization.usedepth, keep.inbag = keep.inbag, \n        inbag = inbag, holdout = holdout, quantreg = quantreg, \n        oob.error = oob.error, num.threads = num.threads, save.memory = save.memory, \n        verbose = verbose, seed = seed, classification = classification)\n    variable.importance.global &lt;- m$variable.importance\n    variable.importance.local &lt;- m$variable.importance.local\n    if (scaled.importance == TRUE) {\n        m.scaled &lt;- ranger::ranger(data = data.scaled, dependent.variable.name = dependent.variable.name, \n            num.trees = num.trees, mtry = mtry, importance = importance, \n            write.forest = write.forest, probability = probability, \n            min.node.size = min.node.size, max.depth = max.depth, \n            replace = replace, sample.fraction = sample.fraction, \n            case.weights = case.weights, class.weights = class.weights, \n            splitrule = splitrule, num.random.splits = num.random.splits, \n            alpha = alpha, minprop = minprop, split.select.weights = split.select.weights, \n            always.split.variables = always.split.variables, \n            respect.unordered.factors = respect.unordered.factors, \n            scale.permutation.importance = FALSE, local.importance = local.importance, \n            regularization.factor = regularization.factor, regularization.usedepth = regularization.usedepth, \n            keep.inbag = keep.inbag, inbag = inbag, holdout = holdout, \n            quantreg = quantreg, oob.error = oob.error, num.threads = num.threads, \n            save.memory = save.memory, verbose = verbose, seed = seed, \n            classification = classification)\n        variable.importance.global &lt;- m.scaled$variable.importance\n        variable.importance.local &lt;- m.scaled$variable.importance.local\n    }\n    m$ranger.arguments &lt;- list(data = data, dependent.variable.name = dependent.variable.name, \n        predictor.variable.names = predictor.variable.names, \n        distance.matrix = distance.matrix, distance.thresholds = distance.thresholds, \n        xy = xy, num.trees = num.trees, mtry = mtry, importance = importance, \n        scaled.importance = scaled.importance, write.forest = write.forest, \n        probability = probability, min.node.size = min.node.size, \n        max.depth = max.depth, replace = replace, sample.fraction = sample.fraction, \n        case.weights = case.weights, class.weights = class.weights, \n        splitrule = splitrule, num.random.splits = num.random.splits, \n        alpha = alpha, minprop = minprop, split.select.weights = split.select.weights, \n        always.split.variables = always.split.variables, respect.unordered.factors = respect.unordered.factors, \n        scale.permutation.importance = scale.permutation.importance, \n        local.importance = local.importance, regularization.factor = regularization.factor, \n        regularization.usedepth = regularization.usedepth, keep.inbag = keep.inbag, \n        inbag = inbag, holdout = holdout, quantreg = quantreg, \n        oob.error = oob.error, num.threads = num.threads, save.memory = save.memory, \n        seed = seed, classification = classification)\n    if (importance == \"permutation\") {\n        m$importance &lt;- list()\n        variable.importance.global.sign &lt;- variable.importance.global\n        variable.importance.global.sign[variable.importance.global.sign &gt;= \n            0] &lt;- 1\n        variable.importance.global.sign[variable.importance.global.sign &lt; \n            0] &lt;- -1\n        variable.importance.global &lt;- sqrt(abs(variable.importance.global)) * \n            variable.importance.global.sign\n        m$importance$per.variable &lt;- data.frame(variable = names(variable.importance.global), \n            importance = variable.importance.global) %&gt;% tibble::remove_rownames() %&gt;% \n            dplyr::arrange(dplyr::desc(importance)) %&gt;% dplyr::mutate(importance = round(importance, \n            3)) %&gt;% as.data.frame()\n        m$importance$per.variable.plot &lt;- plot_importance(m$importance$per.variable, \n            verbose = verbose)\n        variable.importance.local.sign &lt;- variable.importance.local\n        variable.importance.local.sign[variable.importance.local.sign &gt;= \n            0] &lt;- 1\n        variable.importance.local.sign[variable.importance.local.sign &lt; \n            0] &lt;- -1\n        variable.importance.local &lt;- sqrt(abs(variable.importance.local)) * \n            variable.importance.local.sign\n        m$importance$local &lt;- variable.importance.local\n    }\n    predicted &lt;- stats::predict(object = m, data = data, type = \"response\")$predictions\n    m$predictions &lt;- list()\n    m$predictions$values &lt;- predicted\n    observed &lt;- data[, dependent.variable.name]\n    m$performance &lt;- list()\n    m$performance$r.squared.oob &lt;- m$r.squared\n    m$performance$r.squared &lt;- cor(observed, predicted)^2\n    m$performance$pseudo.r.squared &lt;- cor(observed, predicted)\n    m$performance$rmse.oob &lt;- sqrt(m$prediction.error)\n    m$performance$rmse &lt;- root_mean_squared_error(o = observed, \n        p = predicted, normalization = \"rmse\")\n    names(m$performance$rmse) &lt;- NULL\n    m$performance$nrmse &lt;- root_mean_squared_error(o = observed, \n        p = predicted, normalization = \"iq\")\n    names(m$performance$nrmse) &lt;- NULL\n    m$performance$auc &lt;- NA\n    m$performance$auc &lt;- auc(o = observed, p = predicted)\n    m$residuals$values &lt;- observed - predicted\n    m$residuals$stats &lt;- summary(m$residuals$values)\n    if (!is.null(distance.matrix)) {\n        m$residuals$autocorrelation &lt;- moran_multithreshold(x = m$residuals$values, \n            distance.matrix = distance.matrix, distance.thresholds = distance.thresholds, \n            verbose = verbose)\n    }\n    m$residuals$normality &lt;- residuals_diagnostics(residuals = m$residuals$values, \n        predictions = predicted)\n    m$residuals$diagnostics &lt;- plot_residuals_diagnostics(m, \n        verbose = verbose)\n    if (!is.null(cluster)) {\n        m$cluster &lt;- cluster\n    }\n    class(m) &lt;- c(\"rf\", \"ranger\")\n    if (verbose == TRUE) {\n        print(m)\n    }\n    m\n}\n&lt;bytecode: 0x12735d858&gt;\n&lt;environment: namespace:spatialRF&gt;\n\n\n\n\n\n3.13 Predictive Modelling: SpatialML method\n\n3.13.1 Determining bandwidth\n\n# set.seed(1234)\n# gwRF_bw &lt;- grf.bw(formula = resale_price ~ floor_area_sqm + \n#                        storey_order + remaining_lease_mths + \n#                        PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + \n#                        PROX_MRT + PROX_PARK + PROX_MALL + \n#                        PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n#                        WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n#                        WITHIN_1KM_PRISCH,\n#                      dataset=train_data, \n#                      kernel=\"adaptive\",\n#                      coords=coords_train)\n\n\n\n3.13.2 Calibrating with grf\n\n# set.seed(1234)\n# gwRF_adaptive &lt;- grf(formula = resale_price ~ floor_area_sqm + \n#                        storey_order + remaining_lease_mths + \n#                        PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + \n#                        PROX_MRT + PROX_PARK + PROX_MALL + \n#                        PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n#                        WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n#                        WITHIN_1KM_PRISCH,\n#                      dframe=train_data_nogeom, \n#                      bw=55,\n#                      kernel=\"adaptive\",\n#                      coords=coords_train)\n\n\n\n\n3.14 Predicting by using the test data\n\n3.14.1 Preparing the test data\n\n# test_data_nogeom &lt;- cbind(\n#   test_data, coords_test) %&gt;%\n#   st_drop_geometry()\n\n\n\n3.14.2 Predicting with the test data\nIn the code chunk below, predict.grf() of spatialML for predicting re-sale prices in the test data set (i.e. test_data_nogeom)\n\n# \n# gwRF_pred &lt;- predict.grf(gwRF_adaptive, \n#                            test_data_nogeom, \n#                            x.var.name=\"X\",\n#                            y.var.name=\"Y\", \n#                            local.w=1,\n#                            global.w=0)\n\n\n\n3.14.3 Creating DF\nNext, the code chunk below is used to convert the output from predict.grf() into a data.frame.\n\n# GRF_pred_df &lt;- as.data.frame(gwRF_pred)\n\nThen, cbind() is used to append fields in GRF_pred_df data.frame onto test_data.\n\n# test_data_pred &lt;- cbind(test_data, \n#                         GRF_pred_df)\n\n\n\n\n3.15 Visualising the predicted values\n\n# ggplot(data = test_data_pred,\n#        aes(x = GRF_pred,\n#            y = resale_price)) +\n#   geom_point()"
  },
  {
    "objectID": "In-Class_Ex08/in-class_ex08.html#proximity-analysis",
    "href": "In-Class_Ex08/in-class_ex08.html#proximity-analysis",
    "title": "In-class Ex08: Take-home Exercise 3 Kick Starter",
    "section": "4 Proximity Analysis",
    "text": "4 Proximity Analysis\nIn this section, you will learn how to count the number of geographic entities located within a defined distance from each HDB property.\nFor the purpose of this exercise, we are interested to count the number of preschools located with 350m of each resale HDB unit.\n\n4.1 Convert to an sf object\nBefore performing proximity analysis, it is important to ensure that:\n\nboth input data sets must be in sf objects, and\nthey must be in similar projected coordinates systems.\n\n\n\n\n\n\n\nNote\n\n\n\nIn the code chunk below,\n\nst_as_sf() is used to convert HDBresale tibble data.frame to sf object by using values from LONGITUDE and LATITUDE columns to form the geometry features.\nst_transform() is then used to transform the sf object into svy21 projected coordinates system.\nthe output sf object is called HDBresale_sf. It is in sf data.frame format.\n\n\n\n\n# Convert to sf object\nHDBresale_sf &lt;- HDBresale %&gt;%\n  st_as_sf(coords = c(\"LONGITUDE\", \"LATITUDE\"), crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\n# Inspect and verify the  \nglimpse(HDBresale_sf)\n\nRows: 458\nColumns: 12\n$ month               &lt;chr&gt; \"2025-10\", \"2025-10\", \"2025-10\", \"2025-10\", \"2025-…\n$ town                &lt;chr&gt; \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO …\n$ flat_type           &lt;chr&gt; \"4 ROOM\", \"4 ROOM\", \"4 ROOM\", \"4 ROOM\", \"4 ROOM\", …\n$ block               &lt;chr&gt; \"336\", \"415\", \"438\", \"301\", \"302\", \"327\", \"212\", \"…\n$ street_name         &lt;chr&gt; \"ANG MO KIO AVE 1\", \"ANG MO KIO AVE 10\", \"ANG MO K…\n$ storey_range        &lt;chr&gt; \"07 TO 09\", \"07 TO 09\", \"01 TO 03\", \"10 TO 12\", \"1…\n$ floor_area_sqm      &lt;dbl&gt; 91, 92, 92, 98, 98, 98, 81, 92, 99, 91, 99, 91, 90…\n$ flat_model          &lt;chr&gt; \"New Generation\", \"New Generation\", \"New Generatio…\n$ lease_commence_date &lt;dbl&gt; 1982, 1979, 1979, 1978, 1978, 1977, 1977, 1978, 19…\n$ remaining_lease     &lt;chr&gt; \"55 years 04 months\", \"52 years 11 months\", \"52 ye…\n$ resale_price        &lt;dbl&gt; 570000, 562000, 465000, 638000, 580000, 600000, 54…\n$ geometry            &lt;POINT [m]&gt; POINT (30055.03 38404.8), POINT (30263.23 38…\n\n\n\n# Check the CRS (Coordinate Reference System)\nst_crs(HDBresale_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n4.2 Locate, download and import Preschool Location data\nNext, we will locate and download Pre-Schools Location data from Singapore’s open data portal. There are both geojson and kml version. In this exercise, the kml version will be used.\nThen, code chunk below will be used to import the preschool location data into R environment by using st_read() of readr package.\n\npreschool = st_read(\n  \"/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/In-Class_Ex08/data/geospatial/PreSchoolsLocation.kml\") %&gt;%\n  st_transform(crs= 3414)\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/In-Class_Ex08/data/geospatial/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\n\nNote\n\n\n\nst-transform() of sf package is used to transform the preschool sf dataframe from wgs84 geographic coodinates system to svy21 projected coordinates system (i.e. EPSG: 3414)\n\n\n\n\n4.3 Counting number of preschools\nLastly, code chunk below will be used to count the number of pre-schools located within 350m of each HDB property.\n\nwithin_350m &lt;- st_is_within_distance(\n  HDBresale_sf, preschool, dist = 350)\n\nHDBresale_sf &lt;- HDBresale_sf %&gt;%\n  mutate(WITHIN_350M_PRISCHOOL = map_int(within_350m, length))\n\n\n\n\n\n\n\nNote\n\n\n\n\nst_is_within_distance() of sf package is used to determines whether two spatial objects (HDB property and preschool) are within 350m distance of each other. It returns a logical matrix (or a sparse list of indices if sparse = TRUE) indicating for each geometry in HDB property which geometries in preschool are within 350m distance.\nmutate() of dplyr is used to create a new field called WITHIN_350M_PRISCHOOL.\nmap_int() of purr package is used to the number of preschools found in the newly created WITHIN_350M_PRISCHOOL field.\n\n\n\n\n\n4.4 Computing shortest distance\nInstead of counting number of preschools located within 350m of each HDB resale property, code chunk below is used to compute the distance between the nearest preschool from each HDB resale property.\n\nHDBresale_sf &lt;- HDBresale_sf %&gt;%\n  mutate(\n    PROX_PRESCHOOL = as.numeric(\n      st_distance(geometry,\n                  preschool[st_nearest_feature(\n                    geometry, preschool), ], \n                  by_element = TRUE)\n      )\n    )\n\n\n\n\n\n\n\nNote\n\n\n\nThe proximity values computed are in metres because svy21 projected coordinates system is in metres."
  },
  {
    "objectID": "In-Class_Ex08/in-class_ex08.html#learning-outcomes",
    "href": "In-Class_Ex08/in-class_ex08.html#learning-outcomes",
    "title": "In-class Ex08: Take-home Exercise 3 Kick Starter",
    "section": "",
    "text": "By the end of this in-class exercise, students will master the skill of:\n\nprepare and geocode HDB resale price data for geospatial modelling; and\nperform proximity analysis to count the number of geographic entities located within a defined distance from each HDB property."
  }
]