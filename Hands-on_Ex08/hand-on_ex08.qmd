---
title: "Hands-on Ex08"
author: "TAN Chin Khoon"
date: "24 October 2025"
date-modified: "24 October 2025"
---

# 14 Geographically Weighted Predictive Models

This practical reproduces the complete workflow to build **geographically weighted predictive models** (GWR and Geographically Weighted Random Forest), alongside **non-spatial baselines** (Multiple Linear Regression and Random Forest). Follow each subsection in order.

## 14.1 Overview

Predictive modelling estimates an unknown outcome (e.g., resale price) from known predictors (e.g., floor area, amenities). When observations are georeferenced, relationships may vary across space due to infrastructure, socio-economic and environmental context. Geographically weighted models allow coefficients or model structure to change by location, capturing local effects that global models miss.

By the end, we will:

-   prepare train/test datasets with proper sampling,\
-   check collinearity,\
-   fit and save MLR, GWR, RF, and GW-RF models,\
-   generate out-of-sample predictions,\
-   compute RMSE and visualise prediction quality.

## 14.2 The Data

we will work with:

-   Aspatial table: HDB resale transactions (CSV â†’ converted to sf during preprocessing).\
-   Geospatial layers: URA 2014 Master Plan Planning Subzones (polygon sf).\
-   Locational factors with coordinates: eldercare, hawker centres, parks, supermarkets,\
-   MRT/LRT stations, bus stops, kindergartens, childcare (shapefile/GeoJSON).\
-   Locational factors without coordinates: CBD centroid (derived), shopping malls, primary school rankings (CSV/other).

## 14.3 Installing and Loading R Packages

```{r}

# Create/load all required packages in one shot
pacman::p_load(
  sf,            # spatial vector data (simple features)
  spdep,         # spatial dependence utilities (used by some workflows)
  GWmodel,       # Geographically Weighted Regression
  SpatialML,     # Geographically Weighted Random Forest (grf)
  tmap,          # cartography (not central here but part of the stack)
  rsample,       # train/test splitting (tidymodels)
  Metrics,       # RMSE and other metrics
  tidyverse      # dplyr, ggplot2, readr, purrr, etc.
)

```

## 14.4 Preparing Data

### 14.4.1 Reading data file to rds

```{r}

# Read the prepared modelling dataset (sf object)
mdata <- readr::read_rds("/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/rawdata/mdata.rds")

```

### 14.4.2 Data Sampling

The entire data are split into training and test data sets with 65% and 35% respectively by using initial_split() of rsample package. rsample is one of the package of tigymodels.

```{r}

# Set seed to make the split reproducible
set.seed(1234)

# Split into 65% training and 35% testing using rsample
resale_split <- rsample::initial_split(mdata, prop = 6.5/10)

# Extract the two partitions
train_data <- rsample::training(resale_split)
test_data  <- rsample::testing(resale_split)

```

```{r}

# Persist the splits for reuse
readr::write_rds(train_data, "/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/train_data.rds")
readr::write_rds(test_data,  "/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/test_data.rds")

```

## 14.5 Computing Correlation Matrix

Before loading the predictors into a predictive model, it is always a good practice to use correlation matrix to examine if there is sign of multicollinearity.

```{r,fig.width=10,fig.height=8}

# Remove geometry to compute numeric correlations only
mdata_nogeo <- mdata %>% sf::st_drop_geometry()

# Draw an upper-triangle correlation matrix with numbers
corrplot::corrplot(
  cor(mdata_nogeo[, 2:17]), # adjust columns to our numeric predictors
  diag   = FALSE,           # do not draw the diagonal
  order  = "AOE",           # sort for visual clarity
  tl.pos = "td",            # variable labels on top diagonal
  tl.cex = 0.5,             # smaller labels
  method = "number",        # show correlation values
  type   = "upper"          # only the upper triangle
)

```

::: callout-note

If all absolute correlations are below \~0.8, severe multicollinearity is unlikely.

:::

## 14.6 Retrieving the Stored Data

```{r}
# Reload saved splits when resuming work
train_data <- readr::read_rds("/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/train_data.rds")
test_data  <- readr::read_rds("/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/test_data.rds")

```

## 14.7 Building a Non-Spatial Multiple Linear Regression

```{r}

# Fit a global (non-spatial) linear regression as a baseline
price_mlr <- lm(
  resale_price ~ floor_area_sqm +
    storey_order + remaining_lease_mths +
    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
    PROX_MRT + PROX_PARK + PROX_MALL +
    PROX_SUPERMARKET +
    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +
    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,
  data = train_data
)

# Inspect coefficients and diagnostics
summary(price_mlr)

```

```{r}

# Save the fitted model
readr::write_rds(price_mlr, "/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/price_mlr.rds")

```

## 14.8 GWR Predictive Method

In this section, we will learn how to calibrate a model to predict HDB resale price by using geographically weighted regression method of GWmodel package.

### 14.8.1 Computing adaptive bandwidth (CV)

```{r}

# Determine optimal adaptive bandwidth (in neighbors) using CV
bw_adaptive <- GWmodel::bw.gwr(
  formula = resale_price ~ floor_area_sqm +
    storey_order + remaining_lease_mths +
    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
    PROX_MRT + PROX_PARK + PROX_MALL +
    PROX_SUPERMARKET +
    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +
    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,
  data     = train_data,   # training sf
  approach = "CV",         # cross-validation
  kernel   = "gaussian",   # Gaussian kernel
  adaptive = TRUE,         # adaptive neighbor count
  longlat  = FALSE         # data are in projected meters
)

# Persist the chosen bandwidth (e.g., result may be 40 neighbors)
readr::write_rds(bw_adaptive, "/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/bw_adaptive.rds")

```

### 14.8.2 Constructing the adaptive bandwidth GWR model

First, let us call the save bandwidth by using the code chunk below.

```{r}

# Reload bandwidth when needed
bw_adaptive <- readr::read_rds("/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/bw_adaptive.rds")

```

Now, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and Gaussian kernel as shown in the code chunk below.

```{r}

# Calibrate GWR using the selected adaptive bandwidth
gwr_adaptive <- GWmodel::gwr.basic(
  formula = resale_price ~ floor_area_sqm +
    storey_order + remaining_lease_mths +
    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
    PROX_MRT + PROX_PARK + PROX_MALL +
    PROX_SUPERMARKET +
    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +
    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,
  data     = train_data,    # training sf
  bw       = bw_adaptive,   # adaptive neighbors (numeric)
  kernel   = "gaussian",    # kernel shape
  adaptive = TRUE,          # use adaptive bandwidth
  longlat  = FALSE          # projected coordinates
)

# Save the fitted GWR object
readr::write_rds(gwr_adaptive, "/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwr_adaptive.rds")

```

:::{.callout.tip}

Now, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and Gaussian kernel as shown in the code chunk below.

:::

### 14.8.3 Retrieve GWR output object

The code chunk below will be used to retrieve the save gwr model object.

```{r}

# Reload GWR model when resuming work
gwr_adaptive <- readr::read_rds("/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwr_adaptive.rds")

```

The code below can be used to display the model output.

```{r}

# Printing the object shows the model summary header and timings
gwr_adaptive

```

### 14.8.4 Computing adaptive bandwidth for the test data


```{r}

# Some workflows also derive a CV bandwidth using the test sf
gwr_bw_test_adaptive <- GWmodel::bw.gwr(
  formula = resale_price ~ floor_area_sqm +
    storey_order + remaining_lease_mths +
    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
    PROX_MRT + PROX_PARK + PROX_MALL +
    PROX_SUPERMARKET +
    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +
    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,
  data     = test_data,
  approach = "CV",
  kernel   = "gaussian",
  adaptive = TRUE,
  longlat  = FALSE
)

# Save the test-set bandwidth too (for reference)
readr::write_rds(gwr_bw_test_adaptive, "/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwr_bw_test_adaptive.rds")

```

### 14.8.5 Computing predicted values for the test data

```{r}

# gwr_pred <- gwr.predict(
#   formula = resale_price ~ floor_area_sqm + 
#     storey_order + remaining_lease_mths + 
#     PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + 
#     PROX_MRT + PROX_PARK + PROX_MALL + 
#     PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
#     WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + 
#     WITHIN_1KM_PRISCH, 
#   data=train_data, 
#   predictdata = test_data, 
#   bw=40, 
#   kernel = 'gaussian', 
#   adaptive=TRUE, 
#   longlat = FALSE)
# 
# # Save predictions (list-like object)
# readr::write_rds(gwr_pred, "/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwr_pred.rds")

```


### 14.9 Calibrating Random Forest Model (global / non-spatial)

In this section, we will learn how to calibrate a model to predict HDB resale price by using random forest function of ranger package.

### 14.9.1 Preparing coordinates data

The code chunk below extract the x,y coordinates of the full, training and test data sets.

```{r}

# Extract XY matrices for convenience (sf â†’ numeric matrix with X,Y)
coords       <- sf::st_coordinates(mdata)
coords_train <- sf::st_coordinates(train_data)
coords_test  <- sf::st_coordinates(test_data)

```

Before continue, we write all the output into rds for future used.

```{r}

# Save coordinates used later by GW-RF
readr::write_rds(coords_train, "/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/coords_train.rds")
readr::write_rds(coords_test,  "/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/coords_test.rds")

```

### 14.9.2 Dropping geometry field

First, we will drop geometry column of the sf data.frame by using `st_drop_geometry()` of sf package.

```{r}

# Random Forest from ranger expects a data.frame without geometry
train_data_nogeom <- train_data %>% sf::st_drop_geometry()
test_data_nogeom  <- test_data  %>% sf::st_drop_geometry()

```

### 14.9.3 Calibrating a non-spatial Random Forest

```{r}

# Set seed for reproducibility
set.seed(1234)

# Fit a global RF as another baseline model
rf <- ranger::ranger(
  formula = resale_price ~ floor_area_sqm +
    storey_order + remaining_lease_mths +
    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
    PROX_MRT + PROX_PARK + PROX_MALL +
    PROX_SUPERMARKET +
    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +
    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,
  data = train_data_nogeom
)

rf 

```

```{r}

# Save the RF model
readr::write_rds(rf, "/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/rf.rds")

```

## 14.10 Calibrating Geographically Weighted Random Forest (GW-RF)

In this section, we will learn how to calibrate a model to predict HDB resale price by using `grf()` of SpatialML package.

### 14.10.1 Calibrating using training data

```{r}

# Reuse coordinates and no-geometry training input
set.seed(1234)

gwRF_adaptive <- SpatialML::grf(
  formula = resale_price ~ floor_area_sqm +
    storey_order + remaining_lease_mths +
    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
    PROX_MRT + PROX_PARK + PROX_MALL +
    PROX_SUPERMARKET +
    WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE +
    WITHIN_350M_BUS + WITHIN_1KM_PRISCH,
  dframe = train_data_nogeom, # data.frame without geometry
  bw     = 40,                # neighbor size (consistent with earlier choice)
  kernel = "adaptive",        # adaptive kernel for local forests
  coords = coords_train       # matrix of X,Y for training rows
)

# Persist fitted GW-RF
readr::write_rds(gwRF_adaptive, "/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwRF_adaptive.rds")

```

:::{.callout-tip}

This is a computational intensity and time consuming process. It is wiser to save the output as an rds file for future used without having to re-run the process again.

:::

The code chunk below can be used to retrieve the save model in future.

```{r}

# (Later) reload if needed
gwRF_adaptive <- readr::read_rds("/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/gwRF_adaptive.rds")

```

### 14.10.2 Predicting by using test data

#### 14.10.2.1 Preparing the test data

The code chunk below will be used to combine the test data with its corresponding coordinates data.

```{r}

# Combine the test attributes with their coordinates for prediction
test_data_nogeom <- cbind(test_data, coords_test) %>%
  sf::st_drop_geometry()     # drop geometry to keep plain columns

```

#### 14.10.2.2 Predicting with test data

```{r}

# Generate local predictions at test locations
gwRF_pred <- SpatialML::predict.grf(
  gwRF_adaptive,     # trained GW-RF model
  test_data_nogeom,  # test attributes + X,Y columns
  x.var.name = "X",  # column name for X coordinate
  y.var.name = "Y",  # column name for Y coordinate
  local.w    = 1,    # weight for local component
  global.w   = 0     # set to 0 to use purely local predictions
)

# Save the prediction vector
GRF_pred <- readr::write_rds(gwRF_pred, "/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/GRF_pred.rds")

```

#### 14.10.2.3 Converting the predicting output into a data frame

The output of the `predict.grf()` is a vector of predicted values. It is wiser to convert it into a data frame for further visualisation and analysis.

```{r}

# Reload predictions when needed and coerce to data.frame
GRF_pred     <- readr::read_rds("/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/GRF_pred.rds")
GRF_pred_df  <- as.data.frame(GRF_pred)  # single column with predicted values

```

In the code chunk below, `cbind()` is used to append the predicted values onto test_datathe

```{r}
# Attach predictions to the test data and retain only needed columns
test_data_p <- cbind(test_data, GRF_pred_df) %>%
  dplyr::select(resale_price, GRF_pred)   # rename matches grf() output

```


```{r}

# Save the paired actual vs predicted for later evaluation/plots
readr::write_rds(test_data_p, "/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/model/test_data_p.rds")

```

### 14.10.3 Calculating Root Mean Square Error

The root mean square error (RMSE) allows us to measure how far predicted values are from observed values in a regression analysis. In the code chunk below, `rmse()` of Metrics package is used to compute the RMSE.

```{r}

# Compute RMSE between observed and GW-RF predicted prices
Metrics::rmse(
  test_data_p$resale_price,  # actual values
  test_data_p$GRF_pred       # predicted values
)
# Example output in the reference workflow: 28160.87

```

### 14.10.4 Visualising the predicted values

Alternatively, scatterplot can be used to visualise the actual resale price and the predicted resale price by using the code chunk below.

```{r}

# Scatter plot of Predicted (x) vs Actual (y)
ggplot2::ggplot(
  data = test_data_p,                           # data with both columns
  ggplot2::aes(x = GRF_pred, y = resale_price)  # map axes
) +
  ggplot2::geom_point()                         # draw points

```

:::{.callout-note}

A better predictive model should have the scatter point close to the diagonal line. The scatter plot can be also used to detect if any outliers in the model.

:::

