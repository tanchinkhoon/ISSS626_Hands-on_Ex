---
title: "In-class Ex08: Take-home Exercise 3 Kick Starter"
author: "TAN Chin Khoon"
date: "25 October 2025"
number-sections: true
date-modified: "25 October 2025"
---

## Installing and Loading R Packages

```{r}

# Create/load all required packages in one shot
pacman::p_load(httr,tidyverse, sf, tmap,jsonlite, progress, spdep,GWmodel, SpatialML, rsample, Metrics, knitr, kableExtra, spatialRF, randomForestExplainer)

```

## Geocoding for Geometric

### Importing data 

```{r}

# Downloading the raw data from data.gov.sg. 
# Data source: Resale flat prices based on registration date from Jan-2017 onwards

# load full table once
HDBresale_raw <- read_csv("/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/In-Class_Ex08/data/rawdata/ResaleflatpricesbasedonregistrationdatefromJan2017onwards.csv")

# Inspect the loading data
glimpse(HDBresale_raw)


```

### Reducing and filtering the dataset

```{r}

# find the most recent month that has 4 ROOM
month_choice <- HDBresale_raw %>%
  filter(flat_type == "4 ROOM") %>%
  count(month, name = "n") %>%
  filter(n > 0) %>%
  arrange(desc(month)) %>%
  slice(1) %>%
  pull(month)

#Inspect the output
month_choice

```


```{r}

# filter to that month
HDBresale <- HDBresale_raw %>%
  filter(flat_type == "4 ROOM", month == month_choice)

nrow(HDBresale)   # should be greater than zero

```

### Geodata pre-processing and cleaning

#### Address normalisation matters

```{r}

# street name fix
HDBresale$street_name <- gsub("ST\\.", "SAINT", HDBresale$street_name)

```

:::{.callout-note}

The `gsub()` function performs a global substitution (find and replace) in text.

:::

#### Function to convert address to coordinates (LATITUDE and LONGITUDEY)

Below is the code chunk used to build a function that will convert address to coordinates

- The function sends a live API request to OneMap Singapore to obtain geographic coordinates (latitude and longitude) for each given HDB address.  
- Explicit UTF-8 encoding is included to eliminate the “No encoding supplied” warning and ensure correct text handling for special characters.  
- Always returns a tibble with columns LATITUDE and LONGITUDE, even when no match is found, to prevent pipeline breaks during unnesting.  
- Only retrieves the first match from the API (pageNum = "1"), which increases speed but may ignore alternative results for ambiguous addresses.  
- Requires street name standardisation (e.g., “ST.” changed to “SAINT”) before calling the function to improve matching accuracy.  
- Coordinates returned by OneMap are based on WGS84 (EPSG 4326), so conversion to SVY21 (EPSG 3414) is needed for metric-based distance analysis.  
- Each function call makes a separate HTTP request; for large datasets, use progress tracking, pauses (Sys.sleep), and checkpoint saving to avoid rate limits.  
- Wrapping the function with tryCatch or purrr::safely prevents process interruption if a request fails or the API returns an unexpected response.  
- A test call such as geocode("101","JURONG EAST STREET 13") is recommended before batch processing to confirm valid numeric coordinates are returned.  
- For reproducibility and efficiency, store results (block, street, LATITUDE, LONGITUDE) in a CSV file to reuse in future runs without re-querying the API.

```{r}

# professor geocode
# Reference: https://www.onemap.gov.sg/apidocs/coordinate


geocode <- function(block, streetname) {                          # define a function that takes block and street name and returns coordinates
  base_url <- "https://onemap.gov.sg/api/common/elastic/search"   # store the OneMap search endpoint as a constant for reuse
  address  <- paste(block, streetname, sep = " ")                 # build a single query string such as 118 ANG MO KIO AVENUE 4
  query <- list(                                                  # create a named list of query parameters for the HTTP request
    searchVal     = address,                                      # the address string to search
    returnGeom    = "Y",                                          # ask the service to return geometry fields
    getAddrDetails= "N",                                          # do not request extra address fields to keep reply small
    pageNum       = "1"                                           # take the first page only for a single best match
  )                                                               # end of query parameter list
  res     <- httr::GET(base_url, query = query)                   # send a GET request to OneMap with the query parameters
  restext <- httr::content(res, as = "text", encoding = "UTF-8")  # read the response body as text with UTF8 to avoid encoding warnings
  out     <- jsonlite::fromJSON(restext)                          # parse the JSON text into an R list or data frame

  if (length(out$results) == 0) {                                 # if the service returns no match for this address
    tibble(LATITUDE = NA_real_, LONGITUDE = NA_real_)             # return a tibble with missing numeric coordinates
  } else {                                                        # otherwise when there is at least one match
    tibble(                                                              
      LATITUDE  = as.numeric(out$results$LATITUDE[1]),            # take the first result latitude and coerce to numeric
      LONGITUDE = as.numeric(out$results$LONGITUDE[1])            # take the first result longitude and coerce to numeric
    )                                                             # end tibble creation
  }                                                               # end branch
}                                                                 # end function

```

#### Perform minimal unit/smoke test

```{r}

# Test with a single known HDB address
geocode("101", "JURONG EAST STREET 13")

```

### Merge the LATITUDE and LONGITUDE to dataset

```{r}

# create LATITUDE and LONGITUDE and merge into the table
HDBresale <- HDBresale %>%
  mutate(geo = purrr::map2(block, street_name, geocode)) %>%
  tidyr::unnest(geo)

### 
glimpse(HDBresale)   # now includes LATITUDE and LONGITUDE

```

### Convert to sf object

```{r}

# Convert to sf object
HDBresale_sf <- HDBresale %>%
  st_as_sf(coords = c("LONGITUDE", "LATITUDE"), crs = 4326) %>%
  st_transform(crs = 3414)

# Inspect and verify the  
glimpse(HDBresale_sf)
```
```{r}

# Check the CRS (Coordinate Reference System)
st_crs(HDBresale_sf)

```


## Supplement to Hands-on Exercise 8

### Data import

```{r}

# Read the prepared modelling dataset (sf object)
mdata <- readr::read_rds("/Users/cktan/Desktop/SMU/01_Geospatial Analytics (ISSS626)/Hands-on_Ex/Hands-on_Ex08/data/rawdata/mdata.rds")

```


### Data sampling

Calibrating predictive models are computational intensive, especially random forest method is used. For quick prototyping, a 10% sample will be selected at random from the data by using the code chunk below.

```{r}

set.seed(1234)
HDB_sample <- mdata %>%
  sample_n(1500)

```


### Checking of overlapping point

:::{.callout-warning}

When using GWmodel to calibrate explanatory or predictive models, it is very important to ensure that there are no overlapping point features

:::

The code chunk below is used to check if there are overlapping point features.

```{r}

overlapping_points <- HDB_sample %>%
  mutate(overlap = lengths(st_equals(., .)) > 1)

```


### Spatial jittler

In the code code chunk below, `st_jitter()` of **sf** package is used to move the point features by 5 meters to avoid overlapping point features.

```{r}

HDB_sample <- HDB_sample %>%
  st_jitter(amount = 5)

```


### Data Sampling

The entire data are split into training and test data sets with 65% and 35% respectively by using initial_split() of rsample package. rsample is one of the package of tigymodels.

```{r}

set.seed(1234)
resale_split <- initial_split(HDB_sample, 
                              prop = 6.67/10,)
train_data <- training(resale_split)
test_data <- testing(resale_split)

```


### Multicollinearity check

In order to avoid multicollineariy. In the code chunk below, `ggcorrmat()` of **ggstatsplot** is used to plot a correlation matrix to check if there are pairs of highly correlated independent variables.

```{r,fig.width=12,fig.height=10}

mdata_nogeo <- mdata %>%
  st_drop_geometry()
ggstatsplot::ggcorrmat(mdata_nogeo[, 2:17])

```


### Building a non-spatial multiple linear regression

```{r}

price_mlr <- lm(resale_price ~ floor_area_sqm +
                  storey_order + remaining_lease_mths +
                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
                  PROX_MRT + PROX_PARK + PROX_MALL + 
                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                  WITHIN_1KM_PRISCH,
                data=train_data)
olsrr::ols_regress(price_mlr)

```


### Multicollinearity check with VIF


```{r}

vif <- performance::check_collinearity(price_mlr)
kable(vif, 
      caption = "Variance Inflation Factor (VIF) Results") %>%
  kable_styling(font_size = 18) 

```


```{r}

plot(vif) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

### Predictive Modelling with gwr

```{r}

bw_adaptive <- bw.gwr(resale_price ~ floor_area_sqm +
                  storey_order + remaining_lease_mths +
                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
                  PROX_MRT + PROX_PARK + PROX_MALL + 
                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                  WITHIN_1KM_PRISCH,
                  data=train_data,
                  approach="CV",
                  kernel="gaussian",
                  adaptive=TRUE,
                  longlat=FALSE)


```

```{r}

bw_adaptive

```


### Model calibration


```{r}

gwr_adaptive <- gwr.basic(formula = resale_price ~
                            floor_area_sqm + storey_order +
                            remaining_lease_mths + PROX_CBD + 
                            PROX_ELDERLYCARE + PROX_HAWKER +
                            PROX_MRT + PROX_PARK + PROX_MALL + 
                            PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
                            WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                            WITHIN_1KM_PRISCH,
                          data=train_data,
                          bw=bw_adaptive, 
                          kernel = 'gaussian', 
                          adaptive=TRUE,
                          longlat = FALSE)


```


### Predictive Modelling with MLR

#### Predictive Modelling with MLR

##### Test data bw

```{r}

gwr_pred <- gwr.predict(formula = resale_price ~
                          floor_area_sqm + storey_order +
                          remaining_lease_mths + PROX_CBD + 
                          PROX_ELDERLYCARE + PROX_HAWKER + 
                          PROX_MRT + PROX_PARK + PROX_MALL + 
                          PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
                          WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + 
                          WITHIN_1KM_PRISCH, 
                        data=train_data, 
                        predictdata = test_data, 
                        bw=bw_adaptive, 
                        kernel = 'gaussian', 
                        adaptive=TRUE, 
                        longlat = FALSE)

```

##### Predicting

```{r}

gwr_pred <- gwr.predict(formula = resale_price ~
                          floor_area_sqm + storey_order +
                          remaining_lease_mths + PROX_CBD + 
                          PROX_ELDERLYCARE + PROX_HAWKER + 
                          PROX_MRT + PROX_PARK + PROX_MALL + 
                          PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
                          WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + 
                          WITHIN_1KM_PRISCH, 
                        data=train_data, 
                        predictdata = test_data, 
                        bw=bw_adaptive, 
                        kernel = 'gaussian', 
                        adaptive=TRUE, 
                        longlat = FALSE)

```



### Predictive Modelling: RF method

#### Data Preparation

Firstly, code chunk below is used to extract the coordinates of training and test data sets

```{r}

coords <- st_coordinates(HDB_sample)
coords_train <- st_coordinates(train_data)
coords_test <- st_coordinates(test_data)

```


#### Calibrating RF model

```{r}

# set.seed(1234)
# rf <- ranger(resale_price ~ floor_area_sqm + storey_order + 
#                remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + 
#                PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + 
#                PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
#                WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + 
#                WITHIN_1KM_PRISCH,
#              data=train_nogeom)

```

#### Model output

```{r}

rf

```

### Predictive Modelling: SpatialML method

#### Determining bandwidth

```{r}

# set.seed(1234)
# gwRF_bw <- grf.bw(formula = resale_price ~ floor_area_sqm + 
#                        storey_order + remaining_lease_mths + 
#                        PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + 
#                        PROX_MRT + PROX_PARK + PROX_MALL + 
#                        PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
#                        WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
#                        WITHIN_1KM_PRISCH,
#                      dataset=train_data, 
#                      kernel="adaptive",
#                      coords=coords_train)

```

#### Calibrating with grf

```{r}

# set.seed(1234)
# gwRF_adaptive <- grf(formula = resale_price ~ floor_area_sqm + 
#                        storey_order + remaining_lease_mths + 
#                        PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + 
#                        PROX_MRT + PROX_PARK + PROX_MALL + 
#                        PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
#                        WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
#                        WITHIN_1KM_PRISCH,
#                      dframe=train_data_nogeom, 
#                      bw=55,
#                      kernel="adaptive",
#                      coords=coords_train)

```


### Predicting by using the test data

#### Preparing the test data

```{r}

# test_data_nogeom <- cbind(
#   test_data, coords_test) %>%
#   st_drop_geometry()

```


#### Predicting with the test data

In the code chunk below, `predict.grf()` of **spatialML** for predicting re-sale prices in the **test data** set (i.e. test_data_nogeom)

```{r}
# 
# gwRF_pred <- predict.grf(gwRF_adaptive, 
#                            test_data_nogeom, 
#                            x.var.name="X",
#                            y.var.name="Y", 
#                            local.w=1,
#                            global.w=0)

```


#### Creating DF

Next, the code chunk below is used to convert the output from `predict.grf()` into a data.frame.

```{r}

# GRF_pred_df <- as.data.frame(gwRF_pred)

```

Then, `cbind()` is used to append fields in GRF_pred_df data.frame onto test_data.

```{r}

# test_data_pred <- cbind(test_data, 
#                         GRF_pred_df)

```

### Visualising the predicted values

```{r}

# ggplot(data = test_data_pred,
#        aes(x = GRF_pred,
#            y = resale_price)) +
#   geom_point()

```






